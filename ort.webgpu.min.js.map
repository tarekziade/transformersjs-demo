{
  "version": 3,
  "sources": ["../../../common/lib/backend-impl.ts", "../../../common/lib/backend.ts", "../../../common/lib/version.ts", "../../../common/lib/env-impl.ts", "../../../common/lib/env.ts", "../../../common/lib/tensor-conversion-impl.ts", "../../../common/lib/tensor-factory-impl.ts", "../../../common/lib/tensor-impl-type-mapping.ts", "../../../common/lib/tensor-utils-impl.ts", "../../../common/lib/tensor-impl.ts", "../../../common/lib/tensor.ts", "../../../common/lib/inference-session-impl.ts", "../../../common/lib/inference-session.ts", "../../../common/lib/onnx-value.ts", "../../../common/lib/training-session-impl.ts", "../../../common/lib/training-session.ts", "../../../common/lib/index.ts", "nodejs-ignore:fs", "nodejs-ignore:path", "../../lib/wasm/binding/ort-wasm-simd.jsep.js", "nodejs-ignore:worker_threads", "nodejs-ignore:perf_hooks", "nodejs-ignore:os", "../../lib/wasm/binding/ort-wasm-simd-threaded.jsep.js", "../../lib/wasm/binding/ort-wasm-threaded.worker.js", "../../lib/wasm/wasm-factory.ts", "../../lib/wasm/wasm-utils.ts", "../../lib/wasm/run-options.ts", "../../lib/wasm/session-options.ts", "../../lib/wasm/wasm-common.ts", "../../lib/wasm/jsep/log.ts", "../../lib/wasm/jsep/tensor-view.ts", "../../lib/wasm/jsep/webgpu/types.ts", "../../lib/wasm/jsep/webgpu/gpu-data-manager.ts", "../../lib/wasm/jsep/webgpu/attribute-with-cache-key.ts", "../../lib/wasm/jsep/util.ts", "../../lib/wasm/jsep/webgpu/ops/common.ts", "../../lib/wasm/jsep/webgpu/ops/transpose.ts", "../../lib/wasm/jsep/webgpu/ops/reduce-shared.ts", "../../lib/wasm/jsep/webgpu/ops/reduce.ts", "../../lib/wasm/jsep/webgpu/ops/argminmax.ts", "../../lib/wasm/jsep/webgpu/ops/attention.ts", "../../lib/wasm/jsep/webgpu/ops/batch-norm.ts", "../../lib/wasm/jsep/webgpu/ops/bias-add.ts", "../../lib/wasm/jsep/webgpu/ops/unary-op.ts", "../../lib/wasm/jsep/webgpu/ops/bias-split-gelu.ts", "../../lib/wasm/jsep/webgpu/ops/binary-op.ts", "../../lib/wasm/jsep/webgpu/ops/concat.ts", "../../lib/wasm/jsep/webgpu/ops/fuse-utils.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/activation_util.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_util.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/matmul_packed_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv2d_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-grouped.ts", "../../lib/wasm/jsep/webgpu/ops/conv.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-transpose.ts", "../../lib/wasm/jsep/webgpu/ops/einsum.ts", "../../lib/wasm/jsep/webgpu/ops/expand.ts", "../../lib/wasm/jsep/webgpu/ops/gather.ts", "../../lib/wasm/jsep/webgpu/ops/gather-elements.ts", "../../lib/wasm/jsep/webgpu/ops/gemm.ts", "../../lib/wasm/jsep/webgpu/ops/instance-norm.ts", "../../lib/wasm/jsep/webgpu/ops/layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/matmul.ts", "../../lib/wasm/jsep/webgpu/ops/multi-head-attentiion.ts", "../../lib/wasm/jsep/webgpu/ops/pad.ts", "../../lib/wasm/jsep/webgpu/ops/pool.ts", "../../lib/wasm/jsep/webgpu/ops/range.ts", "../../lib/wasm/jsep/webgpu/ops/resize.ts", "../../lib/wasm/jsep/webgpu/ops/skip-layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/slice.ts", "../../lib/wasm/jsep/webgpu/ops/softmax.ts", "../../lib/wasm/jsep/webgpu/ops/split.ts", "../../lib/wasm/jsep/webgpu/ops/tile.ts", "../../lib/wasm/jsep/webgpu/ops/where.ts", "../../lib/wasm/jsep/webgpu/op-resolve-rules.ts", "../../lib/wasm/jsep/webgpu/program-manager.ts", "../../lib/wasm/jsep/backend-webgpu.ts", "../../lib/wasm/jsep/init.ts", "../../lib/wasm/wasm-core-impl.ts", "proxy-worker:./proxy-worker/main", "../../lib/wasm/proxy-wrapper.ts", "../../lib/wasm/session-handler-inference.ts", "../../lib/backend-wasm.ts", "../../lib/backend-wasm-inference.ts", "../../lib/index.ts", "../../lib/version.ts"],
  "sourcesContent": ["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, {backend, priority});\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @ignore\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends.get(backendName);\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init();\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {TrainingSession} from './training-session.js';\n\n/**\n * @ignore\n */\nexport declare namespace SessionHandler {\n  type FeedsType = {[name: string]: OnnxValue};\n  type FetchesType = {[name: string]: OnnxValue | null};\n  type ReturnType = {[name: string]: OnnxValue};\n}\n\n/**\n * Represents shared SessionHandler functionality\n *\n * @ignore\n */\ninterface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @ignore\n */\nexport interface InferenceSessionHandler extends SessionHandler {\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a handler instance of a training inference session.\n *\n * @ignore\n */\nexport interface TrainingSessionHandler extends SessionHandler {\n  runTrainStep(\n      feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n\n  getParametersSize(trainableOnly: boolean): Promise<number>;\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n  getContiguousParameters(trainableOnly: boolean): Promise<OnnxValue>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @ignore\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(): Promise<void>;\n\n  createInferenceSessionHandler(uriOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n\n  createTrainingSessionHandler?\n      (checkpointStateUriOrBuffer: TrainingSession.URIorBuffer, trainModelUriOrBuffer: TrainingSession.URIorBuffer,\n       evalModelUriOrBuffer: TrainingSession.URIorBuffer, optimizerModelUriOrBuffer: TrainingSession.URIorBuffer,\n       options: InferenceSession.SessionOptions): Promise<TrainingSessionHandler>;\n}\n\nexport {registerBackend} from './backend-impl.js';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env.js';\nimport {version} from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: {common: version},\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', {enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env as envImpl} from './env-impl.js';\n\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    /* eslint-disable @typescript-eslint/naming-convention */\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-training-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n    /* eslint-enable @typescript-eslint/naming-convention */\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     */\n    profilingMode?: 'off'|'default';\n    /**\n     * Get the device for WebGPU.\n     *\n     * When use with TypeScript, the type of this property is `GPUDevice` defined in \"@webgpu/types\".\n     * Use `const device = env.webgpu.device as GPUDevice;` in TypeScript to access this property with correct type.\n     *\n     * see comments on {@link GpuBufferType} for more details about why not use types defined in \"@webgpu/types\".\n     */\n    readonly device: unknown;\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {Tensor} from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d');\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n        const A = aTensorPointer === -1 ?\n            255 :\n            ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    return canvas.toDataURL();\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext = document.createElement('canvas').getContext('2d');\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n          (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n        throw new Error('Tensor format doesn\\'t match input tensor dims');\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (let i = 0; i < height * width;\n         rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n      image.data[aImagePointer] = aTensorPointer === -1 ?\n          255 :\n          ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n    }\n\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OptionsDimensions, OptionsFormat, OptionsNormalizationParameters, OptionsTensorFormat, OptionsTensorLayout, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\ninterface BufferToTensorOptions extends OptionsDimensions, OptionsTensorLayout, OptionsNormalizationParameters,\n                                        OptionsFormat, OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray|undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const {height, width} = options;\n\n  const norm = options.norm ?? {mean: 255, bias: 0};\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof (norm.mean) === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof (norm.bias) === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n      options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n  let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (let i = 0; i < stride;\n       i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n                                                 new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async(\n    image: ImageData|HTMLImageElement|ImageBitmap|string,\n    options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n    TensorFromUrlOptions): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray|undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = document.createElement('canvas');\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = tempCanvas.getContext('2d');\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n    texture: TensorInterface.TextureType, options: TensorFromTextureOptions<T>): Tensor => {\n  const {width, height, download, dispose} = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({location: 'texture', type: 'float32', texture, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorInterface.GpuBufferType, options: TensorFromGpuBufferOptions<T>): Tensor => {\n  const {dataType, dims, download, dispose} = options;\n  return new Tensor({location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor =>\n    new Tensor({location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\nexport type SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['float16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt polyfill\n// if available.\nlet isBigIntChecked = false;\nexport const checkBigInt = () => {\n  if (!isBigIntChecked) {\n    isBigIntChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\n    const isBigUint64ArrayAvailable =\n        typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TextureConstructorParameters} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorToDataURL, tensorToImageData} from './tensor-conversion-impl.js';\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {tensorFromGpuBuffer, tensorFromImage, tensorFromPinnedBuffer, tensorFromTexture} from './tensor-factory-impl.js';\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions, TextureConstructorParameters} from './tensor-factory.js';\nimport {checkBigInt, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP, NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, SupportedTypedArray, SupportedTypedArrayConstructors} from './tensor-impl-type-mapping.js';\nimport {calculateSize, tensorReshape} from './tensor-utils-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n      type: TensorType, data: TensorDataType|readonly string[]|readonly number[]|readonly boolean[],\n      dims?: readonly number[]);\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(data: TensorDataType|readonly string[]|readonly boolean[], dims?: readonly number[]);\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n      arg0: TensorType|TensorDataType|readonly string[]|readonly boolean[]|CpuPinnedConstructorParameters|\n      TextureConstructorParameters|GpuBufferConstructorParameters,\n      arg1?: TensorDataType|readonly number[]|readonly string[]|readonly boolean[], arg2?: readonly number[]) {\n    // perform one-time check for BigInt support\n    checkBigInt();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if ((type !== 'float32' && type !== 'float16' && type !== 'int32' && type !== 'int64' && type !== 'uint32' &&\n               type !== 'bool')) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1|typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError('A string tensor\\'s data must be a string array.');\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if (arg0 === 'float16') {\n              // Throw error here because when user try to use number array as data,\n              // e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              // Uint16Array.from(arg1) which generates wrong data.\n              throw new TypeError(\n                  'Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.');\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else {\n          // get tensor type from TypedArray\n          const mappedType =\n              NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError('A tensor\\'s dims must be a number array');\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n      image: ImageData|HTMLImageElement|ImageBitmap|string,\n      options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n      TensorFromUrlOptions): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n      texture: TensorTextureType, options: TensorFromTextureOptions<T>): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n      gpuBuffer: TensorGpuBufferType, options: TensorFromGpuBufferOptions<T>): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n      type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n          'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.');\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorFactory} from './tensor-factory.js';\nimport {Tensor as TensorImpl} from './tensor-impl.js';\nimport {TypedTensorUtils} from './tensor-utils.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  /**\n   * type alias for WebGPU buffer\n   *\n   * The reason why we don't use type \"GPUBuffer\" defined in webgpu.d.ts from @webgpu/types is because \"@webgpu/types\"\n   * requires \"@types/dom-webcodecs\" as peer dependency when using TypeScript < v5.1 and its version need to be chosen\n   * carefully according to the TypeScript version being used. This means so far there is not a way to keep every\n   * TypeScript version happy. It turns out that we will easily broke users on some TypeScript version.\n   *\n   * for more info see https://github.com/gpuweb/types/issues/127\n   */\n  export type GpuBufferType = {size: number; mapState: 'unmapped' | 'pending' | 'mapped'};\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32'|'float16'|'int32'|'int64'|'uint32'|'bool';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none'|'cpu'|'cpu-pinned'|'texture'|'gpu-buffer';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends 'uint64'|'int64'>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly bigint[]|readonly number[],\n      dims?: readonly number[]): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'|'uint64'|'int64'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly string[]|readonly bigint[]|readonly boolean[],\n      dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as (TensorConstructor & TensorFactory);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {InferenceSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, options);\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl.js';\nimport {OnnxValue, OnnxValueDataLocation} from './onnx-value.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: {readonly [dimensionName: string]: number};\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation|{readonly [outputName: string]: OnnxValueDataLocation};\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'xnnpack' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    coreml: CoreMlExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface CoreMlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    coreMlFlags?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW'|'NHWC';\n  }\n  export interface WebNNExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webnn';\n    deviceType?: 'cpu'|'gpu';\n    numThreads?: number;\n    powerPreference?: 'default'|'low-power'|'high-performance';\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    useCPUOnly?: boolean;\n    enableOnSubgraph?: boolean;\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\ntype NonTensorType = never;\n\n/**\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\n *\n * NOTE: currently not support non-tensor\n */\nexport type OnnxValue = Tensor|NonTensorType;\n\n/**\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\n */\nexport type OnnxValueDataLocation = Tensor.DataLocation;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {SessionHandler, TrainingSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\nimport {TrainingSession as TrainingSessionInterface, TrainingSessionCreateOptions} from './training-session.js';\n\ntype SessionOptions = InferenceSession.SessionOptions;\ntype FeedsType = InferenceSession.FeedsType;\ntype FetchesType = InferenceSession.FetchesType;\ntype ReturnType = InferenceSession.ReturnType;\ntype RunOptions = InferenceSession.RunOptions;\n\nconst noBackendErrMsg: string = 'Training backend could not be resolved. ' +\n    'Make sure you\\'re using the correct configuration & WebAssembly files.';\n\nexport class TrainingSession implements TrainingSessionInterface {\n  private constructor(handler: TrainingSessionHandler) {\n    this.handler = handler;\n  }\n  private handler: TrainingSessionHandler;\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  static async create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: SessionOptions):\n      Promise<TrainingSession> {\n    const evalModel: string|Uint8Array = trainingOptions.evalModel || '';\n    const optimizerModel: string|Uint8Array = trainingOptions.optimizerModel || '';\n    const options: SessionOptions = sessionOptions || {};\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    if (backend.createTrainingSessionHandler) {\n      const handler = await backend.createTrainingSessionHandler(\n          trainingOptions.checkpointState, trainingOptions.trainModel, evalModel, optimizerModel, options);\n      return new TrainingSession(handler);\n    } else {\n      throw new Error(noBackendErrMsg);\n    }\n  }\n\n  /**\n   * Helper function for runTrainStep and future runStep methods that handles the type-narrowing conversion from\n   * the given parameters to SessionHandler.FetchesType and RunOptions.\n   *\n   * @param feeds the required input\n   * @param arg1 narrowed & converted into the SessionHandler.FetchesType or RunOptions object\n   * @param arg2 optional RunOptions object.\n   * @returns\n   */\n  typeNarrowingForRunStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions):\n      [SessionHandler.FetchesType, RunOptions] {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSession.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    return [fetches, options];\n  }\n\n  /**\n   * Helper method for runTrainStep and any other runStep methods. Takes the ReturnType result from the SessionHandler\n   * and changes it into a map of Tensors.\n   *\n   * @param results\n   * @returns\n   */\n  convertHandlerReturnTypeToMapOfTensors(results: SessionHandler.ReturnType): ReturnType {\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  runTrainStep(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  runTrainStep(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async runTrainStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const [fetches, options] = this.typeNarrowingForRunStep(feeds, arg1, arg2);\n    const results = await this.handler.runTrainStep(feeds, fetches, options);\n    return this.convertHandlerReturnTypeToMapOfTensors(results);\n  }\n\n  async getParametersSize(trainableOnly = true): Promise<number> {\n    return this.handler.getParametersSize(trainableOnly);\n  }\n\n  async loadParametersBuffer(array: Uint8Array, trainableOnly = true): Promise<void> {\n    const paramsSize = await this.getParametersSize(trainableOnly);\n    // checking that the size of the Uint8Array is equivalent to the byte length of a Float32Array of the number\n    // of parameters\n    if (array.length !== 4 * paramsSize) {\n      throw new Error(\n          'Size of the buffer passed into loadParametersBuffer must match the number of parameters in ' +\n          'the model. Please use getParametersSize method to check.');\n    }\n    return this.handler.loadParametersBuffer(array, trainableOnly);\n  }\n\n  async getContiguousParameters(trainableOnly = true): Promise<OnnxValue> {\n    return this.handler.getContiguousParameters(trainableOnly);\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {TrainingSession as TrainingSessionImpl} from './training-session-impl.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace TrainingSession {\n  /**\n   * Either URI file path (string) or Uint8Array containing model or checkpoint information.\n   */\n  type URIorBuffer = string|Uint8Array;\n}\n\n/**\n * Represent a runtime instance of an ONNX training session,\n * which contains a model that can be trained, and, optionally,\n * an eval and optimizer model.\n */\nexport interface TrainingSession {\n  // #region run()\n\n  /**\n   * Run TrainStep asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for\n   detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  runTrainStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single train step with the given inputs and options.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runTrainStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region copy parameters\n\n  /**\n   * Retrieves the size of all parameters for the training state. Calculates the total number of primitive (datatype of\n   * the parameters) elements of all the parameters in the training state.\n   *\n   * @param trainableOnly - When set to true, the size is calculated for trainable params only. Default value is true.\n   */\n  getParametersSize(trainableOnly: boolean): Promise<number>;\n\n  /**\n   * Copies parameter values from the given array to the training state. Currently, only supporting models with\n   * parameters of type Float32.\n   *\n   * @param buffer - Float32 buffer containing parameters converted to a Uint8Array.\n   * @param trainableOnly - True if trainable parameters only to be modified, false otherwise. Default value is true.\n   */\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n\n  /**\n   * Copies the model parameters to a contiguous buffer. Usually used in the context of Federated Learning.\n   * Currently, only supporting models with parameters of type Float32.\n   *\n   * @param trainableOnly - When set to true, only trainable parameters are copied. Trainable parameters are parameters\n   * for which requires_grad is set to true. Default value is true.\n   * @returns A promise that resolves to a Float32 OnnxValue of the requested parameters.\n   */\n  getContiguousParameters(trainableOnly: boolean): Promise<OnnxValue>;\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n  // #endregion\n}\n\n/**\n * Represents the optional parameters that can be passed into the TrainingSessionFactory.\n */\nexport interface TrainingSessionCreateOptions {\n  /**\n   * URI or buffer for a .ckpt file that contains the checkpoint for the training model.\n   */\n  checkpointState: TrainingSession.URIorBuffer;\n  /**\n   * URI or buffer for the .onnx training file.\n   */\n  trainModel: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx optimizer model file.\n   */\n  optimizerModel?: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx eval model file.\n   */\n  evalModel?: TrainingSession.URIorBuffer;\n}\n\n/**\n * Defines method overload possibilities for creating a TrainingSession.\n */\nexport interface TrainingSessionFactory {\n  // #region create()\n\n  /**\n   * Creates a new TrainingSession and asynchronously loads any models passed in through trainingOptions\n   *\n   * @param trainingOptions specify models and checkpoints to load into the Training Session\n   * @param sessionOptions specify configuration for training session behavior\n   *\n   * @returns Promise that resolves to a TrainingSession object\n   */\n  create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: InferenceSession.SessionOptions):\n      Promise<TrainingSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const TrainingSession: TrainingSessionFactory = TrainingSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript.html)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\nexport * from './backend.js';\nexport * from './env.js';\nexport * from './inference-session.js';\nexport * from './tensor.js';\nexport * from './onnx-value.js';\nexport * from './training-session.js';\n", "export const readFile = undefined;", "export const join = undefined;", "\nvar ortWasm = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nvar g=moduleArg,aa,ba;g.ready=new Promise((a,b)=>{aa=a;ba=b});\"use strict\";\ng.jsepInit=(a,b,c,d,e,f,h,k)=>{g.zh=a;g.ph=b;g.rh=c;g.eh=d;g.qh=e;g.Cd=f;g.sh=h;g.th=k;b=(l,m,n)=>(...q)=>{const r=u,p=m?.();q=l(...q);const t=m?.();p!==t&&(l=t,n(p),m=n=null);return u!=r?ca():q};c=l=>async(...m)=>{try{if(g.Xg)throw Error(\"Session already started\");const n=g.Xg={uh:m[0],errors:[]},q=await l(...m);if(g.Xg!==n)throw Error(\"Session mismatch\");a.flush();const r=n.errors;if(0<r.length){let p=await Promise.all(r);p=p.filter(t=>t);if(0<p.length)throw Error(p.join(\"\\n\"));}return q}finally{g.Xg=\nnull}};g._OrtRun=c(b(g._OrtRun,()=>g._OrtRun,l=>g._OrtRun=l));g._OrtRunWithBinding=c(b(g._OrtRunWithBinding,()=>g._OrtRunWithBinding,l=>g._OrtRunWithBinding=l));g._OrtBindInput=b(g._OrtBindInput,()=>g._OrtBindInput,l=>g._OrtBindInput=l);g.jsepRegisterBuffer=(l,m,n,q)=>a.registerBuffer(l,m,n,q);g.jsepUnregisterBuffers=l=>{a.unregisterBuffers(l)};g.jsepGetBuffer=l=>a.getBuffer(l);g.jsepCreateDownloader=(l,m,n)=>a.createDownloader(l,m,n)};\nvar da=Object.assign({},g),ea=\"./this.program\",fa=(a,b)=>{throw b;},ha=\"object\"==typeof window,ia=\"function\"==typeof importScripts,ja=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,w=\"\",ka,la,ma;\nif(ja){var fs=require(\"fs\"),na=require(\"path\");w=ia?na.dirname(w)+\"/\":__dirname+\"/\";ka=(a,b)=>{a=a.startsWith(\"file://\")?new URL(a):na.normalize(a);return fs.readFileSync(a,b?void 0:\"utf8\")};ma=a=>{a=ka(a,!0);a.buffer||(a=new Uint8Array(a));return a};la=(a,b,c,d=!0)=>{a=a.startsWith(\"file://\")?new URL(a):na.normalize(a);fs.readFile(a,d?void 0:\"utf8\",(e,f)=>{e?c(e):b(d?f.buffer:f)})};!g.thisProgram&&1<process.argv.length&&(ea=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);fa=(a,b)=>{process.exitCode=\na;throw b;};g.inspect=()=>\"[Emscripten Module object]\"}else if(ha||ia)ia?w=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(w=document.currentScript.src),_scriptDir&&(w=_scriptDir),0!==w.indexOf(\"blob:\")?w=w.substr(0,w.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):w=\"\",ka=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},ia&&(ma=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),\nla=(a,b,c)=>{var d=new XMLHttpRequest;d.open(\"GET\",a,!0);d.responseType=\"arraybuffer\";d.onload=()=>{200==d.status||0==d.status&&d.response?b(d.response):c()};d.onerror=c;d.send(null)};var oa=g.print||console.log.bind(console),pa=g.printErr||console.error.bind(console);Object.assign(g,da);da=null;g.thisProgram&&(ea=g.thisProgram);g.quit&&(fa=g.quit);var qa;g.wasmBinary&&(qa=g.wasmBinary);var noExitRuntime=g.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&x(\"no native wasm support detected\");\nvar ra,y,A=!1,sa,K,M,N,Q,ta,ua;function va(){var a=ra.buffer;g.HEAP8=K=new Int8Array(a);g.HEAP16=new Int16Array(a);g.HEAP32=N=new Int32Array(a);g.HEAPU8=M=new Uint8Array(a);g.HEAPU16=new Uint16Array(a);g.HEAPU32=Q=new Uint32Array(a);g.HEAPF32=ta=new Float32Array(a);g.HEAPF64=ua=new Float64Array(a)}var wa=[],xa=[],ya=[];function za(){var a=g.preRun.shift();wa.unshift(a)}var R=0,Aa=null,Ba=null;\nfunction x(a){if(g.onAbort)g.onAbort(a);a=\"Aborted(\"+a+\")\";pa(a);A=!0;sa=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");ba(a);throw a;}function Ca(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var Da;Da=\"ort-wasm-simd.wasm\";if(!Ca(Da)){var Ea=Da;Da=g.locateFile?g.locateFile(Ea,w):w+Ea}function Fa(a){if(a==Da&&qa)return new Uint8Array(qa);if(ma)return ma(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction Ga(a){if(!qa&&(ha||ia)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>Fa(a));if(la)return new Promise((b,c)=>{la(a,d=>b(new Uint8Array(d)),c)})}return Promise.resolve().then(()=>Fa(a))}function Ha(a,b,c){return Ga(a).then(d=>WebAssembly.instantiate(d,b)).then(d=>d).then(c,d=>{pa(\"failed to asynchronously prepare wasm: \"+d);x(d)})}\nfunction Ia(a,b){var c=Da;return qa||\"function\"!=typeof WebAssembly.instantiateStreaming||Ca(c)||c.startsWith(\"file://\")||ja||\"function\"!=typeof fetch?Ha(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(d=>WebAssembly.instantiateStreaming(d,a).then(b,function(e){pa(\"wasm streaming compile failed: \"+e);pa(\"falling back to ArrayBuffer instantiation\");return Ha(c,a,b)}))}\nvar Ja,Ka={1336376:a=>{g.Cd(\"Abs\",a,void 0)},1336427:a=>{g.Cd(\"Neg\",a,void 0)},1336478:a=>{g.Cd(\"Floor\",a,void 0)},1336531:a=>{g.Cd(\"Ceil\",a,void 0)},1336583:a=>{g.Cd(\"Reciprocal\",a,void 0)},1336641:a=>{g.Cd(\"Sqrt\",a,void 0)},1336693:a=>{g.Cd(\"Exp\",a,void 0)},1336744:a=>{g.Cd(\"Erf\",a,void 0)},1336795:a=>{g.Cd(\"Sigmoid\",a,void 0)},1336850:a=>{g.Cd(\"Log\",a,void 0)},1336901:a=>{g.Cd(\"Sin\",a,void 0)},1336952:a=>{g.Cd(\"Cos\",a,void 0)},1337003:a=>{g.Cd(\"Tan\",a,void 0)},1337054:a=>{g.Cd(\"Asin\",a,void 0)},\n1337106:a=>{g.Cd(\"Acos\",a,void 0)},1337158:a=>{g.Cd(\"Atan\",a,void 0)},1337210:a=>{g.Cd(\"Sinh\",a,void 0)},1337262:a=>{g.Cd(\"Cosh\",a,void 0)},1337314:a=>{g.Cd(\"Asinh\",a,void 0)},1337367:a=>{g.Cd(\"Acosh\",a,void 0)},1337420:a=>{g.Cd(\"Atanh\",a,void 0)},1337473:a=>{g.Cd(\"Tanh\",a,void 0)},1337525:a=>{g.Cd(\"Not\",a,void 0)},1337576:(a,b,c)=>{g.Cd(\"Clip\",a,{min:b,max:c})},1337645:a=>{g.Cd(\"Clip\",a,void 0)},1337697:(a,b)=>{g.Cd(\"Elu\",a,{alpha:b})},1337755:a=>{g.Cd(\"Relu\",a,void 0)},1337807:(a,b)=>{g.Cd(\"LeakyRelu\",\na,{alpha:b})},1337871:(a,b)=>{g.Cd(\"ThresholdedRelu\",a,{alpha:b})},1337941:(a,b)=>{g.Cd(\"Cast\",a,{to:b})},1337999:a=>{g.Cd(\"Add\",a,void 0)},1338050:a=>{g.Cd(\"Sub\",a,void 0)},1338101:a=>{g.Cd(\"Mul\",a,void 0)},1338152:a=>{g.Cd(\"Div\",a,void 0)},1338203:a=>{g.Cd(\"Pow\",a,void 0)},1338254:a=>{g.Cd(\"Equal\",a,void 0)},1338307:a=>{g.Cd(\"Greater\",a,void 0)},1338362:a=>{g.Cd(\"GreaterOrEqual\",a,void 0)},1338424:a=>{g.Cd(\"Less\",a,void 0)},1338476:a=>{g.Cd(\"LessOrEqual\",a,void 0)},1338535:(a,b,c,d,e)=>{g.Cd(\"ReduceMean\",\na,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1338699:(a,b,c,d,e)=>{g.Cd(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1338862:(a,b,c,d,e)=>{g.Cd(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1339025:(a,b,c,d,e)=>{g.Cd(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1339189:(a,b,c,d,e)=>{g.Cd(\"ReduceSum\",\na,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1339352:(a,b,c,d,e)=>{g.Cd(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1339514:(a,b,c,d,e)=>{g.Cd(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1339676:(a,b,c,d,e)=>{g.Cd(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1339842:(a,b,c,d,e)=>{g.Cd(\"ReduceSumSquare\",\na,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1340011:(a,b,c,d,e)=>{g.Cd(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1340180:a=>{g.Cd(\"Where\",a,void 0)},1340233:(a,b,c)=>{g.Cd(\"Transpose\",a,{perm:b?Array.from(N.subarray(c>>>0,c+b>>>0)):[]})},1340346:(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)=>{g.Cd(\"ConvTranspose\",a,{format:l?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:d,kernel_shape:[e],pads:[f,h],strides:[k],\nwIsConst:()=>!!K[m>>>0],outputPadding:n?Array.from(N.subarray(q>>>0,q+n>>>0)):[],outputShape:r?Array.from(N.subarray(p>>>0,p+r>>>0)):[],activation:S(t)})},1340760:(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>{g.Cd(\"ConvTranspose\",a,{format:k?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(N.subarray(c>>>0,c+2>>>0)),group:d,kernelShape:Array.from(N.subarray(e>>>0,e+2>>>0)),pads:Array.from(N.subarray(f>>>0,f+4>>>0)),strides:Array.from(N.subarray(h>>>0,h+2>>>0)),wIsConst:()=>!!K[l>>>0],outputPadding:0<m?Array.from(N.subarray(n>>>\n0,n+m>>>0)):[],outputShape:0<q?Array.from(N.subarray(r>>>0,r+q>>>0)):[],activation:S(p)})},1341317:(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)=>{g.Cd(\"ConvTranspose\",a,{format:l?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:d,kernel_shape:[e],pads:[f,h],strides:[k],wIsConst:()=>!!K[m>>>0],outputPadding:n?Array.from(N.subarray(q>>>0,q+n>>>0)):[],outputShape:r?Array.from(N.subarray(p>>>0,p+r>>>0)):[],activation:S(t)})},1341731:(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>{g.Cd(\"ConvTranspose\",a,{format:k?\"NHWC\":\"NCHW\",autoPad:b,\ndilations:Array.from(N.subarray(c>>>0,c+2>>>0)),group:d,kernelShape:Array.from(N.subarray(e>>>0,e+2>>>0)),pads:Array.from(N.subarray(f>>>0,f+4>>>0)),strides:Array.from(N.subarray(h>>>0,h+2>>>0)),wIsConst:()=>!!K[l>>>0],outputPadding:0<m?Array.from(N.subarray(n>>>0,n+m>>>0)):[],outputShape:0<q?Array.from(N.subarray(r>>>0,r+q>>>0)):[],activation:S(p)})},1342288:(a,b)=>{g.Cd(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},1342379:(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>{g.Cd(\"AveragePool\",a,{format:v?\"NHWC\":\n\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:e,dilations:[f,h],kernel_shape:[k,l],pads:[m,n,q,r],strides:[p,t]})},1342663:(a,b)=>{g.Cd(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},1342754:(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>{g.Cd(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:e,dilations:[f,h],kernel_shape:[k,l],pads:[m,n,q,r],strides:[p,t]})},1343038:(a,b)=>{g.Cd(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},1343125:(a,b,c,d,\ne,f,h,k,l,m,n,q,r,p,t,v)=>{g.Cd(\"MaxPool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:e,dilations:[f,h],kernel_shape:[k,l],pads:[m,n,q,r],strides:[p,t]})},1343405:(a,b)=>{g.Cd(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},1343492:(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>{g.Cd(\"MaxPool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:e,dilations:[f,h],kernel_shape:[k,l],pads:[m,n,q,r],strides:[p,t]})},1343772:(a,b,c,d,e)=>{g.Cd(\"Gemm\",\na,{alpha:b,beta:c,transA:d,transB:e})},1343876:a=>{g.Cd(\"MatMul\",a,void 0)},1343930:(a,b,c,d)=>{g.Cd(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:d})},1344038:(a,b,c,d)=>{g.Cd(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:d})},1344146:(a,b)=>{g.Cd(\"Softmax\",a,{axis:b})},1344209:(a,b)=>{g.Cd(\"Concat\",a,{axis:b})},1344269:(a,b,c,d,e)=>{g.Cd(\"Split\",a,{axis:b,numOutputs:c,splitSizes:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1344414:a=>{g.Cd(\"Expand\",a,void 0)},1344468:(a,b)=>{g.Cd(\"Gather\",\na,{axis:Number(b)})},1344539:(a,b)=>{g.Cd(\"GatherElements\",a,{axis:Number(b)})},1344618:(a,b,c,d,e,f,h,k,l,m,n)=>{g.Cd(\"Resize\",a,{antialias:b,axes:c?Array.from(N.subarray(d>>>0,d+c>>>0)):[],coordinateTransformMode:S(e),cubicCoeffA:f,excludeOutside:h,extrapolationValue:k,keepAspectRatioPolicy:S(l),mode:S(m),nearestMode:S(n)})},1344969:(a,b,c,d,e,f,h)=>{g.Cd(\"Slice\",a,{starts:b?Array.from(N.subarray(c>>>0,c+b>>>0)):[],ends:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[],axes:f?Array.from(N.subarray(h>>>\n0,h+f>>>0)):[]})},1345200:a=>{g.Cd(\"Tile\",a,void 0)},1345252:(a,b,c)=>{g.Cd(\"LayerNormalization\",a,{axis:Number(b),epsilon:Number(c)})},1345359:(a,b,c)=>{g.Cd(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},1345473:(a,b,c)=>{g.Cd(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},1345587:a=>{g.Cd(\"Range\",a,void 0)},1345640:(a,b)=>{g.Cd(\"Einsum\",a,{equation:S(b)})},1345721:(a,b,c,d,e)=>{g.Cd(\"Pad\",a,{mode:b,value:c,pads:d?Array.from(N.subarray(e>>>0,e+d>>>0)):[]})},1345853:(a,\nb,c,d,e,f)=>{g.Cd(\"BatchNormalization\",a,{epsilon:b,momentum:c,spatial:!!e,trainingMode:!!d,format:f?\"NHWC\":\"NCHW\"})},1346022:(a,b,c,d,e,f)=>{g.Cd(\"BatchNormalization\",a,{epsilon:b,momentum:c,spatial:!!e,trainingMode:!!d,format:f?\"NHWC\":\"NCHW\"})},1346191:(a,b,c,d,e,f,h,k,l)=>{g.Cd(\"Attention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:d,scale:e,doRotary:f,qkvHiddenSizes:h?Array.from(N.subarray(Number(k)>>>0,Number(k)+h>>>0)):[],pastPresentShareBuffer:!!l})},1346463:a=>{g.Cd(\"Gelu\",a,void 0)},\n1346515:(a,b,c,d,e,f)=>{g.Cd(\"MultiHeadAttention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:d,scale:e,doRotary:f})},1346674:a=>{g.Cd(\"BiasAdd\",a,void 0)},1346729:a=>{g.Cd(\"BiasSplitGelu\",a,void 0)},1346790:(a,b)=>{g.Cd(\"SkipLayerNormalization\",a,{epsilon:b})},1346871:(a,b,c,d,e,f,h,k,l,m,n,q,r)=>{g.Cd(\"Conv\",a,{format:l?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:d,kernel_shape:[e],pads:f?Array.from(N.subarray(h>>>0,h+f>>>0)):[],strides:[k],w_is_const:()=>!!K[m>>>0],activation:S(n),activation_params:q?\nArray.from(ta.subarray(r>>>0,r+q>>>0)):[]})},1347252:(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>{g.Cd(\"Conv\",a,{format:q?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,d],group:e,kernel_shape:[f,h],pads:k?Array.from(N.subarray(l>>>0,l+k>>>0)):[],strides:[m,n],w_is_const:()=>!!K[r>>>0],activation:S(p),activation_params:t?Array.from(ta.subarray(v>>>0,v+t>>>0)):[]})},1347654:a=>{g.sh(a)},1347688:(a,b)=>g.th(a,b,g.Xg.uh,g.Xg.errors),1347800:a=>g.ph(a),1347833:a=>g.rh(a),1347865:(a,b,c)=>{g.eh(a,b,c,!0)},1347904:(a,b,\nc)=>{g.eh(a,b,c)}};function La(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}var Ma=a=>{for(;0<a.length;)a.shift()(g)},Na=[],Oa=0,T=0;\nfunction Pa(a){this.Wg=a;this.Sg=a-24;this.mh=function(b){Q[this.Sg+4>>2>>>0]=b};this.bh=function(){return Q[this.Sg+4>>2>>>0]};this.lh=function(b){Q[this.Sg+8>>2>>>0]=b};this.fh=function(b){K[this.Sg+12>>0>>>0]=b?1:0};this.ih=function(){return 0!=K[this.Sg+12>>0>>>0]};this.gh=function(b){K[this.Sg+13>>0>>>0]=b?1:0};this.oh=function(){return 0!=K[this.Sg+13>>0>>>0]};this.kh=function(b,c){this.dh(0);this.mh(b);this.lh(c)};this.dh=function(b){Q[this.Sg+16>>2>>>0]=b};this.hh=function(){return Q[this.Sg+\n16>>2>>>0]};this.jh=function(){if(Qa(this.bh()))return Q[this.Wg>>2>>>0];var b=this.hh();return 0!==b?b:this.Wg}}\nvar Ta=a=>{var b=T;if(!b)return Ra(0),0;var c=new Pa(b);c.dh(b);var d=c.bh();if(!d)return Ra(0),b;for(var e in a){var f=a[e];if(0===f||f===d)break;if(Sa(f,d,c.Sg+16))return Ra(f),b}Ra(d);return b},Ua=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Va=(a,b,c)=>{b>>>=0;var d=b+c;for(c=b;a[c]&&!(c>=d);)++c;if(16<c-b&&a.buffer&&Ua)return Ua.decode(a.subarray(b,c));for(d=\"\";b<c;){var e=a[b++];if(e&128){var f=a[b++]&63;if(192==(e&224))d+=String.fromCharCode((e&31)<<6|f);else{var h=a[b++]&\n63;e=224==(e&240)?(e&15)<<12|f<<6|h:(e&7)<<18|f<<12|h<<6|a[b++]&63;65536>e?d+=String.fromCharCode(e):(e-=65536,d+=String.fromCharCode(55296|e>>10,56320|e&1023))}}else d+=String.fromCharCode(e)}return d},S=(a,b)=>(a>>>=0)?Va(M,a,b):\"\",Wa=a=>{for(var b=0,c=0;c<a.length;++c){var d=a.charCodeAt(c);127>=d?b++:2047>=d?b+=2:55296<=d&&57343>=d?(b+=4,++c):b+=3}return b},Xa=(a,b,c,d)=>{c>>>=0;if(!(0<d))return 0;var e=c;d=c+d-1;for(var f=0;f<a.length;++f){var h=a.charCodeAt(f);if(55296<=h&&57343>=h){var k=a.charCodeAt(++f);\nh=65536+((h&1023)<<10)|k&1023}if(127>=h){if(c>=d)break;b[c++>>>0]=h}else{if(2047>=h){if(c+1>=d)break;b[c++>>>0]=192|h>>6}else{if(65535>=h){if(c+2>=d)break;b[c++>>>0]=224|h>>12}else{if(c+3>=d)break;b[c++>>>0]=240|h>>18;b[c++>>>0]=128|h>>12&63}b[c++>>>0]=128|h>>6&63}b[c++>>>0]=128|h&63}}b[c>>>0]=0;return c-e},Ya=a=>0===a%4&&(0!==a%100||0===a%400),Za=[0,31,60,91,121,152,182,213,244,274,305,335],$a=[0,31,59,90,120,151,181,212,243,273,304,334],bb=a=>{var b=Wa(a)+1,c=ab(b);c&&Xa(a,M,c,b);return c},cb=[],\ndb=(a,b)=>{cb.length=0;var c;for(b>>=2;c=M[a++>>>0];)b+=105!=c&b,cb.push(105==c?N[b>>>0]:ua[b++>>>1]),++b;return cb},eb={},gb=()=>{if(!fb){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:ea||\"./this.program\"},b;for(b in eb)void 0===eb[b]?delete a[b]:a[b]=eb[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);fb=c}return fb},fb,hb=[null,[],[]],ib=[31,29,31,30,31,\n30,31,31,30,31,30,31],jb=[31,28,31,30,31,30,31,31,30,31,30,31];function kb(a){var b=Array(Wa(a)+1);Xa(a,b,0,b.length);return b}\nfunction lb(a,b,c,d){function e(p,t,v){for(p=\"number\"==typeof p?p.toString():p||\"\";p.length<t;)p=v[0]+p;return p}function f(p,t){return e(p,t,\"0\")}function h(p,t){function v(B){return 0>B?-1:0<B?1:0}var z;0===(z=v(p.getFullYear()-t.getFullYear()))&&0===(z=v(p.getMonth()-t.getMonth()))&&(z=v(p.getDate()-t.getDate()));return z}function k(p){switch(p.getDay()){case 0:return new Date(p.getFullYear()-1,11,29);case 1:return p;case 2:return new Date(p.getFullYear(),0,3);case 3:return new Date(p.getFullYear(),\n0,2);case 4:return new Date(p.getFullYear(),0,1);case 5:return new Date(p.getFullYear()-1,11,31);case 6:return new Date(p.getFullYear()-1,11,30)}}function l(p){var t=p.Ug;for(p=new Date((new Date(p.Vg+1900,0,1)).getTime());0<t;){var v=p.getMonth(),z=(Ya(p.getFullYear())?ib:jb)[v];if(t>z-p.getDate())t-=z-p.getDate()+1,p.setDate(1),11>v?p.setMonth(v+1):(p.setMonth(0),p.setFullYear(p.getFullYear()+1));else{p.setDate(p.getDate()+t);break}}v=new Date(p.getFullYear()+1,0,4);t=k(new Date(p.getFullYear(),\n0,4));v=k(v);return 0>=h(t,p)?0>=h(v,p)?p.getFullYear()+1:p.getFullYear():p.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;d>>>=0;var m=N[d+40>>2>>>0];d={xh:N[d>>2>>>0],wh:N[d+4>>2>>>0],Yg:N[d+8>>2>>>0],ah:N[d+12>>2>>>0],Zg:N[d+16>>2>>>0],Vg:N[d+20>>2>>>0],Tg:N[d+24>>2>>>0],Ug:N[d+28>>2>>>0],Ah:N[d+32>>2>>>0],vh:N[d+36>>2>>>0],yh:m?S(m):\"\"};c=S(c);m={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\n\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var n in m)c=c.replace(new RegExp(n,\"g\"),m[n]);var q=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),r=\"January February March April May June July August September October November December\".split(\" \");m={\"%a\":p=>q[p.Tg].substring(0,3),\"%A\":p=>q[p.Tg],\"%b\":p=>r[p.Zg].substring(0,\n3),\"%B\":p=>r[p.Zg],\"%C\":p=>f((p.Vg+1900)/100|0,2),\"%d\":p=>f(p.ah,2),\"%e\":p=>e(p.ah,2,\" \"),\"%g\":p=>l(p).toString().substring(2),\"%G\":p=>l(p),\"%H\":p=>f(p.Yg,2),\"%I\":p=>{p=p.Yg;0==p?p=12:12<p&&(p-=12);return f(p,2)},\"%j\":p=>{for(var t=0,v=0;v<=p.Zg-1;t+=(Ya(p.Vg+1900)?ib:jb)[v++]);return f(p.ah+t,3)},\"%m\":p=>f(p.Zg+1,2),\"%M\":p=>f(p.wh,2),\"%n\":()=>\"\\n\",\"%p\":p=>0<=p.Yg&&12>p.Yg?\"AM\":\"PM\",\"%S\":p=>f(p.xh,2),\"%t\":()=>\"\\t\",\"%u\":p=>p.Tg||7,\"%U\":p=>f(Math.floor((p.Ug+7-p.Tg)/7),2),\"%V\":p=>{var t=Math.floor((p.Ug+\n7-(p.Tg+6)%7)/7);2>=(p.Tg+371-p.Ug-2)%7&&t++;if(t)53==t&&(v=(p.Tg+371-p.Ug)%7,4==v||3==v&&Ya(p.Vg)||(t=1));else{t=52;var v=(p.Tg+7-p.Ug-1)%7;(4==v||5==v&&Ya(p.Vg%400-1))&&t++}return f(t,2)},\"%w\":p=>p.Tg,\"%W\":p=>f(Math.floor((p.Ug+7-(p.Tg+6)%7)/7),2),\"%y\":p=>(p.Vg+1900).toString().substring(2),\"%Y\":p=>p.Vg+1900,\"%z\":p=>{p=p.vh;var t=0<=p;p=Math.abs(p)/60;return(t?\"+\":\"-\")+String(\"0000\"+(p/60*100+p%60)).slice(-4)},\"%Z\":p=>p.yh,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(n in m)c.includes(n)&&(c=\nc.replace(new RegExp(n,\"g\"),m[n](d)));c=c.replace(/\\0\\0/g,\"%\");n=kb(c);if(n.length>b)return 0;K.set(n,a>>>0);return n.length-1}function mb(a){try{a()}catch(b){x(b)}}function nb(a){var b={},c;for(c in a)(function(d){var e=a[d];b[d]=\"function\"==typeof e?function(){ob.push(d);try{return e.apply(null,arguments)}finally{A||(ob.pop()===d||x(),u&&1===U&&0===ob.length&&(U=0,mb(pb),\"undefined\"!=typeof Fibers&&Fibers.Bh()))}}:e})(c);return b}var U=0,u=null,qb=0,ob=[],rb={},sb={},tb=0,ub=null,vb=[];\nfunction ca(){return new Promise((a,b)=>{ub={resolve:a,reject:b}})}function wb(){var a=ab(65548),b=a+12;Q[a>>2>>>0]=b;Q[a+4>>2>>>0]=b+65536;b=ob[0];var c=rb[b];void 0===c&&(c=tb++,rb[b]=c,sb[c]=b);N[a+8>>2>>>0]=c;return a}\nfunction xb(a){if(!A){if(0===U){var b=!1,c=!1;a((d=0)=>{if(!A&&(qb=d,b=!0,c)){U=2;mb(()=>yb(u));\"undefined\"!=typeof Browser&&Browser.$g.nh&&Browser.$g.resume();d=!1;try{var e=(0,y[sb[N[u+8>>2>>>0]]])()}catch(k){e=k,d=!0}var f=!1;if(!u){var h=ub;h&&(ub=null,(d?h.reject:h.resolve)(e),f=!0)}if(d&&!f)throw e;}});c=!0;b||(U=1,u=wb(),\"undefined\"!=typeof Browser&&Browser.$g.nh&&Browser.$g.pause(),mb(()=>zb(u)))}else 2===U?(U=0,mb(Ab),Bb(u),u=null,vb.forEach(d=>{if(!A)try{if(d(),!noExitRuntime)try{sa=sa=\nd=sa;if(!noExitRuntime){if(g.onExit)g.onExit(d);A=!0}fa(d,new La(d))}catch(e){e instanceof La||\"unwind\"==e||fa(1,e)}}catch(e){e instanceof La||\"unwind\"==e||fa(1,e)}})):x(`invalid state: ${U}`);return qb}}function Cb(a){return xb(b=>{a().then(b)})}\nvar Ke={Ha:function(a,b,c){return Cb(async()=>{await g.qh(a,b,c)})},u:function(a){a=new Pa(a>>>0);a.ih()||(a.fh(!0),Oa--);a.gh(!1);Na.push(a);Db(a.Wg);return a.jh()},C:function(){V(0,0);var a=Na.pop();Eb(a.Wg);T=0},a:function(){return Ta([])},k:function(a){return Ta([a>>>0])},w:function(a,b){return Ta([a>>>0,b>>>0])},q:function(a,b,c){return Ta([a>>>0,b>>>0,c>>>0])},pa:function(){var a=Na.pop();a||x(\"no exception to throw\");var b=a.Wg;a.oh()||(Na.push(a),a.gh(!0),a.fh(!1),Oa++);T=b;throw T;},s:function(a,\nb,c){a>>>=0;(new Pa(a)).kh(b>>>0,c>>>0);T=a;Oa++;throw T;},$:function(){return Oa},g:function(a){T||(T=a>>>0);throw T;},qa:function(){return 0},oc:function(){},Pa:function(){},Ra:function(){},Ja:function(){return 0},Ub:function(){},Ta:function(){},Jb:function(){},Ca:function(){},Qa:function(){},Na:function(){},dc:function(){},Oa:function(){},Tc:()=>!0,Oc:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);N[c>>2>>>0]=a.getUTCSeconds();N[c+4>>2>>>0]=a.getUTCMinutes();\nN[c+8>>2>>>0]=a.getUTCHours();N[c+12>>2>>>0]=a.getUTCDate();N[c+16>>2>>>0]=a.getUTCMonth();N[c+20>>2>>>0]=a.getUTCFullYear()-1900;N[c+24>>2>>>0]=a.getUTCDay();N[c+28>>2>>>0]=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0},Pc:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);N[c>>2>>>0]=a.getSeconds();N[c+4>>2>>>0]=a.getMinutes();N[c+8>>2>>>0]=a.getHours();N[c+12>>2>>>0]=a.getDate();N[c+16>>2>>>0]=a.getMonth();N[c+20>>2>>>0]=a.getFullYear()-\n1900;N[c+24>>2>>>0]=a.getDay();N[c+28>>2>>>0]=(Ya(a.getFullYear())?Za:$a)[a.getMonth()]+a.getDate()-1|0;N[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();var d=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();N[c+32>>2>>>0]=(b!=d&&a.getTimezoneOffset()==Math.min(d,b))|0},Qc:function(a){a>>>=0;var b=new Date(N[a+20>>2>>>0]+1900,N[a+16>>2>>>0],N[a+12>>2>>>0],N[a+8>>2>>>0],N[a+4>>2>>>0],N[a>>2>>>0],0),c=N[a+32>>2>>>0],d=b.getTimezoneOffset(),e=(new Date(b.getFullYear(),\n6,1)).getTimezoneOffset(),f=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),h=Math.min(f,e);0>c?N[a+32>>2>>>0]=Number(e!=f&&h==d):0<c!=(h==d)&&(e=Math.max(f,e),b.setTime(b.getTime()+6E4*((0<c?h:e)-d)));N[a+24>>2>>>0]=b.getDay();N[a+28>>2>>>0]=(Ya(b.getFullYear())?Za:$a)[b.getMonth()]+b.getDate()-1|0;N[a>>2>>>0]=b.getSeconds();N[a+4>>2>>>0]=b.getMinutes();N[a+8>>2>>>0]=b.getHours();N[a+12>>2>>>0]=b.getDate();N[a+16>>2>>>0]=b.getMonth();N[a+20>>2>>>0]=b.getYear();a=b.getTime()/1E3;return Ra((Ja=\na,1<=+Math.abs(Ja)?0<Ja?+Math.floor(Ja/4294967296)>>>0:~~+Math.ceil((Ja-+(~~Ja>>>0))/4294967296)>>>0:0)),a>>>0},Mc:function(){return-52},Nc:function(){},La:function(a,b,c){function d(l){return(l=l.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?l[1]:\"GMT\"}c>>>=0;var e=(new Date).getFullYear(),f=new Date(e,0,1),h=new Date(e,6,1);e=f.getTimezoneOffset();var k=h.getTimezoneOffset();Q[a>>>0>>2>>>0]=60*Math.max(e,k);N[b>>>0>>2>>>0]=Number(e!=k);a=d(f);b=d(h);a=bb(a);b=bb(b);k<e?(Q[c>>2>>>0]=a,Q[c+4>>2>>>0]=\nb):(Q[c>>2>>>0]=b,Q[c+4>>2>>>0]=a)},ja:()=>{x(\"\")},x:function(a,b,c){a>>>=0;b=db(b>>>0,c>>>0);return Ka[a].apply(null,b)},wa:function(a,b,c){a>>>=0;b=db(b>>>0,c>>>0);return Ka[a].apply(null,b)},Ea:function(){return Date.now()},Ma:function(){return 4294901760},I:()=>performance.now(),yb:function(a,b,c){b>>>=0;return M.copyWithin(a>>>0>>>0,b>>>0,b+(c>>>0)>>>0)},Ka:function(a){a>>>=0;var b=M.length;if(4294901760<a)return!1;for(var c=1;4>=c;c*=2){var d=b*(1+.2/c);d=Math.min(d,a+100663296);var e=Math;\nd=Math.max(a,d);a:{e=e.min.call(e,4294901760,d+(65536-d%65536)%65536)-ra.buffer.byteLength+65535>>>16;try{ra.grow(e);va();var f=1;break a}catch(h){}f=void 0}if(f)return!0}return!1},cb:function(a,b){a>>>=0;b>>>=0;var c=0;gb().forEach(function(d,e){var f=b+c;e=Q[a+4*e>>2>>>0]=f;for(f=0;f<d.length;++f)K[e++>>0>>>0]=d.charCodeAt(f);K[e>>0>>>0]=0;c+=d.length+1});return 0},nb:function(a,b){a>>>=0;b>>>=0;var c=gb();Q[a>>2>>>0]=c.length;var d=0;c.forEach(function(e){d+=e.length+1});Q[b>>2>>>0]=d;return 0},\nma:()=>52,Ba:function(){return 52},Rc:function(){return 70},Aa:function(a,b,c,d){b>>>=0;c>>>=0;d>>>=0;for(var e=0,f=0;f<c;f++){var h=Q[b>>2>>>0],k=Q[b+4>>2>>>0];b+=8;for(var l=0;l<k;l++){var m=M[h+l>>>0],n=hb[a];0===m||10===m?((1===a?oa:pa)(Va(n,0)),n.length=0):n.push(m)}e+=k}Q[d>>2>>>0]=e;return 0},ia:Fb,Sc:Gb,M:Hb,K:Ib,Uc:Jb,Wc:Kb,B:Lb,z:Mb,b:Nb,Da:Ob,aa:Pb,f:Qb,ra:Rb,h:Sb,F:Tb,i:Ub,Vc:Vb,j:Wb,t:Xb,r:Yb,n:Zb,W:$b,Y:ac,J:bc,oa:cc,ba:dc,la:ec,vb:fc,fb:gc,yc:hc,ab:ic,db:jc,Sa:kc,Rb:lc,Dc:mc,ib:nc,\nVa:oc,Nb:pc,eb:qc,fc:rc,Lc:sc,nc:tc,gb:uc,bb:vc,Bb:wc,jc:xc,mc:yc,ec:zc,Kc:Ac,Za:Bc,$a:Cc,qb:Dc,mb:Ec,_a:Fc,hc:Gc,Ib:Hc,lb:Ic,Ua:Jc,Sb:Kc,Ic:Lc,zc:Mc,sc:Nc,pb:Oc,kc:Pc,Hb:Qc,Gb:Rc,c:Sc,_:Tc,p:Uc,P:Vc,Z:Wc,ha:Xc,e:Yc,za:Zc,G:$c,da:ad,O:bd,ub:cd,fa:dd,d:ed,xa:fd,Fa:gd,l:hd,va:jd,m:kd,ya:ld,ua:md,Ga:nd,o:od,V:pd,ga:qd,U:rd,na:sd,y:td,A:ud,E:vd,X:wd,ta:xd,ea:yd,N:zd,L:Ad,D:Bd,ca:Cd,T:Dd,ka:Ed,R:Fd,sa:Gd,Q:Hd,S:Id,ic:Jd,zb:Kd,rb:Ld,Db:Md,Ab:Nd,Ac:Od,Mb:Pd,xb:Qd,Eb:Rd,Ob:Sd,cc:Td,ob:Ud,Lb:Vd,sb:Wd,kb:Xd,\nqc:Yd,Fc:Zd,Ya:$d,Pb:ae,wc:be,jb:ce,uc:de,Hc:ee,vc:fe,Bc:ge,Xa:he,Ec:ie,wb:je,Kb:ke,xc:le,Jc:me,hb:ne,Cb:oe,Xb:pe,tb:qe,Gc:re,Yb:se,Qb:te,gc:ue,Cc:ve,pc:we,Fb:xe,Wb:ye,rc:ze,lc:Ae,Wa:Be,tc:Ce,Tb:De,Vb:Ee,_b:Fe,$b:Ge,bc:He,Zb:Ie,ac:Je,v:function(a){return a>>>0},Ia:lb,H:function(a,b,c,d){return lb(a>>>0,b>>>0,c>>>0,d>>>0)}};\n(function(){function a(c){c=c.exports;c=nb(c);y=c=Le(c);ra=y.Xc;va();xa.unshift(y.Yc);R--;g.monitorRunDependencies&&g.monitorRunDependencies(R);if(0==R&&(null!==Aa&&(clearInterval(Aa),Aa=null),Ba)){var d=Ba;Ba=null;d()}return c}var b={a:Ke};R++;g.monitorRunDependencies&&g.monitorRunDependencies(R);if(g.instantiateWasm)try{return g.instantiateWasm(b,a)}catch(c){pa(\"Module.instantiateWasm callback failed with error: \"+c),ba(c)}Ia(b,function(c){a(c.instance)}).catch(ba);return{}})();\ng._OrtInit=(a,b)=>(g._OrtInit=y.Zc)(a,b);g._OrtGetLastError=(a,b)=>(g._OrtGetLastError=y._c)(a,b);g._OrtCreateSessionOptions=(a,b,c,d,e,f,h,k,l,m)=>(g._OrtCreateSessionOptions=y.$c)(a,b,c,d,e,f,h,k,l,m);g._OrtAppendExecutionProvider=(a,b)=>(g._OrtAppendExecutionProvider=y.ad)(a,b);g._OrtAddFreeDimensionOverride=(a,b,c)=>(g._OrtAddFreeDimensionOverride=y.bd)(a,b,c);g._OrtAddSessionConfigEntry=(a,b,c)=>(g._OrtAddSessionConfigEntry=y.cd)(a,b,c);\ng._OrtReleaseSessionOptions=a=>(g._OrtReleaseSessionOptions=y.dd)(a);g._OrtCreateSession=(a,b,c)=>(g._OrtCreateSession=y.ed)(a,b,c);g._OrtReleaseSession=a=>(g._OrtReleaseSession=y.fd)(a);g._OrtGetInputOutputCount=(a,b,c)=>(g._OrtGetInputOutputCount=y.gd)(a,b,c);g._OrtGetInputName=(a,b)=>(g._OrtGetInputName=y.hd)(a,b);g._OrtGetOutputName=(a,b)=>(g._OrtGetOutputName=y.id)(a,b);g._OrtFree=a=>(g._OrtFree=y.jd)(a);g._OrtCreateTensor=(a,b,c,d,e,f)=>(g._OrtCreateTensor=y.kd)(a,b,c,d,e,f);\ng._OrtGetTensorData=(a,b,c,d,e)=>(g._OrtGetTensorData=y.ld)(a,b,c,d,e);g._OrtReleaseTensor=a=>(g._OrtReleaseTensor=y.md)(a);g._OrtCreateRunOptions=(a,b,c,d)=>(g._OrtCreateRunOptions=y.nd)(a,b,c,d);g._OrtAddRunConfigEntry=(a,b,c)=>(g._OrtAddRunConfigEntry=y.od)(a,b,c);g._OrtReleaseRunOptions=a=>(g._OrtReleaseRunOptions=y.pd)(a);g._OrtCreateBinding=a=>(g._OrtCreateBinding=y.qd)(a);g._OrtBindInput=(a,b,c)=>(g._OrtBindInput=y.rd)(a,b,c);g._OrtBindOutput=(a,b,c,d)=>(g._OrtBindOutput=y.sd)(a,b,c,d);\ng._OrtClearBoundOutputs=a=>(g._OrtClearBoundOutputs=y.td)(a);g._OrtReleaseBinding=a=>(g._OrtReleaseBinding=y.ud)(a);g._OrtRunWithBinding=(a,b,c,d,e)=>(g._OrtRunWithBinding=y.vd)(a,b,c,d,e);g._OrtRun=(a,b,c,d,e,f,h,k)=>(g._OrtRun=y.wd)(a,b,c,d,e,f,h,k);g._OrtEndProfiling=a=>(g._OrtEndProfiling=y.xd)(a);g._JsepOutput=(a,b,c)=>(g._JsepOutput=y.yd)(a,b,c);g._JsepGetNodeName=a=>(g._JsepGetNodeName=y.zd)(a);\nvar ab=g._malloc=a=>(ab=g._malloc=y.Ad)(a),Bb=g._free=a=>(Bb=g._free=y.Bd)(a),V=(a,b)=>(V=y.Dd)(a,b),Ra=a=>(Ra=y.Ed)(a),W=()=>(W=y.Fd)(),X=a=>(X=y.Gd)(a),Me=a=>(Me=y.Hd)(a),Eb=a=>(Eb=y.Id)(a),Db=a=>(Db=y.Jd)(a),Sa=(a,b,c)=>(Sa=y.Kd)(a,b,c),Qa=a=>(Qa=y.Ld)(a),dynCall_vi=g.dynCall_vi=(a,b)=>(dynCall_vi=g.dynCall_vi=y.Md)(a,b),dynCall_vii=g.dynCall_vii=(a,b,c)=>(dynCall_vii=g.dynCall_vii=y.Nd)(a,b,c),Ne=g.dynCall_iiii=(a,b,c,d)=>(Ne=g.dynCall_iiii=y.Od)(a,b,c,d),dynCall_iii=g.dynCall_iii=(a,b,c)=>(dynCall_iii=\ng.dynCall_iii=y.Pd)(a,b,c),Oe=g.dynCall_ii=(a,b)=>(Oe=g.dynCall_ii=y.Qd)(a,b),Pe=g.dynCall_iiiiiii=(a,b,c,d,e,f,h)=>(Pe=g.dynCall_iiiiiii=y.Rd)(a,b,c,d,e,f,h),dynCall_v=g.dynCall_v=a=>(dynCall_v=g.dynCall_v=y.Sd)(a),Qe=g.dynCall_iiiiii=(a,b,c,d,e,f)=>(Qe=g.dynCall_iiiiii=y.Td)(a,b,c,d,e,f),Re=g.dynCall_iiij=(a,b,c,d,e)=>(Re=g.dynCall_iiij=y.Ud)(a,b,c,d,e),Se=g.dynCall_iiiii=(a,b,c,d,e)=>(Se=g.dynCall_iiiii=y.Vd)(a,b,c,d,e),Te=g.dynCall_viii=(a,b,c,d)=>(Te=g.dynCall_viii=y.Wd)(a,b,c,d),Ue=g.dynCall_j=\na=>(Ue=g.dynCall_j=y.Xd)(a),Ve=g.dynCall_i=a=>(Ve=g.dynCall_i=y.Yd)(a),We=g.dynCall_iij=(a,b,c,d)=>(We=g.dynCall_iij=y.Zd)(a,b,c,d),Xe=g.dynCall_iiiiij=(a,b,c,d,e,f,h)=>(Xe=g.dynCall_iiiiij=y._d)(a,b,c,d,e,f,h),Ye=g.dynCall_vij=(a,b,c,d)=>(Ye=g.dynCall_vij=y.$d)(a,b,c,d),Ze=g.dynCall_viiiii=(a,b,c,d,e,f)=>(Ze=g.dynCall_viiiii=y.ae)(a,b,c,d,e,f),$e=g.dynCall_viiii=(a,b,c,d,e)=>($e=g.dynCall_viiii=y.be)(a,b,c,d,e),af=g.dynCall_iiiiiiii=(a,b,c,d,e,f,h,k)=>(af=g.dynCall_iiiiiiii=y.ce)(a,b,c,d,e,f,h,k),\nbf=g.dynCall_fi=(a,b)=>(bf=g.dynCall_fi=y.de)(a,b),cf=g.dynCall_fii=(a,b,c)=>(cf=g.dynCall_fii=y.ee)(a,b,c),df=g.dynCall_ji=(a,b)=>(df=g.dynCall_ji=y.fe)(a,b),ef=g.dynCall_di=(a,b)=>(ef=g.dynCall_di=y.ge)(a,b),ff=g.dynCall_jii=(a,b,c)=>(ff=g.dynCall_jii=y.he)(a,b,c),gf=g.dynCall_dii=(a,b,c)=>(gf=g.dynCall_dii=y.ie)(a,b,c),hf=g.dynCall_iiiiiiiii=(a,b,c,d,e,f,h,k,l)=>(hf=g.dynCall_iiiiiiiii=y.je)(a,b,c,d,e,f,h,k,l),jf=g.dynCall_viij=(a,b,c,d,e)=>(jf=g.dynCall_viij=y.ke)(a,b,c,d,e),kf=g.dynCall_viiiiii=\n(a,b,c,d,e,f,h)=>(kf=g.dynCall_viiiiii=y.le)(a,b,c,d,e,f,h),lf=g.dynCall_vijj=(a,b,c,d,e,f)=>(lf=g.dynCall_vijj=y.me)(a,b,c,d,e,f),mf=g.dynCall_viiiiiii=(a,b,c,d,e,f,h,k)=>(mf=g.dynCall_viiiiiii=y.ne)(a,b,c,d,e,f,h,k),nf=g.dynCall_iiiiiiiiii=(a,b,c,d,e,f,h,k,l,m)=>(nf=g.dynCall_iiiiiiiiii=y.oe)(a,b,c,d,e,f,h,k,l,m),of=g.dynCall_viiiiiiii=(a,b,c,d,e,f,h,k,l)=>(of=g.dynCall_viiiiiiii=y.pe)(a,b,c,d,e,f,h,k,l),pf=g.dynCall_iiiiijiiiii=(a,b,c,d,e,f,h,k,l,m,n,q)=>(pf=g.dynCall_iiiiijiiiii=y.qe)(a,b,c,d,\ne,f,h,k,l,m,n,q),qf=g.dynCall_vijjjiiij=(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(qf=g.dynCall_vijjjiiij=y.re)(a,b,c,d,e,f,h,k,l,m,n,q,r),rf=g.dynCall_viiji=(a,b,c,d,e,f)=>(rf=g.dynCall_viiji=y.se)(a,b,c,d,e,f),sf=g.dynCall_viijiii=(a,b,c,d,e,f,h,k)=>(sf=g.dynCall_viijiii=y.te)(a,b,c,d,e,f,h,k),tf=g.dynCall_viiiiij=(a,b,c,d,e,f,h,k)=>(tf=g.dynCall_viiiiij=y.ue)(a,b,c,d,e,f,h,k),uf=g.dynCall_viiiiiiiii=(a,b,c,d,e,f,h,k,l,m)=>(uf=g.dynCall_viiiiiiiii=y.ve)(a,b,c,d,e,f,h,k,l,m),vf=g.dynCall_viid=(a,b,c,d)=>(vf=\ng.dynCall_viid=y.we)(a,b,c,d),wf=g.dynCall_iiiiiiiij=(a,b,c,d,e,f,h,k,l,m)=>(wf=g.dynCall_iiiiiiiij=y.xe)(a,b,c,d,e,f,h,k,l,m),xf=g.dynCall_iiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q)=>(xf=g.dynCall_iiiiiiiiiiii=y.ye)(a,b,c,d,e,f,h,k,l,m,n,q),yf=g.dynCall_viiiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>(yf=g.dynCall_viiiiiiiiiiiii=y.ze)(a,b,c,d,e,f,h,k,l,m,n,q,r,p),zf=g.dynCall_viijjjiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)=>(zf=g.dynCall_viijjjiiiiii=y.Ae)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t),Af=g.dynCall_viiijiiiiiii=\n(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(Af=g.dynCall_viiijiiiiiii=y.Be)(a,b,c,d,e,f,h,k,l,m,n,q,r),Bf=g.dynCall_viffiii=(a,b,c,d,e,f,h)=>(Bf=g.dynCall_viffiii=y.Ce)(a,b,c,d,e,f,h),Cf=g.dynCall_viiijjjii=(a,b,c,d,e,f,h,k,l,m,n,q)=>(Cf=g.dynCall_viiijjjii=y.De)(a,b,c,d,e,f,h,k,l,m,n,q),Df=g.dynCall_viifiii=(a,b,c,d,e,f,h)=>(Df=g.dynCall_viifiii=y.Ee)(a,b,c,d,e,f,h),Ef=g.dynCall_viiiiidiidi=(a,b,c,d,e,f,h,k,l,m,n)=>(Ef=g.dynCall_viiiiidiidi=y.Fe)(a,b,c,d,e,f,h,k,l,m,n),Ff=g.dynCall_viiiiiiiiidi=(a,b,c,d,e,f,h,\nk,l,m,n,q)=>(Ff=g.dynCall_viiiiiiiiidi=y.Ge)(a,b,c,d,e,f,h,k,l,m,n,q),Gf=g.dynCall_vjiiiiii=(a,b,c,d,e,f,h,k,l)=>(Gf=g.dynCall_vjiiiiii=y.He)(a,b,c,d,e,f,h,k,l),Hf=g.dynCall_jiii=(a,b,c,d)=>(Hf=g.dynCall_jiii=y.Ie)(a,b,c,d),If=g.dynCall_viiid=(a,b,c,d,e)=>(If=g.dynCall_viiid=y.Je)(a,b,c,d,e),Jf=g.dynCall_viiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q)=>(Jf=g.dynCall_viiiiiiiiiii=y.Ke)(a,b,c,d,e,f,h,k,l,m,n,q),Kf=g.dynCall_vijjjjjjjjjjjjji=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O,P)=>(Kf=g.dynCall_vijjjjjjjjjjjjji=\ny.Le)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O,P),Lf=g.dynCall_viiiji=(a,b,c,d,e,f,h)=>(Lf=g.dynCall_viiiji=y.Me)(a,b,c,d,e,f,h),Mf=g.dynCall_vijjjiiji=(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(Mf=g.dynCall_vijjjiiji=y.Ne)(a,b,c,d,e,f,h,k,l,m,n,q,r),Nf=g.dynCall_iiiji=(a,b,c,d,e,f)=>(Nf=g.dynCall_iiiji=y.Oe)(a,b,c,d,e,f),Of=g.dynCall_iiijiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)=>(Of=g.dynCall_iiijiiiiiiiiii=y.Pe)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t),Pf=g.dynCall_vj=(a,b,c)=>(Pf=g.dynCall_vj=y.Qe)(a,\nb,c),Qf=g.dynCall_jjj=(a,b,c,d,e)=>(Qf=g.dynCall_jjj=y.Re)(a,b,c,d,e),Rf=g.dynCall_iiijiiiiii=(a,b,c,d,e,f,h,k,l,m,n)=>(Rf=g.dynCall_iiijiiiiii=y.Se)(a,b,c,d,e,f,h,k,l,m,n),Sf=g.dynCall_viiff=(a,b,c,d,e)=>(Sf=g.dynCall_viiff=y.Te)(a,b,c,d,e),Tf=g.dynCall_viiiiiff=(a,b,c,d,e,f,h,k)=>(Tf=g.dynCall_viiiiiff=y.Ue)(a,b,c,d,e,f,h,k),Uf=g.dynCall_vfiii=(a,b,c,d,e)=>(Uf=g.dynCall_vfiii=y.Ve)(a,b,c,d,e),Vf=g.dynCall_viiiiff=(a,b,c,d,e,f,h)=>(Vf=g.dynCall_viiiiff=y.We)(a,b,c,d,e,f,h),Wf=g.dynCall_viiiiiiiiifiii=\n(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>(Wf=g.dynCall_viiiiiiiiifiii=y.Xe)(a,b,c,d,e,f,h,k,l,m,n,q,r,p),Xf=g.dynCall_viiiiiiiijj=(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(Xf=g.dynCall_viiiiiiiijj=y.Ye)(a,b,c,d,e,f,h,k,l,m,n,q,r),Yf=g.dynCall_iiiiiiiiiiiiiifii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z)=>(Yf=g.dynCall_iiiiiiiiiiiiiifii=y.Ze)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z),Zf=g.dynCall_viiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(Zf=g.dynCall_viiiiiiiiiiii=y._e)(a,b,c,d,e,f,h,k,l,m,n,q,r),$f=g.dynCall_ij=(a,b,c)=>($f=g.dynCall_ij=\ny.$e)(a,b,c),ag=g.dynCall_iiiiiiiiiiiiiiiiifii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D)=>(ag=g.dynCall_iiiiiiiiiiiiiiiiifii=y.af)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D),bg=g.dynCall_vijjiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q)=>(bg=g.dynCall_vijjiiiiii=y.bf)(a,b,c,d,e,f,h,k,l,m,n,q),cg=g.dynCall_iiiijjj=(a,b,c,d,e,f,h,k,l,m)=>(cg=g.dynCall_iiiijjj=y.cf)(a,b,c,d,e,f,h,k,l,m),dg=g.dynCall_viiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n)=>(dg=g.dynCall_viiiiiiiiii=y.df)(a,b,c,d,e,f,h,k,l,m,n),eg=g.dynCall_iiijjj=(a,b,\nc,d,e,f,h,k,l)=>(eg=g.dynCall_iiijjj=y.ef)(a,b,c,d,e,f,h,k,l),fg=g.dynCall_fffffff=(a,b,c,d,e,f,h)=>(fg=g.dynCall_fffffff=y.ff)(a,b,c,d,e,f,h),gg=g.dynCall_viiiij=(a,b,c,d,e,f,h)=>(gg=g.dynCall_viiiij=y.gf)(a,b,c,d,e,f,h),hg=g.dynCall_viijj=(a,b,c,d,e,f,h)=>(hg=g.dynCall_viijj=y.hf)(a,b,c,d,e,f,h),ig=g.dynCall_vjjjjjjffiifiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H)=>(ig=g.dynCall_vjjjjjjffiifiiiiii=y.jf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H),jg=g.dynCall_viiiiiiffiifiiiii=\n(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z)=>(jg=g.dynCall_viiiiiiffiifiiiii=y.kf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z),kg=g.dynCall_viiiiiiffifiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>(kg=g.dynCall_viiiiiiffifiiiii=y.lf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v),lg=g.dynCall_viiiiiiffiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)=>(lg=g.dynCall_viiiiiiffiiiiii=y.mf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t),mg=g.dynCall_vjjjjjjjjfffiifiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O,P)=>(mg=g.dynCall_vjjjjjjjjfffiifiiiiii=\ny.nf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O,P),ng=g.dynCall_vjjjjjjfffifiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I)=>(ng=g.dynCall_vjjjjjjfffifiiiiiii=y.of)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I),og=g.dynCall_vjjjjjjfffifiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G)=>(og=g.dynCall_vjjjjjjfffifiiiii=y.pf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G),pg=g.dynCall_vjjjjjjjjfffiifiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O)=>(pg=\ng.dynCall_vjjjjjjjjfffiifiiiii=y.qf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O),qg=g.dynCall_vijjfffiii=(a,b,c,d,e,f,h,k,l,m,n,q)=>(qg=g.dynCall_vijjfffiii=y.rf)(a,b,c,d,e,f,h,k,l,m,n,q),rg=g.dynCall_vijiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q)=>(rg=g.dynCall_vijiiiiiiii=y.sf)(a,b,c,d,e,f,h,k,l,m,n,q),sg=g.dynCall_vijjjjjjifiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E)=>(sg=g.dynCall_vijjjjjjifiiiii=y.tf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E),tg=g.dynCall_vjjjjjiiii=(a,b,c,d,e,f,h,\nk,l,m,n,q,r,p,t)=>(tg=g.dynCall_vjjjjjiiii=y.uf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t),ug=g.dynCall_vjjjjfiii=(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(ug=g.dynCall_vjjjjfiii=y.vf)(a,b,c,d,e,f,h,k,l,m,n,q,r),vg=g.dynCall_viifi=(a,b,c,d,e)=>(vg=g.dynCall_viifi=y.wf)(a,b,c,d,e),wg=g.dynCall_iiiiiji=(a,b,c,d,e,f,h,k)=>(wg=g.dynCall_iiiiiji=y.xf)(a,b,c,d,e,f,h,k),xg=g.dynCall_vijjii=(a,b,c,d,e,f,h,k)=>(xg=g.dynCall_vijjii=y.yf)(a,b,c,d,e,f,h,k),yg=g.dynCall_viiijiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q)=>(yg=g.dynCall_viiijiiiiii=\ny.zf)(a,b,c,d,e,f,h,k,l,m,n,q),zg=g.dynCall_viiiiijjiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)=>(zg=g.dynCall_viiiiijjiiiii=y.Af)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t),Ag=g.dynCall_iiiiji=(a,b,c,d,e,f,h)=>(Ag=g.dynCall_iiiiji=y.Bf)(a,b,c,d,e,f,h),Bg=g.dynCall_viiiiijiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>(Bg=g.dynCall_viiiiijiiiiii=y.Cf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p),Cg=g.dynCall_viiiijii=(a,b,c,d,e,f,h,k,l)=>(Cg=g.dynCall_viiiijii=y.Df)(a,b,c,d,e,f,h,k,l),Dg=g.dynCall_viijjiii=(a,b,c,d,e,f,h,k,l,m)=>(Dg=g.dynCall_viijjiii=\ny.Ef)(a,b,c,d,e,f,h,k,l,m),Eg=g.dynCall_ijii=(a,b,c,d,e)=>(Eg=g.dynCall_ijii=y.Ff)(a,b,c,d,e),Fg=g.dynCall_jjjjjjj=(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(Fg=g.dynCall_jjjjjjj=y.Gf)(a,b,c,d,e,f,h,k,l,m,n,q,r),Gg=g.dynCall_jjjjjj=(a,b,c,d,e,f,h,k,l,m,n)=>(Gg=g.dynCall_jjjjjj=y.Hf)(a,b,c,d,e,f,h,k,l,m,n),Hg=g.dynCall_vijjjjiij=(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>(Hg=g.dynCall_vijjjjiij=y.If)(a,b,c,d,e,f,h,k,l,m,n,q,r,p),Ig=g.dynCall_viiiiijij=(a,b,c,d,e,f,h,k,l,m,n)=>(Ig=g.dynCall_viiiiijij=y.Jf)(a,b,c,d,e,f,h,k,\nl,m,n),Jg=g.dynCall_viiiiiijij=(a,b,c,d,e,f,h,k,l,m,n,q)=>(Jg=g.dynCall_viiiiiijij=y.Kf)(a,b,c,d,e,f,h,k,l,m,n,q),Kg=g.dynCall_vijiii=(a,b,c,d,e,f,h)=>(Kg=g.dynCall_vijiii=y.Lf)(a,b,c,d,e,f,h),Lg=g.dynCall_viiiiiiiiifi=(a,b,c,d,e,f,h,k,l,m,n,q)=>(Lg=g.dynCall_viiiiiiiiifi=y.Mf)(a,b,c,d,e,f,h,k,l,m,n,q),Mg=g.dynCall_iiijiiii=(a,b,c,d,e,f,h,k,l)=>(Mg=g.dynCall_iiijiiii=y.Nf)(a,b,c,d,e,f,h,k,l),Ng=g.dynCall_viiiiiijjiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>(Ng=g.dynCall_viiiiiijjiiiii=y.Of)(a,b,c,d,\ne,f,h,k,l,m,n,q,r,p,t,v),Og=g.dynCall_viiiiiiijiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>(Og=g.dynCall_viiiiiiijiiiiii=y.Pf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v),Pg=g.dynCall_vif=(a,b,c)=>(Pg=g.dynCall_vif=y.Qf)(a,b,c),Qg=g.dynCall_viif=(a,b,c,d)=>(Qg=g.dynCall_viif=y.Rf)(a,b,c,d),Rg=g.dynCall_viiiiiifii=(a,b,c,d,e,f,h,k,l,m)=>(Rg=g.dynCall_viiiiiifii=y.Sf)(a,b,c,d,e,f,h,k,l,m),Sg=g.dynCall_viiiiijiiiiiiiiiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L)=>(Sg=g.dynCall_viiiiijiiiiiiiiiiiiiiiiiii=\ny.Tf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L),Tg=g.dynCall_viijji=(a,b,c,d,e,f,h,k)=>(Tg=g.dynCall_viijji=y.Uf)(a,b,c,d,e,f,h,k),Ug=g.dynCall_iiiiiiiiiiiji=(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>(Ug=g.dynCall_iiiiiiiiiiiji=y.Vf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p),Vg=g.dynCall_viifiifijjjii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>(Vg=g.dynCall_viifiifijjjii=y.Wf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v),Wg=g.dynCall_viiiiiiiiiiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E)=>(Wg=g.dynCall_viiiiiiiiiiiiiiiiiiii=\ny.Xf)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E),Xg=g.dynCall_iif=(a,b,c)=>(Xg=g.dynCall_iif=y.Yf)(a,b,c),Yg=g.dynCall_viiiiifiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(Yg=g.dynCall_viiiiifiiiiii=y.Zf)(a,b,c,d,e,f,h,k,l,m,n,q,r),Zg=g.dynCall_vijiiiiiiijjii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z)=>(Zg=g.dynCall_vijiiiiiiijjii=y._f)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z),$g=g.dynCall_iiiiid=(a,b,c,d,e,f)=>($g=g.dynCall_iiiiid=y.$f)(a,b,c,d,e,f),ah=g.dynCall_viiiijjj=(a,b,c,d,e,f,h,k,l,m,n)=>(ah=g.dynCall_viiiijjj=\ny.ag)(a,b,c,d,e,f,h,k,l,m,n),bh=g.dynCall_viiiiiiiiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C)=>(bh=g.dynCall_viiiiiiiiiiiiiiiiii=y.bg)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C),ch=g.dynCall_viiiiiiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z)=>(ch=g.dynCall_viiiiiiiiiiiiiiii=y.cg)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z),dh=g.dynCall_viiiiiiiiiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D)=>(dh=g.dynCall_viiiiiiiiiiiiiiiiiii=y.dg)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D),eh=g.dynCall_viiiiiiiiiiiiiii=\n(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>(eh=g.dynCall_viiiiiiiiiiiiiii=y.eg)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v),fh=g.dynCall_viiiiiiijjj=(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>(fh=g.dynCall_viiiiiiijjj=y.fg)(a,b,c,d,e,f,h,k,l,m,n,q,r,p),gh=g.dynCall_iiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n)=>(gh=g.dynCall_iiiiiiiiiii=y.gg)(a,b,c,d,e,f,h,k,l,m,n),hh=g.dynCall_iiiiiiiiiiiiiiiiiifi=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D)=>(hh=g.dynCall_iiiiiiiiiiiiiiiiiifi=y.hg)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D),ih=g.dynCall_viiif=\n(a,b,c,d,e)=>(ih=g.dynCall_viiif=y.ig)(a,b,c,d,e),jh=g.dynCall_iijjj=(a,b,c,d,e,f,h,k)=>(jh=g.dynCall_iijjj=y.jg)(a,b,c,d,e,f,h,k),kh=g.dynCall_viiiiji=(a,b,c,d,e,f,h,k)=>(kh=g.dynCall_viiiiji=y.kg)(a,b,c,d,e,f,h,k),lh=g.dynCall_iijjji=(a,b,c,d,e,f,h,k,l)=>(lh=g.dynCall_iijjji=y.lg)(a,b,c,d,e,f,h,k,l),mh=g.dynCall_ijijji=(a,b,c,d,e,f,h,k,l)=>(mh=g.dynCall_ijijji=y.mg)(a,b,c,d,e,f,h,k,l),nh=g.dynCall_viiij=(a,b,c,d,e,f)=>(nh=g.dynCall_viiij=y.ng)(a,b,c,d,e,f),oh=g.dynCall_viiijjiii=(a,b,c,d,e,f,h,\nk,l,m,n)=>(oh=g.dynCall_viiijjiii=y.og)(a,b,c,d,e,f,h,k,l,m,n),ph=g.dynCall_iiiiijji=(a,b,c,d,e,f,h,k,l,m)=>(ph=g.dynCall_iiiiijji=y.pg)(a,b,c,d,e,f,h,k,l,m),qh=g.dynCall_viji=(a,b,c,d,e)=>(qh=g.dynCall_viji=y.qg)(a,b,c,d,e),rh=g.dynCall_iiiifi=(a,b,c,d,e,f)=>(rh=g.dynCall_iiiifi=y.rg)(a,b,c,d,e,f),sh=g.dynCall_iiijii=(a,b,c,d,e,f,h)=>(sh=g.dynCall_iiijii=y.sg)(a,b,c,d,e,f,h),th=g.dynCall_iiiiiiiiijii=(a,b,c,d,e,f,h,k,l,m,n,q,r)=>(th=g.dynCall_iiiiiiiiijii=y.tg)(a,b,c,d,e,f,h,k,l,m,n,q,r),uh=g.dynCall_iiiijjii=\n(a,b,c,d,e,f,h,k,l,m)=>(uh=g.dynCall_iiiijjii=y.ug)(a,b,c,d,e,f,h,k,l,m),vh=g.dynCall_iiiiiijjjii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>(vh=g.dynCall_iiiiiijjjii=y.vg)(a,b,c,d,e,f,h,k,l,m,n,q,r,p),wh=g.dynCall_iiijiii=(a,b,c,d,e,f,h,k)=>(wh=g.dynCall_iiijiii=y.wg)(a,b,c,d,e,f,h,k),xh=g.dynCall_iiiiiiiijjjfi=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)=>(xh=g.dynCall_iiiiiiiijjjfi=y.xg)(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v),yh=g.dynCall_iijiiii=(a,b,c,d,e,f,h,k)=>(yh=g.dynCall_iijiiii=y.yg)(a,b,c,d,e,f,h,k),zh=g.dynCall_iijjjii=\n(a,b,c,d,e,f,h,k,l,m)=>(zh=g.dynCall_iijjjii=y.zg)(a,b,c,d,e,f,h,k,l,m),Ah=g.dynCall_iiji=(a,b,c,d,e)=>(Ah=g.dynCall_iiji=y.Ag)(a,b,c,d,e),Bh=g.dynCall_viiijiiiii=(a,b,c,d,e,f,h,k,l,m,n)=>(Bh=g.dynCall_viiijiiiii=y.Bg)(a,b,c,d,e,f,h,k,l,m,n),Ch=g.dynCall_iid=(a,b,c)=>(Ch=g.dynCall_iid=y.Cg)(a,b,c),Dh=g.dynCall_iiif=(a,b,c,d)=>(Dh=g.dynCall_iiif=y.Dg)(a,b,c,d),Eh=g.dynCall_vidi=(a,b,c,d)=>(Eh=g.dynCall_vidi=y.Eg)(a,b,c,d),Fh=g.dynCall_vjiii=(a,b,c,d,e,f)=>(Fh=g.dynCall_vjiii=y.Fg)(a,b,c,d,e,f),Gh=\ng.dynCall_iiiij=(a,b,c,d,e,f)=>(Gh=g.dynCall_iiiij=y.Gg)(a,b,c,d,e,f),Hh=g.dynCall_viiijii=(a,b,c,d,e,f,h,k)=>(Hh=g.dynCall_viiijii=y.Hg)(a,b,c,d,e,f,h,k),Ih=g.dynCall_viijiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p)=>(Ih=g.dynCall_viijiiiiiiiii=y.Ig)(a,b,c,d,e,f,h,k,l,m,n,q,r,p),Jh=g.dynCall_fiiii=(a,b,c,d,e)=>(Jh=g.dynCall_fiiii=y.Jg)(a,b,c,d,e),Kh=g.dynCall_jfi=(a,b,c)=>(Kh=g.dynCall_jfi=y.Kg)(a,b,c),Lh=g.dynCall_viiiiiiiiiiiiii=(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)=>(Lh=g.dynCall_viiiiiiiiiiiiii=y.Lg)(a,\nb,c,d,e,f,h,k,l,m,n,q,r,p,t),Mh=g.dynCall_jiij=(a,b,c,d,e)=>(Mh=g.dynCall_jiij=y.Mg)(a,b,c,d,e),Nh=g.dynCall_fiii=(a,b,c,d)=>(Nh=g.dynCall_fiii=y.Ng)(a,b,c,d),zb=a=>(zb=y.Og)(a),pb=()=>(pb=y.Pg)(),yb=a=>(yb=y.Qg)(a),Ab=()=>(Ab=y.Rg)();g.___start_em_js=1347937;g.___stop_em_js=1348098;function Sb(a,b,c,d){var e=W();try{return Ne(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}function Qb(a,b,c){var d=W();try{return dynCall_iii(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}\nfunction Yc(a,b,c){var d=W();try{dynCall_vii(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function Nb(a,b){var c=W();try{return Oe(a,b)}catch(d){X(c);if(d!==d+0)throw d;V(1,0)}}function Uc(a,b){var c=W();try{dynCall_vi(a,b)}catch(d){X(c);if(d!==d+0)throw d;V(1,0)}}function Sc(a){var b=W();try{dynCall_v(a)}catch(c){X(b);if(c!==c+0)throw c;V(1,0)}}function Xb(a,b,c,d,e,f,h){var k=W();try{return Pe(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}\nfunction Wb(a,b,c,d,e,f){var h=W();try{return Qe(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function Ub(a,b,c,d,e){var f=W();try{return Se(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function ed(a,b,c,d){var e=W();try{Te(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}function hd(a,b,c,d,e){var f=W();try{$e(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function Mb(a){var b=W();try{return Ve(a)}catch(c){X(b);if(c!==c+0)throw c;V(1,0)}}\nfunction kd(a,b,c,d,e,f){var h=W();try{Ze(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function Yb(a,b,c,d,e,f,h,k){var l=W();try{return af(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function Ib(a,b){var c=W();try{return bf(a,b)}catch(d){X(c);if(d!==d+0)throw d;V(1,0)}}function Fb(a,b){var c=W();try{return ef(a,b)}catch(d){X(c);if(d!==d+0)throw d;V(1,0)}}function Zb(a,b,c,d,e,f,h,k,l){var m=W();try{return hf(a,b,c,d,e,f,h,k,l)}catch(n){X(m);if(n!==n+0)throw n;V(1,0)}}\nfunction od(a,b,c,d,e,f,h){var k=W();try{kf(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}function td(a,b,c,d,e,f,h,k){var l=W();try{mf(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function $b(a,b,c,d,e,f,h,k,l,m){var n=W();try{return nf(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}function ud(a,b,c,d,e,f,h,k,l){var m=W();try{of(a,b,c,d,e,f,h,k,l)}catch(n){X(m);if(n!==n+0)throw n;V(1,0)}}\nfunction vd(a,b,c,d,e,f,h,k,l,m){var n=W();try{uf(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}function Zc(a,b,c,d){var e=W();try{vf(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}function bc(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{return xf(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}function Cd(a,b,c,d,e,f,h,k,l,m,n,q,r,p){var t=W();try{yf(a,b,c,d,e,f,h,k,l,m,n,q,r,p)}catch(v){X(t);if(v!==v+0)throw v;V(1,0)}}\nfunction Xc(a,b,c,d,e,f,h){var k=W();try{Bf(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}function dd(a,b,c,d,e,f,h){var k=W();try{Df(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}function ld(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{Ef(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}function fd(a,b,c,d,e){var f=W();try{If(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}\nfunction Lb(a,b,c,d,e){var f=W();try{return Jh(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function yd(a,b,c,d,e,f,h,k,l,m,n,q,r,p){var t=W();try{Wf(a,b,c,d,e,f,h,k,l,m,n,q,r,p)}catch(v){X(t);if(v!==v+0)throw v;V(1,0)}}function Tc(a,b,c,d,e){var f=W();try{Uf(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function jd(a,b,c,d,e,f,h){var k=W();try{Vf(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}\nfunction ad(a,b,c,d,e){var f=W();try{Sf(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function md(a,b,c,d,e,f,h,k){var l=W();try{Tf(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function cc(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z){var B=W();try{return Yf(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z)}catch(C){X(B);if(C!==C+0)throw C;V(1,0)}}function Bd(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{Zf(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}\nfunction dc(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D){var E=W();try{return ag(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D)}catch(F){X(E);if(F!==F+0)throw F;V(1,0)}}function zd(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{dg(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}function qd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z){var B=W();try{jg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z)}catch(C){X(B);if(C!==C+0)throw C;V(1,0)}}\nfunction pd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v){var z=W();try{kg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)}catch(B){X(z);if(B!==B+0)throw B;V(1,0)}}function rd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t){var v=W();try{lg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)}catch(z){X(v);if(z!==z+0)throw z;V(1,0)}}function Hb(a,b,c,d,e,f,h){var k=W();try{return fg(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}function bd(a,b,c,d,e){var f=W();try{vg(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}\nfunction xd(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{Lg(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}function Dd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t){var v=W();try{Lh(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)}catch(z){X(v);if(z!==z+0)throw z;V(1,0)}}function Wc(a,b,c){var d=W();try{Pg(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function sd(a,b,c,d,e,f,h,k,l,m){var n=W();try{Rg(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}\nfunction Ad(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{Jf(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}function Id(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E){var F=W();try{Wg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E)}catch(G){X(F);if(G!==G+0)throw G;V(1,0)}}function Pb(a,b,c){var d=W();try{return Xg(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function nd(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{Yg(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}\nfunction Fd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z){var B=W();try{ch(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z)}catch(C){X(B);if(C!==C+0)throw C;V(1,0)}}function Hd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D){var E=W();try{dh(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D)}catch(F){X(E);if(F!==F+0)throw F;V(1,0)}}function Gd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C){var D=W();try{bh(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C)}catch(E){X(D);if(E!==E+0)throw E;V(1,0)}}\nfunction ac(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{return gh(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}function ec(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D){var E=W();try{return hh(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D)}catch(F){X(E);if(F!==F+0)throw F;V(1,0)}}function gd(a,b,c,d,e){var f=W();try{ih(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function wd(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{Ff(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}\nfunction $c(a,b,c,d){var e=W();try{Qg(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}function Tb(a,b,c,d,e,f){var h=W();try{return rh(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function Ob(a,b,c){var d=W();try{return Ch(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function Rb(a,b,c,d){var e=W();try{return Dh(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}function Vc(a,b,c,d){var e=W();try{Eh(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}\nfunction Kb(a,b,c,d){var e=W();try{return Nh(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}function Vb(a,b,c,d,e,f){var h=W();try{return $g(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function Ed(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v){var z=W();try{eh(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)}catch(B){X(z);if(B!==B+0)throw B;V(1,0)}}function Jb(a,b,c){var d=W();try{return cf(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}\nfunction Gb(a,b,c){var d=W();try{return gf(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function sc(a,b,c,d,e){var f=W();try{return Re(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function Ac(a,b,c,d){var e=W();try{return We(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}function me(a,b,c,d){var e=W();try{Ye(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}function Lc(a,b){var c=W();try{return df(a,b)}catch(d){X(c);if(d!==d+0)throw d;V(1,0)}}\nfunction ee(a,b,c,d,e){var f=W();try{jf(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function re(a,b,c,d,e,f){var h=W();try{lf(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function Zd(a,b,c,d,e,f,h,k){var l=W();try{Hh(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function ie(a,b,c,d,e,f,h){var k=W();try{hg(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}\nfunction mc(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{return pf(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}function ve(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{qf(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}function ge(a,b,c,d,e,f,h,k){var l=W();try{sf(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function Od(a,b,c,d,e,f,h,k){var l=W();try{tf(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}\nfunction Mc(a,b,c){var d=W();try{return ff(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function hc(a,b,c,d,e,f,h,k,l,m){var n=W();try{return wf(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}function le(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t){var v=W();try{zf(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)}catch(z){X(v);if(z!==z+0)throw z;V(1,0)}}function be(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{Af(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}\nfunction fe(a,b,c,d,e,f){var h=W();try{rf(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function de(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{Cf(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}function Ce(a,b,c,d,e,f,h,k,l){var m=W();try{Gf(a,b,c,d,e,f,h,k,l)}catch(n){X(m);if(n!==n+0)throw n;V(1,0)}}function Nc(a,b,c,d){var e=W();try{return Hf(a,b,c,d)}catch(f){X(e);if(f!==f+0)throw f;V(1,0)}}\nfunction ze(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O,P){var Y=W();try{Kf(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O,P)}catch(Z){X(Y);if(Z!==Z+0)throw Z;V(1,0)}}function Yd(a,b,c,d,e,f,h){var k=W();try{Lf(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}function we(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{Mf(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}\nfunction tc(a,b,c,d,e,f){var h=W();try{return Nf(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function yc(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t){var v=W();try{return Of(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)}catch(z){X(v);if(z!==z+0)throw z;V(1,0)}}function Ae(a,b,c){var d=W();try{Pf(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function Pc(a,b,c,d,e){var f=W();try{return Qf(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}\nfunction xc(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{return Rf(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}function Jd(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{Xf(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}function Gc(a,b,c){var d=W();try{return $f(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function ue(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{bg(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}\nfunction rc(a,b,c,d,e,f,h,k,l,m){var n=W();try{return cg(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}function zc(a,b,c,d,e,f,h,k,l){var m=W();try{return eg(a,b,c,d,e,f,h,k,l)}catch(n){X(m);if(n!==n+0)throw n;V(1,0)}}function Td(a,b,c,d,e,f,h){var k=W();try{gg(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}\nfunction He(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H){var I=W();try{ig(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H)}catch(J){X(I);if(J!==J+0)throw J;V(1,0)}}function Je(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O,P){var Y=W();try{mg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O,P)}catch(Z){X(Y);if(Z!==Z+0)throw Z;V(1,0)}}\nfunction Ge(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I){var J=W();try{ng(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I)}catch(L){X(J);if(L!==L+0)throw L;V(1,0)}}function Fe(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G){var H=W();try{og(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G)}catch(I){X(H);if(I!==I+0)throw I;V(1,0)}}\nfunction Ie(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O){var P=W();try{pg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L,O)}catch(Y){X(P);if(Y!==Y+0)throw Y;V(1,0)}}function se(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{qg(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}function pe(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{rg(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}\nfunction ye(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E){var F=W();try{sg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E)}catch(G){X(F);if(G!==G+0)throw G;V(1,0)}}function Ee(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t){var v=W();try{tg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)}catch(z){X(v);if(z!==z+0)throw z;V(1,0)}}function De(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{ug(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}\nfunction Kc(a,b,c){var d=W();try{return Kh(a,b,c)}catch(e){X(d);if(e!==e+0)throw e;V(1,0)}}function lc(a,b,c,d,e,f,h,k){var l=W();try{return wg(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function te(a,b,c,d,e,f,h,k){var l=W();try{xg(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function ae(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{yg(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}\nfunction Sd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t){var v=W();try{zg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t)}catch(z){X(v);if(z!==z+0)throw z;V(1,0)}}function pc(a,b,c,d,e,f,h){var k=W();try{return Ag(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}function Pd(a,b,c,d,e,f,h,k,l,m,n,q,r,p){var t=W();try{Bg(a,b,c,d,e,f,h,k,l,m,n,q,r,p)}catch(v){X(t);if(v!==v+0)throw v;V(1,0)}}function Vd(a,b,c,d,e,f,h,k,l){var m=W();try{Cg(a,b,c,d,e,f,h,k,l)}catch(n){X(m);if(n!==n+0)throw n;V(1,0)}}\nfunction ke(a,b,c,d,e,f,h,k,l,m){var n=W();try{Dg(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}function Hc(a,b,c,d,e){var f=W();try{return Eg(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function Qc(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{return Gg(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}function Rc(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{return Fg(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}\nfunction xe(a,b,c,d,e,f,h,k,l,m,n,q,r,p){var t=W();try{Hg(a,b,c,d,e,f,h,k,l,m,n,q,r,p)}catch(v){X(t);if(v!==v+0)throw v;V(1,0)}}function Rd(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{Ig(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}function Md(a,b,c,d,e,f,h,k,l,m,n,q){var r=W();try{Jg(a,b,c,d,e,f,h,k,l,m,n,q)}catch(p){X(r);if(p!==p+0)throw p;V(1,0)}}function oe(a,b,c,d,e,f,h){var k=W();try{Kg(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}\nfunction wc(a,b,c,d,e,f,h,k,l){var m=W();try{return Mg(a,b,c,d,e,f,h,k,l)}catch(n){X(m);if(n!==n+0)throw n;V(1,0)}}function Nd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v){var z=W();try{Ng(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)}catch(B){X(z);if(B!==B+0)throw B;V(1,0)}}function Kd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v){var z=W();try{Og(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)}catch(B){X(z);if(B!==B+0)throw B;V(1,0)}}\nfunction Qd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L){var O=W();try{Sg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z,B,C,D,E,F,G,H,I,J,L)}catch(P){X(O);if(P!==P+0)throw P;V(1,0)}}function je(a,b,c,d,e,f,h,k){var l=W();try{Tg(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function fc(a,b,c,d,e,f,h,k,l,m,n,q,r,p){var t=W();try{return Ug(a,b,c,d,e,f,h,k,l,m,n,q,r,p)}catch(v){X(t);if(v!==v+0)throw v;V(1,0)}}\nfunction cd(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v){var z=W();try{Vg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)}catch(B){X(z);if(B!==B+0)throw B;V(1,0)}}function qe(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z){var B=W();try{Zg(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v,z)}catch(C){X(B);if(C!==C+0)throw C;V(1,0)}}function Wd(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{ah(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}\nfunction Ld(a,b,c,d,e,f,h,k,l,m,n,q,r,p){var t=W();try{fh(a,b,c,d,e,f,h,k,l,m,n,q,r,p)}catch(v){X(t);if(v!==v+0)throw v;V(1,0)}}function Dc(a,b,c,d,e,f,h,k){var l=W();try{return jh(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function Oc(a,b,c,d,e){var f=W();try{return Mh(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function Ud(a,b,c,d,e,f,h,k){var l=W();try{kh(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}\nfunction Ec(a,b,c,d,e,f,h,k,l){var m=W();try{return lh(a,b,c,d,e,f,h,k,l)}catch(n){X(m);if(n!==n+0)throw n;V(1,0)}}function Ic(a,b,c,d,e,f,h,k,l){var m=W();try{return mh(a,b,c,d,e,f,h,k,l)}catch(n){X(m);if(n!==n+0)throw n;V(1,0)}}function Xd(a,b,c,d,e,f){var h=W();try{nh(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function ce(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{oh(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}\nfunction nc(a,b,c,d,e,f,h,k,l,m){var n=W();try{return ph(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}function ne(a,b,c,d,e){var f=W();try{qh(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}function uc(a,b,c,d,e,f,h){var k=W();try{return sh(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}function gc(a,b,c,d,e,f,h,k,l,m,n,q,r){var p=W();try{return th(a,b,c,d,e,f,h,k,l,m,n,q,r)}catch(t){X(p);if(t!==t+0)throw t;V(1,0)}}\nfunction qc(a,b,c,d,e,f,h,k,l,m){var n=W();try{return uh(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}function jc(a,b,c,d,e,f,h,k,l,m,n,q,r,p){var t=W();try{return vh(a,b,c,d,e,f,h,k,l,m,n,q,r,p)}catch(v){X(t);if(v!==v+0)throw v;V(1,0)}}function vc(a,b,c,d,e,f,h,k){var l=W();try{return wh(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}\nfunction ic(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v){var z=W();try{return xh(a,b,c,d,e,f,h,k,l,m,n,q,r,p,t,v)}catch(B){X(z);if(B!==B+0)throw B;V(1,0)}}function Cc(a,b,c,d,e,f,h,k){var l=W();try{return yh(a,b,c,d,e,f,h,k)}catch(m){X(l);if(m!==m+0)throw m;V(1,0)}}function Fc(a,b,c,d,e,f,h,k,l,m){var n=W();try{return zh(a,b,c,d,e,f,h,k,l,m)}catch(q){X(n);if(q!==q+0)throw q;V(1,0)}}function Bc(a,b,c,d,e){var f=W();try{return Ah(a,b,c,d,e)}catch(h){X(f);if(h!==h+0)throw h;V(1,0)}}\nfunction $d(a,b,c,d,e,f,h,k,l,m,n){var q=W();try{Bh(a,b,c,d,e,f,h,k,l,m,n)}catch(r){X(q);if(r!==r+0)throw r;V(1,0)}}function he(a,b,c,d,e,f,h,k,l,m,n,q,r,p){var t=W();try{Ih(a,b,c,d,e,f,h,k,l,m,n,q,r,p)}catch(v){X(t);if(v!==v+0)throw v;V(1,0)}}function Be(a,b,c,d,e,f){var h=W();try{Fh(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}function oc(a,b,c,d,e,f){var h=W();try{return Gh(a,b,c,d,e,f)}catch(k){X(h);if(k!==k+0)throw k;V(1,0)}}\nfunction Jc(a){var b=W();try{return Ue(a)}catch(c){X(b);if(c!==c+0)throw c;V(1,0)}}function kc(a,b,c,d,e,f,h){var k=W();try{return Xe(a,b,c,d,e,f,h)}catch(l){X(k);if(l!==l+0)throw l;V(1,0)}}function Le(a){a=Object.assign({},a);var b=d=>()=>d()>>>0,c=d=>e=>d(e)>>>0;a.__errno_location=b(a.__errno_location);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}g.stackAlloc=Me;g.stackSave=W;g.stackRestore=X;g.UTF8ToString=S;g.stringToUTF8=(a,b,c)=>Xa(a,M,b,c);\ng.lengthBytesUTF8=Wa;var Oh;Ba=function Ph(){Oh||Qh();Oh||(Ba=Ph)};\nfunction Qh(){function a(){if(!Oh&&(Oh=!0,g.calledRun=!0,!A)){Ma(xa);aa(g);if(g.onRuntimeInitialized)g.onRuntimeInitialized();if(g.postRun)for(\"function\"==typeof g.postRun&&(g.postRun=[g.postRun]);g.postRun.length;){var b=g.postRun.shift();ya.unshift(b)}Ma(ya)}}if(!(0<R)){if(g.preRun)for(\"function\"==typeof g.preRun&&(g.preRun=[g.preRun]);g.preRun.length;)za();Ma(wa);0<R||(g.setStatus?(g.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){g.setStatus(\"\")},1);a()},1)):a())}}\nif(g.preInit)for(\"function\"==typeof g.preInit&&(g.preInit=[g.preInit]);0<g.preInit.length;)g.preInit.pop()();Qh();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasm;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasm);\n", "", "", "export const cpus = undefined;", "\nvar ortWasmThreaded = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nfunction d(){l.buffer!=p.buffer&&u();return p}function v(){l.buffer!=p.buffer&&u();return aa}function z(){l.buffer!=p.buffer&&u();return ba}function A(){l.buffer!=p.buffer&&u();return ca}function da(){l.buffer!=p.buffer&&u();return ea}function fa(){l.buffer!=p.buffer&&u();return ha}var B=moduleArg,ia,C;B.ready=new Promise((a,b)=>{ia=a;C=b});\"use strict\";\nB.jsepInit=(a,b,c,e,f,h,k,q)=>{B.Qb=a;B.wb=b;B.yb=c;B.jb=e;B.xb=f;B.Ea=h;B.zb=k;B.Ab=q;b=(m,n,r)=>(...w)=>{const y=D,g=n?.();w=m(...w);const t=n?.();g!==t&&(m=t,r(g),n=r=null);return D!=y?ja():w};c=m=>async(...n)=>{try{if(B.bb)throw Error(\"Session already started\");const r=B.bb={Fb:n[0],errors:[]},w=await m(...n);if(B.bb!==r)throw Error(\"Session mismatch\");a.flush();const y=r.errors;if(0<y.length){let g=await Promise.all(y);g=g.filter(t=>t);if(0<g.length)throw Error(g.join(\"\\n\"));}return w}finally{B.bb=\nnull}};B._OrtRun=c(b(B._OrtRun,()=>B._OrtRun,m=>B._OrtRun=m));B._OrtRunWithBinding=c(b(B._OrtRunWithBinding,()=>B._OrtRunWithBinding,m=>B._OrtRunWithBinding=m));B._OrtBindInput=b(B._OrtBindInput,()=>B._OrtBindInput,m=>B._OrtBindInput=m);B.jsepRegisterBuffer=(m,n,r,w)=>a.registerBuffer(m,n,r,w);B.jsepUnregisterBuffers=m=>{a.unregisterBuffers(m)};B.jsepGetBuffer=m=>a.getBuffer(m);B.jsepCreateDownloader=(m,n,r)=>a.createDownloader(m,n,r)};\nvar ka=Object.assign({},B),la=\"./this.program\",E=(a,b)=>{throw b;},ma=\"object\"==typeof window,F=\"function\"==typeof importScripts,G=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,H=B.ENVIRONMENT_IS_PTHREAD||!1,I=\"\";function na(a){return B.locateFile?B.locateFile(a,I):I+a}var oa,J,pa;\nif(G){var fs=require(\"fs\"),qa=require(\"path\");I=F?qa.dirname(I)+\"/\":__dirname+\"/\";oa=(b,c)=>{b=b.startsWith(\"file://\")?new URL(b):qa.normalize(b);return fs.readFileSync(b,c?void 0:\"utf8\")};pa=b=>{b=oa(b,!0);b.buffer||(b=new Uint8Array(b));return b};J=(b,c,e,f=!0)=>{b=b.startsWith(\"file://\")?new URL(b):qa.normalize(b);fs.readFile(b,f?void 0:\"utf8\",(h,k)=>{h?e(h):c(f?k.buffer:k)})};!B.thisProgram&&1<process.argv.length&&(la=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);E=(b,c)=>{process.exitCode=\nb;throw c;};B.inspect=()=>\"[Emscripten Module object]\";let a;try{a=require(\"worker_threads\")}catch(b){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),b;}global.Worker=a.Worker}else if(ma||F)F?I=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(I=document.currentScript.src),(typeof _scriptDir !== \"undefined\" && _scriptDir)&&(I=_scriptDir),0!==I.indexOf(\"blob:\")?I=I.substr(0,I.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):I=\"\",G||(oa=a=>{var b=\nnew XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},F&&(pa=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),J=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)});G&&\"undefined\"==typeof performance&&(global.performance=require(\"perf_hooks\").performance);\nvar ra=console.log.bind(console),sa=console.error.bind(console);G&&(ra=(...a)=>fs.writeSync(1,a.join(\" \")+\"\\n\"),sa=(...a)=>fs.writeSync(2,a.join(\" \")+\"\\n\"));var ta=B.print||ra,K=B.printErr||sa;Object.assign(B,ka);ka=null;B.thisProgram&&(la=B.thisProgram);B.quit&&(E=B.quit);var L;B.wasmBinary&&(L=B.wasmBinary);var noExitRuntime=B.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&M(\"no native wasm support detected\");var l,N,ua,P=!1,Q,p,aa,ba,ca,ea,ha;\nfunction u(){var a=l.buffer;B.HEAP8=p=new Int8Array(a);B.HEAP16=new Int16Array(a);B.HEAP32=ba=new Int32Array(a);B.HEAPU8=aa=new Uint8Array(a);B.HEAPU16=new Uint16Array(a);B.HEAPU32=ca=new Uint32Array(a);B.HEAPF32=ea=new Float32Array(a);B.HEAPF64=ha=new Float64Array(a)}var va=B.INITIAL_MEMORY||16777216;5242880<=va||M(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+va+\"! (STACK_SIZE=5242880)\");\nif(H)l=B.wasmMemory;else if(B.wasmMemory)l=B.wasmMemory;else if(l=new WebAssembly.Memory({initial:va/65536,maximum:65536,shared:!0}),!(l.buffer instanceof SharedArrayBuffer))throw K(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),G&&K(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),\nError(\"bad memory\");u();va=l.buffer.byteLength;var wa=[],xa=[],ya=[],za=0;function Aa(){return noExitRuntime||0<za}var R=0,Ba=null,S=null;function Ca(){R++;B.monitorRunDependencies&&B.monitorRunDependencies(R)}function Da(){R--;B.monitorRunDependencies&&B.monitorRunDependencies(R);if(0==R&&(null!==Ba&&(clearInterval(Ba),Ba=null),S)){var a=S;S=null;a()}}\nfunction M(a){if(B.onAbort)B.onAbort(a);a=\"Aborted(\"+a+\")\";K(a);P=!0;Q=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");C(a);throw a;}function Ea(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var T;T=\"ort-wasm-simd-threaded.wasm\";Ea(T)||(T=na(T));function Fa(a){if(a==T&&L)return new Uint8Array(L);if(pa)return pa(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction Ga(a){if(!L&&(ma||F)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>Fa(a));if(J)return new Promise((b,c)=>{J(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>Fa(a))}function Ha(a,b,c){return Ga(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{K(\"failed to asynchronously prepare wasm: \"+e);M(e)})}\nfunction Ia(a,b){var c=T;return L||\"function\"!=typeof WebAssembly.instantiateStreaming||Ea(c)||c.startsWith(\"file://\")||G||\"function\"!=typeof fetch?Ha(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){K(\"wasm streaming compile failed: \"+f);K(\"falling back to ArrayBuffer instantiation\");return Ha(c,a,b)}))}\nvar U,Ja={913596:a=>{B.Ea(\"Abs\",a,void 0)},913647:a=>{B.Ea(\"Neg\",a,void 0)},913698:a=>{B.Ea(\"Floor\",a,void 0)},913751:a=>{B.Ea(\"Ceil\",a,void 0)},913803:a=>{B.Ea(\"Reciprocal\",a,void 0)},913861:a=>{B.Ea(\"Sqrt\",a,void 0)},913913:a=>{B.Ea(\"Exp\",a,void 0)},913964:a=>{B.Ea(\"Erf\",a,void 0)},914015:a=>{B.Ea(\"Sigmoid\",a,void 0)},914070:a=>{B.Ea(\"Log\",a,void 0)},914121:a=>{B.Ea(\"Sin\",a,void 0)},914172:a=>{B.Ea(\"Cos\",a,void 0)},914223:a=>{B.Ea(\"Tan\",a,void 0)},914274:a=>{B.Ea(\"Asin\",a,void 0)},914326:a=>{B.Ea(\"Acos\",\na,void 0)},914378:a=>{B.Ea(\"Atan\",a,void 0)},914430:a=>{B.Ea(\"Sinh\",a,void 0)},914482:a=>{B.Ea(\"Cosh\",a,void 0)},914534:a=>{B.Ea(\"Asinh\",a,void 0)},914587:a=>{B.Ea(\"Acosh\",a,void 0)},914640:a=>{B.Ea(\"Atanh\",a,void 0)},914693:a=>{B.Ea(\"Tanh\",a,void 0)},914745:a=>{B.Ea(\"Not\",a,void 0)},914796:(a,b,c)=>{B.Ea(\"Clip\",a,{min:b,max:c})},914865:a=>{B.Ea(\"Clip\",a,void 0)},914917:(a,b)=>{B.Ea(\"Elu\",a,{alpha:b})},914975:a=>{B.Ea(\"Relu\",a,void 0)},915027:(a,b)=>{B.Ea(\"LeakyRelu\",a,{alpha:b})},915091:(a,b)=>{B.Ea(\"ThresholdedRelu\",\na,{alpha:b})},915161:(a,b)=>{B.Ea(\"Cast\",a,{to:b})},915219:a=>{B.Ea(\"Add\",a,void 0)},915270:a=>{B.Ea(\"Sub\",a,void 0)},915321:a=>{B.Ea(\"Mul\",a,void 0)},915372:a=>{B.Ea(\"Div\",a,void 0)},915423:a=>{B.Ea(\"Pow\",a,void 0)},915474:a=>{B.Ea(\"Equal\",a,void 0)},915527:a=>{B.Ea(\"Greater\",a,void 0)},915582:a=>{B.Ea(\"GreaterOrEqual\",a,void 0)},915644:a=>{B.Ea(\"Less\",a,void 0)},915696:a=>{B.Ea(\"LessOrEqual\",a,void 0)},915755:(a,b,c,e,f)=>{B.Ea(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>\n0,f+e>>>0)):[]})},915919:(a,b,c,e,f)=>{B.Ea(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},916082:(a,b,c,e,f)=>{B.Ea(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},916245:(a,b,c,e,f)=>{B.Ea(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},916409:(a,b,c,e,f)=>{B.Ea(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>\n0,f+e>>>0)):[]})},916572:(a,b,c,e,f)=>{B.Ea(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},916734:(a,b,c,e,f)=>{B.Ea(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},916896:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},917062:(a,b,c,e,f)=>{B.Ea(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>\n0,f+e>>>0)):[]})},917231:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},917400:a=>{B.Ea(\"Where\",a,void 0)},917453:(a,b,c)=>{B.Ea(\"Transpose\",a,{perm:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[]})},917566:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t)=>{B.Ea(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],wIsConst:()=>!!d()[n>>>0],outputPadding:r?Array.from(z().subarray(w>>>\n0,w+r>>>0)):[],outputShape:y?Array.from(z().subarray(g>>>0,g+y>>>0)):[],activation:V(t)})},917980:(a,b,c,e,f,h,k,q,m,n,r,w,y,g)=>{B.Ea(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[m>>>0],outputPadding:0<n?Array.from(z().subarray(r>>>0,r+n>>>0)):[],outputShape:0<w?Array.from(z().subarray(y>>>\n0,y+w>>>0)):[],activation:V(g)})},918537:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t)=>{B.Ea(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],wIsConst:()=>!!d()[n>>>0],outputPadding:r?Array.from(z().subarray(w>>>0,w+r>>>0)):[],outputShape:y?Array.from(z().subarray(g>>>0,g+y>>>0)):[],activation:V(t)})},918951:(a,b,c,e,f,h,k,q,m,n,r,w,y,g)=>{B.Ea(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>0,c+2>>>0)),\ngroup:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[m>>>0],outputPadding:0<n?Array.from(z().subarray(r>>>0,r+n>>>0)):[],outputShape:0<w?Array.from(z().subarray(y>>>0,y+w>>>0)):[],activation:V(g)})},919508:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},919599:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"AveragePool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,\nstorage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,t]})},919883:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},919974:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"AveragePool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,t]})},920258:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},920345:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"MaxPool\",a,{format:x?\n\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,t]})},920625:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},920712:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"MaxPool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,t]})},920992:(a,b,c,e,f)=>{B.Ea(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:f})},921096:a=>{B.Ea(\"MatMul\",\na,void 0)},921150:(a,b,c,e)=>{B.Ea(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},921258:(a,b,c,e)=>{B.Ea(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},921366:(a,b)=>{B.Ea(\"Softmax\",a,{axis:b})},921429:(a,b)=>{B.Ea(\"Concat\",a,{axis:b})},921489:(a,b,c,e,f)=>{B.Ea(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},921634:a=>{B.Ea(\"Expand\",a,void 0)},921688:(a,b)=>{B.Ea(\"Gather\",a,{axis:Number(b)})},921759:(a,b)=>{B.Ea(\"GatherElements\",a,{axis:Number(b)})},\n921838:(a,b,c,e,f,h,k,q,m,n,r)=>{B.Ea(\"Resize\",a,{antialias:b,axes:c?Array.from(z().subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:V(f),cubicCoeffA:h,excludeOutside:k,extrapolationValue:q,keepAspectRatioPolicy:V(m),mode:V(n),nearestMode:V(r)})},922189:(a,b,c,e,f,h,k)=>{B.Ea(\"Slice\",a,{starts:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[],axes:h?Array.from(z().subarray(k>>>0,k+h>>>0)):[]})},922420:a=>{B.Ea(\"Tile\",a,void 0)},922472:(a,b,c)=>{B.Ea(\"LayerNormalization\",\na,{axis:Number(b),epsilon:Number(c)})},922579:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},922693:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},922807:a=>{B.Ea(\"Range\",a,void 0)},922860:(a,b)=>{B.Ea(\"Einsum\",a,{equation:V(b)})},922941:(a,b,c,e,f)=>{B.Ea(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},923073:(a,b,c,e,f,h)=>{B.Ea(\"BatchNormalization\",a,{epsilon:b,momentum:c,spatial:!!f,trainingMode:!!e,format:h?\n\"NHWC\":\"NCHW\"})},923242:(a,b,c,e,f,h)=>{B.Ea(\"BatchNormalization\",a,{epsilon:b,momentum:c,spatial:!!f,trainingMode:!!e,format:h?\"NHWC\":\"NCHW\"})},923411:(a,b,c)=>{B.Ea(\"CumSum\",a,{exclusive:Number(b),reverse:Number(c)})},923508:(a,b,c,e,f,h,k,q,m)=>{B.Ea(\"Attention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:h,qkvHiddenSizes:k?Array.from(z().subarray(Number(q)>>>0,Number(q)+k>>>0)):[],pastPresentShareBuffer:!!m})},923780:a=>{B.Ea(\"Gelu\",a,void 0)},923832:(a,b,c,e,f,h)=>{B.Ea(\"MultiHeadAttention\",\na,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:h})},923991:a=>{B.Ea(\"BiasAdd\",a,void 0)},924046:a=>{B.Ea(\"BiasSplitGelu\",a,void 0)},924107:(a,b)=>{B.Ea(\"SkipLayerNormalization\",a,{epsilon:b})},924188:(a,b,c,e,f,h,k,q,m,n,r,w,y)=>{B.Ea(\"Conv\",a,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:h?Array.from(z().subarray(k>>>0,k+h>>>0)):[],strides:[q],w_is_const:()=>!!d()[n>>>0],activation:V(r),activation_params:w?Array.from(da().subarray(y>>>0,y+w>>>\n0)):[]})},924569:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,t,x)=>{B.Ea(\"Conv\",a,{format:w?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,k],pads:q?Array.from(z().subarray(m>>>0,m+q>>>0)):[],strides:[n,r],w_is_const:()=>!!d()[y>>>0],activation:V(g),activation_params:t?Array.from(da().subarray(x>>>0,x+t>>>0)):[]})},924971:a=>{B.zb(a)},925005:(a,b)=>B.Ab(a,b,B.bb.Fb,B.bb.errors),925117:a=>B.wb(a),925150:a=>B.yb(a),925182:(a,b,c)=>{B.jb(a,b,c,!0)},925221:(a,b,c)=>{B.jb(a,b,c)}};\nfunction Ka(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}function La(a){a.terminate();a.onmessage=()=>{}}function Ma(a){(a=W.Qa[a])||M();W.Eb(a)}function Na(a){var b=W.tb();if(!b)return 6;W.Ya.push(b);W.Qa[a.Xa]=b;b.Xa=a.Xa;var c={cmd:\"run\",start_routine:a.Gb,arg:a.rb,pthread_ptr:a.Xa};G&&b.unref();b.postMessage(c,a.Mb);return 0}\nvar Oa=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Pa=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Oa)return Oa.decode(a.buffer instanceof SharedArrayBuffer?a.slice(b,c):a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var h=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|h);else{var k=a[b++]&63;f=224==(f&240)?(f&15)<<12|h<<6|k:(f&7)<<18|h<<12|k<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>\n10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},V=(a,b)=>(a>>>=0)?Pa(v(),a,b):\"\";function Qa(a){if(H)return X(1,1,a);Q=a;if(!Aa()){W.Hb();if(B.onExit)B.onExit(a);P=!0}E(a,new Ka(a))}\nvar Sa=a=>{Q=a;if(H)throw Ra(a),\"unwind\";Qa(a)},W={ab:[],Ya:[],mb:[],Qa:{},gb:function(){H?W.vb():W.ub()},ub:function(){wa.unshift(()=>{Ca();W.Bb(()=>Da())})},vb:function(){W.receiveObjectTransfer=W.Db;W.threadInitTLS=W.lb;W.setExitStatus=W.kb;noExitRuntime=!1},kb:function(a){Q=a},Sb:[\"$terminateWorker\"],Hb:function(){for(var a of W.Ya)La(a);for(a of W.ab)La(a);W.ab=[];W.Ya=[];W.Qa=[]},Eb:function(a){var b=a.Xa;delete W.Qa[b];W.ab.push(a);W.Ya.splice(W.Ya.indexOf(a),1);a.Xa=0;Ta(b)},Db:function(){},\nlb:function(){W.mb.forEach(a=>a())},Cb:a=>new Promise(b=>{a.onmessage=h=>{h=h.data;var k=h.cmd;if(h.targetThread&&h.targetThread!=Ua()){var q=W.Qa[h.Rb];q?q.postMessage(h,h.transferList):K('Internal error! Worker sent a message \"'+k+'\" to target pthread '+h.targetThread+\", but that thread no longer exists!\")}else if(\"checkMailbox\"===k)Va();else if(\"spawnThread\"===k)Na(h);else if(\"cleanupThread\"===k)Ma(h.thread);else if(\"killThread\"===k)h=h.thread,k=W.Qa[h],delete W.Qa[h],La(k),Ta(h),W.Ya.splice(W.Ya.indexOf(k),\n1),k.Xa=0;else if(\"cancelThread\"===k)W.Qa[h.thread].postMessage({cmd:\"cancel\"});else if(\"loaded\"===k)a.loaded=!0,b(a);else if(\"alert\"===k)alert(\"Thread \"+h.threadId+\": \"+h.text);else if(\"setimmediate\"===h.target)a.postMessage(h);else if(\"callHandler\"===k)B[h.handler](...h.args);else k&&K(\"worker sent an unknown command \"+k)};a.onerror=h=>{K(\"worker sent an error! \"+h.filename+\":\"+h.lineno+\": \"+h.message);throw h;};G&&(a.on(\"message\",function(h){a.onmessage({data:h})}),a.on(\"error\",function(h){a.onerror(h)}));\nvar c=[],e=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],f;for(f of e)B.hasOwnProperty(f)&&c.push(f);a.postMessage({cmd:\"load\",handlers:c,urlOrBlob:B.mainScriptUrlOrBlob||_scriptDir,wasmMemory:l,wasmModule:ua})}),Bb:function(a){a()},qb:function(){var a=na(\"ort-wasm-simd-threaded.worker.js\");a=new Worker(a);W.ab.push(a)},tb:function(){0==W.ab.length&&(W.qb(),W.Cb(W.ab[0]));return W.ab.pop()}};B.PThread=W;var Wa=a=>{for(;0<a.length;)a.shift()(B)};\nB.establishStackSpace=function(){var a=Ua(),b=z()[a+52>>2>>>0];a=z()[a+56>>2>>>0];Xa(b,b-a);Ya(b)};function Ra(a){if(H)return X(2,0,a);Sa(a)}B.invokeEntryPoint=function(a,b){a=Za.apply(null,[a,b]);Aa()?W.kb(a):$a(a)};function ab(a){this.fb=a-24;this.pb=function(b){A()[this.fb+4>>2>>>0]=b};this.ob=function(b){A()[this.fb+8>>2>>>0]=b};this.gb=function(b,c){this.nb();this.pb(b);this.ob(c)};this.nb=function(){A()[this.fb+16>>2>>>0]=0}}var bb=0,cb=0;\nfunction db(a,b,c,e){return H?X(3,1,a,b,c,e):eb(a,b,c,e)}function eb(a,b,c,e){a>>>=0;b>>>=0;c>>>=0;e>>>=0;if(\"undefined\"==typeof SharedArrayBuffer)return K(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var f=[];if(H&&0===f.length)return db(a,b,c,e);a={Gb:c,Xa:a,rb:e,Mb:f};return H?(a.Ob=\"spawnThread\",postMessage(a,f),0):Na(a)}function fb(a,b,c){return H?X(4,1,a,b,c):0}function gb(a,b){if(H)return X(5,1,a,b)}\nvar hb=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},ib=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var h=0;h<a.length;++h){var k=a.charCodeAt(h);if(55296<=k&&57343>=k){var q=a.charCodeAt(++h);k=65536+((k&1023)<<10)|q&1023}if(127>=k){if(c>=e)break;b[c++>>>0]=k}else{if(2047>=k){if(c+1>=e)break;b[c++>>>0]=192|k>>6}else{if(65535>=k){if(c+2>=e)break;b[c++>>>0]=224|k>>12}else{if(c+3>=e)break;b[c++>>>0]=240|k>>\n18;b[c++>>>0]=128|k>>12&63}b[c++>>>0]=128|k>>6&63}b[c++>>>0]=128|k&63}}b[c>>>0]=0;return c-f},jb=(a,b,c)=>ib(a,v(),b,c);function kb(a,b){if(H)return X(6,1,a,b)}function lb(a,b,c){if(H)return X(7,1,a,b,c)}function mb(a,b,c){return H?X(8,1,a,b,c):0}function nb(a,b){if(H)return X(9,1,a,b)}function ob(a,b,c){if(H)return X(10,1,a,b,c)}function pb(a,b,c,e){if(H)return X(11,1,a,b,c,e)}function qb(a,b,c,e){if(H)return X(12,1,a,b,c,e)}function rb(a,b,c,e){if(H)return X(13,1,a,b,c,e)}\nfunction sb(a){if(H)return X(14,1,a)}function tb(a,b){if(H)return X(15,1,a,b)}function ub(a,b,c){if(H)return X(16,1,a,b,c)}var vb=a=>{if(!P)try{if(a(),!Aa())try{H?$a(Q):Sa(Q)}catch(b){b instanceof Ka||\"unwind\"==b||E(1,b)}}catch(b){b instanceof Ka||\"unwind\"==b||E(1,b)}};function wb(a){a>>>=0;\"function\"===typeof Atomics.Nb&&(Atomics.Nb(z(),a>>2,a).value.then(Va),a+=128,Atomics.store(z(),a>>2,1))}B.__emscripten_thread_mailbox_await=wb;function Va(){var a=Ua();a&&(wb(a),vb(()=>xb()))}B.checkMailbox=Va;\nvar Y=a=>0===a%4&&(0!==a%100||0===a%400),yb=[0,31,60,91,121,152,182,213,244,274,305,335],zb=[0,31,59,90,120,151,181,212,243,273,304,334];function Ab(a,b,c,e,f,h,k,q){return H?X(17,1,a,b,c,e,f,h,k,q):-52}function Bb(a,b,c,e,f,h,k){if(H)return X(18,1,a,b,c,e,f,h,k)}var Db=a=>{var b=hb(a)+1,c=Cb(b);c&&jb(a,c,b);return c},Eb=[],Fb=(a,b)=>{Eb.length=0;var c;for(b>>=2;c=v()[a++>>>0];)b+=105!=c&b,Eb.push(105==c?z()[b>>>0]:fa()[b++>>>1]),++b;return Eb},Hb=a=>{var b=Gb();a=a();Ya(b);return a};\nfunction X(a,b){var c=arguments.length-2,e=arguments;return Hb(()=>{for(var f=Ib(8*c),h=f>>3,k=0;k<c;k++){var q=e[2+k];fa()[h+k>>>0]=q}return Jb(a,c,f,b)})}\nvar Kb=[],Lb={},Nb=()=>{if(!Mb){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:la||\"./this.program\"},b;for(b in Lb)void 0===Lb[b]?delete a[b]:a[b]=Lb[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Mb=c}return Mb},Mb;\nfunction Ob(a,b){if(H)return X(19,1,a,b);a>>>=0;b>>>=0;var c=0;Nb().forEach(function(e,f){var h=b+c;f=A()[a+4*f>>2>>>0]=h;for(h=0;h<e.length;++h)d()[f++>>0>>>0]=e.charCodeAt(h);d()[f>>0>>>0]=0;c+=e.length+1});return 0}function Pb(a,b){if(H)return X(20,1,a,b);a>>>=0;b>>>=0;var c=Nb();A()[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});A()[b>>2>>>0]=e;return 0}function Qb(a){return H?X(21,1,a):52}function Rb(a,b,c,e){return H?X(22,1,a,b,c,e):52}\nfunction Sb(a,b,c,e,f){return H?X(23,1,a,b,c,e,f):70}var Tb=[null,[],[]];function Vb(a,b,c,e){if(H)return X(24,1,a,b,c,e);b>>>=0;c>>>=0;e>>>=0;for(var f=0,h=0;h<c;h++){var k=A()[b>>2>>>0],q=A()[b+4>>2>>>0];b+=8;for(var m=0;m<q;m++){var n=v()[k+m>>>0],r=Tb[a];0===n||10===n?((1===a?ta:K)(Pa(r,0)),r.length=0):r.push(n)}f+=q}A()[e>>2>>>0]=f;return 0}var Wb=[31,29,31,30,31,30,31,31,30,31,30,31],Xb=[31,28,31,30,31,30,31,31,30,31,30,31];function Yb(a){var b=Array(hb(a)+1);ib(a,b,0,b.length);return b}\nvar Zb=(a,b)=>{d().set(a,b>>>0)};\nfunction $b(a,b,c,e){function f(g,t,x){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<t;)g=x[0]+g;return g}function h(g,t){return f(g,t,\"0\")}function k(g,t){function x(Ub){return 0>Ub?-1:0<Ub?1:0}var O;0===(O=x(g.getFullYear()-t.getFullYear()))&&0===(O=x(g.getMonth()-t.getMonth()))&&(O=x(g.getDate()-t.getDate()));return O}function q(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function m(g){var t=g.Za;for(g=new Date((new Date(g.$a+1900,0,1)).getTime());0<t;){var x=g.getMonth(),O=(Y(g.getFullYear())?Wb:Xb)[x];if(t>O-g.getDate())t-=O-g.getDate()+1,g.setDate(1),11>x?g.setMonth(x+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+t);break}}x=new Date(g.getFullYear()+1,0,4);t=q(new Date(g.getFullYear(),\n0,4));x=q(x);return 0>=k(t,g)?0>=k(x,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var n=z()[e+40>>2>>>0];e={Kb:z()[e>>2>>>0],Jb:z()[e+4>>2>>>0],cb:z()[e+8>>2>>>0],ib:z()[e+12>>2>>>0],eb:z()[e+16>>2>>>0],$a:z()[e+20>>2>>>0],Wa:z()[e+24>>2>>>0],Za:z()[e+28>>2>>>0],Tb:z()[e+32>>2>>>0],Ib:z()[e+36>>2>>>0],Lb:n?V(n):\"\"};c=V(c);n={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\n\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var r in n)c=c.replace(new RegExp(r,\"g\"),n[r]);var w=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),y=\"January February March April May June July August September October November December\".split(\" \");n={\"%a\":g=>w[g.Wa].substring(0,3),\"%A\":g=>w[g.Wa],\"%b\":g=>\ny[g.eb].substring(0,3),\"%B\":g=>y[g.eb],\"%C\":g=>h((g.$a+1900)/100|0,2),\"%d\":g=>h(g.ib,2),\"%e\":g=>f(g.ib,2,\" \"),\"%g\":g=>m(g).toString().substring(2),\"%G\":g=>m(g),\"%H\":g=>h(g.cb,2),\"%I\":g=>{g=g.cb;0==g?g=12:12<g&&(g-=12);return h(g,2)},\"%j\":g=>{for(var t=0,x=0;x<=g.eb-1;t+=(Y(g.$a+1900)?Wb:Xb)[x++]);return h(g.ib+t,3)},\"%m\":g=>h(g.eb+1,2),\"%M\":g=>h(g.Jb,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.cb&&12>g.cb?\"AM\":\"PM\",\"%S\":g=>h(g.Kb,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.Wa||7,\"%U\":g=>h(Math.floor((g.Za+7-g.Wa)/7),2),\"%V\":g=>\n{var t=Math.floor((g.Za+7-(g.Wa+6)%7)/7);2>=(g.Wa+371-g.Za-2)%7&&t++;if(t)53==t&&(x=(g.Wa+371-g.Za)%7,4==x||3==x&&Y(g.$a)||(t=1));else{t=52;var x=(g.Wa+7-g.Za-1)%7;(4==x||5==x&&Y(g.$a%400-1))&&t++}return h(t,2)},\"%w\":g=>g.Wa,\"%W\":g=>h(Math.floor((g.Za+7-(g.Wa+6)%7)/7),2),\"%y\":g=>(g.$a+1900).toString().substring(2),\"%Y\":g=>g.$a+1900,\"%z\":g=>{g=g.Ib;var t=0<=g;g=Math.abs(g)/60;return(t?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.Lb,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(r in n)c.includes(r)&&\n(c=c.replace(new RegExp(r,\"g\"),n[r](e)));c=c.replace(/\\0\\0/g,\"%\");r=Yb(c);if(r.length>b)return 0;Zb(r,a);return r.length-1}function ac(a){try{a()}catch(b){M(b)}}function bc(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){cc.push(e);try{return f.apply(null,arguments)}finally{P||(cc.pop()===e||M(),D&&1===Z&&0===cc.length&&(Z=0,za+=1,ac(dc),\"undefined\"!=typeof Fibers&&Fibers.Ub()))}}:f})(c);return b}var Z=0,D=null,ec=0,cc=[],fc={},gc={},hc=0,ic=null,jc=[];\nfunction ja(){return new Promise((a,b)=>{ic={resolve:a,reject:b}})}function kc(){var a=Cb(65548),b=a+12;A()[a>>2>>>0]=b;A()[a+4>>2>>>0]=b+65536;b=cc[0];var c=fc[b];void 0===c&&(c=hc++,fc[b]=c,gc[c]=b);b=c;z()[a+8>>2>>>0]=b;return a}function lc(){var a=z()[D+8>>2>>>0];a=N[gc[a]];--za;return a()}\nfunction mc(a){if(!P){if(0===Z){var b=!1,c=!1;a((e=0)=>{if(!P&&(ec=e,b=!0,c)){Z=2;ac(()=>nc(D));\"undefined\"!=typeof Browser&&Browser.hb.sb&&Browser.hb.resume();e=!1;try{var f=lc()}catch(q){f=q,e=!0}var h=!1;if(!D){var k=ic;k&&(ic=null,(e?k.reject:k.resolve)(f),h=!0)}if(e&&!h)throw f;}});c=!0;b||(Z=1,D=kc(),\"undefined\"!=typeof Browser&&Browser.hb.sb&&Browser.hb.pause(),ac(()=>oc(D)))}else 2===Z?(Z=0,ac(pc),qc(D),D=null,jc.forEach(e=>vb(e))):M(`invalid state: ${Z}`);return ec}}\nfunction rc(a){return mc(b=>{a().then(b)})}W.gb();\nvar sc=[null,Qa,Ra,db,fb,gb,kb,lb,mb,nb,ob,pb,qb,rb,sb,tb,ub,Ab,Bb,Ob,Pb,Qb,Rb,Sb,Vb],vc={r:function(a,b,c){return rc(async()=>{await B.xb(a,b,c)})},b:function(a,b,c){a>>>=0;(new ab(a)).gb(b>>>0,c>>>0);bb=a;cb++;throw bb;},O:function(a){tc(a>>>0,!F,1,!ma,131072,!1);W.lb()},l:function(a){a>>>=0;H?postMessage({cmd:\"cleanupThread\",thread:a}):Ma(a)},I:eb,i:fb,U:gb,E:kb,G:lb,V:mb,S:nb,K:ob,R:pb,p:qb,F:rb,C:sb,T:tb,D:ub,q:()=>!0,A:function(a,b){a>>>=0;a==b>>>0?setTimeout(()=>Va()):H?postMessage({targetThread:a,\ncmd:\"checkMailbox\"}):(a=W.Qa[a])&&a.postMessage({cmd:\"checkMailbox\"})},M:function(){return-1},N:wb,X:function(a){G&&W.Qa[a>>>0].ref()},u:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getUTCSeconds();z()[c+4>>2>>>0]=a.getUTCMinutes();z()[c+8>>2>>>0]=a.getUTCHours();z()[c+12>>2>>>0]=a.getUTCDate();z()[c+16>>2>>>0]=a.getUTCMonth();z()[c+20>>2>>>0]=a.getUTCFullYear()-1900;z()[c+24>>2>>>0]=a.getUTCDay();a=(a.getTime()-Date.UTC(a.getUTCFullYear(),\n0,1,0,0,0,0))/864E5|0;z()[c+28>>2>>>0]=a},v:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getSeconds();z()[c+4>>2>>>0]=a.getMinutes();z()[c+8>>2>>>0]=a.getHours();z()[c+12>>2>>>0]=a.getDate();z()[c+16>>2>>>0]=a.getMonth();z()[c+20>>2>>>0]=a.getFullYear()-1900;z()[c+24>>2>>>0]=a.getDay();b=(Y(a.getFullYear())?yb:zb)[a.getMonth()]+a.getDate()-1|0;z()[c+28>>2>>>0]=b;z()[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),\n6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();a=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0;z()[c+32>>2>>>0]=a},w:function(a){a>>>=0;var b=new Date(z()[a+20>>2>>>0]+1900,z()[a+16>>2>>>0],z()[a+12>>2>>>0],z()[a+8>>2>>>0],z()[a+4>>2>>>0],z()[a>>2>>>0],0),c=z()[a+32>>2>>>0],e=b.getTimezoneOffset(),f=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),h=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),k=Math.min(h,f);0>c?z()[a+32>>2>>>0]=Number(f!=h&&k==e):\n0<c!=(k==e)&&(f=Math.max(h,f),b.setTime(b.getTime()+6E4*((0<c?k:f)-e)));z()[a+24>>2>>>0]=b.getDay();c=(Y(b.getFullYear())?yb:zb)[b.getMonth()]+b.getDate()-1|0;z()[a+28>>2>>>0]=c;z()[a>>2>>>0]=b.getSeconds();z()[a+4>>2>>>0]=b.getMinutes();z()[a+8>>2>>>0]=b.getHours();z()[a+12>>2>>>0]=b.getDate();z()[a+16>>2>>>0]=b.getMonth();z()[a+20>>2>>>0]=b.getYear();a=b.getTime()/1E3;return uc((U=a,1<=+Math.abs(U)?0<U?+Math.floor(U/4294967296)>>>0:~~+Math.ceil((U-+(~~U>>>0))/4294967296)>>>0:0)),a>>>0},s:Ab,t:Bb,\nz:function(a,b,c){function e(n){return(n=n.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?n[1]:\"GMT\"}a>>>=0;b>>>=0;c>>>=0;var f=(new Date).getFullYear(),h=new Date(f,0,1),k=new Date(f,6,1);f=h.getTimezoneOffset();var q=k.getTimezoneOffset(),m=Math.max(f,q);A()[a>>2>>>0]=60*m;z()[b>>2>>>0]=Number(f!=q);a=e(h);b=e(k);a=Db(a);b=Db(b);q<f?(A()[c>>2>>>0]=a,A()[c+4>>2>>>0]=b):(A()[c>>2>>>0]=b,A()[c+4>>2>>>0]=a)},d:()=>{M(\"\")},c:function(a,b,c){a>>>=0;b=Fb(b>>>0,c>>>0);return Ja[a].apply(null,b)},k:function(a,\nb,c){a>>>=0;b=Fb(b>>>0,c>>>0);return Ja[a].apply(null,b)},m:function(){},j:function(){return Date.now()},W:()=>{za+=1;throw\"unwind\";},B:function(){return 4294901760},f:()=>performance.timeOrigin+performance.now(),g:function(){return G?require(\"os\").cpus().length:navigator.hardwareConcurrency},L:function(a,b,c,e){W.Pb=b>>>0;Kb.length=c;b=e>>>0>>3;for(e=0;e<c;e++)Kb[e]=fa()[b+e>>>0];return(0>a?Ja[-a-1]:sc[a]).apply(null,Kb)},y:function(a){a>>>=0;var b=v().length;if(a<=b||4294901760<a)return!1;for(var c=\n1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;e=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-l.buffer.byteLength+65535>>>16;try{l.grow(f);u();var h=1;break a}catch(k){}h=void 0}if(h)return!0}return!1},P:Ob,Q:Pb,H:Sa,h:Qb,o:Rb,x:Sb,n:Vb,a:l||B.wasmMemory,J:$b,e:function(a,b,c,e){return $b(a>>>0,b>>>0,c>>>0,e>>>0)}};\n(function(){function a(c,e){c=c.exports;c=bc(c);N=c=wc(c);W.mb.push(N.Da);xa.unshift(N.Y);ua=e;Da();return c}var b={a:vc};Ca();if(B.instantiateWasm)try{return B.instantiateWasm(b,a)}catch(c){K(\"Module.instantiateWasm callback failed with error: \"+c),C(c)}Ia(b,function(c){a(c.instance,c.module)}).catch(C);return{}})();B._OrtInit=(a,b)=>(B._OrtInit=N.Z)(a,b);B._OrtGetLastError=(a,b)=>(B._OrtGetLastError=N._)(a,b);\nB._OrtCreateSessionOptions=(a,b,c,e,f,h,k,q,m,n)=>(B._OrtCreateSessionOptions=N.$)(a,b,c,e,f,h,k,q,m,n);B._OrtAppendExecutionProvider=(a,b)=>(B._OrtAppendExecutionProvider=N.aa)(a,b);B._OrtAddFreeDimensionOverride=(a,b,c)=>(B._OrtAddFreeDimensionOverride=N.ba)(a,b,c);B._OrtAddSessionConfigEntry=(a,b,c)=>(B._OrtAddSessionConfigEntry=N.ca)(a,b,c);B._OrtReleaseSessionOptions=a=>(B._OrtReleaseSessionOptions=N.da)(a);B._OrtCreateSession=(a,b,c)=>(B._OrtCreateSession=N.ea)(a,b,c);\nB._OrtReleaseSession=a=>(B._OrtReleaseSession=N.fa)(a);B._OrtGetInputOutputCount=(a,b,c)=>(B._OrtGetInputOutputCount=N.ga)(a,b,c);B._OrtGetInputName=(a,b)=>(B._OrtGetInputName=N.ha)(a,b);B._OrtGetOutputName=(a,b)=>(B._OrtGetOutputName=N.ia)(a,b);B._OrtFree=a=>(B._OrtFree=N.ja)(a);B._OrtCreateTensor=(a,b,c,e,f,h)=>(B._OrtCreateTensor=N.ka)(a,b,c,e,f,h);B._OrtGetTensorData=(a,b,c,e,f)=>(B._OrtGetTensorData=N.la)(a,b,c,e,f);B._OrtReleaseTensor=a=>(B._OrtReleaseTensor=N.ma)(a);\nB._OrtCreateRunOptions=(a,b,c,e)=>(B._OrtCreateRunOptions=N.na)(a,b,c,e);B._OrtAddRunConfigEntry=(a,b,c)=>(B._OrtAddRunConfigEntry=N.oa)(a,b,c);B._OrtReleaseRunOptions=a=>(B._OrtReleaseRunOptions=N.pa)(a);B._OrtCreateBinding=a=>(B._OrtCreateBinding=N.qa)(a);B._OrtBindInput=(a,b,c)=>(B._OrtBindInput=N.ra)(a,b,c);B._OrtBindOutput=(a,b,c,e)=>(B._OrtBindOutput=N.sa)(a,b,c,e);B._OrtClearBoundOutputs=a=>(B._OrtClearBoundOutputs=N.ta)(a);B._OrtReleaseBinding=a=>(B._OrtReleaseBinding=N.ua)(a);\nB._OrtRunWithBinding=(a,b,c,e,f)=>(B._OrtRunWithBinding=N.va)(a,b,c,e,f);B._OrtRun=(a,b,c,e,f,h,k,q)=>(B._OrtRun=N.wa)(a,b,c,e,f,h,k,q);B._OrtEndProfiling=a=>(B._OrtEndProfiling=N.xa)(a);B._JsepOutput=(a,b,c)=>(B._JsepOutput=N.ya)(a,b,c);B._JsepGetNodeName=a=>(B._JsepGetNodeName=N.za)(a);var Ua=B._pthread_self=()=>(Ua=B._pthread_self=N.Aa)(),Cb=B._malloc=a=>(Cb=B._malloc=N.Ba)(a),qc=B._free=a=>(qc=B._free=N.Ca)(a);B.__emscripten_tls_init=()=>(B.__emscripten_tls_init=N.Da)();\nvar tc=B.__emscripten_thread_init=(a,b,c,e,f,h)=>(tc=B.__emscripten_thread_init=N.Fa)(a,b,c,e,f,h);B.__emscripten_thread_crashed=()=>(B.__emscripten_thread_crashed=N.Ga)();\nvar Jb=(a,b,c,e)=>(Jb=N.Ha)(a,b,c,e),Ta=a=>(Ta=N.Ia)(a),$a=B.__emscripten_thread_exit=a=>($a=B.__emscripten_thread_exit=N.Ja)(a),xb=B.__emscripten_check_mailbox=()=>(xb=B.__emscripten_check_mailbox=N.Ka)(),uc=a=>(uc=N.La)(a),Xa=(a,b)=>(Xa=N.Ma)(a,b),Gb=()=>(Gb=N.Na)(),Ya=a=>(Ya=N.Oa)(a),Ib=a=>(Ib=N.Pa)(a),Za=B.dynCall_ii=(a,b)=>(Za=B.dynCall_ii=N.Ra)(a,b),oc=a=>(oc=N.Sa)(a),dc=()=>(dc=N.Ta)(),nc=a=>(nc=N.Ua)(a),pc=()=>(pc=N.Va)();B.___start_em_js=925254;B.___stop_em_js=925415;\nfunction wc(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.pthread_self=b(a.pthread_self);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}B.keepRuntimeAlive=Aa;B.wasmMemory=l;B.stackAlloc=Ib;B.stackSave=Gb;B.stackRestore=Ya;B.UTF8ToString=V;B.stringToUTF8=jb;B.lengthBytesUTF8=hb;B.ExitStatus=Ka;B.PThread=W;var xc;S=function yc(){xc||zc();xc||(S=yc)};\nfunction zc(){function a(){if(!xc&&(xc=!0,B.calledRun=!0,!P)){H||Wa(xa);ia(B);if(B.onRuntimeInitialized)B.onRuntimeInitialized();if(!H){if(B.postRun)for(\"function\"==typeof B.postRun&&(B.postRun=[B.postRun]);B.postRun.length;){var b=B.postRun.shift();ya.unshift(b)}Wa(ya)}}}if(!(0<R))if(H)ia(B),H||Wa(xa),startWorker(B);else{if(B.preRun)for(\"function\"==typeof B.preRun&&(B.preRun=[B.preRun]);B.preRun.length;)wa.unshift(B.preRun.shift());Wa(wa);0<R||(B.setStatus?(B.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){B.setStatus(\"\")},\n1);a()},1)):a())}}if(B.preInit)for(\"function\"==typeof B.preInit&&(B.preInit=[B.preInit]);0<B.preInit.length;)B.preInit.pop()();zc();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasmThreaded;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasmThreaded);\n", "\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason??e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(\"worker.js received unknown command \"+e.data.cmd),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport * as path from 'node:path';\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from './binding/ort-wasm';\nimport {OrtWasmThreadedModule} from './binding/ort-wasm-threaded';\n\n/* eslint-disable @typescript-eslint/no-require-imports */\nlet ortWasmFactory: EmscriptenModuleFactory<OrtWasmModule>;\n\nif (!BUILD_DEFS.DISABLE_TRAINING) {\n  ortWasmFactory = require('./binding/ort-training-wasm-simd.js');\n} else {\n  ortWasmFactory =\n      BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm.js') : require('./binding/ort-wasm-simd.jsep.js');\n}\n\nconst ortWasmFactoryThreaded: EmscriptenModuleFactory<OrtWasmModule> = !BUILD_DEFS.DISABLE_WASM_THREAD ?\n    (BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm-threaded.js') :\n                                 require('./binding/ort-wasm-simd-threaded.jsep.js')) :\n    ortWasmFactory;\n/* eslint-enable @typescript-eslint/no-require-imports */\n\nlet wasm: OrtWasmModule|undefined;\nlet initialized = false;\nlet initializing = false;\nlet aborted = false;\n\nconst isMultiThreadSupported = (): boolean => {\n  try {\n    // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\n    if (typeof SharedArrayBuffer === 'undefined') {\n      return false;\n    }\n\n    // Test for transferability of SABs (for browsers. needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    if (typeof MessageChannel !== 'undefined') {\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    }\n\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing threaded instructions.\n    return WebAssembly.validate(new Uint8Array([\n      0, 97, 115, 109, 1, 0,  0,  0, 1, 4, 1,  96, 0,   0,  3, 2, 1,  0, 5,\n      4, 1,  3,   1,   1, 10, 11, 1, 9, 0, 65, 0,  254, 16, 2, 0, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    //\n    // (module\n    //   (type $t0 (func))\n    //   (func $f0 (type $t0)\n    //     (drop\n    //       (i32x4.dot_i16x8_s\n    //         (i8x16.splat\n    //           (i32.const 0))\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\n\n    return WebAssembly.validate(new Uint8Array([\n      0,   97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1,   28,  0, 65, 0,\n      253, 15, 253, 12,  0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0,  0,  253, 186, 1, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst getWasmFileName = (useSimd: boolean, useThreads: boolean) => {\n  if (useSimd) {\n    if (!BUILD_DEFS.DISABLE_TRAINING) {\n      return 'ort-training-wasm-simd.wasm';\n    }\n    return useThreads ? 'ort-wasm-simd-threaded.wasm' : 'ort-wasm-simd.wasm';\n  } else {\n    return useThreads ? 'ort-wasm-threaded.wasm' : 'ort-wasm.wasm';\n  }\n};\n\nexport const initializeWebAssembly = async(flags: Env.WebAssemblyFlags): Promise<void> => {\n  if (initialized) {\n    return Promise.resolve();\n  }\n  if (initializing) {\n    throw new Error('multiple calls to \\'initializeWebAssembly()\\' detected.');\n  }\n  if (aborted) {\n    throw new Error('previous call to \\'initializeWebAssembly()\\' failed.');\n  }\n\n  initializing = true;\n\n  // wasm flags are already initialized\n  const timeout = flags.initTimeout!;\n  const numThreads = flags.numThreads!;\n  const simd = flags.simd!;\n\n  const useThreads = numThreads > 1 && isMultiThreadSupported();\n  const useSimd = simd && isSimdSupported();\n\n  const wasmPaths = flags.wasmPaths;\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\n  const wasmFileName = getWasmFileName(useSimd, useThreads);\n  const wasmPathOverride = typeof wasmPaths === 'object' ? wasmPaths[wasmFileName] : undefined;\n\n  let isTimeout = false;\n\n  const tasks: Array<Promise<void>> = [];\n\n  // promise for timeout\n  if (timeout > 0) {\n    tasks.push(new Promise((resolve) => {\n      setTimeout(() => {\n        isTimeout = true;\n        resolve();\n      }, timeout);\n    }));\n  }\n\n  // promise for module initialization\n  tasks.push(new Promise((resolve, reject) => {\n    const factory = useThreads ? ortWasmFactoryThreaded : ortWasmFactory;\n    const config: Partial<OrtWasmModule> = {\n      locateFile: (fileName: string, scriptDirectory: string) => {\n        if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads && fileName.endsWith('.worker.js') &&\n            typeof Blob !== 'undefined') {\n          return URL.createObjectURL(new Blob(\n              [\n                // This require() function is handled by esbuild plugin to load file content as string.\n                // eslint-disable-next-line @typescript-eslint/no-require-imports\n                require('./binding/ort-wasm-threaded.worker.js')\n              ],\n              {type: 'text/javascript'}));\n        }\n\n        if (fileName.endsWith('.wasm')) {\n          if (wasmPathOverride) {\n            return wasmPathOverride;\n          }\n\n          const prefix = wasmPrefixOverride ?? scriptDirectory;\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            if (wasmFileName === 'ort-wasm-simd.wasm') {\n              return prefix + 'ort-wasm-simd.jsep.wasm';\n            } else if (wasmFileName === 'ort-wasm-simd-threaded.wasm') {\n              return prefix + 'ort-wasm-simd-threaded.jsep.wasm';\n            }\n          }\n\n          return prefix + wasmFileName;\n        }\n\n        return scriptDirectory + fileName;\n      }\n    };\n\n    if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads) {\n      if (typeof Blob === 'undefined') {\n        config.mainScriptUrlOrBlob = path.join(__dirname, 'ort-wasm-threaded.js');\n      } else {\n        const scriptSourceCode = `var ortWasmThreaded=${factory.toString()};`;\n        config.mainScriptUrlOrBlob = new Blob([scriptSourceCode], {type: 'text/javascript'});\n      }\n    }\n\n    factory(config).then(\n        // wasm module initialized successfully\n        module => {\n          initializing = false;\n          initialized = true;\n          wasm = module;\n          resolve();\n        },\n        // wasm module failed to initialize\n        (what) => {\n          initializing = false;\n          aborted = true;\n          reject(what);\n        });\n  }));\n\n  await Promise.race(tasks);\n\n  if (isTimeout) {\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\n  }\n};\n\nexport const getInstance = (): OrtWasmModule => {\n  if (initialized && wasm) {\n    return wasm;\n  }\n\n  throw new Error('WebAssembly is not initialized yet.');\n};\n\nexport const dispose = (): void => {\n  if (initialized && !initializing && !aborted) {\n    initializing = true;\n\n    (wasm as OrtWasmThreadedModule).PThread?.terminateAllThreads();\n    wasm = undefined;\n\n    initializing = false;\n    initialized = false;\n    aborted = true;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {getInstance} from './wasm-factory';\n\nexport const allocWasmString = (data: string, allocs: number[]): number => {\n  const wasm = getInstance();\n\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\n  const dataOffset = wasm._malloc(dataLength);\n  wasm.stringToUTF8(data, dataOffset, dataLength);\n  allocs.push(dataOffset);\n\n  return dataOffset;\n};\n\ninterface ExtraOptionsHandler {\n  (name: string, value: string): void;\n}\n\nexport const iterateExtraOptions =\n    (options: Record<string, unknown>, prefix: string, seen: WeakSet<Record<string, unknown>>,\n     handler: ExtraOptionsHandler): void => {\n      if (typeof options == 'object' && options !== null) {\n        if (seen.has(options)) {\n          throw new Error('Circular reference in options');\n        } else {\n          seen.add(options);\n        }\n      }\n\n      Object.entries(options).forEach(([key, value]) => {\n        const name = (prefix) ? prefix + key : key;\n        if (typeof value === 'object') {\n          iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\n        } else if (typeof value === 'string' || typeof value === 'number') {\n          handler(name, value.toString());\n        } else if (typeof value === 'boolean') {\n          handler(name, (value) ? '1' : '0');\n        } else {\n          throw new Error(`Can't handle extra config type: ${typeof value}`);\n        }\n      });\n    };\n\n/**\n * check web assembly API's last error and throw error if any error occurred.\n * @param message a message used when an error occurred.\n */\nexport const checkLastError = (message: string): void => {\n  const wasm = getInstance();\n\n  const stack = wasm.stackSave();\n  try {\n    const paramsOffset = wasm.stackAlloc(8);\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + 4);\n    const errorCode = wasm.HEAP32[paramsOffset / 4];\n    const errorMessagePointer = wasm.HEAPU32[paramsOffset / 4 + 1];\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let runOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const runOptions: InferenceSession.RunOptions = options || {};\n\n  try {\n    if (options?.logSeverityLevel === undefined) {\n      runOptions.logSeverityLevel = 2;  // Default to warning\n    } else if (\n        typeof options.logSeverityLevel !== 'number' || !Number.isInteger(options.logSeverityLevel) ||\n        options.logSeverityLevel < 0 || options.logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${options.logSeverityLevel}`);\n    }\n\n    if (options?.logVerbosityLevel === undefined) {\n      runOptions.logVerbosityLevel = 0;  // Default to 0\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\n    }\n\n    if (options?.terminate === undefined) {\n      runOptions.terminate = false;\n    }\n\n    let tagDataOffset = 0;\n    if (options?.tag !== undefined) {\n      tagDataOffset = allocWasmString(options.tag, allocs);\n    }\n\n    runOptionsHandle = wasm._OrtCreateRunOptions(\n        runOptions.logSeverityLevel!, runOptions.logVerbosityLevel!, !!runOptions.terminate!, tagDataOffset);\n    if (runOptionsHandle === 0) {\n      checkLastError('Can\\'t create run options.');\n    }\n\n    if (options?.extra !== undefined) {\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [runOptionsHandle, allocs];\n  } catch (e) {\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string|unknown): number => {\n  switch (graphOptimizationLevel) {\n    case 'disabled':\n      return 0;\n    case 'basic':\n      return 1;\n    case 'extended':\n      return 2;\n    case 'all':\n      return 99;\n    default:\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\n  }\n};\n\nconst getExecutionMode = (executionMode: 'sequential'|'parallel'): number => {\n  switch (executionMode) {\n    case 'sequential':\n      return 0;\n    case 'parallel':\n      return 1;\n    default:\n      throw new Error(`unsupported execution mode: ${executionMode}`);\n  }\n};\n\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\n  if (!options.extra) {\n    options.extra = {};\n  }\n  if (!options.extra.session) {\n    options.extra.session = {};\n  }\n  const session = options.extra.session as Record<string, string>;\n  if (!session.use_ort_model_bytes_directly) {\n    // eslint-disable-next-line camelcase\n    session.use_ort_model_bytes_directly = '1';\n  }\n\n  // if using JSEP with WebGPU, always disable memory pattern\n  if (options.executionProviders &&\n      options.executionProviders.some(ep => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')) {\n    options.enableMemPattern = false;\n  }\n};\n\nconst setExecutionProviders =\n    (sessionOptionsHandle: number, executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\n     allocs: number[]): void => {\n      for (const ep of executionProviders) {\n        let epName = typeof ep === 'string' ? ep : ep.name;\n\n        // check EP name\n        switch (epName) {\n          case 'xnnpack':\n            epName = 'XNNPACK';\n            break;\n          case 'webnn':\n            epName = 'WEBNN';\n            if (typeof ep !== 'string') {\n              const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\n              if (webnnOptions?.deviceType) {\n                const keyDataOffset = allocWasmString('deviceType', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.deviceType, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'deviceType' - ${webnnOptions.deviceType}.`);\n                }\n              }\n              if (webnnOptions?.numThreads) {\n                let numThreads = webnnOptions.numThreads;\n                // Just ignore invalid webnnOptions.numThreads.\n                if (typeof numThreads != 'number' || !Number.isInteger(numThreads) || numThreads < 0) {\n                  numThreads = 0;\n                }\n                const keyDataOffset = allocWasmString('numThreads', allocs);\n                const valueDataOffset = allocWasmString(numThreads.toString(), allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'numThreads' - ${webnnOptions.numThreads}.`);\n                }\n              }\n              if (webnnOptions?.powerPreference) {\n                const keyDataOffset = allocWasmString('powerPreference', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.powerPreference, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'powerPreference' - ${webnnOptions.powerPreference}.`);\n                }\n              }\n            }\n            break;\n          case 'webgpu':\n            epName = 'JS';\n            if (typeof ep !== 'string') {\n              const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\n              if (webgpuOptions?.preferredLayout) {\n                if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\n                  throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\n                }\n                const keyDataOffset = allocWasmString('preferredLayout', allocs);\n                const valueDataOffset = allocWasmString(webgpuOptions.preferredLayout, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'preferredLayout' - ${webgpuOptions.preferredLayout}.`);\n                }\n              }\n            }\n            break;\n          case 'wasm':\n          case 'cpu':\n            continue;\n          default:\n            throw new Error(`not supported execution provider: ${epName}`);\n        }\n\n        const epNameDataOffset = allocWasmString(epName, allocs);\n        if (getInstance()._OrtAppendExecutionProvider(sessionOptionsHandle, epNameDataOffset) !== 0) {\n          checkLastError(`Can't append execution provider: ${epName}.`);\n        }\n      }\n    };\n\nexport const setSessionOptions = (options?: InferenceSession.SessionOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let sessionOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\n  appendDefaultOptions(sessionOptions);\n\n  try {\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\n    const logIdDataOffset =\n        typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\n\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2;  // Default to 2 - warning\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${logSeverityLevel}`);\n    }\n\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0;  // Default to 0 - verbose\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\n    }\n\n    const optimizedModelFilePathOffset = typeof sessionOptions.optimizedModelFilePath === 'string' ?\n        allocWasmString(sessionOptions.optimizedModelFilePath, allocs) :\n        0;\n\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\n        graphOptimizationLevel, !!sessionOptions.enableCpuMemArena, !!sessionOptions.enableMemPattern, executionMode,\n        !!sessionOptions.enableProfiling, 0, logIdDataOffset, logSeverityLevel, logVerbosityLevel,\n        optimizedModelFilePathOffset);\n    if (sessionOptionsHandle === 0) {\n      checkLastError('Can\\'t create session options.');\n    }\n\n    if (sessionOptions.executionProviders) {\n      setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\n    }\n\n    if (sessionOptions.freeDimensionOverrides) {\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\n        if (typeof name !== 'string') {\n          throw new Error(`free dimension override name must be a string: ${name}`);\n        }\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\n        }\n        const nameOffset = allocWasmString(name, allocs);\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\n        }\n      }\n    }\n\n    if (sessionOptions.extra !== undefined) {\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [sessionOptionsHandle, allocs];\n  } catch (e) {\n    if (sessionOptionsHandle !== 0) {\n      wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\n\n/**\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\n */\nexport const enum DataType {\n  undefined = 0,\n  float = 1,\n  uint8 = 2,\n  int8 = 3,\n  uint16 = 4,\n  int16 = 5,\n  int32 = 6,\n  int64 = 7,\n  string = 8,\n  bool = 9,\n  float16 = 10,\n  double = 11,\n  uint32 = 12,\n  uint64 = 13,\n  complex64 = 14,\n  complex128 = 15,\n  bfloat16 = 16\n}\n\n/**\n * Map string tensor data to enum value\n */\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\n  switch (type) {\n    case 'int8':\n      return DataType.int8;\n    case 'uint8':\n      return DataType.uint8;\n    case 'bool':\n      return DataType.bool;\n    case 'int16':\n      return DataType.int16;\n    case 'uint16':\n      return DataType.uint16;\n    case 'int32':\n      return DataType.int32;\n    case 'uint32':\n      return DataType.uint32;\n    case 'float16':\n      return DataType.float16;\n    case 'float32':\n      return DataType.float;\n    case 'float64':\n      return DataType.double;\n    case 'string':\n      return DataType.string;\n    case 'int64':\n      return DataType.int64;\n    case 'uint64':\n      return DataType.uint64;\n\n    default:\n      throw new Error(`unsupported data type: ${type}`);\n  }\n};\n\n/**\n * Map enum value to string tensor data\n */\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\n  switch (typeProto) {\n    case DataType.int8:\n      return 'int8';\n    case DataType.uint8:\n      return 'uint8';\n    case DataType.bool:\n      return 'bool';\n    case DataType.int16:\n      return 'int16';\n    case DataType.uint16:\n      return 'uint16';\n    case DataType.int32:\n      return 'int32';\n    case DataType.uint32:\n      return 'uint32';\n    case DataType.float16:\n      return 'float16';\n    case DataType.float:\n      return 'float32';\n    case DataType.double:\n      return 'float64';\n    case DataType.string:\n      return 'string';\n    case DataType.int64:\n      return 'int64';\n    case DataType.uint64:\n      return 'uint64';\n\n    default:\n      throw new Error(`unsupported data type: ${typeProto}`);\n  }\n};\n\n/**\n * get tensor element size in bytes by the given data type\n * @returns size in integer or undefined if the data type is not supported\n */\nexport const getTensorElementSize = (dateType: number): number|\n    undefined => [undefined, 4, 1, 1, 2, 2, 4, 8, undefined, 1, 2, 8, 4, 8, undefined, undefined, undefined][dateType];\n\n/**\n * get typed array constructor by the given tensor type\n */\nexport const tensorTypeToTypedArrayConstructor = (type: Tensor.Type): Float32ArrayConstructor|Uint8ArrayConstructor|\n    Int8ArrayConstructor|Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|\n    Uint8ArrayConstructor|Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor => {\n      switch (type) {\n        case 'float16':\n          return Uint16Array;\n        case 'float32':\n          return Float32Array;\n        case 'uint8':\n          return Uint8Array;\n        case 'int8':\n          return Int8Array;\n        case 'uint16':\n          return Uint16Array;\n        case 'int16':\n          return Int16Array;\n        case 'int32':\n          return Int32Array;\n        case 'bool':\n          return Uint8Array;\n        case 'float64':\n          return Float64Array;\n        case 'uint32':\n          return Uint32Array;\n        case 'int64':\n          return BigInt64Array;\n        case 'uint64':\n          return BigUint64Array;\n        default:\n          throw new Error(`unsupported type: ${type}`);\n      }\n    };\n\n/**\n * Map string log level to integer value\n */\nexport const logLevelStringToEnum = (logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal'): number => {\n  switch (logLevel) {\n    case 'verbose':\n      return 0;\n    case 'info':\n      return 1;\n    case 'warning':\n      return 2;\n    case 'error':\n      return 3;\n    case 'fatal':\n      return 4;\n    default:\n      throw new Error(`unsupported logging level: ${logLevel}`);\n  }\n};\n\n/**\n * Check whether the given tensor type is supported by GPU buffer\n */\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes => type === 'float32' ||\n    type === 'int32' || type === 'int64' || type === 'bool' || type === 'float16' || type === 'uint32';\n\n/**\n * Map string data location to integer value\n */\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\n  switch (location) {\n    case 'none':\n      return 0;\n    case 'cpu':\n      return 1;\n    case 'cpu-pinned':\n      return 2;\n    case 'texture':\n      return 3;\n    case 'gpu-buffer':\n      return 4;\n    default:\n      throw new Error(`unsupported data location: ${location}`);\n  }\n};\n\n/**\n * Map integer data location to string value\n */\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation|undefined =>\n    (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer'] as const)[location];\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {logLevelStringToEnum} from '../wasm-common';\n\ntype LogLevel = NonNullable<Env['logLevel']>;\ntype MessageString = string;\ntype MessageFunction = () => string;\ntype Message = MessageString|MessageFunction;\n\nconst logLevelPrefix = ['V', 'I', 'W', 'E', 'F'];\n\nconst doLog = (level: number, message: string): void => {\n  // eslint-disable-next-line no-console\n  console.log(`[${logLevelPrefix[level]},${new Date().toISOString()}]${message}`);\n};\n\nlet configLogLevel: LogLevel|undefined;\nlet debug: boolean|undefined;\n\nexport const configureLogger = ($configLogLevel: LogLevel, $debug: boolean): void => {\n  configLogLevel = $configLogLevel;\n  debug = $debug;\n};\n\n/**\n * A simple logging utility to log messages to the console.\n */\nexport const LOG = (logLevel: LogLevel, msg: Message): void => {\n  const messageLevel = logLevelStringToEnum(logLevel);\n  const configLevel = logLevelStringToEnum(configLogLevel);\n  if (messageLevel >= configLevel) {\n    doLog(messageLevel, typeof msg === 'function' ? msg() : msg);\n  }\n};\n\n/**\n * A simple logging utility to log messages to the console. Only logs when debug is enabled.\n */\nexport const LOG_DEBUG: typeof LOG = (...args: Parameters<typeof LOG>) => {\n  if (debug) {\n    LOG(...args);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\nimport {tensorTypeToTypedArrayConstructor} from '../wasm-common';\n\nexport const createView = (dataBuffer: ArrayBuffer, type: Tensor.Type): Int32Array|Uint32Array|BigInt64Array|\n    BigUint64Array|Uint8Array|Float32Array|Float64Array|Int8Array|Int16Array|Uint16Array =>\n        new (tensorTypeToTypedArrayConstructor(type))(dataBuffer);\n\n/**\n * a TensorView does not own the data.\n */\nexport interface TensorView {\n  readonly data: number;\n  readonly dataType: number;\n  readonly dims: readonly number[];\n\n  /**\n   * get a Float32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getFloat32Array(): Float32Array;\n\n  /**\n   * get a BigInt64Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getBigInt64Array(): BigInt64Array;\n\n  /**\n   * get a Int32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getInt32Array(): Int32Array;\n\n  /**\n   * create a new tensor view with the same data but different dimensions.\n   */\n  reshape(newDims: readonly number[]): TensorView;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../tensor-view';\n\nimport {ShaderHelper} from './ops/common';\n\nexport enum GpuDataType {\n  default = 0,\n  upload = 1,\n  profile = 2\n}\nexport type GpuDataId = number;\n\nexport interface GpuData {\n  type: GpuDataType;\n  id: GpuDataId;\n  buffer: GPUBuffer;\n}\n\nexport interface TensorInfo {\n  dims: readonly number[];\n  dataType: number;\n}\n\n\nexport interface ProgramUniform {\n  type: 'int32'|'float32'|'uint32';\n  data: number|readonly number[];\n}\n\n/**\n * Represent the dependency of a program on a specific input tensor.\n *\n * - 'none': the shader/uniform does not depend on this input's info\n * - 'type': the shader/uniform depends on data type of this input\n * - 'rank': the shader/uniform depends on data type and the rank of this input\n * - 'dims': the shader/uniform depends on data type and the dims of this input\n * - 'data': the shader/uniform depends on data type, the dims and the data of this input\n */\nexport type ProgramInputTensorInfoDependency = 'none'|'type'|'rank'|'dims'|'data';\n\n/**\n * Represent information about a program's cache for shader.\n */\nexport interface ProgramShaderCacheInfo {\n  /**\n   * an optional string as a cache hint in the artifact cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains initializing-time information, such as the attributes or any information of\n   * initializers. It should NOT contain any runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'dims' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n/**\n * Represent information about a program's cache for uniform.\n */\nexport interface ProgramUniformCacheInfo {\n  /**\n   * an optional string as a cache hint in the uniform cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'none' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n\n/**\n * A set of data that represent a shader program\n */\nexport interface ProgramInfo {\n  /**\n   * the name of the program. used for debugging and profiling\n   */\n  name: string;\n\n  /**\n   * an optional object describing the cache information of the program shader.\n   *\n   * If this is not specified, assume hint is empty and inputDependencies are ['dims'] for all inputs.\n   */\n  shaderCache?: ProgramShaderCacheInfo;\n\n  /**\n   * the shader's processing source code.\n   *\n   * This function will be called when shader cache missed.\n   */\n  getShaderSource: (shaderHelper: ShaderHelper) => string;\n\n  /**\n   * A function to get run data required to run the program.\n   *\n   * This function will be called every time the program is executed. Should keep this function as simple as possible.\n   */\n  getRunData: (inputs: readonly TensorView[]) => {\n    outputs: readonly TensorInfo[];\n    dispatchGroup: {x: number; y?: number; z?: number};\n    programUniforms?: readonly ProgramUniform[];\n  };\n}\n\nexport interface Artifact {\n  programInfo: ProgramInfo;\n  computePipeline: GPUComputePipeline;\n}\n\nexport interface ComputeContextInputsOutputsMapping {\n  /**\n   * specify the mapping to the program's inputs. the value can be a number or a tensor view.\n   * - if it's a number, it's the index of the kernel's input\n   * - if it's a tensor view, it's an existing tensor view that will be used as the input\n   *\n   * if inputs is not specified, the mapping will be the kernel's inputs in order.\n   */\n  readonly inputs?: ReadonlyArray<TensorView|number>;\n  /**\n   * specify the mapping to the program's outputs. the value must be a number.\n   * - if it's a non-negative number, it's the index of the kernel's output\n   * - if it's -1, it's an output that will be created as a temporary value. this value will be released after\n   * the kernel is executed.\n   * - if it's -2, it's an output that will be created as a persistent value. this value will be released when the\n   * kernel is released.\n   *\n   * if outputs is not specified, the mapping will be the kernel's outputs in order.\n   */\n  readonly outputs?: readonly number[];\n}\n\n/**\n * A ComputeContext instance carries the states that representing the current running of a kernel.\n */\nexport interface ComputeContext {\n  /**\n   * stores the pointer to OpKernelContext\n   */\n  readonly opKernelContext: number;\n\n  /**\n   * a list of inputs, each input is an instance of TensorView\n   */\n  readonly inputs: readonly TensorView[];\n\n  /**\n   * a custom data object that can be used to store any data that is needed by the kernel\n   */\n  readonly kernelCustomData: {[key: string]: unknown};\n\n  /**\n   * a buffer that can be used to access custom data created each time the kernel is executed\n   */\n  readonly customDataBuffer: Uint8Array;\n\n  /**\n   * a number of outputs for the node\n   */\n  readonly outputCount: number;\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[];\n  output(index: number, dims: readonly number[]): number;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\n\nimport {GpuData, GpuDataId, GpuDataType} from './types';\n\n/**\n * manages GpuDataId -> GpuBuffer\n */\nexport interface GpuDataManager {\n  /**\n   * copy data from CPU to GPU.\n   */\n  upload(id: GpuDataId, data: Uint8Array): void;\n  /**\n   * copy data from GPU to GPU.\n   */\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void;\n  /**\n   * create new data on GPU.\n   */\n  create(size: number, usage?: number): GpuData;\n  /**\n   * get GPU data by ID.\n   */\n  get(id: GpuDataId): GpuData|undefined;\n  /**\n   * release the data on GPU by ID.\n   *\n   * @return size of the data released\n   */\n  release(id: GpuDataId): number;\n  /**\n   * copy data from GPU to CPU.\n   */\n  download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void>;\n\n  /**\n   * refresh the buffers that marked for release.\n   *\n   * when release() is called, the buffer is not released immediately. this is because we need to wait for the commands\n   * to be submitted to the GPU. this function is called after the commands are submitted so that the buffers can be\n   * actually released.\n   */\n  refreshPendingBuffers(): void;\n\n  /**\n   * register an external buffer for IO Binding. If the buffer is already registered, return the existing GPU data ID.\n   *\n   * GPU data manager only manages a mapping between the buffer and the GPU data ID. It will not manage the lifecycle of\n   * the external buffer.\n   */\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number;\n\n  /**\n   * unregister an external buffer for IO Binding.\n   */\n  unregisterExternalBuffer(buffer: GPUBuffer): void;\n\n  /**\n   * destroy all gpu buffers. Call this when the session.release is called.\n   */\n  dispose(): void;\n}\n\ninterface StorageCacheValue {\n  gpuData: GpuData;\n  originalSize: number;\n}\n\n/**\n * normalize the buffer size so that it fits the 128-bits (16 bytes) alignment.\n */\nconst calcNormalizedBufferSize = (size: number) => Math.ceil(size / 16) * 16;\n\nlet guid = 1;\nconst createNewGpuDataId = () => guid++;\n\n/**\n * exported standard download function. This function is used by the session to download the data from GPU, and also by\n * factory to create GPU tensors with the capacity of downloading data from GPU.\n *\n * @param backend - the WebGPU backend\n * @param gpuBuffer - the GPU buffer to download\n * @param originalSize - the original size of the data\n * @param getTargetBuffer - optional. If provided, the data will be copied to the target buffer. Otherwise, a new buffer\n * will be created and returned.\n */\nexport const downloadGpuData =\n    async(backend: WebGpuBackend, gpuBuffer: GPUBuffer, originalSize: number, getTargetBuffer?: () => Uint8Array):\n        Promise<Uint8Array> => {\n          const bufferSize = calcNormalizedBufferSize(originalSize);\n          const gpuReadBuffer = backend.device.createBuffer(\n              // eslint-disable-next-line no-bitwise\n              {size: bufferSize, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ});\n          try {\n            const commandEncoder = backend.getCommandEncoder();\n            backend.endComputePass();\n            commandEncoder.copyBufferToBuffer(\n                gpuBuffer /* source buffer */, 0 /* source offset */, gpuReadBuffer /* destination buffer */,\n                0 /* destination offset */, bufferSize /* size */\n            );\n            backend.flush();\n\n            await gpuReadBuffer.mapAsync(GPUMapMode.READ);\n\n            const arrayBuffer = gpuReadBuffer.getMappedRange();\n            if (getTargetBuffer) {\n              // if we already have a CPU buffer to accept the data, no need to clone the ArrayBuffer.\n              const targetBuffer = getTargetBuffer();\n              targetBuffer.set(new Uint8Array(arrayBuffer, 0, originalSize));\n              return targetBuffer;\n            } else {\n              // the mapped ArrayBuffer will be released when the GPU buffer is destroyed. Need to clone the\n              // ArrayBuffer.\n              return new Uint8Array(arrayBuffer.slice(0, originalSize));\n            }\n          } finally {\n            gpuReadBuffer.destroy();\n          }\n        };\n\nclass GpuDataManagerImpl implements GpuDataManager {\n  // GPU Data ID => GPU Data ( storage buffer )\n  private storageCache: Map<GpuDataId, StorageCacheValue>;\n\n  // pending buffers for uploading ( data is unmapped )\n  private buffersForUploadingPending: GPUBuffer[];\n  // pending buffers for computing\n  private buffersPending: GPUBuffer[];\n\n  // The reusable storage buffers for computing.\n  private freeBuffers: Map<number, GPUBuffer[]>;\n  // The reusable uniform buffers\n  private freeUniformBuffers: Map<number, GPUBuffer[]>;\n\n  // The external buffers registered users for IO Binding.\n  private externalBuffers: Map<GPUBuffer, GpuDataId>;\n\n  constructor(private backend: WebGpuBackend) {\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n    this.buffersForUploadingPending = [];\n    this.buffersPending = [];\n    this.externalBuffers = new Map();\n  }\n\n  upload(id: GpuDataId, data: Uint8Array): void {\n    const srcArrayBuffer = data.buffer;\n    const srcOffset = data.byteOffset;\n    const srcLength = data.byteLength;\n    const size = calcNormalizedBufferSize(srcLength);\n\n    // get destination gpu buffer\n    const gpuDataCache = this.storageCache.get(id);\n    if (!gpuDataCache) {\n      throw new Error('gpu data for uploading does not exist');\n    }\n    if (gpuDataCache.originalSize !== srcLength) {\n      throw new Error(`inconsistent data size. gpu data size=${gpuDataCache.originalSize}, data size=${srcLength}`);\n    }\n\n    // create gpu buffer\n    const gpuBufferForUploading = this.backend.device.createBuffer(\n        // eslint-disable-next-line no-bitwise\n        {mappedAtCreation: true, size, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC});\n\n    // copy (upload) data\n    const arrayBuffer = gpuBufferForUploading.getMappedRange();\n    new Uint8Array(arrayBuffer).set(new Uint8Array(srcArrayBuffer, srcOffset, srcLength));\n    gpuBufferForUploading.unmap();\n\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(gpuBufferForUploading, 0, gpuDataCache.gpuData.buffer, 0, size);\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.upload(id=${id})`);\n\n    this.buffersForUploadingPending.push(gpuBufferForUploading);\n  }\n\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void {\n    // get source gpu buffer\n    const sourceGpuDataCache = this.storageCache.get(sourceId);\n    if (!sourceGpuDataCache) {\n      throw new Error('source gpu data for memcpy does not exist');\n    }\n    // get destination gpu buffer\n    const destinationGpuDataCache = this.storageCache.get(destinationId);\n    if (!destinationGpuDataCache) {\n      throw new Error('destination gpu data for memcpy does not exist');\n    }\n    if (sourceGpuDataCache.originalSize !== destinationGpuDataCache.originalSize) {\n      throw new Error('inconsistent source and destination gpu data size');\n    }\n    const size = calcNormalizedBufferSize(sourceGpuDataCache.originalSize);\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(\n        sourceGpuDataCache.gpuData.buffer, 0, destinationGpuDataCache.gpuData.buffer, 0, size);\n  }\n\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number {\n    let id: number|undefined;\n    if (previousBuffer) {\n      id = this.externalBuffers.get(previousBuffer);\n      if (id === undefined) {\n        throw new Error('previous buffer is not registered');\n      }\n      if (buffer === previousBuffer) {\n        LOG_DEBUG(\n            'verbose',\n            () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${\n                id}, buffer is the same, skip.`);\n        return id;\n      }\n      this.externalBuffers.delete(previousBuffer);\n    } else {\n      id = createNewGpuDataId();\n    }\n\n    this.storageCache.set(id, {gpuData: {id, type: GpuDataType.default, buffer}, originalSize});\n    this.externalBuffers.set(buffer, id);\n    LOG_DEBUG(\n        'verbose',\n        () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${id}, registered.`);\n    return id;\n  }\n\n  unregisterExternalBuffer(buffer: GPUBuffer): void {\n    const id = this.externalBuffers.get(buffer);\n    if (id !== undefined) {\n      this.storageCache.delete(id);\n      this.externalBuffers.delete(buffer);\n      LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${id}`);\n    }\n  }\n\n  // eslint-disable-next-line no-bitwise\n  create(size: number, usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST): GpuData {\n    const bufferSize = calcNormalizedBufferSize(size);\n\n    let gpuBuffer;\n    // Currently, only storage buffers are reused.\n    // eslint-disable-next-line no-bitwise\n    const isStorage = (usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE;\n    // eslint-disable-next-line no-bitwise\n    const isUniform = (usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;\n    if (isStorage || isUniform) {\n      const freeBuffers = isStorage ? this.freeBuffers : this.freeUniformBuffers;\n      let buffers = freeBuffers.get(bufferSize);\n      if (!buffers) {\n        buffers = [];\n        freeBuffers.set(bufferSize, buffers);\n      }\n      if (buffers.length > 0) {\n        gpuBuffer = buffers.pop() as GPUBuffer;\n      } else {\n        // create gpu buffer\n        gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n      }\n    } else {\n      // create gpu buffer\n      gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n    }\n\n    const gpuData = {id: createNewGpuDataId(), type: GpuDataType.default, buffer: gpuBuffer};\n    this.storageCache.set(gpuData.id, {gpuData, originalSize: size});\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.create(size=${size}) => id=${gpuData.id}`);\n    return gpuData;\n  }\n\n  get(id: GpuDataId): GpuData|undefined {\n    return this.storageCache.get(id)?.gpuData;\n  }\n\n  release(id: GpuDataId): number {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('releasing data does not exist');\n    }\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.release(id=${id}), gpuDataId=${cachedData.gpuData.id}`);\n\n    this.storageCache.delete(id);\n    this.buffersPending.push(cachedData.gpuData.buffer);\n    // cachedData.gpuData.buffer.destroy();\n\n    return cachedData.originalSize;\n  }\n\n  async download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void> {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('data does not exist');\n    }\n\n    await downloadGpuData(this.backend, cachedData.gpuData.buffer, cachedData.originalSize, getTargetBuffer);\n  }\n\n  refreshPendingBuffers(): void {\n    for (const buffer of this.buffersForUploadingPending) {\n      // upload buffer is only useful in the session creation time. So we don't need to reuse them in session running.\n      buffer.destroy();\n    }\n    this.buffersForUploadingPending = [];\n    for (const buffer of this.buffersPending) {\n      // eslint-disable-next-line no-bitwise\n      if ((buffer.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {\n        // Put the pending buffer to freeBuffers list instead of really destroying it for buffer reusing.\n        this.freeBuffers.get(buffer.size)!.push(buffer);\n        // eslint-disable-next-line no-bitwise\n      } else if ((buffer.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {\n        // Put the pending buffer to freeUniformBuffers list instead of really destroying it for buffer reusing.\n        this.freeUniformBuffers.get(buffer.size)!.push(buffer);\n      } else {\n        buffer.destroy();\n      }\n    }\n    this.buffersPending = [];\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n    this.freeUniformBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.storageCache.forEach((storage) => {\n      storage.gpuData.buffer.destroy();\n    });\n\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n  }\n}\n\nexport const createGpuDataManager = (...args: ConstructorParameters<typeof GpuDataManagerImpl>): GpuDataManager =>\n    new GpuDataManagerImpl(...args);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nclass AttributeWithCacheKeyImpl {\n  constructor(attribute: Record<string, unknown>) {\n    Object.assign(this, attribute);\n  }\n\n  private key: string;\n  public get cacheKey(): string {\n    if (!this.key) {\n      this.key =\n          Object.getOwnPropertyNames(this).sort().map(name => `${(this as Record<string, unknown>)[name]}`).join(';');\n    }\n    return this.key;\n  }\n}\n\nexport interface AttributeWithCacheKey {\n  readonly cacheKey: string;\n}\n\n/**\n * create a new object from the given attribute, and add a cacheKey property to it\n */\nexport const createAttributeWithCacheKey = <T extends Record<string, unknown>>(attribute: T): T&AttributeWithCacheKey =>\n    new AttributeWithCacheKeyImpl(attribute) as unknown as T & AttributeWithCacheKey;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable no-param-reassign */\n\nexport class MatMulUtil {\n  /**\n   * Calculate the expected shape when matrix multiplication\n   * @param a The shape of tensor A. Should be a tuple of 2 positive integers\n   * @param b The shape of tensor B. Should be a tuple of 2 positive integers\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcMatMulShape(a: [number, number], b: [number, number]): [number, number]|undefined {\n    return (a[1] !== b[0]) ? undefined : [a[0], b[1]];\n  }\n}\n\n\nexport class BroadcastUtil {\n  /**\n   * Calculate the expected shape when broadcasting 2 tensors\n   * @param a The shape of tensor A. Should be an array of positive integers\n   * @param b The shape of tensor B. Should be an array of positive integers\n   * @param isMatMul Whether the operation is MatMul\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcShape(adims: readonly number[], bdims: readonly number[], isMatMul = false): readonly number[]|undefined {\n    const arank = adims.length;\n    const brank = bdims.length;\n    if (arank === 0) {\n      return bdims;\n    }\n    if (brank === 0) {\n      return adims;\n    }\n    const crank = Math.max(adims.length, bdims.length);\n    const cdims = new Array<number>(crank);\n\n    // calculate the last 2 dimension if it is MatMul\n    if (isMatMul) {\n      if (arank < 2 || brank < 2) {\n        return undefined;\n      }\n      const cShapeMatMul =\n          MatMulUtil.calcMatMulShape([adims[arank - 2], adims[arank - 1]], [bdims[brank - 2], bdims[brank - 1]]);\n      if (cShapeMatMul === undefined) {\n        return undefined;\n      }\n      [cdims[crank - 2], cdims[crank - 1]] = cShapeMatMul;\n    }\n\n    for (let i = isMatMul ? 3 : 1; i <= crank; i++) {\n      const aLen = arank - i < 0 ? 1 : adims[arank - i];\n      const bLen = brank - i < 0 ? 1 : bdims[brank - i];\n\n      if (aLen !== bLen && aLen > 1 && bLen > 1) {\n        return undefined;\n      }\n      cdims[crank - i] = Math.max(aLen, bLen);\n    }\n\n    return cdims;\n  }\n\n  /**\n   * Determine if a shape is unidirectional broadcastable to another shape\n   * @param shape The input shape\n   * @param finalShape The desired shape after broadcasting\n   */\n  static isValidBroadcast(shape: readonly number[], finalShape: readonly number[]): boolean {\n    // align shape to the right\n    const inputRank = shape.length;\n    const finalRank = finalShape.length;\n    if (inputRank > finalRank) {\n      return false;\n    }\n    for (let i = 1; i <= inputRank; i++) {\n      if (shape[inputRank - i] !== 1 && shape[inputRank - i] !== finalShape[finalRank - i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\n\nexport class ShapeUtil {\n  /**\n   * calculate the size (number of elements)\n   */\n  static size(dims: readonly number[]): number {\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) from the given axis (inclusive)\n   */\n  static sizeFromDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeFromDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, axis, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) to the given axis (exclusive)\n   */\n  static sizeToDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeToDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, axis);\n  }\n\n  /**\n   * calculate the size (number of elements) from and to the given axis [start, end)\n   */\n  static getSizeFromDimensionRange(dims: readonly number[], start: number, end: number): number {\n    let size = 1;\n    for (let i = start; i < end; i++) {\n      // safety check as this method is called by multiple other methods requiring size.\n      // size cannot be negative.\n      if (dims[i] < 0) {\n        throw new Error(\n            // eslint-disable-next-line max-len\n            'cannot get valid size from specified dimension range. Most likely the range contains negative values in them.');\n      }\n      size *= dims[i];\n    }\n    return size;\n  }\n\n  static computeStrides(dims: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    if (rank === 0) {\n      return [];\n    } else if (rank === 1) {\n      return [1];\n    }\n    const strides = new Array(rank);\n    strides[rank - 1] = 1;\n    strides[rank - 2] = dims[rank - 1];\n    for (let i = rank - 3; i >= 0; --i) {\n      strides[i] = strides[i + 1] * dims[i + 1];\n    }\n    return strides;\n  }\n\n  /**\n   * normailze axis of range [-r, r) into [0, r).\n   */\n  static normalizeAxis(axis: number, tensorRank: number): number {\n    if (axis < -tensorRank && axis >= tensorRank) {\n      throw new Error('unsupported axis for this operation.');\n    }\n    return axis < 0 ? axis + tensorRank : axis;\n  }\n\n  static normalizeAxes(axes: readonly number[], tensorRank?: number): number[] {\n    return axes.map(x => this.normalizeAxis(x, tensorRank ?? axes.length));\n  }\n\n  /**\n   * Sorts a given array based on the indices in the Perm array\n   * Used in Transpose\n   * @param a Array to be sorted such as dims or strides\n   * @param perm Perm given; if null a will be reversed\n   */\n  static sortBasedOnPerm(a: readonly number[], perm?: readonly number[]): readonly number[] {\n    if (perm) {\n      return perm.map((v) => a[v]);\n    } else {\n      return a.slice().reverse();\n    }\n  }\n\n  /**\n   * Pads a given shape according to the padding values\n   * @param dims shape of the Tensor to be padded\n   * @param pad pad values\n   */\n  static padShape(dims: readonly number[], pad: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    return dims.map((v, i) => v + pad[i] + pad[i + rank]);\n  }\n\n  /**\n   * Determines if the two shapes are identical\n   * @param shape1\n   * @param shape2\n   */\n  static areEqual(shape1: readonly number[], shape2: readonly number[]): boolean {\n    if (shape1.length !== shape2.length) {\n      return false;\n    }\n    return shape1.every((v, i) => v === shape2[i]);\n  }\n}\n\nexport class PoolConvUtil {\n  /**\n   * Adjust the kernel, strides, pads to correct rank. Set to default value if not present\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   */\n  static adjustPoolAttributes(\n      isGlobalOperator: boolean, inputDims: readonly number[], kernelShape: number[], strides: number[],\n      dilations: number[], pads: number[]): void {\n    if (!isGlobalOperator && kernelShape.length !== inputDims.length - 2) {\n      throw new Error('length of specified kernel shapes should be 2 less than length of input dimensions');\n    }\n\n    if (isGlobalOperator) {\n      // adjust kernel shape to cover the input dims\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        if (dim >= kernelShape.length) {\n          kernelShape.push(inputDims[dim + 2]);\n        } else {\n          kernelShape[dim] = inputDims[dim + 2];\n        }\n      }\n    }\n\n    // adjust strides length to match kernel shape length\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < strides.length) {\n        if (strides[dim] < 0) {\n          throw new Error('strides should be greater than or equal to 1');\n        }\n      } else {\n        strides.push(1);\n      }\n    }\n\n    // adjust dilation value\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < dilations.length) {\n        if (dilations[dim] < 0) {\n          throw new Error('dilations should be greater than or equal to 1');\n        }\n      } else {\n        dilations.push(1);\n      }\n    }\n\n    // adjust pads length to match 2 * kernel shape length\n    for (let dim = 0; dim < kernelShape.length * 2; dim++) {\n      if (dim < pads.length) {\n        if (pads[dim] < 0) {\n          throw new Error('pad should be greater than or equal to 1');\n        }\n      } else {\n        pads.push(0);\n      }\n    }\n\n    // sanity checks for values in kernel shapes and pads\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (kernelShape[dim] <= 0) {\n        throw new Error('kernel shapes need to be greater than 0');\n      }\n\n      if (pads[dim] >= kernelShape[dim] || pads[dim + kernelShape.length] >= kernelShape[dim]) {\n        throw new Error('pads should be smaller than kernel');\n      }\n    }\n  }\n\n  // adjust pad values based on 'autoPad' attribute\n  static adjustPadsBasedOnAutoPad(\n      inputDims: readonly number[], strides: readonly number[], dilations: readonly number[],\n      kernelShape: readonly number[], pads: number[], isChannelLast: boolean, autoPad?: string): void {\n    if (!autoPad) {\n      return;\n    }\n\n    if (pads.length !== 2 * (inputDims.length - 2)) {\n      throw new Error('length of pads should be twice the length of data dimensions');\n    }\n\n    if (strides.length !== (inputDims.length - 2)) {\n      throw new Error('length of strides should be the length of data dimensions');\n    }\n\n    if (kernelShape.length !== (inputDims.length - 2)) {\n      throw new Error('length of kernel shapes should be the length of data dimensions');\n    }\n\n    for (let dim = 0; dim < inputDims.length - 2; dim++) {\n      PoolConvUtil.adjustPadAndReturnShape(\n          inputDims[dim + (isChannelLast ? 1 : 2)], strides[dim], dilations[dim], kernelShape[dim], pads, dim,\n          dim + inputDims.length - 2, autoPad);\n    }\n  }\n\n  /**\n   * Calculate the output shape for Pool ops based on input attributes. (Should be used only for Pool ops)\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computePoolOutputShape(\n      isGlobalOperator: boolean, inputDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0) {\n      throw new Error('input shape must be of size greater than 0');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], inputDims[1]];\n\n    PoolConvUtil.computeShapeHelper(\n        isGlobalOperator, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  /**\n   * Calculate the output shape for Conv op based on input attributes. (Should be used only for Conv op)\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param filterDims The filter tensor dimension. (inputs[1].dims)\n   * @param strides Stride along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computeConvOutputShape(\n      inputDims: readonly number[], filterDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0 || filterDims.length <= 0) {\n      throw new Error('invalid input tensor dims or invalid filter tensor dims');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], filterDims[0]];\n\n    PoolConvUtil.computeShapeHelper(false, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  // will compute output shapes for data dimensions ONLY (i.e.) no batch size and channels\n  // called by computePoolOutputShape() and computeConvOutputShape()\n  // adjust pads based on 'autoPad' attribute prior to shape computation\n  private static computeShapeHelper(\n      isGlobalOperator: boolean, inputDims: readonly number[], outputDims: number[], strides: readonly number[],\n      dilations: readonly number[], kernelShape: readonly number[], pads: number[], autoPad?: string) {\n    if (isGlobalOperator) {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(1);\n      }\n    } else {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(PoolConvUtil.adjustPadAndReturnShape(\n            inputDims[dim + 2], strides[dim], dilations[dim], kernelShape[dim], pads, dim, dim + inputDims.length - 2,\n            autoPad));\n      }\n    }\n  }\n\n  // helper for computeShapeHelper() and adjustPadsBasedOnAutoPad()\n  // adjusts pad value for given 'autoPad' string and computes output shape along a particular dimension\n  private static adjustPadAndReturnShape(\n      inSize: number, stride: number, dilation: number, kernel: number, pads: number[], padHeadIndex: number,\n      padTailIndex: number, autoPad?: string): number {\n    const dkernel = dilation * (kernel - 1) + 1;\n    if (autoPad && autoPad !== 'NOTSET') {\n      switch (autoPad) {\n        case 'VALID':\n          pads[padHeadIndex] = 0;\n          pads[padTailIndex] = 0;\n          return Math.floor(((inSize - dkernel) / stride) + 1);\n        case 'SAME_LOWER':\n        case 'SAME_UPPER':\n          if (dilation !== 1) {\n            throw new Error('Dilation not supported for SAME_UPPER or SAME_LOWER');\n          } else {\n            const legacyTargetSize = (inSize + stride - 1) / stride;\n            const padNeeded = (legacyTargetSize - 1) * stride + kernel - inSize;\n            pads[padHeadIndex] =\n                (autoPad === 'SAME_LOWER') ? Math.floor((padNeeded + 1) / 2) : Math.floor(padNeeded / 2);\n            pads[padTailIndex] = padNeeded - pads[padHeadIndex];\n            return Math.floor(((inSize + padNeeded - kernel) / stride) + 1);\n          }\n        default:\n          throw new Error('Unsupported AutoPad type');\n      }\n    } else {\n      return Math.floor(((inSize + pads[padHeadIndex] + pads[padTailIndex] - dkernel) / stride) + 1);\n    }\n  }\n}\n\nexport class GemmUtil {\n  // will make sure input shapes are compatible for this op\n  // and return back the shape of the output in the form of a tuple\n  // will throw exception if the input shapes are not compatible\n  static getShapeOfGemmResult(\n      leftShape: readonly number[], transLeft: boolean, rightShape: readonly number[], transRight: boolean,\n      biasShape?: readonly number[]): readonly number[] {\n    if (leftShape.length !== 2 || rightShape.length !== 2) {\n      throw new Error('shape need to be of size 2');\n    }\n\n    let M: number;\n    let K: number;\n    let N: number;\n\n    if (transLeft) {\n      M = leftShape[1];\n      K = leftShape[0];\n    } else {\n      M = leftShape[0];\n      K = leftShape[1];\n    }\n\n    let kDim = -1;\n\n    if (transRight) {\n      N = rightShape[0];\n      kDim = 1;\n    } else {\n      N = rightShape[1];\n      kDim = 0;\n    }\n\n    if (rightShape[kDim] !== K) {\n      throw new Error('dimension mismatch');\n    }\n\n    if (M <= 0 || N <= 0 || K <= 0) {\n      throw new Error('invalid shape specified');\n    }\n\n    if (biasShape && !BroadcastUtil.isValidBroadcast(biasShape, [M, N])) {\n      throw new Error('gemm: invalid bias shape for broadcast');\n    }\n\n    return [M, N, K];\n  }\n}\n\n\nexport const MIN_CLIP = -3.4028234663852886e+38;\nexport const MAX_CLIP = 3.4028234663852886e+38;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {ShapeUtil} from '../../util';\nimport {ProgramUniform} from '../types';\n\n/**\n * constant value for a workgroup size.\n *\n * We definitely can do further optimization in future, but for now we use 64.\n *\n * rule of thumb: Use [a workgroup size of] 64 unless you know what GPU you are targeting or that your workload\n *                needs something different.\n *\n * from: https://surma.dev/things/webgpu/\n **/\nexport const WORKGROUP_SIZE = 64;\n\ninterface IndicesHelperTypes {\n  /**\n   * WGSL type of indices expression\n   */\n  readonly indices: string;\n\n  /**\n   * WGSL type of a value\n   */\n  readonly value: string;\n\n  /**\n   * WGSL type of storage type representing a value\n   *\n   * This is usually the same to `value`, but for some type (eg. bool), we need to use `u32` as storage type for\n   * value type `vec4<bool>`\n   */\n  readonly storage: string;\n\n  /**\n   * tensor type as represented in TensorView\n   */\n  readonly tensor: number;\n}\n\n/**\n * A helper class for generating WGSL code for manipulating indices and data for a shader's input or output.\n *\n * This class is designed to offer a unified way to generate WGSL code for manipulating indices and data for a shader's\n * input or output.\n *\n * The following is a list of terminologies used in this class:\n * - `offset`: a uint32 value representing the offset of an element in the data buffer.\n * - `indices`: an abstraction of a multi-dimensional array's indices representing the data's index on each dimension.\n * - `value`: a value of a data element.\n *\n * Users are expected to create an instance of this class for each shader's input or output, and use the instance to\n * generate WGSL code for manipulating indices and data. The following 2 exported functions are for users to call to\n * create an instance of an indices helper:\n * - `inputVariable()`: create an indices helper instance for an input.\n * - `outputVariable()`: create an indices helper instance for an output.\n * - `internalVariable()`: create an indices helper instance for an internal variable.\n *\n * An indices helper instance contains helper functions for the following operations:\n * - access readonly basic information, including: `name`(the name of the input or output), `usage`(whether it's an\n * input, an output or an internal variable) and `shape`(the passed in shape).\n * - `type`: access readonly type information, including: `indices`(the type of indices), `value`(the type of value at\n * runtime), `storage`(the type of value at storage) and `tensor`(the tensor type as represented in TensorView).\n * - generate WGSL code for getting indices from offset. Use `offsetToIndices()` for WGSL code snippet to calculate\n * indices from offset, and use `indicesToOffset()` for WGSL code snippet to calculate offset from indices.\n * - to manipulate an instance of indices, use `setIndices()` and `getIndices()` to set and get the indices on an\n * indices variable.\n * - to manipulate data, use `set()`/`get()` to access data at the given indices from parameter list, use\n * `setByIndices()`/`getByIndices()` to access data at the given indices from an indices variable, and use\n * `setByOffset()`/`getByOffset()` to access data at the given offset.\n * - `impl`: get WGSL code of function implementation for the util functions mentioned above.\n */\nexport interface IndicesHelper {\n  /**\n   * get WGSL code of function implementation for the util functions.\n   *\n   */\n  readonly impl: () => string;\n\n  /**\n   * get type info\n   */\n  readonly type: IndicesHelperTypes;\n\n  /**\n   * WGSL code of a expression for getting indices from offset.\n   *\n   * @param varOffset - a u32 expression representing the offset.\n   *\n   * @returns an `type.indices` expression\n   */\n  readonly offsetToIndices: (varOffset: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting offset from indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the indices.\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesToOffset: (varIndices: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting original offset from broadcasted indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the output indices.\n   * @param output - output IndicesHelper.\n   *\n   * @returns an `u32` expression\n   */\n  readonly broadcastedIndicesToOffset: (varIndices: string, output: IndicesHelper) => string;\n\n  /**\n   * WGSL code of generating an indices literal\n   *\n   * @param init - initial value.\n   */\n  readonly indices: (...init: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code of a statement for setting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to set. can be a number or a string (WGSL `u32` expression).\n   * @param value - the value to set. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns a WGSL statement\n   */\n  readonly indicesSet: (varIndices: string, idx: number|string, value: number|string) => void;\n\n  /**\n   * WGSL code of an `u32` expression for getting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to get. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesGet: (varIndices: string, idx: number|string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices.\n   *\n   * @param indicesAndValue - an array of numbers or strings (WGSL `u32` expression) representing the indices, followed\n   *     by the value to set. This array should have exactly `shape.length + 1` elements.\n   */\n  readonly set: (...indicesAndValue: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByIndices: (varIndices: string, value: string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByOffset: (offset: number|string, value: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices.\n   *\n   * @param indices - an array of numbers or strings (WGSL `u32` expression) representing the indices.\n   */\n  readonly get: (...indices: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   */\n  readonly getByIndices: (varIndices: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   */\n  readonly getByOffset: (offset: number|string) => string;\n\n  /**\n   * name of the data variable\n   */\n  readonly name: string;\n\n  /**\n   * whether the helper is for an input, an output or an internal variable.\n   */\n  readonly usage: 'input'|'output'|'internal';\n\n  /**\n   * the rank of the input or output.\n   */\n  readonly rank: number;\n\n  /**\n   * a string representing the variable name for the shape of the input or output.\n   */\n  readonly shape: string;\n\n  /**\n   * a string representing the variable name for the strides of the input or output.\n   */\n  readonly strides: string;\n}\n\nconst getWgslMappedType = (type: number, components: 1|2|3|4): string|[string, string] => {\n  if (components === 3) {\n    throw new Error('vec3 has same alignment as vec4, use vec4 instead');\n  }\n\n  // return type is [ storage type, runtime type ] or a single string for both\n  switch (type) {\n    case DataType.float16:\n      return components > 1 ? `vec${components}<f16>` : 'f16';\n    case DataType.float:\n      return components > 1 ? `vec${components}<f32>` : 'f32';\n    case DataType.int32:\n      return components > 1 ? `vec${components}<i32>` : 'i32';\n    case DataType.uint32:\n      return components > 1 ? `vec${components}<u32>` : 'u32';\n    case DataType.int64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'i32'];\n    case DataType.uint64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'u32'];\n    case DataType.bool:\n      if (components !== 4) {\n        throw new Error('bool must be vec4');\n      }\n      return ['u32', 'vec4<bool>'];\n\n    default:\n      throw new Error(`Unknown data type: ${type}`);\n  }\n};\n\nexport const tensorTypeToWsglStorageType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[0];\n};\n\nexport const tensorTypeToWsglValueType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[1];\n};\n\nexport const createTensorShapeVariables = (dims: readonly number[]): ProgramUniform[] =>\n    dims.length === 0 ? [] : [{type: 'uint32', data: dims}, {type: 'uint32', data: ShapeUtil.computeStrides(dims)}];\n\n/**\n * A helper function to get maximum vector size for specified data length\n * @param size\n */\nexport const getMaxComponents = (size: number) => {\n  // we cannot use vec3 type since it has alignment of 16 bytes\n  if (size % 4 === 0) {\n    return 4;\n  } else if (size % 2 === 0) {\n    return 2;\n  }\n\n  return 1;\n};\n\n/**\n * A helper function that initializes variable as a scalar or vector. e.g. f32(0) or vec4f(0,0,0,0)\n * @param dataType\n * @param components\n * @param value\n */\nexport const fillVector = (dataType = 'f32', components?: number, value = '0') => {\n  if (!components || components === 1) {\n    return `${dataType}(${value})`;\n  }\n\n  return `vec${components}<${dataType}>(${value})`;\n};\n\n/**\n * A helper function that casts value or vector to f32\n * @param dataType\n * @param components\n * @param value\n */\nexport const castToF32 = (dataType: string, components: number, value: string) => {\n  if (dataType === 'f32') {\n    return value;\n  }\n  if (components === 1) {\n    return `f32(${value})`;\n  }\n\n  return `vec${components}f(${value})`;\n};\n\n/**\n * A helper function that returns scalar or sums all components of a vector\n * @param name\n * @param components\n */\nexport const sumVector = (name: string, components: number) => {\n  if (components === 4) {\n    return `(${name}.x + ${name}.y + ${name}.z + ${name}.w)`;\n  } else if (components === 2) {\n    return `(${name}.x + ${name}.y)`;\n  } else if (components === 3) {\n    return `(${name}.x + ${name}.y + ${name}.z)`;\n  }\n\n  return name;\n};\n\n/**\n * A helper function that returns variable element at index.\n * @param name - the name of variable.\n * @param index - the index of variable element.\n * @param length - the length of variable.\n */\nexport const getElementAt = (name: string, index: number|string, length: number): string => {\n  if (name.startsWith('uniforms.') && length > 4) {\n    if (typeof (index) === 'string') {\n      return `${name}[(${index}) / 4][(${index}) % 4]`;\n    } else {\n      return `${name}[${Math.floor(index / 4)}][${index % 4}]`;\n    }\n  } else {\n    return length > 1 ? `${name}[${index}]` : name;\n  }\n};\n\n/**\n * A helper function to get a IndicesHelper for a given input or output.\n *\n * @param name - the name of the input or output.\n * @param tensorType - the tensor type of the input or output.\n * @param shapeOrRank - the tensor shape or the rank of the input or output.\n * @param usage - the usage of the indices helper.\n * @param components - indicates the number of components of each element. 1 for scalar, 2 for vec2, 3 for vec3, 4 for\n *    vec4.\n */\nconst createIndicesHelper =\n    (name: string, tensorType: number, shapeOrRank: number|readonly number[], usage: IndicesHelper['usage'],\n     components: 1|2|3|4): IndicesHelper => {\n      const useUniform = typeof shapeOrRank === 'number';\n      const rank = useUniform ? shapeOrRank : shapeOrRank.length;\n      const rankIdentity = [...new Array(rank).keys()];\n      const indicesType = rank < 2 ? 'u32' : rank <= 4 ? `vec${rank}<u32>` : `array<u32, ${rank}>`;\n      const mappedType = getWgslMappedType(tensorType, components);\n      const valueType = typeof mappedType === 'string' ? mappedType : mappedType[1];\n      const storageType = typeof mappedType === 'string' ? mappedType : mappedType[0];\n      const type = {indices: indicesType, value: valueType, storage: storageType, tensor: tensorType};\n\n      const normalizeDim = (dim: number|string): string => typeof dim === 'string' ? dim : `${dim}u`;\n\n      const implementationUsed = {\n        offsetToIndices: false,\n        indicesToOffset: false,\n        broadcastedIndicesToOffset: false,\n        set: false,\n        setByIndices: false,\n        get: false,\n        getByIndices: false,\n      };\n\n      const uniformPrefix = useUniform ? 'uniforms.' : '';\n      const shape = `${uniformPrefix}${name}_shape`;\n      const strides = `${uniformPrefix}${name}_strides`;\n\n      let o2iSnippet = '';\n      for (let i = 0; i < rank - 1; i++) {\n        o2iSnippet += `\n    let dim${i} = current / ${getElementAt(strides, i, rank)};\n    let rest${i} = current % ${getElementAt(strides, i, rank)};\n    indices[${i}] = dim${i};\n    current = rest${i};\n    `;\n      }\n      o2iSnippet += `indices[${rank - 1}] = current;`;\n\n      const offsetToIndicesImplementation = rank < 2 ? '' : `\n  fn o2i_${name}(offset: u32) -> ${type.indices} {\n    var indices: ${type.indices};\n    var current = offset;\n    ${o2iSnippet}\n    return indices;\n  }`;\n\n      const offsetToIndices = (varOffset: string) => {\n        implementationUsed.offsetToIndices = true;\n        return rank < 2 ? varOffset : `o2i_${name}(${varOffset})`;\n      };\n\n      const offsets: string[] = [];\n      if (rank >= 2) {\n        for (let i = rank - 1; i >= 0; i--) {\n          offsets.push(`${getElementAt(strides, i, rank)} * (indices[${i}])`);\n        }\n      }\n\n      const indicesToOffsetImplementation = rank < 2 ? '' : `\n  fn i2o_${name}(indices: ${type.indices}) -> u32 {\n    return ${offsets.join('+')};\n  }`;\n\n      const indicesToOffset = (varIndices: string) => {\n        implementationUsed.indicesToOffset = true;\n        return rank < 2 ? varIndices : `i2o_${name}(${varIndices})`;\n      };\n\n      const indices = (...init: ReadonlyArray<number|string>) =>\n          rank === 0 ? '0u' : `${type.indices}(${init.map(normalizeDim).join(',')})`;\n\n      const indicesGet = (varIndices: string, idx: number|string) => {\n        if (rank < 2) {\n          return `${varIndices}`;\n        } else {\n          return `${getElementAt(varIndices, idx, rank)}`;\n        }\n      };\n\n      const indicesSet = (varIndices: string, idx: number|string, value: string) => {\n        if (rank < 2) {\n          return `${varIndices}=${value};`;\n        } else {\n          return `${getElementAt(varIndices, idx, rank)}=${value};`;\n        }\n      };\n\n      const broadcastedIndicesToOffsetImplementation: {[key: string]: string} = {};\n      const broadcastedIndicesToOffset = (varIndices: string, output: IndicesHelper) => {\n        implementationUsed.broadcastedIndicesToOffset = true;\n        const implKey = `${output.name}broadcastedIndicesTo${name}Offset`;\n        if (implKey in broadcastedIndicesToOffsetImplementation) {\n          return `${implKey}(${varIndices})`;\n        }\n        const offsets = [];\n        for (let i = rank - 1; i >= 0; i--) {\n          const idx = output.indicesGet('outputIndices', i + output.rank - rank);\n          offsets.push(`${indicesGet(strides, i)} * (${idx} % ${indicesGet(shape, i)})`);\n        }\n        broadcastedIndicesToOffsetImplementation[implKey] =\n            `fn ${implKey}(outputIndices: ${output.type.indices}) -> u32 {\n             return ${offsets.length > 0 ? offsets.join('+') : '0u'};\n           }`;\n\n        return `${implKey}(${varIndices})`;\n      };\n\n      const setByOffset = (offset: number|string, value: string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]=${value};`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), select(0u, 0xFFFFFFFFu, ${value} < 0));`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), 0u);`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `${name}[${offset}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${value}));`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByOffset = (offset: number|string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `i32(${name}[${offset}].x)`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `u32(${name}[${offset}].x)`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `vec4<bool>(bool(${name}[${offset}] & 0xFFu), bool(${name}[${offset}] & 0xFF00u), bool(${name}[${\n              offset}] & 0xFF0000u), bool(${name}[${offset}] & 0xFF000000u))`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByIndicesImplementation = rank < 2 ? '' : `\n  fn get_${name}ByIndices(indices: ${type.indices}) -> ${valueType} {\n    return ${getByOffset(`i2o_${name}(indices)`)};\n  }`;\n\n      const getImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn get_${name}(${functionParams}) -> ${valueType} {\n    return get_${name}ByIndices(${indices(dimsParams)});\n  }`;\n      })();\n\n      const get = (...indices: ReadonlyArray<number|string>) => {\n        if (indices.length !== rank) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n\n        const normalizedIndices = indices.map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return getByOffset('0u');\n        } else if (rank === 1) {\n          return getByOffset(normalizedIndices[0]);\n        } else {\n          implementationUsed.get = true;\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}(${normalizedIndices})`;\n        }\n      };\n\n      const getByIndices = (varIndices: string) => {\n        if (rank < 2) {\n          return getByOffset(varIndices);\n        } else {\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}ByIndices(${varIndices})`;\n        }\n      };\n\n      const setByIndicesImplementation = rank < 2 ? '' : `\n  fn set_${name}ByIndices(indices: ${type.indices}, value: ${valueType}) {\n    ${setByOffset(`i2o_${name}(indices)`, 'value')}\n  }`;\n\n      const setImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn set_${name}(${functionParams}, value: ${valueType}) {\n    set_${name}ByIndices(${indices(dimsParams)}, value);\n  }`;\n      })();\n\n      const set = (...indicesAndValue: ReadonlyArray<number|string>) => {\n        if (indicesAndValue.length !== rank + 1) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n        const value = indicesAndValue[rank];\n        if (typeof value !== 'string') {\n          throw new Error('value must be string');\n        }\n\n        const normalizedIndices = indicesAndValue.slice(0, rank).map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return setByOffset('0u', value);\n        } else if (rank === 1) {\n          return setByOffset(normalizedIndices[0], value);\n        } else {\n          implementationUsed.set = true;\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}(${normalizedIndices}, ${value})`;\n        }\n      };\n\n      const setByIndices = (varIndices: string, value: string) => {\n        if (rank < 2) {\n          return setByOffset(varIndices, value);\n        } else {\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}ByIndices(${varIndices}, ${value});`;\n        }\n      };\n\n      const impl = () => {\n        const impls = [];\n        if (!useUniform) {\n          impls.push(`const ${shape} = ${type.indices}(${shapeOrRank.join(',')});`);\n          impls.push(`const ${strides} = ${type.indices}(${ShapeUtil.computeStrides(shapeOrRank).join(',')});`);\n        }\n        if (implementationUsed.offsetToIndices) {\n          impls.push(offsetToIndicesImplementation);\n        }\n        if (implementationUsed.indicesToOffset) {\n          impls.push(indicesToOffsetImplementation);\n        }\n        if (implementationUsed.broadcastedIndicesToOffset) {\n          Object.values(broadcastedIndicesToOffsetImplementation).forEach(impl => impls.push(impl));\n        }\n        if (implementationUsed.set) {\n          impls.push(setImplementation);\n        }\n        if (implementationUsed.setByIndices) {\n          impls.push(setByIndicesImplementation);\n        }\n        if (implementationUsed.get) {\n          impls.push(getImplementation);\n        }\n        if (implementationUsed.getByIndices) {\n          impls.push(getByIndicesImplementation);\n        }\n        return impls.join('\\n');\n      };\n\n      return {\n        impl,\n        type,\n        offsetToIndices,\n        indicesToOffset,\n        broadcastedIndicesToOffset,\n        indices,\n        indicesGet,\n        indicesSet,\n        set,\n        setByOffset,\n        setByIndices,\n        get,\n        getByOffset,\n        getByIndices,\n        // isVec4,\n        usage,\n        name,\n        strides,\n        shape,\n        rank\n      };\n    };\n\n/**\n * Create a IndicesHelper for an input.\n *\n * @param name - the name of the input.\n * @param type - the tensor type of the input.\n * @param shapeOrRank - the tensor shape or the rank of the input.\n * @param components - the number of components of the input. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the input.\n */\nexport const inputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, 'input', components);\n\n/**\n * Create a IndicesHelper for an output.\n *\n * @param name - the name of the output.\n * @param type - the tensor type of the output.\n * @param shapeOrRank - the tensor shape or the rank of the output.\n * @param components - the number of components of the output. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the output.\n */\nexport const outputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, 'output', components);\n\n/**\n * Create a IndicesHelper for an internal variable.\n *\n * @param name - the name of the variable.\n * @param type - the tensor type of the variable.\n * @param shapeOrRank - the tensor shape or the rank of the variable.\n * @param components - the number of components of the variable. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the variable.\n */\nexport const internalVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, 'internal', components);\n\nexport type UniformDataElementType = 'u32'|'f32'|'i32';\nexport type UniformsArrayType = Array<{name: string; type: UniformDataElementType; length?: number}>;\n\n/**\n * A ShaderHelper is a helper class for generating WGSL code.\n */\nexport interface ShaderHelper {\n  /**\n   * A helper function to generate the start of main function in WGSL source code.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param workgroupSize - an optional workgroup size. default is WORKGROUP_SIZE.\n   */\n  mainStart(workgroupSize?: number|[number, number, number]): string;\n\n  /**\n   * A helper function to generate the code snippet for guarding against out-of-bounds size.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n   *\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param size - the size of the data to guard against. can be a number or a string (WGSL `u32` expression).\n   */\n  guardAgainstOutOfBoundsWorkgroupSizes(size: unknown): string;\n\n  /**\n   * A helper function to generate the code snippet for declaring multiple inputs or outputs.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  declareVariables(...variables: IndicesHelper[]): string;\n\n  /**\n   * A helper function to register one uniform. Can be called multiple times to register multiple uniforms.\n   *\n   * @param name - the name of the uniform.\n   * @param type - the type of the uniform.\n   * @param length - the length of the uniform, default to 1 when it is not provided.\n   */\n  registerUniform(name: string, type: string, length?: number): ShaderHelper;\n\n  /**\n   * A helper function to register multiple uniforms. Can be called multiple times to register multiple uniforms.\n   *\n   * @param uniforms - an array of uniforms. Each element of the array is an object with 2 properties: `name` and\n   *     `type`.\n   */\n  registerUniforms(uniforms: UniformsArrayType): ShaderHelper;\n\n  /**\n   * A helper function to register multiple internal variables. Can be called multiple times to register multiple\n   * internal variables.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  registerInternalVariables(...variables: IndicesHelper[]): ShaderHelper;\n}\n\nclass ShaderHelperImpl implements ShaderHelper {\n  constructor(private normalizedDispatchGroup: [number, number, number]) {}\n\n  guardAgainstOutOfBoundsWorkgroupSizes(size: number|string): string {\n    // Guard against out-of-bounds work group sizes\n    const sizeInCode = typeof size === 'number' ? `${size}u` : size;\n    return `if (global_idx >= ${sizeInCode}) { return; }`;\n  }\n\n  mainStart(workgroupSize: number|[number, number, number] = WORKGROUP_SIZE) {\n    const workgroupSizeX = typeof workgroupSize === 'number' ? workgroupSize : workgroupSize[0];\n    const workgroupSizeY = typeof workgroupSize === 'number' ? 1 : workgroupSize[1];\n    const workgroupSizeZ = typeof workgroupSize === 'number' ? 1 : workgroupSize[2];\n\n    const is1DimensionDispatch = this.normalizedDispatchGroup[1] === 1 && this.normalizedDispatchGroup[2] === 1;\n    const paramList = is1DimensionDispatch ? `@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>` :\n                                             `@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`;\n    const globalIdxDefinition = is1DimensionDispatch ?\n        'let global_idx = global_id.x;' :\n        `let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${\n            workgroupSizeX * workgroupSizeY * workgroupSizeZ}u + local_index;`;\n\n    return `@compute @workgroup_size(${workgroupSizeX}, ${workgroupSizeY}, ${workgroupSizeZ})\n  fn main(${paramList}) {\n    ${globalIdxDefinition}\n  `;\n  }\n\n  private appendVariableUniforms(variable: IndicesHelper): void {\n    if (variable.rank !== 0) {\n      if (variable.shape.startsWith('uniforms.')) {\n        this.uniforms.push({name: variable.shape.replace('uniforms.', ''), type: 'u32', length: variable.rank});\n      }\n      if (variable.strides.startsWith('uniforms.')) {\n        this.uniforms.push({name: variable.strides.replace('uniforms.', ''), type: 'u32', length: variable.rank});\n      }\n    }\n  }\n\n  private declareVariable(variable: IndicesHelper, bindingIndex: number): string {\n    if (variable.usage === 'internal') {\n      throw new Error('cannot use internal variable with declareVariable(). use registerInternalVariables() instead.');\n    }\n    this.variables.push(variable);\n    this.appendVariableUniforms(variable);\n\n    const access = variable.usage === 'input' ? 'read' : 'read_write';\n    const storageType = variable.type.storage;\n    return `@group(0) @binding(${bindingIndex}) var<storage, ${access}> ${variable.name}: array<${storageType}>;`;\n  }\n\n  declareVariables(...variables: IndicesHelper[]): string {\n    return variables.map(v => this.declareVariable(v, this.variableIndex++)).join('\\n');\n  }\n\n  private registerInternalVariable(variable: IndicesHelper): void {\n    if (variable.usage !== 'internal') {\n      throw new Error(\n          'cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.');\n    }\n\n    this.internalVariables.push(variable);\n    this.appendVariableUniforms(variable);\n  }\n\n  registerInternalVariables(...variables: IndicesHelper[]): ShaderHelper {\n    variables.forEach(v => this.registerInternalVariable(v));\n    return this;\n  }\n\n  registerUniform(name: string, type: UniformDataElementType, length = 1): ShaderHelper {\n    this.uniforms.push({name, type, length});\n    return this;\n  }\n\n  registerUniforms(additionalUniforms: UniformsArrayType): ShaderHelper {\n    this.uniforms = this.uniforms.concat(additionalUniforms);\n    return this;\n  }\n\n  private internalVariables: IndicesHelper[] = [];\n  private variables: IndicesHelper[] = [];\n  private uniforms: UniformsArrayType = [];\n  private uniformDeclaration(): string {\n    if (this.uniforms.length === 0) {\n      return '';\n    }\n\n    const uniformSnippets: string[] = [];\n    for (const {name, type, length} of this.uniforms) {\n      if (length && length > 4) {\n        uniformSnippets.push(`${name}:array<vec4<${type}>, ${Math.ceil(length / 4)}>`);\n      } else {\n        const typeTemp = length == null || length === 1 ? type : `vec${length}<${type}>`;\n        uniformSnippets.push(`${name}:${typeTemp}`);\n      }\n    }\n\n    return `\n      struct Uniforms { ${uniformSnippets.join(', ')} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;\n  }\n  private variableIndex = 0;\n\n  /**\n   * Get additional implementation that needs to be added to the shader source.\n   */\n  get additionalImplementations(): string {\n    return this.uniformDeclaration() + this.variables.map(i => i.impl()).join('\\n') +\n        this.internalVariables.map(i => i.impl()).join('\\n');\n  }\n}\n\nexport const createShaderHelper = (dispatchGroup: [number, number, number]) => new ShaderHelperImpl(dispatchGroup);\n\n/**\n * This function comes from https://github.com/tensorflow/tfjs/blob/master/tfjs-core/src/ops/broadcast_util.ts#L18-L40\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport const getBroadcastDims = (inShape: readonly number[], outShape: readonly number[]): number[] => {\n  const inRank = inShape.length;\n  const dims: number[] = [];\n  for (let i = 0; i < inRank; i++) {\n    const dim = inRank - 1 - i;\n    const a = inShape[dim] || 1;\n    const b = outShape[outShape.length - 1 - i] || 1;\n    if (b > 1 && a === 1) {\n      dims.unshift(dim);\n    }\n  }\n  return dims;\n};\n\n// TODO: remove this when all related uses have been removed.\nexport const enableShapesUniforms = (_rank: number): boolean => true;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface TransposeAttributes extends AttributeWithCacheKey {\n  readonly perm: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Transpose requires 1 input.');\n  }\n};\n\nconst getAdjustedPerm = (inputRank: number, perm: number[]): number[] =>\n    (perm && perm.length !== inputRank) ? [...(new Array(inputRank).keys())].reverse() : perm;\n\nconst getOutputShape = (inputShape: readonly number[], perm: number[]): readonly number[] =>\n    ShapeUtil.sortBasedOnPerm(inputShape, getAdjustedPerm(inputShape.length, perm));\n\nconst permFunctionBody = (perm: number[], rank: number, input: IndicesHelper, output: IndicesHelper): string => {\n  const reverseFunc = [];\n  reverseFunc.push(`fn perm(i: ${output.type.indices}) -> ${input.type.indices} {\n    var a: ${input.type.indices};`);\n  for (let i = 0; i < rank; ++i) {\n    reverseFunc.push(input.indicesSet('a', perm[i], `i[${i}]`));\n  }\n  reverseFunc.push('return a;}');\n  return reverseFunc.join('\\n');\n};\n\nexport const createTransposeProgramInfo = (inputTensor: TensorView, permAttr: number[]): ProgramInfo => {\n  const inputDataType = inputTensor.dataType;\n  const inputRank = inputTensor.dims.length;\n  const perm = getAdjustedPerm(inputRank, permAttr);\n  const useShapesUniforms = enableShapesUniforms(inputRank);\n  const outputShape = getOutputShape(inputTensor.dims, perm);\n  const outShapeOrRank = useShapesUniforms ? outputShape.length : outputShape;\n  const inShapeOrRank = useShapesUniforms ? inputRank : inputTensor.dims;\n  const output = outputVariable('output', inputDataType, outShapeOrRank);\n  const input = inputVariable('a', inputDataType, inShapeOrRank);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n  ${permFunctionBody(perm, inputRank, input, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let indices = ${output.offsetToIndices('global_idx')};\n    let aIndices = perm(indices);\n\n    ${output.setByOffset('global_idx', input.getByIndices('aIndices'))}\n  }`;\n  return {\n    name: 'Transpose',\n    shaderCache: {hint: `${permAttr}`, inputDependencies: useShapesUniforms ? ['rank'] : ['dims']},\n    getRunData: (inputs) => {\n      const outputSize = ShapeUtil.size(outputShape);\n      return {\n        outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n        dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        programUniforms: useShapesUniforms ?\n            [\n              {type: 'uint32', data: outputSize},\n              ...createTensorShapeVariables(inputs[0].dims),\n              ...createTensorShapeVariables(outputShape),\n            ] :\n            [\n              {type: 'uint32', data: outputSize},\n            ],\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const transpose = (context: ComputeContext, attributes: TransposeAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createTransposeProgramInfo(context.inputs[0], attributes.perm));\n};\n\nexport const parseTransposeAttributes = (attributes: Record<string, unknown>): TransposeAttributes =>\n    createAttributeWithCacheKey({perm: attributes.perm as number[]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {createReduceAttributesFromInputs, ReduceAttributes} from './reduce';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst reduceOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate * candidate',\n  logSumExp: 'bestValue + exp(candidate)',\n  l1: 'bestValue + abs(candidate)',\n  l2: 'bestValue + candidate * candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceSharedOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate',\n  logSumExp: 'bestValue + candidate',\n  l1: 'bestValue + candidate',\n  l2: 'bestValue + candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceInitValues: {[key: string]: string} = {\n  max: '_A[offset]',\n  min: '_A[offset]',\n  mean: '0',\n  sum: '0',\n  prod: '1',\n  sumSquare: '0',\n  logSumExp: '0',\n  l1: '0',\n  l2: '0',\n  logSum: '0'\n};\n\nconst reduceOutputValues: {[key: string]: string} = {\n  max: 'bestValue',\n  min: 'bestValue',\n  sum: 'bestValue',\n  prod: 'bestValue',\n  sumSquare: 'bestValue',\n  logSumExp: 'log(bestValue)',\n  l1: 'bestValue',\n  l2: 'sqrt(bestValue)',\n  logSum: 'log(bestValue)'\n};\n\nconst getInnerMostAxes = (numInnerAxes: number, rank: number): number[] => {\n  const res = [];\n  for (let i = rank - numInnerAxes; i < rank; ++i) {\n    res.push(i);\n  }\n  return res;\n};\n\nconst computeOutAndReduceShapes = (shape: readonly number[], axes: readonly number[]): [number[], number[]] => {\n  const outputShape = [];\n  const rank = shape.length;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      outputShape.push(shape[dim]);\n    }\n  }\n  const reduceShape = axes.map(dim => shape[dim]);\n  return [outputShape, reduceShape];\n};\n\nconst expandShapeToKeepDim = (shape: number[], axes: number[]): number[] => {\n  const rank = shape.length + axes.length;\n  const expandShape = [];\n  let shapeIdx = 0;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      expandShape.push(shape[shapeIdx++]);\n    } else {\n      expandShape.push(1);\n    }\n  }\n  return expandShape;\n};\n\nconst areAxesInnerMostDims = (axes: number[], rank: number): boolean => {\n  for (let i = 0; i < axes.length; ++i) {\n    if (axes[axes.length - i - 1] !== rank - 1 - i) {\n      return false;\n    }\n  }\n  return true;\n};\n\nconst getAxesPermutation = (axes: number[], rank: number): number[] => {\n  const res = [];\n  if (!areAxesInnerMostDims(axes, rank)) {\n    for (let i = 0; i < rank; ++i) {\n      if (axes.indexOf(i) === -1) {\n        res.push(i);\n      }\n    }\n    axes.forEach(axis => res.push(axis));\n  }\n  return res;\n};\n\nexport const createReduceSharedProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceType: string,\n     outputDataType: DataType, outputShape: number[], reduceShape: number[]): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const reduceSize = ShapeUtil.size(reduceShape);\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n\n      const workgroupSize = 32;\n\n      const sharedMemorySnippet = `\n          var<workgroup> aBestValues : array<${output.type.storage}, ${workgroupSize}>;\n       `;\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.registerUniform('reduceSize', 'u32').declareVariables(input, output)}\n        ${sharedMemorySnippet}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${shaderHelper.mainStart(workgroupSize)}\n          let local_idx = local_id.x;\n\n          let outputIndex = global_idx / ${workgroupSize};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${output.type.storage}(${reduceInitValues[reduceType]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${workgroupSize}) {\n           let candidate = ${output.type.storage}(${input.getByOffset('offset + k')});\n           bestValue = ${reduceOps[reduceType]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${workgroupSize}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${reduceSharedOps[reduceType]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${\n          output.setByOffset(\n              'outputIndex',\n              `${\n                  reduceType === 'mean' ? `bestValue / ${output.type.storage}(uniforms.reduceSize)` :\n                                          `${reduceOutputValues[reduceType]}`}`)};\n         }\n        }`;\n\n      // One work group is responsible for only one element of output.\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: outputSize},\n          programUniforms: [{type: 'uint32', data: reduceSize}]\n        }),\n      };\n    };\n\nconst reduceCommon =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes,\n     reduceType: 'sum'|'sumSquare'|'prod'|'min'|'max'|'mean'|'logSumExp'|'l1'|'l2'|'logSum'): void => {\n      const updatedAttributes: ReduceAttributes =\n          context.inputs.length === 1 ? attributes : createReduceAttributesFromInputs(context.inputs, attributes);\n\n      let updatedAxes = updatedAttributes.axes;\n      if (updatedAxes.length === 0 && !updatedAttributes.noopWithEmptyAxes) {\n        updatedAxes = context.inputs[0].dims.map((_dim, i) => i);\n      }\n      const normalizeAxes = ShapeUtil.normalizeAxes(updatedAxes, context.inputs[0].dims.length);\n\n      let axes = normalizeAxes;\n      let input = context.inputs[0];\n      const permutedAxes = getAxesPermutation(axes, context.inputs[0].dims.length);\n      if (permutedAxes.length > 0) {\n        input = context.compute(\n            createTransposeProgramInfo(context.inputs[0], permutedAxes), {inputs: [0], outputs: [-1]})[0];\n        axes = getInnerMostAxes(axes.length, input.dims.length);\n      }\n\n      const [outputShape, reduceShape] = computeOutAndReduceShapes(input.dims, axes);\n      let finalOutputShape = outputShape;\n      if (updatedAttributes.keepDims) {\n        finalOutputShape = expandShapeToKeepDim(outputShape, normalizeAxes);\n      }\n\n      context.compute(\n          createReduceSharedProgramInfo(\n              name, {hint: updatedAttributes.cacheKey, inputDependencies: ['type']}, [input], reduceType,\n              context.inputs[0].dataType, finalOutputShape, reduceShape),\n          {inputs: [input]});\n    };\n\nexport const reduceMeanShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMeanShared', attributes, 'mean');\n};\n\nexport const reduceL1Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL1Shared', attributes, 'l1');\n};\n\nexport const reduceL2Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL2Shared', attributes, 'l2');\n};\n\nexport const reduceLogSumExpShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumExpShared', attributes, 'logSumExp');\n};\n\nexport const reduceMaxShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMaxShared', attributes, 'max');\n};\n\nexport const reduceMinShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMinShared', attributes, 'min');\n};\n\nexport const reduceProdShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceProdShared', attributes, 'prod');\n};\n\nexport const reduceSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumShared', attributes, 'sum');\n};\n\nexport const reduceSumSquareShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumSquareShared', attributes, 'sumSquare');\n};\n\nexport const reduceLogSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumShared', attributes, 'logSum');\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\nimport {reduceL1Shared, reduceL2Shared, reduceLogSumExpShared, reduceLogSumShared, reduceMaxShared, reduceMeanShared, reduceMinShared, reduceProdShared, reduceSumShared, reduceSumSquareShared} from './reduce-shared';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('Reduce op requires 1 or 2 inputs.');\n  }\n\n  if (inputs.length === 2 && inputs[1].dims.length !== 1) {\n    throw new Error('Invalid axes input dims.');\n  }\n};\n\nexport interface ReduceAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  noopWithEmptyAxes: boolean;\n  axes: number[];\n}\n\nexport type ReduceOp =\n    (input: IndicesHelper, output: IndicesHelper,\n     axes: readonly number[]) => [string, string, string, string, ...string[]];\n\nconst noOp: ReduceOp = (input) => ['', '', `var value = ${input.getByOffset('inputOffset')};`, ''];\nexport const createReduceProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceOp: ReduceOp,\n     axesInput: number[], outputDataType: DataType, keepDims = false, noopWithEmptyAxes = false): ProgramInfo => {\n      const outputShape: number[] = [];\n      const inputShape = inputs[0].dims;\n\n      const axes = ShapeUtil.normalizeAxes(axesInput, inputs[0].dims.length);\n      const reduceOnAllAxes = !noopWithEmptyAxes && axes.length === 0;\n      inputShape.forEach((d, i) => {\n        if (reduceOnAllAxes || axes.indexOf(i) >= 0) {\n          if (keepDims) {\n            outputShape.push(1);\n          }  // else { // skip this axis}\n        } else {\n          outputShape.push(d);\n        }\n      });\n\n      const idxCopy: string[] = [];  // copy output indexes to input indexes\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n      const ops = reduceOp(input, output, axes);\n      const inputOffsetAssignment = `inputOffset = ${input.indicesToOffset('inputIndices')};`;\n      const initinputOffsetLet = `let ${inputOffsetAssignment};`;\n      const initinputOffsetVar = `var ${inputOffsetAssignment};`;\n      const initinputOffset = (ops[1] === '') ? '' : initinputOffsetVar;\n      let reduceOps = ((ops[1] === '') ? initinputOffsetLet : inputOffsetAssignment) + '\\n' + ops[2];\n\n      for (let k = 0, l = 0; k < inputs[0].dims.length; k++) {\n        // if this axis is reduced\n        if (reduceOnAllAxes || axes.indexOf(k) >= 0) {\n          if (keepDims) {\n            l++;\n          }\n          // loop over the d-th axis\n          reduceOps = `for(var j${k}: u32 = 0; j${k} < ${inputs[0].dims[k]}; j${k}++) {\n                ${ops[2].includes('lastIndex') ? `let lastIndex = j${k};` : ''}\n                ${input.indicesSet('inputIndices', k, `j${k}`)}\n                ${reduceOps}\n              }`;\n        } else {\n          idxCopy.push(`${input.indicesSet('inputIndices', k, output.indicesGet('outputIndices', l))};`);\n          l++;\n        }\n      }\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(input, output)}\n\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n          var inputIndices: ${input.type.indices};\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n\n          ${idxCopy.join('\\n')}\n          ${ops[0]}       // init ops for reduce max/min\n          ${initinputOffset}\n          ${ops[1]}\n          ${reduceOps}\n          ${ops[3]}\n          ${ops.length === 4 ? output.setByOffset('global_idx', 'value') : ops.slice(4).join('\\n')}\n        }`;\n\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n      };\n    };\n\nexport const createReduceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ReduceAttributes): ReduceAttributes => {\n      const axes: number[] = [];\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => axes.push(Number(v)));\n      }\n      return createAttributeWithCacheKey(\n          {axes, keepDims: attributes.keepDims, noopWithEmptyAxes: attributes.noopWithEmptyAxes});\n    };\n\nconst runReduceProgram =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes, reduceOp: ReduceOp): void => {\n      const inputs = context.inputs;\n      const updatedAttributes: ReduceAttributes =\n          inputs.length === 1 ? attributes : createReduceAttributesFromInputs(inputs, attributes);\n\n      context.compute(\n          createReduceProgramInfo(\n              name, {hint: updatedAttributes.cacheKey}, [inputs[0]],\n              updatedAttributes.noopWithEmptyAxes && updatedAttributes.axes.length === 0 ? noOp : reduceOp,\n              updatedAttributes.axes, inputs[0].dataType, updatedAttributes.keepDims,\n              updatedAttributes.noopWithEmptyAxes),\n          {inputs: [0]});\n    };\n\nconst reduceLogSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSum', attributes, reduceOp);\n};\n\nconst reduceL1Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += abs(${input.getByOffset('inputOffset')});`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceL1', attributes, reduceOp);\n};\n\nconst reduceL2Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += (t * t);`,\n       'value = sqrt(value);',\n  ];\n  runReduceProgram(context, 'ReduceL2', attributes, reduceOp);\n};\n\nconst reduceLogSumExpNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += exp(${input.getByOffset('inputOffset')});`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSumExp', attributes, reduceOp);\n};\n\nconst reduceMaxNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(input.indicesSet('inputIndices', k, 0));\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = max(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMax', attributes, reduceOp);\n};\n\nconst reduceMeanNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output, axes) => {\n    let size = 1.0;\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        // TODO: this depends on the input dims. If we want to use uniform, this need to be updated.\n        size *= context.inputs[0].dims[k];\n      }\n    }\n\n    return [\n      'var sum = f32(0);',\n      '',\n      `sum += f32(${input.getByOffset('inputOffset')});`,\n      `let value = ${output.type.value}(sum / ${size});`,\n    ];\n  };\n  runReduceProgram(context, 'ReduceMean', attributes, reduceOp);\n};\n\nconst reduceMinNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = min(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMin', attributes, reduceOp);\n};\n\nconst reduceProdNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(1);`,\n       '',\n       `value *= ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceProd', attributes, reduceOp);\n};\n\nconst reduceSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSum', attributes, reduceOp);\n};\n\nconst reduceSumSquareNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += t * t;`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSumSquare', attributes, reduceOp);\n};\n\nconst useNaiveReduceMethod =\n    (shape: readonly number[], axes: readonly number[], noopWithEmptyAxes: boolean): boolean => {\n      if (axes.length === 0) {\n        return noopWithEmptyAxes ? true : false;\n      }\n\n      let outputSize = 1;\n      let reduceSize = 1;\n      for (let dim = 0; dim < axes.length; dim++) {\n        if (axes.indexOf(dim) === -1) {\n          outputSize *= shape[dim];\n        } else {\n          reduceSize *= shape[dim];\n        }\n      }\n\n      // The condition data is very rough, although considering the count of Execution Unit (EU), the potential\n      // work groups in a EU and the counts of loops in the naive and shared methods, also doing experiments\n      // on some machines.\n      return reduceSize < 32 && outputSize > 1024 ? true : false;\n    };\n\nexport const reduceMean = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMeanNaive(context, attributes);\n  } else {\n    reduceMeanShared(context, attributes);\n  }\n};\n\nexport const reduceL1 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL1Naive(context, attributes);\n  } else {\n    reduceL1Shared(context, attributes);\n  }\n};\n\nexport const reduceL2 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL2Naive(context, attributes);\n  } else {\n    reduceL2Shared(context, attributes);\n  }\n};\n\nexport const reduceLogSumExp = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumExpNaive(context, attributes);\n  } else {\n    reduceLogSumExpShared(context, attributes);\n  }\n};\n\nexport const reduceMax = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMaxNaive(context, attributes);\n  } else {\n    reduceMaxShared(context, attributes);\n  }\n};\n\nexport const reduceMin = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMinNaive(context, attributes);\n  } else {\n    reduceMinShared(context, attributes);\n  }\n};\n\nexport const reduceProd = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceProdNaive(context, attributes);\n  } else {\n    reduceProdShared(context, attributes);\n  }\n};\n\nexport const reduceSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumNaive(context, attributes);\n  } else {\n    reduceSumShared(context, attributes);\n  }\n};\n\nexport const reduceSumSquare = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumSquareNaive(context, attributes);\n  } else {\n    reduceSumSquareShared(context, attributes);\n  }\n};\n\nexport const reduceLogSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumNaive(context, attributes);\n  } else {\n    reduceLogSumShared(context, attributes);\n  }\n};\n\nexport const parseReduceAttributes = (attributes: Record<string, unknown>): ReduceAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ReduceAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createReduceProgramInfo, ReduceOp} from './reduce';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('ArgMinMaxOp op requires 1 or 2 inputs.');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Invalid input type.');\n  }\n};\n\nexport interface ArgMinMaxAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  axis: number;\n  selectLastIndex: number;\n}\n\nexport const argMin = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '<=' : '<'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  context.compute(\n      createReduceProgramInfo(\n          'ArgMin', {hint: attributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [attributes.axis], DataType.int64,\n          attributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const argMax = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '>=' : '>'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  context.compute(\n      createReduceProgramInfo(\n          'argMax', {hint: attributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [attributes.axis], DataType.int64,\n          attributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const parseArgMinMaxAttributes = (attributes: Record<string, unknown>): ArgMinMaxAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ArgMinMaxAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, GpuDataType} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType} from './common';\n\nexport const enum AttentionQkvFormat {\n  unknown,          // enum value not set, or depends on qkv projection implementation details\n  qkvBNSH,          // for non-packed qkv, permuted\n  qkvBSNH,          // for non-packed qkv, not permuted, used by memory efficient attention or MultiHeadAttention\n  qkvBSN3H,         // for TRT fused attention, qkv are packed\n  qkvBNSHqkvBS3NH,  // for TRT fused causal attention, data has two formats (qkv is 3BNSH, gemm_buffer is BS3NH)\n  qKvBSNHxBSN2H,    // for TRT fused cross attention, kv are packed\n  qkvTNH,           // for memory efficient attention, qkv are not packed, and paddings are removed.\n  qkvTN3H,          // for TRT fused attention, qkv are packed and paddings are removed\n}\n\nexport const enum AttentionMaskType {\n  none,                  // No mask\n  mask1dKeySeqLen,       // [batch_size], key sequence length\n  mask1dEndStart,        // [2 * batch_size] with end positions and start positions\n  mask1DKeySeqLenStart,  // [3 * batch_size + 2] with [key_len[0], ..., key_len[batch_size - 1], query_start[0],\n                         // ..., query_start[batch_size - 1], query_end[batch_size - 1], key_start[0], ...,\n                         // key_start[batch_size - 1], key_end[batch_size - 1]]\n  mask2dDummy,           // dummy mask with shape [1, 1] or [batch_size, 1]. It has same effect as no mask.\n  mask2dKeyPadding,      // [batch_size, total_sequence_length]\n  mask3dAttention,       // [batch_size, sequence_length, total_sequence_length]\n  mask4dMegatron,        // Megatron causal mask with shape [batch_size, 1, max_sequence_length, max_sequence_length]\n  maskUnknown\n}\n\nexport interface AttentionParameters {\n  batchSize: number;\n  sequenceLength: number;\n  pastSequenceLength: number;\n  kvSequenceLength: number;\n  totalSequenceLength: number;\n  maxSequenceLength: number;\n  inputHiddenSize: number;\n  hiddenSize: number;\n  vHiddenSize: number;\n  headSize: number;\n  vHeadSize: number;\n  numHeads: number;\n  isUnidirectional: boolean;\n  pastPresentShareBuffer: boolean;\n  maskFilterValue: number;\n  maskType: AttentionMaskType;\n  scale: number;\n  broadcastResPosBias: boolean;\n  passPastInKv: boolean;\n  qkvFormat: AttentionQkvFormat;\n}\n\nexport interface AttentionAttrs {\n  numHeads: number;\n  isUnidirectional: number;\n  maskFilterValue: number;\n  scale: number;\n  doRotary: number;\n  qkvHiddenSizes: number[];\n  pastPresentShareBuffer: boolean;\n}\n\nconst validateAttentionInputs = (inputs: readonly TensorView[], attributes: AttentionAttrs): AttentionParameters => {\n  // Abbreviation and Meanings:\n  //   B:    batch_size\n  //   S:    sequence_length (input sequence length of query)\n  //   P:    past_sequence_length (past sequence length of key or value)\n  //   L:    kv_sequence_length (input sequence length of key or value)\n  //   M:    max_sequence_length\n  //   T:    total_sequence_length = past_sequence_length + kv_sequence_length\n  //   N:    num_heads\n  //   H:    head size for Q and K, aka q_head_size or k_head_size or qk_head_size\n  //   H_v:  v_head_size\n  //   D_i:  input hidden size\n  //   D:    hidden size for Q and K (D = N * H), aka q_hidden_size or k_hidden_size or qk_hidden_size\n  //   D_v:  v_hidden_size = num_heads * v_head_size\n\n  // When past state is used, Q, K and V should have same hidden size (unless we split it into past_key and past_value).\n\n  // Input shapes:\n  //   input        (Q/K/V)    : (B, S, D_i)\n  //   weights      (Q/K/V)    : (D_i, D + D + D_v)\n  //   bias         (Q/K/V)    : (D + D + D_v)\n  //   mask_index              : see below\n  //   past         (K/V)      : (2, B, N, P, H) or NULL\n  //   relative_position_bias            : (B, N, S, T) or NULL\n\n  // For mask_index, the following shapes are supported:\n  //     NULL, (B, 1), (1, 1)\n  //     (B), (2 * B), (3 * B + 2)\n  //     (B, T)\n  //     (B, S, T)\n  //     (B, 1, M, M)\n  //\n  // When a model is pruned (like some attention heads are removed in Q/K/V), input_hidden_size could be larger\n  // than hidden dimension of Q, K and V.\n\n  const input = inputs[0];\n  const weights = inputs[1];\n  const bias = inputs[2];\n  const maskIndex = inputs[3];\n  const past = inputs[4];\n  const relativePositionBias = inputs[5];\n\n  if (past && relativePositionBias) {\n    throw new Error('Attention cannot have both past and relative_position_bias');\n  }\n\n  if (input.dims.length !== 3) {\n    throw new Error('Input \"input\" must have 3 dimensions');\n  }\n\n  const batchSize = input.dims[0];\n  const sequenceLength = input.dims[1];\n  const inputHiddenSize = input.dims[2];\n\n  if (bias.dims.length !== 1) {\n    throw new Error('Input \"bias\" is expected to have 1 dimensions');\n  }\n\n  if (weights.dims.length !== 2) {\n    throw new Error('Input \"weights\" is expected to have 2 dimensions');\n  }\n\n  if (weights.dims[0] !== inputHiddenSize) {\n    throw new Error('Input 1 dimension 0 should have same length as dimension 2 of input 0');\n  }\n\n  if (bias.dims[0] !== weights.dims[1]) {\n    throw new Error('Input \"bias\" dimension 0 should have same length as dimension 1 of input \"weights\"');\n  }\n\n  let qHiddenSize = bias.dims[0] / 3;\n  let kHiddenSize = qHiddenSize;\n  let vHiddenSize = kHiddenSize;\n  if (attributes.qkvHiddenSizes.length > 0) {\n    if (attributes.qkvHiddenSizes.length !== 3) {\n      throw new Error('qkv_hidden_sizes attribute should have 3 elements');\n    }\n    for (const sz of attributes.qkvHiddenSizes) {\n      if (sz % attributes.numHeads !== 0) {\n        throw new Error('qkv_hidden_sizes should be divisible by num_heads');\n      }\n    }\n\n    qHiddenSize = attributes.qkvHiddenSizes[0];\n    kHiddenSize = attributes.qkvHiddenSizes[1];\n    vHiddenSize = attributes.qkvHiddenSizes[2];\n  }\n\n  const kvSequenceLength = sequenceLength;\n\n  if (qHiddenSize !== kHiddenSize) {\n    throw new Error('qkv_hidden_sizes first element should be same as the second');\n  }\n\n  if (bias.dims[0] !== qHiddenSize + kHiddenSize + vHiddenSize) {\n    throw new Error('Input \"bias\" dimension 0 should have same length as sum of Q/K/V hidden sizes');\n  }\n\n  let pastSequenceLength = 0;\n  if (past) {\n    if (kHiddenSize !== vHiddenSize) {\n      throw new Error('Input \"past\" expect k_hidden_size == v_hidden_size');\n    }\n    if (past.dims.length !== 5) {\n      throw new Error('Input \"past\" must have 5 dimensions');\n    }\n    if (past.dims[0] !== 2) {\n      throw new Error('Input \"past\" first dimension must be 2');\n    }\n    if (past.dims[1] !== batchSize) {\n      throw new Error('Input \"past\" second dimension must be batch_size');\n    }\n    if (past.dims[2] !== attributes.numHeads) {\n      throw new Error('Input \"past\" third dimension must be num_heads');\n    }\n    if (past.dims[4] !== kHiddenSize / attributes.numHeads) {\n      throw new Error('Input \"past\" fifth dimension must be k_hidden_size / num_heads');\n    }\n\n    if (!attributes.pastPresentShareBuffer) {\n      pastSequenceLength = past.dims[3];\n    }\n    // TODO: handle past_seq_len\n  }\n\n  const totalSequenceLength = kvSequenceLength + pastSequenceLength;\n  const maxSequenceLength = -1;\n\n  const maskType = AttentionMaskType.none;\n  if (maskIndex) {\n    // maskType = AttentionMaskType.MASK_UNKNOWN;\n    // TODO: handle mask\n    throw new Error('Mask not supported');\n  }\n\n  if (past) {\n    throw new Error('past is not supported');\n  }\n  if (relativePositionBias) {\n    throw new Error('relativePositionBias is not supported');\n  }\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize,\n    hiddenSize: qHiddenSize,\n    vHiddenSize,\n    headSize: Math.floor(qHiddenSize / attributes.numHeads),\n    vHeadSize: Math.floor(vHiddenSize / attributes.numHeads),\n    numHeads: attributes.numHeads,\n    isUnidirectional: false,\n    pastPresentShareBuffer: false,\n    maskFilterValue: attributes.maskFilterValue,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias: false,\n    passPastInKv: false,\n    qkvFormat: AttentionQkvFormat.qkvBNSH,\n  };\n};\n\nexport const parseAttentionAttributes = (attributes: AttentionAttrs): AttentionAttrs =>\n    createAttributeWithCacheKey({...attributes});\n\nexport const computeInPlaceSoftmax = (context: ComputeContext, input: TensorView, n: number, d: number) => {\n  const components = getMaxComponents(d);\n  const inputHelper = outputVariable('x', input.dataType, input.dims, components);\n\n  let threadMaxValue = 'threadMaxVector';\n  if (components === 2) {\n    threadMaxValue = 'max(threadMaxVector.x, threadMaxVector.y)';\n  } else if (components === 4) {\n    threadMaxValue = 'max(max(threadMaxVector.x, threadMaxVector.y), max(threadMaxVector.z, threadMaxVector.w))';\n  }\n  const dataType = tensorTypeToWsglStorageType(input.dataType);\n  let WG = 64;\n  const dComp = d / components;\n  if (dComp < WG) {\n    WG = 1;\n  } else if (dComp / 8 < 64) {\n    WG = Math.ceil(dComp / 8);\n  }\n  const elementsPerWG = Math.ceil(d / components / WG);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const dInv: ${dataType} = 1 / ${d};\n  const dComp = ${d / components};\n  var<workgroup> wgMax: array<f32, ${WG}>;\n  var<workgroup> wgSum: array<f32, ${WG}>;\n\n  ${shaderHelper.declareVariables(inputHelper)}\n  @compute @workgroup_size(${WG}, 1, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_index) local_index : u32) {\n    let localOffset = local_index * ${elementsPerWG};\n    let offset: u32 = workgroup_id.x * dComp + localOffset;\n\n    var threadMaxVector = ${fillVector('f32', components, '-3.402823e+38f')};\n    for (var i: u32 = 0; i < ${elementsPerWG} && i + localOffset < dComp; i++) {\n      threadMaxVector = max(${castToF32(dataType, components, 'x[offset + i]')}, threadMaxVector);\n    }\n    wgMax[local_index] = ${threadMaxValue};\n    workgroupBarrier();\n\n    var maxValue = -3.402823e+38f;\n    for (var i = 0u; i < ${WG}; i++) {\n      maxValue = max(wgMax[i], maxValue);\n    }\n\n    var sumVector = ${fillVector('f32', components, '0')};\n    for (var i: u32 = 0; i < ${elementsPerWG} && i + localOffset < dComp; i++) {\n      sumVector += exp(${castToF32(dataType, components, 'x[offset + i]')} - maxValue);\n    }\n    wgSum[local_index] = ${sumVector('sumVector', components)};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${WG}; i++) {\n      sum += wgSum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < ${elementsPerWG} && i + localOffset < dComp; i++) {\n        x[offset + i] = ${fillVector(dataType, components, 'dInv')};\n      }\n    } else {\n      for (var i: u32 = 0; i < ${elementsPerWG} && i + localOffset < dComp; i++) {\n        let f32input = ${castToF32(dataType, components, 'x[offset + i]')};\n        x[offset + i] = ${inputHelper.type.value}(exp(f32input - maxValue) / sum);\n      }\n    }\n  }`;\n\n  context.compute(\n      {\n        name: 'AttentionProbsSoftmax',\n        shaderCache: {hint: `${d}`},\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [],\n          dispatchGroup: {x: n},\n        }),\n      },\n      {inputs: [input], outputs: []});\n};\n\nconst computeAttentionProbs =\n    (context: ComputeContext, q: TensorView, key: TensorView, _bias: TensorView|undefined,\n     parameters: AttentionParameters, attributes: AttentionAttrs) => {\n      const probsShape = [\n        parameters.batchSize, parameters.numHeads, parameters.sequenceLength,\n        parameters.kvSequenceLength + parameters.pastSequenceLength\n      ];\n      // TODO: handle mask\n\n      const alpha = attributes.scale === 0 ? 1.0 / Math.sqrt(parameters.headSize) : attributes.scale;\n\n      const dataType = tensorTypeToWsglStorageType(q.dataType);\n\n      const components = getMaxComponents(parameters.headSize);\n      const qInput = inputVariable('q', q.dataType, q.dims, components);\n      const kInput = inputVariable('key', key.dataType, key.dims, components);\n      const output = outputVariable('output', q.dataType, probsShape);\n\n      const vectorizedHeadSize = parameters.headSize / components;\n      const M = parameters.sequenceLength;\n      const N = parameters.totalSequenceLength;\n      const K = vectorizedHeadSize;\n\n      const TILE_SIZE = 12;\n\n      const dispatch = {\n        x: Math.ceil(parameters.totalSequenceLength / TILE_SIZE),\n        y: Math.ceil(parameters.sequenceLength / TILE_SIZE),\n        z: parameters.batchSize * parameters.numHeads\n      };\n\n      const inputs = [q, key];\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${M}u;\n  const N: u32 = ${N}u;\n  const K: u32 = ${K}u;\n  const alpha: ${dataType} = ${alpha};\n  const beta: ${dataType} = 1.0;\n  const TILE_SIZE = ${TILE_SIZE}u;\n\n  var<workgroup> tileQ: array<${qInput.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileK: array<${qInput.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n\n  ${shaderHelper.declareVariables(qInput, kInput, output)}\n\n  @compute @workgroup_size(${TILE_SIZE}, ${TILE_SIZE}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${dispatch.x * dispatch.y}u +\n          workgroup_id.y * ${dispatch.x}u + workgroup_id.x) * ${TILE_SIZE * TILE_SIZE}u + local_index;\n\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let lm = m + local_id.y;\n    let ln = n + local_id.x;\n\n    let qOffset = ${parameters.sequenceLength * vectorizedHeadSize} * headIdx + m * K;\n    let kOffset = ${parameters.kvSequenceLength * vectorizedHeadSize} * headIdx + n * K;\n\n    var value = ${fillVector(dataType, components)};\n    for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n      if (m + local_id.y < M && w + local_id.x < K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * K + w + local_id.x];\n      }\n      if (n + local_id.y < N && w + local_id.x < K) {\n        tileK[TILE_SIZE * local_id.y + local_id.x] = key[kOffset + local_id.y * K + w + local_id.x];\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n        value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = headIdx * M * N;\n    if (lm < M && ln < N) {\n      let outputIdx = headOffset + lm * N + ln;\n      output[outputIdx] = ${sumVector('value', components)} * alpha;\n    }\n  }`;\n\n      const probs = context.compute(\n          {\n            name: 'AttentionProbs',\n            shaderCache: {hint: JSON.stringify(parameters)},\n            getRunData: () => ({\n              outputs: [{dims: probsShape, dataType: q.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: dispatch,\n            }),\n            getShaderSource,\n          },\n          {inputs, outputs: [-1]})[0];\n\n      computeInPlaceSoftmax(\n          context, probs, parameters.batchSize * parameters.numHeads * parameters.sequenceLength,\n          parameters.totalSequenceLength);\n\n      return probs;\n    };\n\nconst computeVxAttentionScore =\n    (context: ComputeContext, probs: TensorView, v: TensorView, params: AttentionParameters) => {\n      const outputShape = [params.batchSize, params.sequenceLength, params.vHiddenSize];\n\n      const probsHelper = inputVariable('probs', probs.dataType, probs.dims);\n      const vHelper = inputVariable('v', v.dataType, v.dims);\n      const output = outputVariable('output', probs.dataType, outputShape);\n\n      const dataType = tensorTypeToWsglStorageType(probs.dataType);\n\n      const TILE_SIZE = 12;\n      const dispatch = {\n        x: Math.ceil(params.vHeadSize / TILE_SIZE),\n        y: Math.ceil(params.sequenceLength / TILE_SIZE),\n        z: params.batchSize * params.numHeads\n      };\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${params.sequenceLength}u;\n  const N: u32 = ${params.vHeadSize}u;\n  const K: u32 = ${params.totalSequenceLength}u;\n  const numHeads: u32 = ${params.numHeads}u;\n  const TILE_SIZE = ${TILE_SIZE}u;\n\n  var<workgroup> tileQ: array<${probsHelper.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileK: array<${probsHelper.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n\n  ${shaderHelper.declareVariables(probsHelper, vHelper, output)}\n\n  @compute @workgroup_size(${TILE_SIZE}, ${TILE_SIZE}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${dispatch.x * dispatch.y}u +\n          workgroup_id.y * ${dispatch.x}u + workgroup_id.x) * ${TILE_SIZE * TILE_SIZE}u + local_index;\n\n   let headIdx = workgroup_id.z;\n   let m = workgroup_id.y * TILE_SIZE + local_id.y;\n   let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n   let offsetA = headIdx * (M * K) + m * K;\n   let offsetB = headIdx * (N * K) + n;\n\n   var value = ${dataType}(0);\n   for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n     if (m < M && w + local_id.x < K) {\n       tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n     }\n     if (n < N && w + local_id.y < K) {\n       tileK[TILE_SIZE * local_id.y + local_id.x] = v[offsetB + (w + local_id.y) * N];\n     }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   let batchIdx = workgroup_id.z / ${params.numHeads};\n   let currentBatchHeadNumber = workgroup_id.z % ${params.numHeads};\n   let headOffset = (batchIdx * M * ${params.numHeads} + currentBatchHeadNumber) * ${params.vHeadSize};\n   if (m < M && n < N) {\n     let outputIdx = batchIdx * ${params.sequenceLength * params.vHiddenSize} + m * ${params.vHiddenSize}\n       + currentBatchHeadNumber * ${params.vHeadSize} + n;\n     output[outputIdx] = value;\n   }\n  }`;\n\n      return context.compute(\n          {\n            name: 'AttentionScore',\n            shaderCache: {hint: JSON.stringify(params)},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: probs.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: dispatch,\n            }),\n            getShaderSource,\n          },\n          {inputs: [probs, v], outputs: [0]})[0];\n    };\n\nexport const applyAttention =\n    (context: ComputeContext, q: TensorView, k: TensorView, v: TensorView, _maskIndex: TensorView|undefined,\n     _past: TensorView|undefined, _pastKey: TensorView|undefined, _pastValue: TensorView|undefined,\n     relativePositionBias: TensorView|undefined, parameters: AttentionParameters, attributes: AttentionAttrs) => {\n      const probs = computeAttentionProbs(context, q, k, relativePositionBias, parameters, attributes);\n\n      computeVxAttentionScore(context, probs, v, parameters);\n    };\n\nconst prepare = (context: ComputeContext, parameters: AttentionParameters) => {\n  const outputShape = [\n    parameters.batchSize,\n    parameters.numHeads,\n    parameters.sequenceLength,\n    parameters.headSize,\n  ];\n\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n\n  const M = parameters.sequenceLength;\n  const K = parameters.inputHiddenSize;\n  const N = parameters.headSize;\n\n  const TILE_SIZE = 12;\n  const dispatch = {\n    x: Math.ceil(parameters.headSize / TILE_SIZE),\n    y: Math.ceil(parameters.sequenceLength / TILE_SIZE),\n    z: parameters.batchSize * parameters.numHeads\n  };\n\n  const getShaderSource = () => `\n  const M: u32 = ${M}u;\n  const K: u32 = ${K}u;\n  const N: u32 = ${N}u;\n  const numHeads: u32 = ${parameters.numHeads};\n  const ldb = ${parameters.hiddenSize + parameters.hiddenSize + parameters.vHiddenSize}u;\n  const TILE_SIZE = ${TILE_SIZE}u;\n\n  var<workgroup> tileInput: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightQ: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightK: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightV: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n\n  @group(0) @binding(0) var<storage, read> input: array<${dataType}>;\n  @group(0) @binding(1) var<storage, read> weight: array<${dataType}>;\n  @group(0) @binding(2) var<storage, read> bias: array<${dataType}>;\n  @group(0) @binding(3) var<storage, read_write> outputQ: array<${dataType}>;\n  @group(0) @binding(4) var<storage, read_write> outputK: array<${dataType}>;\n  @group(0) @binding(5) var<storage, read_write> outputV: array<${dataType}>;\n\n  @compute @workgroup_size(${TILE_SIZE}, ${TILE_SIZE}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${dispatch.x * dispatch.y}u +\n          workgroup_id.y * ${dispatch.x}u + workgroup_id.x) * ${TILE_SIZE * TILE_SIZE}u + local_index;\n\n    let batchIndex = workgroup_id.z / ${parameters.numHeads};\n    let headNumber = workgroup_id.z % ${parameters.numHeads};\n    let m = workgroup_id.y * TILE_SIZE + local_id.y;\n    let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n    let inputOffset = batchIndex * (M * K) + m * K;\n    let biasOffsetQ = headNumber * ${parameters.headSize};\n    let biasOffsetK = ${parameters.hiddenSize} + biasOffsetQ;\n    let biasOffsetV = ${parameters.hiddenSize} + biasOffsetK;\n\n    var valueQ = ${dataType}(0);\n    var valueK = ${dataType}(0);\n    var valueV = ${dataType}(0);\n    for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n      if (m < M && w + local_id.x < K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < N && w + local_id.y < K) {\n        let offset = n + (w + local_id.y) * ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * N + n) % ${parameters.headSize};\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * M * N;\n    if (m < M && n < N) {\n      let outputIdx = offset + m * N + n;\n      outputQ[outputIdx] = valueQ;\n      outputK[outputIdx] = valueK;\n      outputV[outputIdx] = valueV;\n    }\n  }`;\n\n  const inputs = [context.inputs[0], context.inputs[1], context.inputs[2]];\n\n  return context.compute(\n      {\n        name: 'AttentionPrepare',\n        shaderCache: {hint: JSON.stringify(parameters)},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n          ],\n          dispatchGroup: dispatch,\n        }),\n        getShaderSource,\n      },\n      {inputs, outputs: [-1, -1, -1]});\n};\n\nexport const attention = (context: ComputeContext, attributes: AttentionAttrs): void => {\n  const params = validateAttentionInputs(context.inputs, attributes);\n\n  const [q, k, v] = prepare(context, params);\n\n  return applyAttention(\n      context, q, k, v, context.inputs[4], undefined, undefined, undefined, context.inputs[5], params, attributes);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, getMaxComponents, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface BatchNormAttributes extends AttributeWithCacheKey {\n  readonly epsilon: number;\n  readonly momentum: number;\n  readonly spatial: boolean;\n  readonly trainingMode: boolean;\n  readonly format: 'NHWC'|'NCHW';\n  readonly outputCount: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: BatchNormAttributes): void => {\n  if (!inputs || inputs.length !== 5) {\n    throw new Error('BatchNormalization requires 5 inputs');\n  }\n\n  const checkShapeEqual = (actual: readonly number[], expected: readonly number[], message: string) => {\n    const r = expected.length;\n    if (r !== actual.length) {\n      throw new Error(`${message}: num dimensions != ${r}`);\n    }\n    expected.forEach((v, i) => {\n      if (v !== actual[i]) {\n        throw new Error(`${message}: dim[${i}] do not match`);\n      }\n    });\n  };\n\n  if (inputs[0].dims.length > 1) {\n    const shape = attributes.format === 'NHWC' ?\n        (attributes.spatial ? inputs[0].dims.slice(-1) :\n                              inputs[0].dims.slice(-1).concat(inputs[0].dims.slice(1, inputs[0].dims.length - 1))) :\n        inputs[0].dims.slice(1, attributes.spatial ? 2 : undefined);\n    checkShapeEqual(inputs[1].dims, shape, 'Invalid input scale');\n    checkShapeEqual(inputs[2].dims, shape, 'Invalid input B');\n    checkShapeEqual(inputs[3].dims, shape, 'Invalid input mean');\n    checkShapeEqual(inputs[4].dims, shape, 'Invalid input var');\n  } else {\n    checkShapeEqual(inputs[1].dims, [1], 'Invalid input scale');\n    checkShapeEqual(inputs[2].dims, [1], 'Invalid input B');\n    checkShapeEqual(inputs[3].dims, [1], 'Invalid input mean');\n    checkShapeEqual(inputs[4].dims, [1], 'Invalid input var');\n  }\n};\n\nconst createBatchNormInferenceProgramInfo =\n    (inputs: readonly TensorView[], attributes: BatchNormAttributes): ProgramInfo => {\n      const {epsilon, spatial, format} = attributes;\n      const yShape = inputs[0].dims;\n      const components = spatial ? getMaxComponents(yShape[yShape.length - 1]) : 1;\n      const cComponents = format === 'NHWC' && yShape.length > 1 ? components : 1;\n      const outputSize = ShapeUtil.size(yShape) / components;\n      // Only support uniforms for opset version >= 9 (spatial = true).\n      const useShapesUniforms = enableShapesUniforms(yShape.length) && spatial;\n      const shapeOrRank = useShapesUniforms ? yShape.length : yShape;\n      const x = inputVariable('x', inputs[0].dataType, inputs[0].dims, components);\n      const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims, cComponents);\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims, cComponents);\n      const inputMean = inputVariable('inputMean', inputs[3].dataType, inputs[3].dims, cComponents);\n      const inputVar = inputVariable('inputVar', inputs[4].dataType, inputs[4].dims, cComponents);\n      const y = outputVariable('y', inputs[0].dataType, shapeOrRank, components);\n      // TODO: support inputs with different data type. Current we need to make sure all inputs have the same data type.\n      // Otherwise, the shader compilation will fail.\n      const calcCOffset = (): string => {\n        let cOffset = '';\n        if (spatial) {\n          cOffset = `let cOffset = ${\n              yShape.length === 1   ? '0u' :\n                  format === 'NHWC' ? `outputIndices[${yShape.length - 1}] / ${components}` :\n                                      'outputIndices[1]'};`;\n        } else {\n          if (format === 'NCHW') {\n            cOffset = `\n            ${y.indicesSet('outputIndices', '0', '0')}\n            let cOffset = ${y.indicesToOffset('outputIndices')};`;\n          } else {\n            // update C channel.\n            cOffset = `var cIndices = ${scale.type.indices}(0);\n                       cIndices[0] = outputIndices[${yShape.length - 1}];`;\n            // update D1 x ... x Dn channels.\n            for (let i = 1; i < scale.rank; i++) {\n              cOffset += `cIndices[${i}] = outputIndices[${i}];`;\n            }\n            cOffset += `let cOffset = ${scale.indicesToOffset('cIndices')};`;\n          }\n        }\n        return cOffset;\n      };\n      const getInferenceModeShaderSource = (helper: ShaderHelper) => `\n  const epsilon = ${epsilon};\n  ${helper.registerUniform('outputSize', 'u32').declareVariables(x, scale, bias, inputMean, inputVar, y)}\n  ${helper.mainStart()}\n  ${helper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n    var outputIndices = ${y.offsetToIndices(`global_idx * ${components}`)};\n    ${calcCOffset()}\n    let scale = ${scale.getByOffset('cOffset')};\n    let bias = ${bias.getByOffset('cOffset')};\n    let inputMean = ${inputMean.getByOffset('cOffset')};\n    let inputVar = ${inputVar.getByOffset('cOffset')};\n    let x = ${x.getByOffset('global_idx')};\n    let value = (x - inputMean) / sqrt(inputVar + epsilon) * scale + bias;\n    ${y.setByOffset('global_idx', 'value')}\n  }`;\n      return {\n        name: 'BatchNormalization',\n        shaderCache: {\n          hint: `${attributes.epsilon}_${attributes.format}_${spatial}_${components}`,\n          inputDependencies: useShapesUniforms ? ['rank', 'type', 'type', 'type', 'type'] : undefined,\n        },\n        getShaderSource: getInferenceModeShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: inputs[0].dims, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n          programUniforms: useShapesUniforms ?\n              [\n                {type: 'uint32', data: outputSize},\n                ...createTensorShapeVariables(yShape),\n              ] :\n              [\n                {type: 'uint32', data: outputSize},\n              ],\n        }),\n      };\n    };\n\nexport const parseBatchNormAttributes = (attributes: Record<string, unknown>): BatchNormAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<BatchNormAttributes, keyof AttributeWithCacheKey>);\n\nexport const batchNorm = (context: ComputeContext, attributes: Record<string, unknown>): void => {\n  const {inputs, outputCount} = context;\n  const updatedAttributes = parseBatchNormAttributes({...attributes, outputCount});\n  if (env.webgpu.validateInputContent) {\n    validateInputs(inputs, updatedAttributes);\n  }\n  if (attributes.trainingMode) {\n    throw new Error('BatchNormalization trainingMode is not supported yet.');\n  } else {\n    context.compute(createBatchNormInferenceProgramInfo(inputs, updatedAttributes));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![320, 640, 1280].includes(inputs[0].dims[2])) {\n    throw new Error('number of channels should be 320, 640 or 1280');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasAddProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims;\n\n  const channels = inputs[0].dims[2];\n  // since channel number can be only 320/640/1280, it's always divisable by 4\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, outputShape, 4);\n  const bias = inputVariable('bias', dataType, [channels], 4);\n  const residual = inputVariable('residual', dataType, outputShape, 4);\n  const output = outputVariable('output', dataType, outputShape, 4);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const channels = ${channels}u / 4;\n  ${shaderHelper.declareVariables(input, bias, residual, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let value = ${input.getByOffset('global_idx')}\n      + ${bias.getByOffset('global_idx % channels')} + ${residual.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n\n  return {\n    name: 'BiasAdd',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasAdd = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasAddProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {MAX_CLIP, MIN_CLIP, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\ntype BuiltinFunctionName = string;\ntype ElementwiseCustomExpression = (expression: string) => string;\ntype ElementwiseFunctionCall = BuiltinFunctionName|ElementwiseCustomExpression;\n\nconst createElementwiseProgramShader =\n    (shaderHelper: ShaderHelper, datasize: number, inputDataType: number, outputDataType: number,\n     funcCall: ElementwiseFunctionCall, additionalImplementation?: string): string => {\n      const vecSize = Math.ceil(datasize / 4);\n\n      let expression = '';\n      if (typeof funcCall === 'string') {\n        expression = `${funcCall}(a)`;\n      } else {\n        expression = funcCall('a');\n      }\n\n      const input = inputVariable('inputData', inputDataType, [vecSize], 4);\n      const output = outputVariable('outputData', outputDataType, [vecSize], 4);\n\n      return `\n      ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(input, output)}\n\n  ${additionalImplementation ?? ''}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n\n    let a = ${input.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', expression)}\n  }`;\n    };\n\nconst createElementwiseProgramInfo =\n    (input: TensorView, name: string, funcCall: ElementwiseFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType: number = input.dataType): ProgramInfo => ({\n      name,\n      shaderCache: {hint: cacheKey, inputDependencies: ['type']},\n      getShaderSource: shaderHelper => createElementwiseProgramShader(\n          shaderHelper, ShapeUtil.size(input.dims), input.dataType, outputDataType, funcCall, additionalImplementation),\n      getRunData: (inputTensors) => ({\n        outputs: [{dims: input.dims, dataType: outputDataType}],\n        dispatchGroup:\n            {x: Math.ceil(ShapeUtil.size(inputTensors[0].dims) / 64 /* workgroup size */ / 4 /* vec size */)},\n        programUniforms: [\n          {type: 'uint32', data: Math.ceil(ShapeUtil.size(input.dims) / 4)},\n        ],\n      })\n    });\n\nexport const abs = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Abs', 'abs'));\n};\n\nexport const acos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acos', 'acos'));\n};\n\nexport const acosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acosh', 'acosh'));\n};\n\nexport const asin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asin', 'asin'));\n};\n\nexport const asinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asinh', 'asinh'));\n};\n\nexport const atan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atan', 'atan'));\n};\nexport const atanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atanh', 'atanh'));\n};\n\nexport interface CastAttributes extends AttributeWithCacheKey {\n  readonly to: number;\n  readonly saturate?: boolean;\n}\n\nexport const parseCastAttributes = (attributes: Record<string, unknown>): CastAttributes =>\n    createAttributeWithCacheKey(attributes as {to: number});\n\n\nexport const cast = (context: ComputeContext, attributes: CastAttributes): void => {\n  let func: ElementwiseFunctionCall;\n  switch (attributes.to) {\n    case DataType.float16:\n      func = 'vec4<f16>';\n      break;\n    case DataType.float:\n      func = 'vec4<f32>';\n      break;\n    case DataType.uint32:\n      func = 'vec4<u32>';\n      break;\n    case DataType.int32:\n      func = 'vec4<i32>';\n      break;\n    case DataType.bool:\n      func = 'vec4<bool>';\n      break;\n    default:\n      throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${attributes.to}`);\n  }\n  context.compute(\n      createElementwiseProgramInfo(context.inputs[0], 'Cast', func, undefined, attributes.cacheKey, attributes.to));\n};\n\nexport interface ClipAttributes extends AttributeWithCacheKey {\n  readonly min: number;\n  readonly max: number;\n}\n\nconst generateClipAttributesFromInputs = (inputs: readonly TensorView[]): ClipAttributes => {\n  const min = (inputs.length >= 2) ? inputs[1].getFloat32Array()[0] : MIN_CLIP;\n  const max = (inputs.length >= 3) ? inputs[2].getFloat32Array()[0] : MAX_CLIP;\n  return createAttributeWithCacheKey({min, max});\n};\n\nexport const clip = (context: ComputeContext, clipAttributes: ClipAttributes): void => {\n  const attributes = context.inputs.length === 1 ? clipAttributes : generateClipAttributesFromInputs(context.inputs);\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(\n      createElementwiseProgramInfo(\n          context.inputs[0], 'Clip', a => `clamp(${a}, clip_min_, clip_max_)`, `\n    const clip_min_: vec4<${dataType}> = vec4(${dataType}(${attributes.min}));\n    const clip_max_: vec4<${dataType}> = vec4(${dataType}(${attributes.max}));\n`,\n          attributes.cacheKey),\n      {inputs: [0]});\n};\n\nexport const ceil = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Ceil', 'ceil'));\n};\n\nexport const cos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cos', 'cos'));\n};\n\nexport const cosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cosh', 'cosh'));\n};\n\nexport interface AlphaAttributes extends AttributeWithCacheKey {\n  readonly alpha: number;\n}\n\nexport const parseAlphaAttributes = (attributes: Record<string, unknown>): AlphaAttributes =>\n    createAttributeWithCacheKey(attributes as {alpha: number});\n\nexport const elu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Elu', a => `elu_vf32(${a})`, `\n  const elu_alpha_: f32 = f32(${attributes.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,\n      attributes.cacheKey));\n};\n\nexport const erfImpl = (dataType: string, varType = 'f32') => `\nconst r0: ${varType} = 0.3275911;\nconst r1: ${varType} = 0.254829592;\nconst r2: ${varType} = -0.284496736;\nconst r3: ${varType} = 1.421413741;\nconst r4: ${varType} = -1.453152027;\nconst r5: ${varType} = 1.061405429;\n\nfn erf_vf32(v: ${dataType}) -> ${dataType} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`;\n\nexport const erf = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Erf', a => `erf_vf32(${a})`, erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const exp = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Exp', 'exp'));\n};\n\nexport const floor = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Floor', 'floor'));\n};\n\nexport const gelu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Gelu', a => `0.5 * ${a} * (1.0 + erf_vf32(${a} * 0.7071067811865475))`,\n      erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const leakyRelu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'LeakyRelu', a => `select(leaky_relu_alpha_ * ${a}, ${a}, ${a} >= vec4<f32>(0.0))`,\n      `const leaky_relu_alpha_: f32 = f32(${attributes.alpha});`, attributes.cacheKey));\n};\n\nexport const not = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Not', a => `!${a}`));\n};\n\nexport const neg = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Neg', a => `-${a}`));\n};\n\nexport const reciprocal = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Reciprocal', a => `1.0/${a}`));\n};\n\nexport const relu = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Relu', a => `select(vec4<f32>(0.0), ${a}, ${a} > vec4<f32>(0.0))`));\n};\n\nexport const sigmoid = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sigmoid', a => `(1.0 / (1.0 + exp(-${a})))`));\n};\n\nexport const sin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sin', 'sin'));\n};\n\nexport const sinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sinh', 'sinh'));\n};\n\nexport const sqrt = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sqrt', 'sqrt'));\n};\n\nexport const tan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tan', 'tan'));\n};\n\nexport const tanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tanh', 'tanh'));\n};\n\nexport const thresholdedRelu = (context: ComputeContext, attributes: AlphaAttributes): number => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'ThresholdedRelu', a => `select(vec4<f32>(0.0), ${a}, ${a} > thresholded_relu_alpha_)`,\n      `const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${attributes.alpha});`, attributes.cacheKey));\n  return 0;\n};\n\nexport const log = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Log', 'log'));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\nimport {erfImpl} from './unary-op';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![2560, 5120, 10240].includes(inputs[0].dims[2])) {\n    throw new Error('hidden state should be 2560, 5120 or 10240');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasSplitGeluProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims.slice();\n  outputShape[2] = outputShape[2] / 2;\n\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims, 4);\n  const bias = inputVariable('bias', inputs[0].dataType, [inputs[0].dims[2]], 4);\n  const output = outputVariable('output', inputs[0].dataType, outputShape, 4);\n\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n  const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${inputs[0].dims[2] / 4 / 2}u;\n\n  ${shaderHelper.declareVariables(input, bias, output)}\n\n  ${erfImpl(`vec4<${dataType}>`, dataType)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${output.setByOffset('global_idx', 'valueLeft * geluRight')}\n  }`;\n\n  return {\n    name: 'BiasSplitGelu',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasSplitGelu = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasSplitGeluProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype BuiltinFunctionName = string;\ntype BinaryCustomExpression = (expressionA: string, expressionB: string) => string;\ntype BinaryFunctionCall = BuiltinFunctionName|BinaryCustomExpression|{\n  scalar: BinaryCustomExpression;\n  vector: BinaryCustomExpression;\n};\n\nconst createBinaryOpProgramShader =\n    (shaderHelper: ShaderHelper, dimsA: readonly number[], dimsB: readonly number[], dimsOutput: readonly number[],\n     vectorize: boolean, doBroadcast: boolean, sharedDimensionDivisibleBy4: boolean, funcCall: BinaryFunctionCall,\n     typeA: number, typeB: number, typeOutput: number, useShapesUniforms: boolean,\n     additionalImplementation?: string) => {\n      let expressionScalar: BinaryCustomExpression;\n      let expressionVector: BinaryCustomExpression;\n      if (typeof funcCall === 'string') {\n        expressionScalar = expressionVector = (a, b) => `${funcCall}((${a}),(${b}))`;\n      } else if (typeof funcCall === 'function') {\n        expressionScalar = expressionVector = funcCall;\n      } else {\n        expressionScalar = funcCall.scalar;\n        expressionVector = funcCall.vector;\n      }\n\n      const inputAShapeOrRank = useShapesUniforms ? dimsA.length : dimsA;\n      const inputBShapeOrRank = useShapesUniforms ? dimsB.length : dimsB;\n      const outputShapeOrRank = useShapesUniforms ? dimsOutput.length : dimsOutput;\n      const output = outputVariable('outputData', typeOutput, outputShapeOrRank, 4);\n      const a = inputVariable('aData', typeA, inputAShapeOrRank, 4);\n      const b = inputVariable('bData', typeB, inputBShapeOrRank, 4);\n\n      let assignment: string;\n      if (vectorize) {\n        if (doBroadcast) {\n          const isAOneElement = ShapeUtil.size(dimsA) === 1;\n          const isBOneElement = ShapeUtil.size(dimsB) === 1;\n          const aLastDimDivisibleBy4 = dimsA.length > 0 && dimsA[dimsA.length - 1] % 4 === 0;\n          const bLastDimDivisibleBy4 = dimsB.length > 0 && dimsB[dimsB.length - 1] % 4 === 0;\n          if (isAOneElement || isBOneElement) {\n            assignment = output.setByOffset(\n                'global_idx',\n                expressionVector(\n                    isAOneElement ? `${a.type.value}(${a.getByOffset('0')}.x)` : a.getByOffset('global_idx'),\n                    isBOneElement ? `${b.type.value}(${b.getByOffset('0')}.x)` : b.getByOffset('global_idx')));\n          } else {\n            assignment = `\n            let outputIndices = ${output.offsetToIndices('global_idx * 4u')};\n            let offsetA = ${a.broadcastedIndicesToOffset('outputIndices', output)};\n            let offsetB = ${b.broadcastedIndicesToOffset('outputIndices', output)};\n            ${\n                output.setByOffset(\n                    'global_idx',\n                    expressionVector(\n                        sharedDimensionDivisibleBy4 || aLastDimDivisibleBy4 ?\n                            a.getByOffset('offsetA / 4u') :\n                            `${a.type.value}(${a.getByOffset('offsetA / 4u')}[offsetA % 4u])`,\n                        sharedDimensionDivisibleBy4 || bLastDimDivisibleBy4 ?\n                            b.getByOffset('offsetB / 4u') :\n                            `${b.type.value}(${b.getByOffset('offsetB / 4u')}[offsetB % 4u])`))}\n          `;\n          }\n        } else {\n          assignment = output.setByOffset(\n              'global_idx', expressionVector(a.getByOffset('global_idx'), b.getByOffset('global_idx')));\n        }\n      } else {\n        if (!doBroadcast) {\n          throw new Error('no necessary to use scalar implementation for element-wise binary op implementation.');\n        }\n\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expressionScalar(expressionA, expressionB)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(a, b, output)}\n\n        ${additionalImplementation ?? ''}\n\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n        ${assignment}\n      }`;\n    };\n\nconst createBinaryOpProgramInfo =\n    (name: string, cacheKey: string, a: TensorView, b: TensorView, funcCall: BinaryFunctionCall,\n     additionalImplementation?: string, outputDataType: number = a.dataType): ProgramInfo => {\n      const isBroadcast = !ShapeUtil.areEqual(a.dims, b.dims);\n      let outputShape = a.dims;\n      let outputSize = ShapeUtil.size(a.dims);\n\n      let vectorize = false;\n      let sharedDimensionDivisibleBy4 = false;\n\n      // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n      const cacheKeyAux = [isBroadcast];\n      if (isBroadcast) {\n        const calculatedShape = BroadcastUtil.calcShape(a.dims, b.dims, false);\n        if (!calculatedShape) {\n          throw new Error('Can\\'t perform binary op on the given tensors');\n        }\n        outputShape = calculatedShape;\n        outputSize = ShapeUtil.size(outputShape);\n        const isAOneElement = ShapeUtil.size(a.dims) === 1;\n        const isBOneElement = ShapeUtil.size(b.dims) === 1;\n        const aLastDimDivisibleBy4 = a.dims.length > 0 && a.dims[a.dims.length - 1] % 4 === 0;\n        const bLastDimDivisibleBy4 = b.dims.length > 0 && b.dims[b.dims.length - 1] % 4 === 0;\n        cacheKeyAux.push(isAOneElement);\n        cacheKeyAux.push(isBOneElement);\n        cacheKeyAux.push(aLastDimDivisibleBy4);\n        cacheKeyAux.push(bLastDimDivisibleBy4);\n        // check whether vectorize can be enabled\n        let sharedDimension = 1;\n        for (let i = 1; i < outputShape.length; i++) {\n          const dimA = a.dims[a.dims.length - i] ?? 1;\n          const dimB = b.dims[b.dims.length - i] ?? 1;\n          if (dimA === dimB) {\n            sharedDimension *= dimA;\n          } else {\n            break;\n          }\n        }\n        if (sharedDimension % 4 === 0) {\n          sharedDimensionDivisibleBy4 = true;\n          vectorize = true;\n        } else if (isAOneElement || isBOneElement || aLastDimDivisibleBy4 || bLastDimDivisibleBy4) {\n          vectorize = true;\n        }\n      } else {\n        // element-wise\n        vectorize = true;\n      }\n      cacheKeyAux.push(vectorize);\n      const useShapesUniforms = enableShapesUniforms(a.dims.length) && enableShapesUniforms(b.dims.length) &&\n          enableShapesUniforms(outputShape.length);\n      return {\n        name,\n        shaderCache: {\n          hint: cacheKey + cacheKeyAux.map((x) => x.toString()).join('_'),\n          inputDependencies: useShapesUniforms ? ['rank', 'rank'] : ['dims', 'dims'],\n        },\n        getShaderSource: (shaderHelper) => createBinaryOpProgramShader(\n            shaderHelper, a.dims, b.dims, outputShape, vectorize, isBroadcast, sharedDimensionDivisibleBy4, funcCall,\n            a.dataType, b.dataType, outputDataType, useShapesUniforms, additionalImplementation),\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* component size */)},\n          programUniforms: useShapesUniforms ?\n              [\n                {type: 'uint32', data: Math.ceil(ShapeUtil.size(outputShape) / 4)},\n                ...createTensorShapeVariables(a.dims),\n                ...createTensorShapeVariables(b.dims),\n                ...createTensorShapeVariables(outputShape),\n              ] :\n              [\n                {type: 'uint32', data: Math.ceil(ShapeUtil.size(outputShape) / 4)},\n              ],\n        }),\n      };\n    };\n\nconst runBinaryOp =\n    (context: ComputeContext, name: string, funcCall: BinaryFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType?: number): void => {\n      context.compute(createBinaryOpProgramInfo(\n          name, cacheKey ?? '', context.inputs[0], context.inputs[1], funcCall, additionalImplementation,\n          outputDataType));\n    };\n\nexport const add = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Add', (a, b) => `${a}+${b}`);\n};\n\nexport const div = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Div', (a, b) => `${a}/${b}`);\n};\n\nexport const equal = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Equal', ({scalar: (a, b) => `u32(${a}==${b})`, vector: (a, b) => `vec4<u32>(${a}==${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const mul = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Mul', (a, b) => `${a}*${b}`);\n};\n\nexport const pow = (context: ComputeContext): void => {\n  const type = inputVariable('input', context.inputs[0].dataType, context.inputs[0].dims).type.value;\n  const roundStr = type === 'i32' ? 'round' : '';\n  runBinaryOp(\n      context, 'Pow', ({scalar: (a, b) => `pow_custom(${a},${b})`, vector: (a, b) => `pow_vector_custom(${a},${b})`}),\n      `\n    fn pow_custom(a : ${type}, b : ${type}) -> ${type} {\n      if (b == ${type}(0.0)) {\n        return ${type}(1.0);\n      } else if (a < ${type}(0.0) && f32(b) != floor(f32(b))) {\n        return ${type}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${type}(1.0), round(f32(abs(b) % ${type}(2.0))) != 1.0) * ${type}(${\n          roundStr}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${type}>, b : vec4<${type}>) -> vec4<${type}> {\n      // TODO: implement vectorized pow\n      return vec4<${type}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `);\n};\n\nexport const sub = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Sub', (a, b) => `${a}-${b}`);\n};\n\nexport const greater = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Greater', ({scalar: (a, b) => `u32(${a}>${b})`, vector: (a, b) => `vec4<u32>(${a}>${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const less = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Less', ({scalar: (a, b) => `u32(${a}<${b})`, vector: (a, b) => `vec4<u32>(${a}<${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const greaterOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'GreaterOrEqual', ({scalar: (a, b) => `u32(${a}>=${b})`, vector: (a, b) => `vec4<u32>(${a}>=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n\nexport const lessOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'LessOrEqual', ({scalar: (a, b) => `u32(${a}<=${b})`, vector: (a, b) => `vec4<u32>(${a}<=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface ConcatAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n\n  const inputType = inputs[0].dataType;\n  const inputDimensionality = inputs[0].dims.length;\n\n  for (const input of inputs) {\n    // make sure types of all inputs match\n    if (input.dataType !== inputType) {\n      throw new Error('input tensors should be one type');\n    }\n\n    // make sure the dimensionality of all inputs are the same\n    if (input.dims.length !== inputDimensionality) {\n      throw new Error('input tensors should have the same shape');\n    }\n  }\n};\n\nconst calculateInputIndexImpl = (numberOfTensors: number, sizeInConcatAxisStr: string): string => `\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${numberOfTensors}u>(${sizeInConcatAxisStr});\n    for (var i: u32 = 0u; i < ${numberOfTensors}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${numberOfTensors}u;\n  }`;\n\nconst assignOutputData = (inputs: readonly IndicesHelper[], output: IndicesHelper) => {\n  const numberOfTensors = inputs.length;\n\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = output.setByOffset('global_idx', inputs[i].getByIndices('indices'));\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (inputIndex == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (inputIndex == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return codeLines.join('\\n');\n};\n\nconst createConcatProgramInfo = (inputs: readonly TensorView[], axis: number): ProgramInfo => {\n  const inputShape = inputs[0].dims.slice();\n  if (axis >= inputShape.length || axis < (-1 * inputShape.length)) {\n    throw new Error('axis specified for concat doesn\\'t match input dimensionality');\n  }\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  // ensure all of the non-concatenated axes match each other\n  // calculate the shape of the output tensor while we do that\n  const outputShape = inputShape.slice(0);\n  for (let i = 1; i < inputs.length; i++) {\n    const dataNShape = inputs[i].dims.slice();\n    for (let axisIndex = 0; axisIndex < inputShape.length; axisIndex++) {\n      // add to the placeholder for computing output shape\n      if (axisIndex === adjustedAxis) {\n        outputShape[adjustedAxis] += dataNShape[axisIndex];\n      }\n      // ensure all non-cancatenated axes match each other\n      else if (inputShape[axisIndex] !== dataNShape[axisIndex]) {\n        throw new Error('non concat dimensions must match');\n      }\n    }\n  }\n\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const sizeInConcatAxis = new Array<number>(inputs.length);\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  const dataType = inputs[0].dataType;\n\n  let previousSum = 0;\n  const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n  const inputShapeOrRanks = [];\n  const enableInputShapesUniforms = [];\n  const programUniforms: ProgramUniform[] = [{type: 'uint32', data: outputSize}];\n  for (let i = 0; i < inputs.length; ++i) {\n    previousSum += inputs[i].dims[adjustedAxis];\n    sizeInConcatAxis[i] = previousSum;\n    enableInputShapesUniforms.push(enableShapesUniforms(inputs[i].dims.length));\n    inputShapeOrRanks.push(enableInputShapesUniforms[i] ? inputs[i].dims.length : inputs[i].dims);\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputShapeOrRanks[i]);\n    inputDependencies.push(enableInputShapesUniforms[i] ? 'rank' : 'dims');\n    programUniforms.push({type: 'uint32', data: sizeInConcatAxis[i]});\n  }\n  for (let i = 0; i < inputs.length; ++i) {\n    if (enableInputShapesUniforms[i]) {\n      programUniforms.push(...createTensorShapeVariables(inputs[i].dims));\n    }\n  }\n\n  const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n  if (enableOutputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n\n  const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n  const output = outputVariable('output', dataType, outputShapeOrRank);\n\n  const indicesAxis = output.indicesGet('indices', adjustedAxis);\n  const sizeInConcatAxisStr =\n      Array.from(Array(sizeInConcatAxis.length).keys()).map(i => `uniforms.sizeInConcatAxis${i}`).join(',');\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  ${(() => {\n    shaderHelper.registerUniform('outputSize', 'u32');\n    for (let i = 0; i < inputs.length; i++) {\n      shaderHelper.registerUniform(`sizeInConcatAxis${i}`, 'u32');\n    }\n    return shaderHelper.declareVariables(...inputVars, output);\n  })()}\n\n  ${calculateInputIndexImpl(sizeInConcatAxis.length, sizeInConcatAxisStr)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n    var indices = ${output.offsetToIndices('global_idx')};\n\n    let inputIndex = calculateInputIndex(${indicesAxis});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}u>(${sizeInConcatAxisStr});\n      ${indicesAxis} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${assignOutputData(inputVars, output)}\n  }`;\n\n  return {\n    name: 'Concat',\n    shaderCache: {hint: `${axis}`, inputDependencies},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const concat = (context: ComputeContext, attributes: ConcatAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createConcatProgramInfo(context.inputs, attributes.axis));\n};\n\nexport const parseConcatAttributes = (attributes: Record<string, unknown>): ConcatAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {MAX_CLIP, MIN_CLIP} from '../../util';\n\nexport interface InternalActivationAttributes {\n  readonly activation: string;\n  readonly clipMin?: number;\n  readonly clipMax?: number;\n  readonly activationCacheKey: string;\n}\n\nexport const getActivationSnippet = (attributes: InternalActivationAttributes, valueType: string):\n    {activationFunction: string; applyActivation: string} => {\n      switch (attributes.activation) {\n        case 'Relu':\n          return {activationFunction: '', applyActivation: `value = max(value, ${valueType}(0.0));`};\n        case 'Sigmoid':\n          return {\n            activationFunction: '',\n            applyActivation: `value = (${valueType}(1.0) / (${valueType}(1.0) + exp(-value)));`\n          };\n        case 'Clip':\n          return {\n            activationFunction: `const clip_min_=${valueType}(${attributes.clipMin!});const clip_max_=${valueType}(${\n                attributes.clipMax!});`,\n            applyActivation: 'value = clamp(value, clip_min_, clip_max_);'\n          };\n          // TODO: adding other activations that can be fused.\n        default:\n          return {activationFunction: '', applyActivation: ''};\n      }\n    };\n\nexport const parseInternalActivationAttributes =\n    (attributes: Record<string, unknown>|undefined): InternalActivationAttributes => {\n      const activation = attributes?.activation as string || '';\n\n      if (activation === 'Clip') {\n        const [clipMin, clipMax] = attributes?.activation_params as [number, number] || [MIN_CLIP, MAX_CLIP];\n        return {activation, clipMax, clipMin, activationCacheKey: `${activation}:${clipMin},${clipMax}`};\n      }\n      return {activation, activationCacheKey: activation};\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/activation_util.ts\n//\n// modified to fit the needs of the project\n\nexport const typeSnippet = (component: number, dataType: string) => {\n  switch (component) {\n    case 1:\n      return dataType;\n    case 2:\n      return `vec2<${dataType}>`;\n    case 3:\n      return `vec3<${dataType}>`;\n    case 4:\n      return `vec4<${dataType}>`;\n    default:\n      throw new Error(`${component}-component is not supported.`);\n  }\n};\n\nexport const biasSnippet = (hasBias: boolean): string => `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      `;\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-core/src/ops/conv_util.ts\n//\n// modified to fit the needs of the project\n\nexport const utilFunctions = (strideStr: string) => (`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    i32(${strideStr}.x), i32(${strideStr}.y), i32(${strideStr}.z), 1));\n}\n`);\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/matmul_packed_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../../types';\nimport {createTensorShapeVariables, enableShapesUniforms, getBroadcastDims, IndicesHelper, inputVariable, internalVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {getActivationSnippet, InternalActivationAttributes} from '../fuse-utils';\n\nimport {typeSnippet} from './activation_util';\n\nconst writeDataToSubAVec4Snippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n  }\n};\n\nconst calculateResultSnippet = (transposeA: boolean, innerElementSize: number) => {\n  if (transposeA) {\n    return `\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${innerElementSize === 3 ? '' : 'let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];'}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached3[i] + acc[i];'}\n        }`;\n  } else {\n    return `\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached.w + acc[i];'}\n        }`;\n  }\n};\n\nexport const makeMatMulPackedVec4Source =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32): string => {\n      const tileAOuter = workgroupSize[1] * workPerThread[1];\n      const tileBOuter = workgroupSize[0] * workPerThread[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n      const innerElementSize = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n\n      if (!(((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n             (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n            tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4)) {\n        throw new Error(`If transposeA ${transposeA} is true, innerElementSize ${\n            innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n      Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n  tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${\n            tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${\n            workPerThread[0]} must be 4.`);\n      }\n      return `\nvar<workgroup> mm_Asub: array<array<vec${innerElementSize}<${type}>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${type}>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\nconst rowPerThread = ${workPerThread[1]};\nconst colPerThread = ${workPerThread[0]};\nconst innerElementSize = ${innerElementSize};\nconst tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n  ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(uniforms.dimInner - 1) / tileInner + 1'};\n  var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n  var acc: array<vec4<${type}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${rowPerThreadB};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${writeDataToSubAVec4Snippet(transposeA, batchDims)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${\n          batchDims ? ', batchIndices' : ''});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${innerElementSize === 3 ? '' : 'let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];'}\n\n          ${calculateResultSnippet(transposeA, innerElementSize)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`;\n    };\n\nconst writeDataToSubASnippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n\n  } else {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) =>\n    transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport const makeMatMulPackedSource =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n     sequentialAccessByThreads = false): string => {\n      const tileAOuter = workPerThread[1] * workgroupSize[1];\n      const tileBOuter = workPerThread[0] * workgroupSize[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n\n      if (!(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 &&\n            tileInner % workgroupSize[1] === 0)) {\n        throw new Error(`tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n            workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n            workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n      }\n      const rowPerThreadA = tileAHight / workgroupSize[1];\n      const colPerThreadA = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n      const matmulSnippet = sequentialAccessByThreads ?\n          `\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n    let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n        for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n          ${writeDataToSubASnippet(transposeA, batchDims)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n            for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${batchDims ? ', batchIndices' : ''});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${type}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${\n              transposeA ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n                           `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    ` :\n          `\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\nlet tileRowA = i32(localId.y) * ${rowPerThreadA};\nlet tileColA = i32(localId.x) * ${colPerThreadA};\nlet tileRowB = i32(localId.y) * ${rowPerThreadB};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${writeDataToSubASnippet(transposeA, batchDims)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${batchDims ? ', batchIndices' : ''});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${type}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${readDataFromSubASnippet(transposeA)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;\n\n      return `\n  var<workgroup> mm_Asub : array<array<${type}, ${tileAWidth}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<${type}, ${tileBOuter}>, ${tileInner}>;\n  const rowPerThread = ${workPerThread[1]};\n  const colPerThread = ${workPerThread[0]};\n  const tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(uniforms.dimInner - 1) / tileInner + 1'};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc : array<array<${type}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${matmulSnippet}\n  }\n`;\n    };\n\nconst matMulReadWriteFnSource =\n    (component: number, hasBias: boolean, applyActivation: string, variables: IndicesHelper[],\n     batchShapes: Array<readonly number[]>, isChannelsLast = false): string => {\n      const [batchAShape, batchBShape, batchShape] = batchShapes;\n      const [batchVariable, aVariable, bVariable, outputVariable] = variables;\n      const broadCastADims = getBroadcastDims(batchAShape, batchShape);\n      const broadCastBDims = getBroadcastDims(batchBShape, batchShape);\n      const dataType = tensorTypeToWsglStorageType(variables[0].type.tensor);\n      const getAIndices = () => {\n        const aRank = aVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var aIndices: ${aVariable.type.indices};`;\n        for (let i = aRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\naIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastADims.forEach(i => {\n          resStr += `\\naIndices[${i}] = 0;`;\n        });\n        resStr += `\\naIndices[${aRank - 2}] = u32(row);\n                   aIndices[${aRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const getBIndices = () => {\n        const bRank = bVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var bIndices: ${bVariable.type.indices};`;\n        for (let i = bRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\nbIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastBDims.forEach(i => {\n          resStr += `\\nbIndices[${i}] = 0;`;\n        });\n        resStr += `\\nbIndices[${bRank - 2}] = u32(row);\n                   bIndices[${bRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const source = `\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < uniforms.dimAOuter && col < uniforms.dimInner)\n      {\n        ${getAIndices()}\n        value = ${aVariable.getByIndices('aIndices')};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < uniforms.dimInner && col < uniforms.dimBOuter)\n      {\n        ${getBIndices()}\n        value = ${bVariable.getByIndices('bIndices')};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${typeSnippet(component, dataType)}) {\n      let col = colIn * ${component};\n      if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${\n          hasBias ?\n              `value = value + ${isChannelsLast ? 'bias[colIn]' : `${typeSnippet(component, dataType)}(bias[row])`};` :\n                                                  ''                                    }\n        ${applyActivation}\n        ${outputVariable.setByIndices('vec3<u32>(coords)', 'value')}\n      }\n    }\n    `;\n      return source;\n    };\n\nexport const createMatmulProgramInfo =\n    (inputs: readonly TensorView[], activationAttributes: InternalActivationAttributes, outputShape: readonly number[],\n     reshapedOutputShape?: readonly number[],\n     isChannelsLast = false /* only used for conv2dByMatMul*/): ProgramInfo => {\n      const aShape = inputs[0].dims;\n      const bShape = inputs[1].dims;\n\n      const outerDimsA = aShape.slice(0, -2);\n      const outerDimsB = bShape.slice(0, -2);\n\n      const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n      const enableBatchUniforms = enableShapesUniforms(outerDims.length);\n      const batchShapeOrRank = enableBatchUniforms ? outerDims.length : outerDims;\n      const batchDims = internalVariable('batchDims', inputs[0].dataType, batchShapeOrRank, 1);\n      const batchSize = ShapeUtil.size(outerDims);\n\n      const dimAOuter = aShape[aShape.length - 2];\n      const dimInner = aShape[aShape.length - 1];\n      const dimBOuter = bShape[bShape.length - 1];\n      const isVec4 = dimInner % 4 === 0 && dimBOuter % 4 === 0;\n\n      // TODO: fine tune size\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const workgroupSize: [number, number, number] = [8, 8, 1];\n      const dispatch = [\n        Math.ceil(dimBOuter / workgroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dimAOuter / workgroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workgroupSize[2] / elementsPerThread[2])\n      ];\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const components = isVec4 ? 4 : 1;\n\n      const aShapeTemp = [...outerDimsA, dimAOuter, dimInner / components];\n      const enableAShapesUniforms = enableShapesUniforms(aShapeTemp.length);\n      const aShapeOrRank = enableAShapesUniforms ? aShapeTemp.length : aShapeTemp;\n\n      const bShapeTemp = [...outerDimsB, dimInner, dimBOuter / components];\n      const enableBShapesUniforms = enableShapesUniforms(bShapeTemp.length);\n      const bShapeOrRank = enableBShapesUniforms ? bShapeTemp.length : bShapeTemp;\n\n      const outputShapeTemp = [batchSize, dimAOuter, dimBOuter / components];\n\n      const A = inputVariable('a', inputs[0].dataType, aShapeOrRank, components);\n      const B = inputVariable('b', inputs[1].dataType, bShapeOrRank, components);\n      const output = outputVariable('result', inputs[0].dataType, outputShapeTemp.length, components);\n      const inputVariables = [A, B];\n      const programUniforms: ProgramUniform[] =\n          [{type: 'int32', data: dimAOuter}, {type: 'int32', data: dimBOuter}, {type: 'int32', data: dimInner}];\n      if (enableBatchUniforms) {\n        programUniforms.push(...createTensorShapeVariables(outerDims));\n      }\n      if (enableAShapesUniforms) {\n        programUniforms.push(...createTensorShapeVariables(aShapeTemp));\n      }\n      if (enableBShapesUniforms) {\n        programUniforms.push(...createTensorShapeVariables(bShapeTemp));\n      }\n      const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n      inputDependencies.push(enableAShapesUniforms ? 'rank' : 'dims');\n      inputDependencies.push(enableBShapesUniforms ? 'rank' : 'dims');\n\n      const hasBias = inputs.length > 2;\n      const {activationFunction, applyActivation} = getActivationSnippet(activationAttributes, output.type.value);\n      const declareFunctions = matMulReadWriteFnSource(\n          components, hasBias, applyActivation, [batchDims, A, B, output], [outerDimsA, outerDimsB, outerDims],\n          isChannelsLast);\n      if (hasBias) {\n        const biasComponents = isChannelsLast ? components : 1;\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, biasComponents));\n        programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n\n        inputDependencies.push('rank');\n      }\n      programUniforms.push(...createTensorShapeVariables(outputShapeTemp));\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${\n          shaderHelper.registerUniform('dimAOuter', 'i32')\n              .registerUniform('dimBOuter', 'i32')\n              .registerUniform('dimInner', 'i32')\n              .registerInternalVariables(batchDims)\n              .declareVariables(...inputVariables, output)}\n  ${activationFunction}\n  ${declareFunctions}\n  ${\n          isVec4 ? makeMatMulPackedVec4Source(elementsPerThread, workgroupSize, dataType, batchDims) :\n                   makeMatMulPackedSource(elementsPerThread, workgroupSize, dataType, batchDims)}\n                   `;\n      // TODO: turn clipMax and clipMin to uniforms.\n      return {\n        name: 'MatMul',\n        shaderCache: {\n          hint: activationAttributes.activationCacheKey + `${elementsPerThread}` +\n              `${activationAttributes.activation}` +\n              `${activationAttributes.clipMax}` +\n              `${activationAttributes.clipMin}` +\n              `${isVec4}` +\n              `${hasBias}` +\n              `${isChannelsLast}`,\n          inputDependencies\n        },\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          programUniforms\n        }),\n        getShaderSource,\n      };\n    };\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ProgramInfo, ProgramUniform} from '../../types';\nimport {createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {ConvAttributes} from '../conv';\nimport {getActivationSnippet} from '../fuse-utils';\n\nimport {biasSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dCommonSnippet =\n    (isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean, fitInner: boolean, addBias = false,\n     attributes: ConvAttributes, innerElementSizeX = 4, innerElementSizeW = 4, innerElementSize = 4,\n     dataType = 'f32'): string => {\n      const getXSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'resData = x[xIndex];';\n          case 3:\n            return `resData = vec3<${dataType}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;\n          case 4:\n            return 'resData = x[xIndex / 4];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return w[row * i32(uniforms.w_shape[3]) + colIn];';\n          case 4:\n            return 'return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    ` :\n                                             `\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'i32(uniforms.x_shape[1])' : 'i32(uniforms.x_shape[2])';\n      const xWidth = isChannelsLast ? 'i32(uniforms.x_shape[2])' : 'i32(uniforms.x_shape[3])';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n      const readXSnippet = `\n    let inChannels = i32(uniforms.w_shape[2]);\n    let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n    let outRow = ${row} / outWidth;\n    let outCol = ${row} % outWidth;\n\n    let WRow = ${col} / (filterDims[1] * inChannels);\n    let WCol = ${col} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${col} % inChannels;\n    var resData = ${typeSnippet(innerElementSizeX, dataType)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${xHeight} && xCol >= 0 && xCol < ${xWidth}) {\n      ${coordASnippet}\n      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));\n      ${getXSnippet(innerElementSizeX)}\n    }\n    return resData;`;\n\n      const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`) :\n                                       (fitInner && fitBOuter ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`);\n\n      const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n      const resType = typeSnippet(innerElementSize, dataType);\n      const aType =\n          isChannelsLast ? typeSnippet(innerElementSizeX, dataType) : typeSnippet(innerElementSizeW, dataType);\n      const bType =\n          isChannelsLast ? typeSnippet(innerElementSizeW, dataType) : typeSnippet(innerElementSizeX, dataType);\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, resType);\n      const userCode = `\n    ${activationFunction}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {\n      ${isChannelsLast ? sampleX : sampleW}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {\n      ${isChannelsLast ? sampleW : sampleX}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {\n      let col = colIn * ${innerElementSize};\n      if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`;\n      return userCode;\n    };\n\nexport const createConv2DMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes, outputShape: readonly number[], dimAOuter: number,\n     dimBOuter: number, dimInner: number, hasBias: boolean, sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      // TODO: enable vec4 for NCHW\n      const isVec4 = isChannelsLast && (inChannels % 4 === 0 || inChannels % 3 === 0) && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = [8, 8, 1];\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv2d_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? (isChannelsLast && inChannels % 4 !== 0 ? 3 : 4) : 1;\n\n      const tileAOuter = workGroupSize[1] * elementsPerThread[1];\n      const tileBOuter = workGroupSize[0] * elementsPerThread[0];\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n      const fitAOuter = dimAOuter % tileAOuter === 0;\n      const fitBOuter = dimBOuter % tileBOuter === 0;\n      const fitInner = dimInner % tileInner === 0;\n\n      const elementsSize = isVec4 ? [innerElementSize, 4, 4] : [1, 1, 1];\n      const t = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n      // TODO: support component 2, 3.\n      const components = isVec4 ? 4 : 1;\n      const programUniforms: ProgramUniform[] =\n          [{type: 'int32', data: dimAOuter}, {type: 'int32', data: dimBOuter}, {type: 'int32', data: dimInner}];\n      const x =\n          inputVariable('x', inputs[0].dataType, inputs[0].dims.length, innerElementSize === 3 ? 1 : innerElementSize);\n      const w = inputVariable('w', inputs[1].dataType, inputs[1].dims.length, components);\n      const inputVariables = [x, w];\n\n      programUniforms.push(...createTensorShapeVariables(inputs[0].dims));\n      programUniforms.push(...createTensorShapeVariables(inputs[1].dims));\n\n      let declareFunctions = `\n      fn setOutputAtIndex(flatIndex : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        result[flatIndex] = ${isVec4 ? `vec4<${t}>` : t}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${isVec4 ? '/ 4' : ''}, value);\n      }`;\n      if (hasBias) {\n        const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, components);\n        inputVariables.push(bias);\n\n        programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? `vec4<${t}>` : t} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n      const output = outputVariable('result', inputs[0].dataType, outputShape.length, components);\n      programUniforms.push(...createTensorShapeVariables(outputShape));\n      return {\n        name: 'Conv2DMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          programUniforms,\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => `\n        ${utilFunctions('uniforms.result_strides')}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${\n            shaderHelper.registerUniform('dimAOuter', 'i32')\n                .registerUniform('dimBOuter', 'i32')\n                .registerUniform('dimInner', 'i32')\n                .declareVariables(...inputVariables, output)}\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[0]}, ${attributes.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${attributes.pads[0]}, ${attributes.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        ${declareFunctions}\n        ${\n            conv2dCommonSnippet(\n                isChannelsLast, fitAOuter, fitBOuter, fitInner, hasBias, attributes, elementsSize[0], elementsSize[1],\n                elementsSize[2], t)}\n            ${\n            isVec4 ?\n                makeMatMulPackedVec4Source(elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner) :\n                makeMatMulPackedSource(\n                    elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner, false, undefined,\n                    sequentialAccessByThreads)}`\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {calculateOutputShape, ConvAttributes} from './conv';\nimport {getActivationSnippet} from './fuse-utils';\n\n/**\n * naive grouped conv implementation, supports 1d/2d conv\n * @param squeezeOutputShapeFunction - an optional function to squeeze the output shape, only used in conv1d\n */\nexport const createGroupedConvProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      const processBias = hasBias ? 'value += b[output_channel];' : '';\n      const xShape = inputs[0].dims;\n      const wShape = inputs[1].dims;\n      const outputChannelsPerGroup = wShape[0] / attributes.group;\n\n      const isChannelLast = attributes.format === 'NHWC';\n      const outputShape = calculateOutputShape(\n          xShape, wShape, attributes.dilations, attributes.pads, attributes.strides, isChannelLast);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const output = outputVariable('output', inputs[0].dataType, outputShape);\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, output.type.value);\n      const x = inputVariable('x', inputs[0].dataType, xShape);\n      const w = inputVariable('w', inputs[1].dataType, wShape);\n      const inputVars = [x, w];\n      if (hasBias) {\n        inputVars.push(inputVariable('b', inputs[2].dataType, inputs[2].dims));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const strides: vec2<u32> = vec2(${attributes.strides[0]}u, ${attributes.strides[1]}u);\n  const pads: vec2<u32> = vec2(${attributes.pads[0]}u, ${attributes.pads[1]}u);\n\n  ${shaderHelper.declareVariables(...inputVars, output)}\n\n  ${activationFunction}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${isChannelLast ? 3 : 1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${isChannelLast ? 1 : 2}], outputIndices[${\n          isChannelLast ? 2 : 3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${outputChannelsPerGroup}u;\n\n    var value: ${output.type.value} = ${output.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${wShape[1]}u; wInChannel++) {\n      let input_channel = group_id * ${wShape[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${wShape[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${attributes.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${xShape[isChannelLast ? 1 : 2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${wShape[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${attributes.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${xShape[isChannelLast ? 2 : 3]}u) {\n            continue;\n          }\n\n          let xVal = ${\n          isChannelLast ? x.get('batch', 'xHeight', 'xWidth', 'input_channel') :\n                          x.get('batch', 'input_channel', 'xHeight', 'xWidth')};\n          let wVal = ${w.get('output_channel', 'wInChannel', 'wHeight', 'wWidth')};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${processBias}\n    ${applyActivation}\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n      return {\n        name: 'GroupedConv',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        }),\n        getShaderSource,\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DMatMulProgramInfo} from './3rd-party/conv2d_mm_webgpu';\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\nimport {createGroupedConvProgramInfo} from './conv-grouped';\nimport {InternalActivationAttributes, parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nexport const calculateOutputShape =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[],\n     adjustPads: readonly number[], strides: readonly number[], isChannelLast: boolean): number[] => {\n      const batchSize = inputShape[0];\n      const inputSpatialShape = inputShape.slice(isChannelLast ? 1 : 2, isChannelLast ? 3 : 4);\n      const spatialRank = inputSpatialShape.length;\n      const outChannels = kernelShape[0];\n      const kernelSpatialShape = kernelShape.slice(2);\n      const dilatedKernelShape = kernelSpatialShape.map((v, i) => v + (v - 1) * (dilations[i] - 1));\n      const inputSpatialShapeWithPad = inputSpatialShape.map((v, i) => v + adjustPads[i] + adjustPads[i + spatialRank]);\n      const outputShape =\n          inputSpatialShapeWithPad.map((v, i) => Math.floor((v - dilatedKernelShape[i] + strides[i]) / strides[i]));\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n      return outputShape;\n    };\n\nexport interface ConvAttributes extends InternalActivationAttributes, AttributeWithCacheKey {\n  readonly autoPad: string;\n  readonly dilations: readonly number[];\n  readonly format: 'NHWC'|'NCHW';\n  readonly group: number;\n  readonly kernelShape: readonly number[];\n  readonly pads: readonly number[];\n  readonly strides: readonly number[];\n  readonly wIsConst: boolean;\n}\n\n// for transposing weight tensor from [M, C/group, KH, KW] to [KH, KW, C/group, M]\nconst weightTransposeAttribute = [2, 3, 1, 0];\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support conv 1D and 2D');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[1] * attributes.group;\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[1].dims[0] !== inputs[2].dims[0])) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  // wrong dilations dimension\n  if (attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  // Wrong strides dimension\n  if (attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  if (attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  if (attributes.kernelShape.length !== 0 && attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n};\n\nconst getAdjustedConvAttributes = <T extends ConvAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n  const kernelShape = attributes.kernelShape.slice();\n  // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n  for (let i = 2; i < inputs[1].dims.length; ++i) {\n    if (kernelShape[i - 2] === 0) {\n      kernelShape[i - 2] = inputs[1].dims[i];\n    }\n  }\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPadsBasedOnAutoPad(\n      inputs[0].dims, attributes.strides, attributes.dilations, kernelShape, pads, attributes.format === 'NHWC',\n      attributes.autoPad);\n\n  // always return a new object so does not modify the original attributes\n  const newAttributes: T = Object.assign({}, attributes);\n  Object.assign(newAttributes, {kernelShape, pads, cacheKey: attributes.cacheKey});\n  return newAttributes;\n};\n\nexport const parseConvAttributes = (attributes: Record<string, unknown>): ConvAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad = ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernel_shape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.w_is_const as () => boolean)();\n\n  return createAttributeWithCacheKey(\n      {autoPad, format, dilations, group, kernelShape, pads, strides, wIsConst, ...activationAttributes});\n};\n\nconst conv2d = (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  const adjustedAttributes = getAdjustedConvAttributes(attributes, inputs);\n\n  // check attributes\n\n  // const hasPreluActivationWeights = false; /* TODO: add support for prelu activation weights */\n  if (attributes.group !== 1) {\n    context.compute(createGroupedConvProgramInfo(inputs, adjustedAttributes));\n    return;\n  }\n\n  const isChannelsLast = attributes.format === 'NHWC';\n  const hasBias = inputs.length === 3;\n  const inputHeight = inputs[0].dims[isChannelsLast ? 1 : 2];\n  const inputWidth = inputs[0].dims[isChannelsLast ? 2 : 3];\n  const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n  const weightHeight = inputs[1].dims[2];\n  const weightWidth = inputs[1].dims[3];\n\n  const outputShape = calculateOutputShape(\n      inputs[0].dims, inputs[1].dims, attributes.dilations, adjustedAttributes.pads, attributes.strides,\n      isChannelsLast);\n  const outHeight = outputShape[isChannelsLast ? 1 : 2];\n  const outWidth = outputShape[isChannelsLast ? 2 : 3];\n  const outChannels = outputShape[isChannelsLast ? 3 : 1];\n\n  const sameSize = isChannelsLast && weightHeight === inputHeight && weightWidth === inputWidth &&\n      attributes.pads[0] === 0 && attributes.pads[1] === 0;\n  if (sameSize ||\n      (weightHeight === 1 && weightWidth === 1 && attributes.dilations[0] === 1 && attributes.dilations[1] === 1 &&\n       attributes.strides[0] === 1 && attributes.strides[1] === 1 && attributes.pads[0] === 0 &&\n       attributes.pads[1] === 0)) {\n    // conv2dByMatMul\n    const batch = outputShape[0];\n    let xReshaped, wReshaped, matmulOutputShape;\n    const matmulInputs = [];\n    if (isChannelsLast) {\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n      if (sameSize) {\n        const sharedDim = inputHeight * inputWidth * inputChannels;\n        xReshaped = inputs[0].reshape([1, batch, sharedDim]);\n        wReshaped = transposedWeight.reshape([1, sharedDim, outChannels]);\n        matmulOutputShape = [1, batch, outChannels];\n      } else {\n        xReshaped = inputs[0].reshape([batch, inputHeight * inputWidth, inputChannels]);\n        wReshaped = transposedWeight.reshape([1, inputChannels, outChannels]);\n        matmulOutputShape = [batch, outHeight * outWidth, outChannels];\n      }\n      matmulInputs.push(xReshaped);\n      matmulInputs.push(wReshaped);\n    } else {\n      xReshaped = inputs[0].reshape([batch, inputChannels, inputHeight * inputWidth]);\n      wReshaped = inputs[1].reshape([1, outChannels, inputChannels]);\n      matmulOutputShape = [batch, outChannels, outHeight * outWidth];\n      matmulInputs.push(wReshaped);\n      matmulInputs.push(xReshaped);\n    }\n    if (hasBias) {\n      matmulInputs.push(inputs[2]);\n    }\n    context.compute(\n        createMatmulProgramInfo(matmulInputs, adjustedAttributes, outputShape, matmulOutputShape, isChannelsLast),\n        {inputs: matmulInputs});\n    return;\n  }\n\n  // TODO: implement conv2dWithIm2Col()\n\n  const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n  // STEP.1: transpose weight\n  const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n      context.compute(\n          createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n          {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n  if (attributes.wIsConst && !context.kernelCustomData.wT) {\n    context.kernelCustomData.wT = transposedWeight;\n  }\n\n  // STEP.2: prepare reshaped inputs\n  const convInputs = [inputs[0], transposedWeight];\n  if (hasBias) {\n    convInputs.push(inputs[2]);\n  }\n\n  // STEP.3: compute matmul\n  const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n  const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n  const dimInner = weightHeight * weightWidth * inputChannels;\n  context.compute(\n      createConv2DMatMulProgramInfo(\n          convInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n          sequentialAccessByThreads),\n      {inputs: convInputs});\n};\n\nconst conv1d = (context: ComputeContext, attributes: ConvAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (context.inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  const pads = [0, attributes.pads[0], 0, attributes.pads[1]];\n  const strides = [1].concat(attributes.strides);\n  const dilations = [1].concat(attributes.dilations);\n  const kernelShape = [1].concat(attributes.kernelShape);\n  const adjustedAttributes = getAdjustedConvAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createGroupedConvProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] : []));\n};\n\nexport const conv = (context: ComputeContext, attributes: ConvAttributes): void => {\n  validateInputs(context.inputs, attributes);  // currently will fail if not conv1D/2D\n  if (context.inputs[0].dims.length === 3) {\n    conv1d(context, attributes);\n  } else {\n    conv2d(context, context.inputs, attributes);\n  }\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ProgramInfo, ProgramUniform} from '../../types';\nimport {createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper} from '../common';\nimport {ConvTransposeAttributes} from '../conv-transpose';\nimport {getActivationSnippet} from '../fuse-utils';\n\nimport {biasSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dTransposeCommonSnippet =\n    (isChannelsLast: boolean, addBias = false, attributes: ConvTransposeAttributes, innerElementSize = 4): string => {\n      const type = typeSnippet(innerElementSize, 'f32');\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];';\n          case 4:\n            return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];\n            let v1 = w[getIndexFromCoords4D(coord1, vec4<i32>(uniforms.w_shape))];\n            let v2 = w[getIndexFromCoords4D(coord2, vec4<i32>(uniforms.w_shape))];\n            let v3 = w[getIndexFromCoords4D(coord3, vec4<i32>(uniforms.w_shape))];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      ` :\n                                             `\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'outBackprop[1]' : 'outBackprop[2]';\n      const xWidth = isChannelsLast ? 'outBackprop[2]' : 'outBackprop[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n\n      const readASnippet = `\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${xHeight}) || fract(xR) > 0.0) {\n        return ${type}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${xWidth}) || fract(xC) > 0.0) {\n        return ${type}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${col} % inChannels;\n      ${coordASnippet}\n      return x[getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape))/${innerElementSize}];`;\n\n      const sampleA = isChannelsLast ? `\n      let col = colIn * ${innerElementSize};\n      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);` :\n                                       `\n      let col = colIn * ${innerElementSize};\n      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);`;\n\n      const sampleW = `\n      let col = colIn * ${innerElementSize};\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${\n          isChannelsLast ? 'row < uniforms.dimInner && col < uniforms.dimBOuter' :\n                           'row < uniforms.dimInner && col < uniforms.dimAOuter'}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${getWSnippet(innerElementSize)}\n      }\n      return ${type}(0.0);\n      `;\n\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, type);\n      const userCode = `\n      ${activationFunction}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleA : sampleW}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleW : sampleA}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${type}) {\n    let col = colIn * ${innerElementSize};\n    if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      result[getIndexFromCoords4D(coords, vec4<i32>(uniforms.result_shape))/${innerElementSize}] = value;\n    }\n  }`;\n      return userCode;\n    };\n\nexport const createConv2DTransposeMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes, outputShape: readonly number[],\n     dimAOuter: number, dimBOuter: number, dimInner: number, hasBias: boolean,\n     sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      const isVec4 =\n          isChannelsLast ? inChannels % 4 === 0 && outChannels % 4 === 0 : outWidth % 4 === 0 && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = isVec4 ?\n          [8, 8, 1] :\n          [(dispatchX <= 4 || dispatchY <= 4) ? 4 : 16, dispatchX > 4 && dispatchY <= 4 ? 4 : 16, 1];\n      const elementsPerThread =\n          isVec4 ? [4, 4, 1] : [dispatchX <= 4 ? 1 : 4, dispatchX > 4 && dispatchY <= 4 ? 1 : 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv_backprop_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? 4 : 1;\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n      const components = isVec4 ? 4 : 1;\n      const programUniforms: ProgramUniform[] =\n          [{type: 'int32', data: dimAOuter}, {type: 'int32', data: dimBOuter}, {type: 'int32', data: dimInner}];\n      const x = inputVariable('x', inputs[0].dataType, inputs[0].dims.length, components);\n      const w = inputVariable('w', inputs[1].dataType, inputs[1].dims.length, 1);\n      const output = outputVariable('result', inputs[0].dataType, outputShape.length, components);\n      const inputVariables = [x, w];\n      programUniforms.push(...createTensorShapeVariables(inputs[0].dims));\n      programUniforms.push(...createTensorShapeVariables(inputs[1].dims));\n\n      let declareFunctions = '';\n      if (hasBias) {\n        const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, components);\n        inputVariables.push(bias);\n        programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? 'vec4<f32>' : 'f32'} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n\n      programUniforms.push(...createTensorShapeVariables(outputShape));\n\n      return {\n        name: 'Conv2DTransposeMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          programUniforms\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => `\n        ${utilFunctions('uniforms.result_strides')}\n        ${\n            shaderHelper.registerUniform('dimAOuter', 'i32')\n                .registerUniform('dimBOuter', 'i32')\n                .registerUniform('dimInner', 'i32')\n                .declareVariables(...inputVariables, output)};\n        const outBackprop : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n            attributes.kernelShape[isChannelsLast ? 2 : 3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${\n            attributes.dilations[0] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n              ${\n            attributes.dilations[1] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${\n            attributes.pads[0] + attributes.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${\n            attributes.pads[1] + attributes.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${conv2dTransposeCommonSnippet(isChannelsLast, hasBias, attributes, innerElementSize)}\n        ${\n            isVec4 ? makeMatMulPackedVec4Source(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner) :\n                     makeMatMulPackedSource(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner, false,\n                         undefined, sequentialAccessByThreads)}`\n      };\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_webgpu.ts\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {ConvTransposeAttributes} from '../conv-transpose';\n\nconst createConvTranspose2DOpProgramShaderSource =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     outputShape: readonly number[], hasBias: boolean, is1DimensionDispatch: boolean, isVec4 = false,\n     dataType: string): string => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const rowDim = isChannelsLast ? 1 : 2;\n      const colDim = isChannelsLast ? 2 : 3;\n      const channelDim = isChannelsLast ? 3 : 1;\n      const outputSize = ShapeUtil.size(outputShape);\n      const workPerThread = isVec4 ? 2 : 1;\n      const group = attributes.group;\n      const wShape = inputs[1].dims;\n      const inputChannelsPerGroup = wShape[0] / group;\n      const outputChannelsPerGroup = wShape[1];\n\n      let declareFunctions = `\n  fn setOutputAtIndex(flatIndex : u32, value : ${isVec4 ? `vec4<${dataType}>` : dataType}) {\n    result[flatIndex] = ${isVec4 ? `vec4<${dataType}>` : dataType}(value);\n  }`;\n      if (hasBias) {\n        declareFunctions += `\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${isVec4 ? `vec4<${dataType}>` : dataType} {\n      return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n    }`;\n      }\n      const components = isVec4 ? 4 : 1;\n      const w = inputVariable('W', inputs[1].dataType, inputs[1].dims, components);\n      const dy = inputVariable('Dy', inputs[0].dataType, inputs[0].dims, components);\n      const inputVariables = [dy, w];\n      if (hasBias) {\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, [outputShape[channelDim]], components));\n      }\n      const output = outputVariable('result', inputs[0].dataType, outputShape, components);\n      const codeSnippet4 = `{\n        let batch: u32 = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} / outShape[1];\n        let r = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} % outShape[1];\n        let c = ${is1DimensionDispatch ? 'global_id.y' : 'workgroup_id.y'} * ${workPerThread};\n        let d1: u32 = ${is1DimensionDispatch ? 'global_id.x' : 'workgroup_id.x'} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${dataType}>, ${workPerThread}>;\n        for (var i = 0; i < ${workPerThread}; i++) {\n          dotProd[i] = vec4<${dataType}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${dataType}(dyCorner.x) + ${dataType}(wR)) / ${dataType}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${dataType}(dyCorner.y) + ${dataType}(wC)) / ${dataType}(strides.y);\n            let dyC2 = (${dataType}(dyCorner.y) + 1.0 + ${dataType}(wC)) / ${dataType}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${dataType}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n\n                dotProd[1] = dotProd[1] + vec4<${dataType}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${channelDim}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${workPerThread}; i = i + 1) {\n          let value = dotProd[i] + ${hasBias ? 'bias[c+i]' : '0.0'};\n          ${output.set('batch', 'r', 'c + i', 'd1', 'value')};\n        }\n      }`;\n      const codeSnippet = `\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let batch = ${output.indicesGet('outputIndices', 0)};\n          let d1 = ${output.indicesGet('outputIndices', channelDim)};\n          let r = ${output.indicesGet('outputIndices', rowDim)};\n          let c = ${output.indicesGet('outputIndices', colDim)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${outputChannelsPerGroup};\n          let wOutChannel = d1 - groupId * ${outputChannelsPerGroup};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${dataType}(dyRCorner) + ${dataType}(wR)) / ${dataType}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[${rowDim}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${dataType}(dyCCorner) + ${dataType}(wC)) / ${dataType}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[${colDim}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${inputChannelsPerGroup};\n              for (var d2: u32 = 0; d2 < ${inputChannelsPerGroup}; d2 = d2 + 1) {\n                let xValue = ${\n          isChannelsLast ? dy.get('batch', 'idyR', 'idyC', 'inputChannel') :\n                           dy.get('batch', 'inputChannel', 'idyR', 'idyC')};\n                let wValue = ${w.get('inputChannel', 'wOutChannel', 'u32(wRPerm)', 'u32(wCPerm)')};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${hasBias ? 'bias[d1]' : '0.0'};\n          ${output.setByOffset('global_idx', 'value')};\n        `;\n\n      return `\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${declareFunctions}\n  const outShape : vec4<u32> = vec4<u32>(${outputShape.join(',')});\n  const outBackprop : vec4<u32> = vec4<u32>(${inputs[0].dims.join(',')});\n  const strides : vec2<u32> = vec2<u32>(${attributes.strides[0]}, ${attributes.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n          attributes.kernelShape[isChannelsLast ? 2 : 3]});\n  const dilations : vec2<u32> = vec2<u32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${\n          attributes.dilations[0] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n          ${\n          attributes.dilations[1] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${attributes.pads[0] + attributes.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${attributes.pads[1] + attributes.pads[3]})/2);\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)};\n  ${isVec4 ? codeSnippet4 : codeSnippet}}`;\n    };\n\nexport const createConvTranspose2DProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      // const isChannelsLast = attributes.format === 'NHWC';\n      const outputShape = attributes.outputShape;\n      const outputSize = ShapeUtil.size(outputShape);\n\n      // const inChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n      // TODO Enable isVec4 for performance\n      // Disabled due to weight matrix layout issue\n      // const isVec4 = attributes.group === 1 && isChannelsLast && inChannels % 4 === 0 && outChannels % 4 === 0;\n      const dispatch = [\n        Math.ceil(outputSize / 64),\n        1,\n        1,\n      ];\n      LOG_DEBUG('verbose', () => `[conv2d_backprop_webgpu] dispatch = ${dispatch}`);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      return {\n        name: 'ConvTranspose2D',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }]\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => createConvTranspose2DOpProgramShaderSource(\n            shaderHelper, inputs, attributes, outputShape, hasBias, dispatch[1] === 1 && dispatch[2] === 1, false,\n            dataType),\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DTransposeMatMulProgramInfo} from './3rd-party/conv_backprop_mm_webgpu';\nimport {createConvTranspose2DProgramInfo} from './3rd-party/conv_backprop_webgpu';\nimport {ConvAttributes} from './conv';\nimport {parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst computeTotalPad =\n    (inDim: number, stride: number, adj: number, kernel: number, dilation: number, outSize: number) =>\n        (inDim - 1) * stride + adj + (kernel - 1) * dilation + 1 - outSize;\n\nconst distributePadding = (totalPad: number, autoPad: string, pads: number[], head: number, tail: number) => {\n  const smallPad = Math.floor(totalPad / 2);\n  if (autoPad === 'SAME_UPPER') {\n    pads[head] = smallPad;\n    pads[tail] = totalPad - smallPad;\n  } else if (autoPad === 'SAME_LOWER') {\n    pads[head] = totalPad - smallPad;\n    pads[tail] = smallPad;\n  }\n};\n\nconst calculateOutputShapeAndPads =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[], autoPad: string,\n     group: number, pads: number[], strides: readonly number[], isChannelLast: boolean, outputPadding: number[],\n     outputShape: number[]) => {\n      const spatialRank = inputShape.length - 2;\n      const updateOutputShape = outputShape.length === 0;\n      if (outputPadding.length === 0) {\n        for (let i = 0; i < spatialRank; ++i) {\n          outputPadding.push(0);\n        }\n      }\n      const batchSize = inputShape[0];\n      const outChannels = kernelShape[isChannelLast ? 3 : 1] * group;\n      for (let i = 0, j = inputShape.length - spatialRank - (isChannelLast ? 1 : 0); i < spatialRank; ++i, ++j) {\n        const inSize = inputShape[j];\n        const outSize = updateOutputShape ? inSize * strides[i] : outputShape[i];\n        const totalPad = computeTotalPad(inSize, strides[i], pads[i], kernelShape[j], dilations[i], outSize);\n        distributePadding(totalPad, autoPad, pads, i, i + spatialRank);\n        if (updateOutputShape) {\n          outputShape.push(\n              strides[i] * (inSize - 1) + outputPadding[i] + (kernelShape[j] - 1) * dilations[i] + 1 - pads[i] -\n              pads[i + spatialRank]);\n        }\n      }\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n    };\n\nexport interface ConvTransposeAttributes extends ConvAttributes {\n  readonly outputPadding: readonly number[];\n  readonly outputShape: readonly number[];\n}\n\n\nconst getAdjustedConvTransposeAttributes =\n    <T extends ConvTransposeAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n      const kernelShape = attributes.kernelShape.slice();\n      // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n      if (attributes.kernelShape.length === 0 || attributes.kernelShape.reduce((a, b) => a * b, 1) === 0) {\n        kernelShape.length = 0;\n        for (let i = 2; i < inputs[1].dims.length; ++i) {\n          kernelShape.push(inputs[1].dims[i]);\n        }\n      }\n      const isChannelsLast = attributes.format === 'NHWC';\n      kernelShape.splice(0, 0, inputs[1].dims[0]);\n      kernelShape.splice(isChannelsLast ? 3 : 1, 0, inputs[1].dims[1]);\n\n      const pads = attributes.pads.slice();\n      const outputShape = attributes.outputShape.slice();\n      const outputPadding = attributes.outputPadding.slice();\n      const inputShape = inputs[0].dims;\n      let dilations = attributes.dilations.slice();\n      if (dilations.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        dilations = new Array(spatialRank).fill(1);\n      }\n      let strides = attributes.strides.slice();\n      if (strides.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        strides = new Array(spatialRank).fill(1);\n      }\n      // If outputShape is not specified in the attributes of this op, infer it from the parameters\n      // Similarly, automatically infer pads if not specified\n      calculateOutputShapeAndPads(\n          inputShape, kernelShape, dilations, attributes.autoPad, attributes.group, pads, strides, isChannelsLast,\n          outputPadding, outputShape);\n\n      // always return a new object so does not modify the original attributes\n      const newAttributes: T = Object.assign({}, attributes);\n      const cacheKey = attributes.cacheKey + [\n        kernelShape.join('n,'), pads.join(','), strides.join(','), outputPadding.join(','), outputShape.join(','),\n        dilations.join(',')\n      ].join('_');\n      Object.assign(newAttributes, {kernelShape, pads, outputPadding, outputShape, dilations, strides, cacheKey});\n      return newAttributes;\n    };\n\nexport const parseConvTransposeAttributes = (attributes: Record<string, unknown>): ConvTransposeAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad =\n      ['NOTSET', 'VALID', 'SAME_UPPER',\n       'SAME_LOWER'][typeof attributes.autoPad == 'undefined' ? 0 : attributes.autoPad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernelShape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.wIsConst as () => boolean)();\n  const outputPadding = attributes.outputPadding as [number, number, number, number];\n  const outputShape = attributes.outputShape as [number, number];\n  return createAttributeWithCacheKey({\n    autoPad,\n    format,\n    dilations,\n    group,\n    kernelShape,\n    outputPadding,\n    outputShape,\n    pads,\n    strides,\n    wIsConst,\n    ...activationAttributes\n  });\n};\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support 2-dimensional conv');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[0];\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  const featureMaps = inputs[1].dims[1] * attributes.group;\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[2].dims[0] !== featureMaps)) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  const dilationsSet = attributes.dilations.reduce((a, b) => a + b, 0) > 0;\n  // wrong dilations dimension\n  if (dilationsSet && attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  const stridesSet = attributes.strides.reduce((a, b) => a + b, 0) > 0;\n  // Wrong strides dimension\n  if (stridesSet && attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  const padsSet = attributes.pads.reduce((a, b) => a + b, 0) > 0;\n  if (padsSet && attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // Wrong output padding dimension\n  if (attributes.outputPadding.length !== spatialRank && attributes.outputPadding.length !== 0) {\n    throw new Error(`output_padding should be ${spatialRank}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  const kernelShapeSet = attributes.kernelShape.reduce((a, b) => a + b, 0) > 0;\n  if (kernelShapeSet && attributes.kernelShape.length !== 0 &&\n      attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n\n  // as with kernelShape, must have same number of spatial dims as input\n  if (attributes.outputShape.length !== 0 && attributes.outputShape.length !== inputs[0].dims.length - 2) {\n    throw new Error('invalid output shape');\n  }\n};\n\n// for transposing weight tensor from [C, M/group, KH, KW] to [KH, KW, M/group, C]\nconst weightTransposePerm = [2, 3, 1, 0];\n\nconst convTranspose2d =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n      const adjustedAttributes = getAdjustedConvTransposeAttributes(attributes, inputs);\n      const isChannelsLast = attributes.format === 'NHWC';\n      const hasBias = inputs.length === 3;\n      if (adjustedAttributes.group !== 1) {\n        context.compute(createConvTranspose2DProgramInfo(inputs, adjustedAttributes));\n        return;\n      }\n      const outputShape = adjustedAttributes.outputShape;\n      const outHeight = outputShape[isChannelsLast ? 1 : 2];\n      const outWidth = outputShape[isChannelsLast ? 2 : 3];\n      const outChannels = outputShape[isChannelsLast ? 3 : 1];\n      const weightHeight = inputs[1].dims[2];\n      const weightWidth = inputs[1].dims[3];\n      const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n\n      const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n      const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n      const dimInner = weightHeight * weightWidth * inputChannels;\n\n      const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n\n      // STEP.1: transpose weight\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposePerm),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n\n      // STEP.2: prepare reshaped inputs\n      const convTransposeInputs = [inputs[0], transposedWeight];\n      if (hasBias) {\n        if (!isChannelsLast && inputs[2].dims.length === 1) {\n          convTransposeInputs.push(inputs[2].reshape([inputs[2].dims[0], 1, 1]));\n        } else {\n          convTransposeInputs.push(inputs[2]);\n        }\n      }\n\n      // STEP.3: compute matmul\n      context.compute(\n          createConv2DTransposeMatMulProgramInfo(\n              convTransposeInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n              sequentialAccessByThreads),\n          {inputs: convTransposeInputs});\n    };\n\nconst convTranspose1d = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  let kernelShape = attributes.kernelShape;\n  if (kernelShape.length === 0 || kernelShape[0] === 0) {\n    kernelShape = [context.inputs[1].dims[2]];\n  }\n  let dilations = attributes.dilations;\n  if (dilations.length === 0 || dilations[0] === 0) {\n    dilations = [1];\n  }\n  let strides = attributes.strides;\n  if (strides.length === 0 || strides[0] === 0) {\n    strides = [1];\n  }\n  let pads = attributes.pads;\n  if (pads.length === 0) {\n    pads = [0, 0];\n  }\n  pads = [0, pads[0], 0, pads[1]];\n  strides = [1].concat(strides);\n  dilations = [1].concat(dilations);\n  kernelShape = [1].concat(kernelShape);\n  const adjustedAttributes =\n      getAdjustedConvTransposeAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createConvTranspose2DProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] :\n                                     [outputShape[0], outputShape[1], outputShape[3]]));\n};\n\nexport const convTranspose = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 3) {\n    convTranspose1d(context, attributes);\n  } else {\n    convTranspose2d(context, context.inputs, attributes);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\n\nexport interface EinsumAttributes extends AttributeWithCacheKey {\n  readonly equation: string;\n}\n// The equation attribute value is a string which consists of left hand side (LHS) and optionally right hand side (RHS)\n// separated by '->'. Ex. \"ij,jk -> ik\" expresses matrix multiplication\n//     \"ij->ji\" expresses matrix transpose\n//      \"ii->i\" diagonal elements of a square matrix\n// LHS consists of a sequence of terms separated by commas. Each term corresponds to an input variable.\n// Each symbol corresponds to a dimension in the input variable. The symbol can be either a letter, 'a' to 'z' or 'A' to\n// 'Z' or '...' to represent arbitrary dimensions.\n\nconst symbolPattern =\n    '[a-zA-Z]|\\\\.\\\\.\\\\.';  // The pattern each symbol in each term in the symbolic equation should match\nconst termPattern = '(' + symbolPattern + ')+';   // The pattern each term in the symbolic equation should match\nconst termPatternOnly = '^' + termPattern + '$';  // The patterns only matchs a term begin to end.\nconst lhsPattern = '(' + termPattern + ',)*' + termPattern;  // The pattern the LHS should match\nconst lhsPatternOnly = '^' + lhsPattern + '$';               // The patterns only matchs a LHS begin to end.\n\ninterface SymbolInfo {\n  count: number;           // Symbol corresponding to a dimmension of an input\n  inputIndices: number[];  // Number of input variables the symbol corresponds to\n  dimValue: number;        // Number of dimensions the symbol corresponds to\n}\n\nclass EinsumTerm {\n  constructor(inputIndex = -1) {\n    this.symbolToIndices = new Map<string, number[]>();\n    this.inputIndex = inputIndex;\n  }\n\n  // Add a symbol to the term\n  addSymbol(symbol: string, index: number) {\n    let value = this.symbolToIndices.get(symbol);\n    if (value === undefined) {\n      value = [index];\n    } else {\n      value.push(index);\n    }\n    this.symbolToIndices.set(symbol, value);\n  }\n\n  symbolToIndices: Map<string, number[]>;  // Map from symbol to dimensions of the input corresponding to the term\n  inputIndex: number;                      // -1 for output and 0, 1, 2, ... for inputs\n}\n\nclass EinsumEquation {\n  constructor(inputs: readonly TensorView[], public readonly equation: string) {\n    this.hasEllipsis = false;\n    this.symbolToInfo = new Map<string, SymbolInfo>();\n    this.lhs = new Array<EinsumTerm>();\n    this.outputDims = [];\n    // As rhs needs to be updated allow using let instead of const for both lhs and rhs.\n    // eslint-disable-next-line prefer-const\n    let [lhs, rhs] = equation.includes('->') ? equation.split('->', 2) : [equation, ''];\n    if (!lhs.match(RegExp(lhsPatternOnly))) {\n      throw new Error('Invalid LHS term');\n    }\n    const inputTerms = lhs.split(',');\n    inputTerms.forEach((inputTerm, index) => {\n      const dims = inputs[index].dims.slice();\n      if (!inputTerm.match(RegExp(termPatternOnly))) {\n        throw new Error('Invalid LHS term');\n      }\n      const einsumTerm = this.processTerm(inputTerm, true, dims, index);\n      this.lhs.push(einsumTerm);\n    });\n\n    // Initialize the RHS if not specified\n    if (rhs === '') {\n      // Construct RHS from LHS terms/symbols\n      rhs += [...this.symbolToInfo.entries()]\n                 .filter(([sym, info]) => (info.count === 1 || sym === '...'))\n                 .map(([sym]) => sym)\n                 .join('');\n    } else {\n      if (!rhs.match(RegExp(termPattern))) {\n        throw new Error('Invalid RHS');\n      }\n    }\n\n    // Compute output dims\n    const rhsSymbols = rhs.match(RegExp(symbolPattern, 'g'));\n    rhsSymbols?.forEach((symbol) => {\n      if (symbol === '...') {\n        this.outputDims = this.outputDims.concat(this.ellipsisDims);\n      } else {\n        const info = this.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid RHS symbol');\n        }\n        this.outputDims.push(info.dimValue);\n      }\n    });\n    this.rhs = this.processTerm(rhs, false, this.outputDims);\n  }  // End of EinsumEqation constructor\n\n  // Add a symbol to the equation\n  addSymbol(symbol: string, dimValue: number, inputIndex: number) {\n    let info = this.symbolToInfo.get(symbol);\n    if (info !== undefined) {\n      if (info.dimValue !== dimValue && info.count !== 1) {\n        throw new Error('Dimension mismatch');\n      } else {\n        info.count++;\n        info.inputIndices.push(inputIndex);\n      }\n    } else {\n      info = {count: 1, dimValue, inputIndices: [inputIndex]};\n    }\n    this.symbolToInfo.set(symbol, info);\n  }\n\n  // Process one input/output term\n  processTerm(term: string, isInput: boolean, dims: readonly number[], index = -1): EinsumTerm {\n    const rank = dims.length;\n    let ellipsis = false;\n    let ellipsisDims = [];\n    let nextDim = 0;\n    // For output empty string is allowed because the output may be reduced to a scalar value\n    if (!term.match(RegExp(termPatternOnly)) && (!isInput && term !== '')) {\n      throw new Error('Invalid LHS term');\n    }\n    const indexSymbols = term.match(RegExp(symbolPattern, 'g'));\n    const einsumTerm = new EinsumTerm(index);\n    // symbol can be either a lettre, 'a' to 'z' or 'A' to 'Z', or '...'\n    indexSymbols?.forEach((symbol: string, i: number) => {\n      if (symbol === '...') {\n        if (ellipsis) {\n          throw new Error('Only one ellipsis is allowed per input term');\n        }\n        ellipsis = true;\n        const ellipsisDimLength = rank - indexSymbols.length + 1;\n        if (ellipsisDimLength < 0) {\n          throw new Error('Ellipsis out of bounds');\n        }\n        ellipsisDims = dims.slice(nextDim, nextDim + ellipsisDimLength);\n        if (this.hasEllipsis) {\n          if (this.ellipsisDims.length !== ellipsisDims.length ||\n              this.ellipsisDims.toString() !== ellipsisDims.toString()) {\n            throw new Error('Ellipsis dimensions mismatch');\n          }\n        } else if (isInput) {\n          this.hasEllipsis = true;\n          this.ellipsisDims = ellipsisDims;\n        } else {\n          throw new Error('Ellipsis must be specified in the LHS');\n        }\n        // Add '0', '1', '2', '3', '4', etc to represent ellipsis dimensions to avoid special handling\n        for (let j = 0; j < ellipsisDims.length; j++) {\n          const symbol = String.fromCharCode('0'.charCodeAt(0) + j);\n          einsumTerm.addSymbol(symbol, i + j);\n          this.addSymbol(symbol, dims[nextDim++], index);\n        }\n      } else {\n        einsumTerm.addSymbol(symbol, i + (this.hasEllipsis ? this.ellipsisDims.length - 1 : 0));\n        this.addSymbol(symbol, dims[nextDim++], index);\n      }\n    });\n    return einsumTerm;\n  }\n\n  symbolToInfo: Map<string, SymbolInfo>;  // All symbols in the equation\n  hasEllipsis: boolean;                   // The equation has ellipsis or not\n  ellipsisDims: number[];                 // The dimensions of the equation ellipsis corresponds to.\n  lhs: EinsumTerm[];                      // Terms on the left-hand side of the equation\n  rhs: EinsumTerm;                        // Term on the right-hand side of the equation\n  outputDims: number[];                   // Output dimensions of the equation\n}  // End of class EinsumEquation\n\nconst appendMax = (name: string): string => name + '_max';\n\nconst createEinsumProgramInfo =\n    (enableInputShapesUniforms: readonly boolean[], inputShapes: Array<readonly number[]>, dataType: number,\n     einsumEquation: EinsumEquation, outputShape: readonly number[]): ProgramInfo => {\n      const shapeOrRanks = inputShapes.map((dims, index) => enableInputShapesUniforms[index] ? dims.length : dims);\n      const inputVars = shapeOrRanks.map((shapeOrRank, index) => inputVariable(`input${index}`, dataType, shapeOrRank));\n      const outputSize = ShapeUtil.size(outputShape);\n      const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n      const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n      const output = outputVariable('output', dataType, outputShapeOrRank);\n      const uniformsSymbols =\n          [...einsumEquation.symbolToInfo.keys()].filter((symbol) => !einsumEquation.rhs.symbolToIndices.has(symbol));\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const idxCopy: string[] = [];\n        const initProd = 'var prod = 1.0;';\n        const initSum = 'var sum = 0.0;';\n        const updateSum = 'sum += prod;';\n        const reduceOpsSetIndices: string[] = [];\n        const reduceOpsLoopHeaders: string[] = [];\n        const reduceOpsLoopFooters: string[] = [];\n        const reduceOpCompute: string[] = [];\n        const isReduceOpsWithoutLoop = einsumEquation.symbolToInfo.size === einsumEquation.rhs.symbolToIndices.size;\n        einsumEquation.symbolToInfo.forEach((info, symbol) => {\n          if (einsumEquation.rhs.symbolToIndices.has(symbol)) {\n            const outputIndex = einsumEquation.rhs.symbolToIndices.get(symbol)?.[0];\n            if (outputIndex !== undefined) {\n              einsumEquation.lhs.forEach((term, i) => {\n                if (info.inputIndices.includes(i)) {\n                  const indices = term.symbolToIndices.get(symbol);\n                  if (indices === undefined) {\n                    throw new Error('Invalid symbol error');\n                  }\n                  indices.forEach((index) => {\n                    idxCopy.push(`${\n                        inputVars[i].indicesSet(\n                            `input${i}Indices`, index, output.indicesGet('outputIndices', outputIndex))}`);\n                  });\n                }\n              });\n            }\n          } else {\n            einsumEquation.lhs.forEach((term, i) => {\n              if (info.inputIndices.includes(i)) {\n                const indices = term.symbolToIndices.get(symbol);\n                if (indices === undefined) {\n                  throw new Error('Invalid symbol error');\n                }\n                indices.forEach((index) => {\n                  reduceOpsSetIndices.push(`${inputVars[i].indicesSet(`input${i}Indices`, index, `${symbol}`)}`);\n                });\n                reduceOpCompute.push(`prod *= ${inputVars[i].getByIndices(`input${i}Indices`)};`);\n              }\n            });\n            reduceOpsLoopHeaders.push(\n                `for(var ${symbol}: u32 = 0; ${symbol} < uniforms.${appendMax(symbol)}; ${symbol}++) {`);\n            reduceOpsLoopFooters.push('}');\n          }\n        });\n        const reduceOps = isReduceOpsWithoutLoop ?\n            [\n              ...idxCopy,\n              `let sum = ${inputVars.map((inputVar, i) => inputVar.getByIndices(`input${i}Indices`)).join(' * ')};`\n            ] :\n            [\n              ...idxCopy,\n              initSum,\n              ...reduceOpsLoopHeaders,\n              ...reduceOpsSetIndices,\n              initProd,\n              ...reduceOpCompute,\n              updateSum,\n              ...reduceOpsLoopFooters,\n            ];\n        return `\n            ${\n            shaderHelper\n                .registerUniforms(uniformsSymbols.map((symbol) => ({name: `${appendMax(symbol)}`, type: 'u32'})))\n                .registerUniform('outputSize', 'u32')\n                .declareVariables(...inputVars, output)}\n\n            ${shaderHelper.mainStart()}\n            ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n            var outputIndices = ${output.offsetToIndices('global_idx')};\n            ${inputVars.map((_var, i) => `var input${i}Indices: ${inputVars[i].type.indices};`).join('\\n')}\n            ${reduceOps.join('\\n')};\n            ${output.setByOffset('global_idx', 'sum')};\n          }`;\n      };\n      return {\n        name: 'Einsum',\n        shaderCache: {\n          hint: einsumEquation.equation,\n          inputDependencies: enableInputShapesUniforms.map((enableShapeUniform) => enableShapeUniform ? 'rank' : 'dims')\n        },\n        getRunData: () => {\n          // The symbols from uniformSymbols array are guaranteed to exist in einsumEquations.symbolToInfo map. The\n          // filter is added to make sure that dimValue is never 0.\n          const programUniformsInit: ProgramUniform[] =\n              uniformsSymbols.filter((symbol) => einsumEquation.symbolToInfo.has(symbol))\n                  .map((symbol) => ({type: 'uint32', data: einsumEquation.symbolToInfo.get(symbol)?.dimValue || 0}));\n          programUniformsInit.push({type: 'uint32', data: outputSize});\n          const programUniforms: ProgramUniform[] =\n              inputShapes.filter((_, index) => enableInputShapesUniforms[index])\n                  .map((dims, _) => [...createTensorShapeVariables(dims)])\n                  .reduce((acc, inputProgramUniforms) => acc.concat(inputProgramUniforms), programUniformsInit);\n          if (enableOutputShapesUniforms) {\n            programUniforms.push(...createTensorShapeVariables(outputShape));\n          }\n          return ({\n            outputs: [{dims: outputShape, dataType}],\n            dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n            programUniforms\n          });\n        },\n        getShaderSource,\n      };\n    };\n\nexport const einsum = (context: ComputeContext, attributes: EinsumAttributes): void => {\n  const einsumEquation = new EinsumEquation(context.inputs, attributes.equation);\n  const enableInputShapesUniforms = context.inputs.map((input, _) => enableShapesUniforms(input.dims.length));\n  const outputShape = einsumEquation.outputDims;\n  const inputShapes = context.inputs.map((input, _) => input.dims);\n  context.compute(createEinsumProgramInfo(\n      enableInputShapesUniforms, inputShapes, context.inputs[0].dataType, einsumEquation, outputShape));\n};\n\nexport const parseEinsumAttributes = (attributes: Record<string, unknown>): EinsumAttributes => {\n  const equation = (attributes.equation as string).replace(/\\s+/g, '');\n  return createAttributeWithCacheKey({equation});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Expand requires 2 input.');\n  }\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n\n  let shapeIndex = shape.length < inputShape.length ? 0 : shape.length - inputShape.length;\n  let inputShapeIndex = inputShape.length < shape.length ? 0 : inputShape.length - shape.length;\n  for (; shapeIndex < shape.length && inputShapeIndex < inputShape.length; ++shapeIndex, ++inputShapeIndex) {\n    if (shape[shapeIndex] !== inputShape[inputShapeIndex] && shape[shapeIndex] !== 1 &&\n        inputShape[inputShapeIndex] !== 1) {\n      throw new Error('Expand requires shape to be broadcastable to input');\n    }\n  }\n};\n\nconst getAdjustedShape = (shape1: readonly number[], shape2: readonly number[]): number[] => {\n  const diff = shape1.length - shape2.length;\n  const shape: number[] = [];\n  for (let i = 0; i < diff; ++i) {\n    shape.push(shape1[i]);\n  }\n  for (let i = 0; i < shape2.length; ++i) {\n    shape.push(shape2[i] === 1 ? shape1[i + diff] : shape2[i]);\n  }\n  return shape;\n};\n\nconst calculateOutputShape = (inputShape: readonly number[], shape: readonly number[]): number[] =>\n    (inputShape.length > shape.length) ? getAdjustedShape(inputShape, shape) : getAdjustedShape(shape, inputShape);\n\n\nconst createExpandProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n  const outputShape: number[] = calculateOutputShape(inputShape, shape);\n  const dataType = inputs[0].dataType;\n  const components = dataType === DataType.bool ? 4 : 1;\n  const outputSize = ShapeUtil.size(outputShape) / components;\n\n  const enableInputShapeUniform = enableShapesUniforms(inputShape.length);\n  const enableOutputShapeUniform = enableShapesUniforms(outputShape.length);\n\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const inputShapeOrRank = enableInputShapeUniform ? inputShape.length : inputShape;\n    const outputShapeOrRank = enableOutputShapeUniform ? outputShape.length : outputShape;\n    const input = inputVariable('input', dataType, inputShapeOrRank, components);\n    const output = outputVariable('output', dataType, outputShapeOrRank, components);\n    let assignment: string;\n    if (dataType === DataType.bool) {\n      const singleAssignment = (resStr: string, x: number, typeCast = '') => `\n          let outputIndices${x} = ${output.offsetToIndices(`outputOffset + ${x}u`)};\n          let offset${x} = ${input.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n          let index${x} = offset${x} / 4u;\n          let component${x} = offset${x} % 4u;\n          ${resStr}[${x}] = ${typeCast}(${input.getByOffset(`index${x}`)}[component${x}]);\n        `;\n      assignment = `\n        let outputOffset = global_idx * ${components};\n        var data = vec4<u32>(0);\n        ${singleAssignment('data', 0, 'u32')}\n        ${singleAssignment('data', 1, 'u32')}\n        ${singleAssignment('data', 2, 'u32')}\n        ${singleAssignment('data', 3, 'u32')}\n        ${output.setByOffset('global_idx', 'data')}\n      }`;\n    } else {\n      assignment = `\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        let inputOffset = ${input.broadcastedIndicesToOffset('outputIndices', output)};\n        ${output.setByOffset('global_idx', input.getByOffset('inputOffset'))}\n      }`;\n    }\n    return `\n    ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(input, output)}\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n    ${assignment}`;\n  };\n\n  const programUniforms: ProgramUniform[] = [{type: 'uint32', data: outputSize}];\n  if (enableInputShapeUniform) {\n    programUniforms.push(...createTensorShapeVariables(inputShape));\n  }\n  if (enableOutputShapeUniform) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n  return {\n    name: 'Expand',\n    shaderCache: {hint: `${outputShape.length}`, inputDependencies: [enableInputShapeUniform ? 'rank' : 'dims']},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms\n    })\n  };\n};\n\nexport const expand = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createExpandProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Gather requires 2 inputs.');\n  }\n};\n\nconst createGatherProgramInfo = (inputs: readonly TensorView[], attributes: GatherAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n\n  const inputRank = inputShape.length;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n\n  const outputShape = inputShape.slice(0);\n  outputShape.splice(axis, 1, ...indicesShape);\n\n  const axisDimLimit = inputShape[axis];\n  const components = inputs[0].dataType === DataType.bool ? 4 : 1;\n  const outputSize = ShapeUtil.size(outputShape) / components;\n\n  const enableInputShapesUniforms = enableShapesUniforms(inputs[0].dims.length);\n  const inputShapeOrRank = enableInputShapesUniforms ? inputs[0].dims.length : inputs[0].dims;\n  const enableIndicesShapesUniforms = enableShapesUniforms(inputs[1].dims.length);\n  const indicesShapeOrRank = enableIndicesShapesUniforms ? inputs[1].dims.length : inputs[1].dims;\n  const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n  const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n\n  const programUniforms: ProgramUniform[] =\n      [{type: 'uint32', data: outputSize}, {type: 'int32', data: axisDimLimit}, {type: 'uint32', data: axis}];\n  if (enableInputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(inputs[0].dims));\n  }\n  if (enableIndicesShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(inputs[1].dims));\n  }\n  if (enableOutputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n\n  const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n  inputDependencies.push(enableInputShapesUniforms ? 'rank' : 'dims');\n  inputDependencies.push(enableIndicesShapesUniforms ? 'rank' : 'dims');\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const data = inputVariable('data', inputs[0].dataType, inputShapeOrRank, components);\n    const indices = inputVariable('inputIndices', inputs[1].dataType, indicesShapeOrRank);\n    const output = outputVariable('output', inputs[0].dataType, outputShapeOrRank, components);\n\n    const calcDataIndices = (x: number|string): string => {\n      const indicesRank = indicesShape.length;\n      let calcStr = `var indicesIndices${x}  = ${indices.type.indices}(0);`;\n      for (let i = 0; i < indicesRank; i++) {\n        calcStr += `${indicesRank > 1 ? `indicesIndices${x}[${i}]` : `indicesIndices${x}`} = ${\n            outputShape.length > 1 ? `outputIndices${x}[uniforms.axis + ${i}]` : `outputIndices${x}`};`;\n      }\n      calcStr += `\n          var idx${x} = ${indices.getByIndices(`indicesIndices${x}`)};\n          if (idx${x} < 0) {\n            idx${x} = idx${x} + uniforms.axisDimLimit;\n          }\n          var dataIndices${x} = ${data.type.indices}(0);\n        `;\n      for (let i = 0, j = 0; i < inputRank; i++) {\n        if (i === axis) {\n          calcStr += `${inputRank > 1 ? `dataIndices${x}[${i}]` : `dataIndices${x}`} = u32(idx${x});`;\n          j += indicesRank;\n        } else {\n          calcStr += `${inputRank > 1 ? `dataIndices${x}[${i}]` : `dataIndices${x}`} = ${\n              outputShape.length > 1 ? `outputIndices${x}[${j}]` : `outputIndices${x}`};`;\n          j++;\n        }\n      }\n      return calcStr;\n    };\n    let assignment: string;\n    if (inputs[0].dataType === DataType.bool) {\n      const singleAssignment = (resStr: string, x: number, typeCast = '') => `\n          let outputIndices${x} = ${output.offsetToIndices(`outputOffset + ${x}u`)};\n          ${calcDataIndices(x)};\n          let offset${x} = ${data.indicesToOffset(`dataIndices${x}`)};\n          let index${x} = offset${x} / 4u;\n          let component${x} = offset${x} % 4u;\n          ${resStr}[${x}] = ${typeCast}(${data.getByOffset(`index${x}`)}[component${x}]);\n        `;\n      assignment = `\n        let outputOffset = global_idx * ${components};\n        var value = vec4<u32>(0);\n        ${singleAssignment('value', 0, 'u32')}\n        ${singleAssignment('value', 1, 'u32')}\n        ${singleAssignment('value', 2, 'u32')}\n        ${singleAssignment('value', 3, 'u32')}\n        ${output.setByOffset('global_idx', 'value')}\n      `;\n    } else {\n      assignment = `\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      ${calcDataIndices('')};\n      let value = ${data.getByIndices('dataIndices')};\n      ${output.setByOffset('global_idx', 'value')};\n      `;\n    }\n    return `\n      ${\n        shaderHelper.registerUniform('outputSize', 'u32')\n            .registerUniform('axisDimLimit', 'i32')\n            .registerUniform('axis', 'u32')\n            .declareVariables(data, indices, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n        ${assignment}\n      }`;\n  };\n  return {\n    name: 'Gather',\n    shaderCache: {hint: attributes.cacheKey, inputDependencies},\n    getRunData: () => ({\n      outputs: [\n        {dims: outputShape, dataType: inputs[0].dataType},\n      ],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGatherAttributes = (attributes: Record<string, unknown>): GatherAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gather = (context: ComputeContext, attributes: GatherAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherElementsAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('GatherElements requires 2 inputs.');\n  }\n\n  if (inputs[0].dims.length < 1) {\n    throw new Error('GatherElements requires that the data input be rank >= 1.');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`);\n  }\n};\n\nconst createGatherElementsProgramInfo =\n    (inputs: readonly TensorView[], attributes: GatherElementsAttributes): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n      const inputOutputDataType = inputs[0].dataType;\n      const inputRank = inputShape.length;\n      const inputStrides = ShapeUtil.computeStrides(inputShape);\n      const inputSize = ShapeUtil.size(inputShape);\n\n      const indicesShape = inputs[1].dims;\n      const indicesDataType = inputs[1].dataType;\n      const indicesSize = ShapeUtil.size(indicesShape);\n\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n      const axisDimLimit = inputShape[axis];\n\n      const outputShape = indicesShape.slice(0);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const input = inputVariable('input', inputOutputDataType, inputShape);\n      const indices = inputVariable('indices', indicesDataType, [indicesSize]);\n      const output = outputVariable('output', inputOutputDataType, outputShape);\n\n\n      // int64 indices would be treated as little endian i32 with assumption they fall in i32 limits\n      // That assumption is safe as it's not possible to allocate >2gb buffer for input tensor\n      // Input data will be treated as u32 or two u32 for 8-byte tensors\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputStrides = array<u32, ${inputStrides.length}>(${inputStrides.map(i => `${i}u`).join(',')});\n      ${shaderHelper.declareVariables(input, indices, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n\n      var idx = ${indices.getByOffset('global_idx')};\n      if (idx < 0) {\n        idx = idx + ${axisDimLimit};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        if (i == ${axis}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${output.indicesGet('outputIndices', 'i')} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${inputSize}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;\n\n      return {\n        name: 'GatherElements',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n        getShaderSource,\n      };\n    };\n\nexport const parseGatherElementsAttributes = (attributes: Record<string, unknown>): GatherElementsAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gatherElements = (context: ComputeContext, attributes: GatherElementsAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherElementsProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {GemmUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs) {\n    throw new Error('Input is missing');\n  }\n  if (inputs.length < 2 || inputs.length > 3) {\n    throw new Error('Invaid input number.');\n  }\n\n  // 'C' can be of dimensionality 0, 1 or 2 only\n  if (inputs.length === 3 && inputs[2].dims.length > 2) {\n    throw new Error('Invalid input shape of C');\n  }\n\n  if ((inputs[0].dataType !== inputs[1].dataType) ||\n      (inputs.length === 3 && inputs[0].dataType !== inputs[2].dataType)) {\n    throw new Error('Input types are mismatched');\n  }\n};\n\nexport interface GemmAttributes extends AttributeWithCacheKey {\n  transA: boolean;\n  transB: boolean;\n  alpha: number;\n  beta: number;\n}\n\nconst offsetC = (m: number, n: number, dims: readonly number[]): string => {\n  if (dims.length === 0) {\n    return '0u';\n  }\n\n  const broadcastM = (dims.length === 1 && m !== 1) || (dims.length === 2 && dims[0] !== m);\n  const broadcastN = dims[dims.length - 1] !== n;\n\n  let offset = '0u';\n  if (!broadcastM) {\n    offset += `+ m * ${dims[dims.length - 1]}u`;\n  }\n  if (!broadcastN) {\n    offset += '+n';\n  }\n\n  return offset;\n};\n\nconst createGemmProgramInfo = (inputs: readonly TensorView[], attributes: GemmAttributes): ProgramInfo => {\n  const aShape = inputs[0].dims.slice();\n  const bShape = inputs[1].dims.slice();\n  const [M, N, K] = GemmUtil.getShapeOfGemmResult(\n      aShape, attributes.transA, bShape, attributes.transB, inputs.length === 3 ? inputs[2].dims : undefined);\n  const outputShape = [M, N];\n  if (!outputShape) {\n    throw new Error('Can\\'t use gemm on the given tensors');\n  }\n  const outputSize = ShapeUtil.size(outputShape);\n  let line = '';\n  if (attributes.transA && attributes.transB) {\n    line = 'value += a[k * M + m] * b[n * K + k];';\n  } else if (attributes.transA && !attributes.transB) {\n    line = 'value += a[k * M + m] * b[k * N + n];';\n  } else if (!attributes.transA && attributes.transB) {\n    line = 'value += a[m * K + k] * b[n * K + k];';\n  } else if (!attributes.transA && !attributes.transB) {\n    line = 'value += a[m * K + k] * b[k * N + n];';\n  }\n\n  const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n  const calculateAlpha = attributes.alpha === 1 ? '' : 'value *= alpha;';\n  const calculateC = inputs.length === 3 ? `value += beta * c[${offsetC(M, N, inputs[2].dims)}];` : '';\n  const inputStorageBuffersDeclarations = [\n    `@group(0) @binding(0) var<storage, read> a : array<${dataType}>;`,\n    `@group(0) @binding(1) var<storage, read> b : array<${dataType}>;`\n  ];\n  if (inputs.length === 3) {\n    inputStorageBuffersDeclarations.push(`@group(0) @binding(2) var<storage, read> c : array<${dataType}>;`);\n  }\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${M}u;\n  const N: u32 = ${N}u;\n  const K: u32 = ${K}u;\n  const alpha = ${dataType}(${attributes.alpha});\n  const beta = ${dataType}(${attributes.beta});\n\n  ${inputStorageBuffersDeclarations.join('\\n')}\n  @group(0) @binding(${inputs.length}) var<storage, read_write> output : array<${dataType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${dataType}(0);\n    for (var k: u32 = 0u; k<${K}u; k++) {\n      ${line}\n    }\n\n    ${calculateAlpha}\n    ${calculateC}\n    output[global_id.x] = value;\n\n  }`;\n  return {\n    name: 'Gemm',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const gemm = (context: ComputeContext, attributes: GemmAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createGemmProgramInfo(context.inputs, attributes));\n};\n\nexport const parseGemmAttributes = (attributes: Record<string, unknown>): GemmAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<GemmAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nexport interface InstanceNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n  format: 'NHWC'|'NCHW';\n}\n\nconst metadata = {\n  name: 'InstanceNormalization'\n};\n\nconst createInstanceNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: InstanceNormAttributes): ProgramInfo => {\n      const xShape = inputs[0].dims;\n\n      const outputShape = xShape;\n      const axis = 2;\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n      const C = xShape[1];\n      const x = inputVariable('x', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims);\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims);\n      const output = outputVariable('output', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const variables = [x, scale, bias, output];\n      const dataType = x.type.value;\n      const workgroupSize = 64;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  const C: u32 = ${C};\n  const normSize: u32 = ${normSize};\n  const epsilon: f32 = ${attributes.epsilon};\n  var<workgroup> meanShared : ${dataType};\n  var<workgroup> squaredNormShared : ${dataType};\n  var<workgroup> workgroupShared : array<${dataType}, ${workgroupSize}>;\n  const workgroupSize = ${workgroupSize}u;\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart(workgroupSize)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${dataType} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${x.get('batch', 'channel', 'h')};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${dataType}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${x.get('batch', 'channel', 'h')} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${dataType}(normSize) + epsilon);\n    let channelScale = invStdDev * ${scale.getByOffset('channel')};\n    let channelShift = ${bias.getByOffset('channel')} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${x.get('batch', 'channel', 'h')} * channelScale + channelShift;\n      ${output.set('batch', 'channel', 'h', 'value')};\n    }\n  }`;\n      return {\n        ...metadata,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: inputs[0].dataType},\n          ],\n          dispatchGroup: {x: normCount}\n        }),\n        getShaderSource,\n      };\n    };\n\nconst computeMean =\n    (context: ComputeContext, input: TensorView, scale: TensorView, bias: TensorView, n: number, h: number, c: number,\n     epsilon: number) => {\n      const components = getMaxComponents(c);\n      const inputHelper = inputVariable('input', input.dataType, input.dims, components);\n      const scaleHelper = inputVariable('scale', scale.dataType, scale.dims, components);\n      const biasHelper = inputVariable('bias', bias.dataType, bias.dims, components);\n\n      const WG = 64;\n      // we will store channel scale and channel shift in [2, components] matrix\n      // or in vec2 when components == 1\n      const outputType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const sumCastType = components === 1 ? 'f32' : `vec${components}f`;\n      const setOutputValue = (var1: string, var2: string) => `${outputType}(${var1}, ${var2})`;\n      const unitsOfWork = n * c / components;\n      const wgSize = Math.ceil(h / WG);\n\n      const getMeanShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${h};\n  const C: u32 = ${c / components};\n  const imageSize: u32 = ${h * c / components};\n\n  ${shaderHelper.declareVariables(inputHelper)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${outputType}>;\n\n  ${shaderHelper.mainStart(WG)}\n    let currentImageNumber = global_idx / ${WG} / C;\n    let currentChannelNumber = (global_idx / ${WG}) % C;\n    let wgId = global_idx % ${WG};\n    let wgOffset = wgId * ${wgSize};\n    if (wgOffset >= H) {\n        return;\n    }\n    let wgMax = min(wgOffset + ${wgSize}, H);\n\n    let offset = currentImageNumber * imageSize + currentChannelNumber;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${sumCastType}(input[offset + i * C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${setOutputValue('sum', 'squaredSum')};\n  }`;\n\n      const meanValues = context.compute(\n          {\n            name: 'InstanceNormComputeMean',\n            shaderCache: {hint: JSON.stringify({components, n, h, c})},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, WG, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: n * c / components},\n            }),\n            getShaderSource: getMeanShaderSource,\n          },\n          {inputs: [input], outputs: [-1]})[0];\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${h};\n  const C: u32 = ${c / components};\n  const imageSize: u32 = ${WG * c / components};\n  const epsilon: f32 = ${epsilon};\n\n  @group(0) @binding(0) var<storage, read> input : array<${outputType}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${scaleHelper.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${biasHelper.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${outputType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(unitsOfWork)}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    let offset = currentImageNumber * imageSize;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = 0; i < ${WG}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${WG}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(H);\n    squaredSum = squaredSum / f32(H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + epsilon);\n    let channelScale = invStdDev * ${sumCastType}(scale[currentChannelNumber]);\n    let channelShift = ${sumCastType}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${setOutputValue('channelScale', 'channelShift')};\n  }`;\n\n      return context.compute(\n          {\n            name: 'InstanceNormComputeChannelScaleShift',\n            shaderCache: {hint: JSON.stringify({components, n, h, c, epsilon})},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: Math.ceil(unitsOfWork / 64 /* workgroup size */)},\n            }),\n            getShaderSource,\n          },\n          {inputs: [meanValues, scale, bias], outputs: [-1]})[0];\n    };\n\nconst createInstanceNormNHWCProgramInfo =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: InstanceNormAttributes) => {\n      const xShape = inputs[0].dims;\n      const outputShape = xShape;\n      const N = xShape[0];\n      const C = xShape[xShape.length - 1];\n      const H = ShapeUtil.sizeFromDimension(xShape, 1) / C;\n\n      const components = getMaxComponents(C);\n      const outputSize = ShapeUtil.size(outputShape) / components;\n      const inputHelper = inputVariable('input', inputs[0].dataType, inputs[0].dims, components);\n      const outputHelper = outputVariable('output', inputs[0].dataType, outputShape, components);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const scaleType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const scaleCastType = components === 1 ? dataType : `vec${components}<${dataType}>`;\n      // first compute mean\n      const channelScaleShift = computeMean(context, inputs[0], inputs[1], inputs[2], N, H, C, attributes.epsilon);\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${H};\n  const C: u32 = ${C / components};\n\n  @group(0) @binding(0) var<storage, read> input : array<${inputHelper.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${scaleType}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${outputHelper.type.storage}>;\n\n  ${shaderHelper.mainStart()}\n    let currentImageNumber = global_idx / (C * H);\n    let currentChannelNumber = global_idx % C;\n\n    let scaleOffset = currentImageNumber * C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${scaleCastType}(scale[0]), ${scaleCastType}(scale[1]));\n  }`;\n      context.compute(\n          {\n            name: 'InstanceNormalization',\n            shaderCache: {hint: `${attributes.cacheKey}`},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n            }),\n            getShaderSource,\n          },\n          {inputs: [inputs[0], channelScaleShift]});\n    };\n\nexport const parseInstanceNormAttributes = (attributes: InstanceNormAttributes): InstanceNormAttributes =>\n    createAttributeWithCacheKey({epsilon: attributes.epsilon, format: attributes.format});\n\nexport const instanceNorm = (context: ComputeContext, attributes: InstanceNormAttributes): void => {\n  if (attributes.format === 'NHWC') {\n    createInstanceNormNHWCProgramInfo(context, context.inputs, attributes);\n  } else {\n    context.compute(createInstanceNormProgramInfo(context.inputs, attributes));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface LayerNormAttributes extends AttributeWithCacheKey {\n  axis: number;\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 2) {\n    throw new Error('layerNorm requires at least 2 inputs.');\n  }\n};\n\nconst createLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: LayerNormAttributes, outputCount: number): ProgramInfo => {\n      const xShape = inputs[0].dims;\n      const scale = inputs[1];\n      const bias = inputs[2];\n\n      const outputShape = xShape;\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, xShape.length);\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n\n      const scaleSize = ShapeUtil.size(scale.dims);\n      const biasSize = bias ? ShapeUtil.size(bias.dims) : 0;\n      if (scaleSize !== normSize || (bias && biasSize !== normSize)) {\n        throw new Error(`Size of X.shape()[axis:] == ${normSize}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${scaleSize} and bias size of ${biasSize}`);\n      }\n\n      const meanInvStdDevDim = [];\n      for (let i = 0; i < xShape.length; ++i) {\n        if (i < axis) {\n          meanInvStdDevDim.push(xShape[i]);\n        } else {\n          meanInvStdDevDim.push(1);\n        }\n      }\n\n      const components = getMaxComponents(normSize);\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const variables = [\n        inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n        inputVariable('scale', scale.dataType, scale.dims, components),\n      ];\n      if (bias) {\n        variables.push(inputVariable('bias', bias.dataType, bias.dims, components));\n      }\n      variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n\n      const hasMeanDataOutput = outputCount > 1;\n      const hasInvStdOutput = outputCount > 2;\n\n      if (hasMeanDataOutput) {\n        variables.push(outputVariable('meanDataOutput', DataType.float, meanInvStdDevDim));\n      }\n      if (hasInvStdOutput) {\n        variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const normSize: f32 = ${normSize};\n  const normSizeVectorized: u32 = ${normSize / components};\n  const epsilon: f32 = ${attributes.epsilon};\n\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(normCount)}\n    let offset = global_idx * normSizeVectorized;\n    var meanVector = ${fillVector('f32', components)};\n    var meanSquareVector = ${fillVector('f32', components)};\n\n    for (var h: u32 = 0u; h < normSizeVectorized; h++) {\n      let value = ${castToF32(dataType, components, 'x[h + offset]')};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${sumVector('meanVector', components)} / normSize;\n    let meanSquare = sqrt(${sumVector('meanSquareVector', components)} \n      / normSize - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSizeVectorized; j++) {\n      let f32input = ${castToF32(dataType, components, 'x[j + offset]')};\n      let f32scale = ${castToF32(dataType, components, 'scale[j]')};\n      output[j + offset] = ${variables[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${bias ? `+ ${castToF32(dataType, components, 'bias[j]')}` : ''}\n      );\n    }\n\n    ${hasMeanDataOutput ? 'meanDataOutput[global_idx] = mean' : ''};\n    ${hasInvStdOutput ? 'invStdOutput[global_idx] = 1 / meanSquare' : ''};\n  }`;\n      const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n      if (hasMeanDataOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n      if (hasInvStdOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n\n      return {\n        name: 'LayerNormalization',\n        shaderCache: {hint: `${attributes.cacheKey}|${outputCount}|${inputs.length}`},\n        getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(normCount / 64 /* workgroup size */)}}),\n        getShaderSource,\n      };\n    };\n\nexport const parseLayerNormAttributes = (attributes: LayerNormAttributes): LayerNormAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis, epsilon: attributes.epsilon});\n\nexport const layerNorm = (context: ComputeContext, attributes: LayerNormAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createLayerNormProgramInfo(context.inputs, attributes, context.outputCount));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil} from '../../util';\nimport {ComputeContext} from '../types';\n\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('MatMul requires 2 inputs.');\n  }\n\n  if (inputs[0].dims[inputs[0].dims.length - 1] !== inputs[1].dims[inputs[1].dims.length - 2]) {\n    throw new Error('shared dimension does not match.');\n  }\n};\n\nexport const matMul = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  const outputShape = BroadcastUtil.calcShape(context.inputs[0].dims, context.inputs[1].dims, true);\n  if (!outputShape) {\n    throw new Error('Can\\'t use matmul on the given tensors');\n  }\n  context.compute(createMatmulProgramInfo(context.inputs, {activation: '', activationCacheKey: ''}, outputShape));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, GpuDataType} from '../types';\n\nimport {applyAttention, AttentionAttrs, AttentionMaskType, AttentionParameters, AttentionQkvFormat} from './attention';\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\nimport {createTransposeProgramInfo, TransposeAttributes} from './transpose';\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: AttentionAttrs): AttentionParameters => {\n  const query = inputs[0];\n  const key = inputs[1];\n  const value = inputs[2];\n  const bias = inputs[3];\n  const keyPaddingMask = inputs[4];\n  const relativePositionBias = inputs[5];\n  const pastKey = inputs[6];\n  const pastValue = inputs[7];\n\n  // Abbreviation and Meanings:\n  //   B:    batch_size\n  //   S:    sequence_length (input sequence length of query)\n  //   P:    past_sequence_length (past sequence length of key or value)\n  //   L:    kv_sequence_length (input sequence length of key or value)\n  //   M:    max_sequence_length\n  //   T:    total_sequence_length = past_sequence_length + kv_sequence_length\n  //   N:    num_heads\n  //   H:    head size for Q and K, aka q_head_size or k_head_size or qk_head_size\n  //   H_v:  v_head_size\n  //   D_i:  input hidden size\n  //   D:    hidden size for Q and K (D = N * H), aka q_hidden_size or k_hidden_size or qk_hidden_size\n  //   D_v:  v_hidden_size = num_heads * v_head_size\n\n  //     key_padding_mask (K/V)     : (B) or (2*B + 1) or (B, L) or None\n  //     relative_position_bias     : (B, 1, S, L)\n  //     past_key                   : (B, N, S*, H)\n  //     past_value                 : (B, N, S*, H)\n  // When no packing for q/k/v:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, D) or (B, N, S*, H)\n  //     value            (V)       : (B, L, D_v) or (B, N, S*, H)\n  //     bias             (Q/K/V)   : (D + D + D_v)\n  // When packed kv is used:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, N, 2, H)\n  //     value            (V)       : None\n  //     bias             (Q/K/V)   : None\n  // When packed qkv is used:\n  //     query            (Q)       : (B, L, N, 3, H) or (B, S, 3*D)\n  //     key              (K)       : None\n  //     value            (V)       : None\n  //     bias             (Q/K/V)   : None or (D + D + D_v)\n\n  if (query.dims.length !== 3 && query.dims.length !== 5) {\n    throw new Error('Input query is expected to have 3 or 5 dimensions');\n  }\n\n  const dmmhaPacking = false;\n  const batchSize = query.dims[0];\n  const sequenceLength = query.dims[1];\n  const hiddenSize = query.dims.length === 3 ? (dmmhaPacking ? query.dims[2] / 3 : query.dims[2]) :\n                                               attributes.numHeads * query.dims[4];\n  let kvSequenceLength = sequenceLength;\n\n  let pastSequenceLength = 0;\n  let maxSequenceLength = 0;\n  const headSize = Math.floor(hiddenSize / attributes.numHeads);\n  if (pastKey && pastValue) {\n    if (pastKey.dims.length !== 4) {\n      throw new Error('Input \"past_key\" is expected to have 4 dimensions');\n    }\n    if (pastValue.dims.length !== 4) {\n      throw new Error('Input \"past_value\" is expected to have 4 dimensions');\n    }\n    pastSequenceLength = pastKey.dims[2];\n    maxSequenceLength = pastKey.dims[2];\n  } else if (pastKey || pastValue) {\n    throw new Error('Input \"past_key\" and \"past_value\" shall be both present or both absent');\n  }\n\n  let qkvFormat: AttentionQkvFormat;\n  if (key) {\n    if (query.dims.length !== 3) {\n      throw new Error('Input \"query\" is expected to have 3 dimensions when key is given');\n    }\n    if (key.dims.length < 3 || key.dims.length > 5) {\n      throw new Error('Input \"key\" is expected to have 3, 4, or 5 dimensions');\n    }\n    if (query.dims[0] !== key.dims[0]) {\n      throw new Error('Input \"query\" and \"key\" shall have same dim 0 (batch size)');\n    }\n\n    if (key.dims.length === 3) {\n      if (key.dims[2] !== query.dims[2]) {\n        throw new Error('Input \"query\" and \"key\" shall have same dim 2 (hidden_size)');\n      }\n      qkvFormat = AttentionQkvFormat.qkvBSNH;\n      kvSequenceLength = key.dims[1];\n    } else if (key.dims.length === 5) {\n      if (key.dims[2] !== attributes.numHeads || key.dims[3] !== 2 || key.dims[4] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');\n      }\n      if (value) {\n        throw new Error('Expect \"value\" be none when \"key\" has packed kv format.');\n      }\n      qkvFormat = AttentionQkvFormat.qKvBSNHxBSN2H;\n      kvSequenceLength = key.dims[1];\n    } else {  // key_dims.size() == 4 (cross-attention with past_key)\n      if (key.dims[1] !== attributes.numHeads || key.dims[3] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');\n      }\n\n      qkvFormat = AttentionQkvFormat.unknown;\n      kvSequenceLength = key.dims[2];\n    }\n  } else {  // packed QKV\n    if (query.dims.length !== 3 && query.dims.length !== 5) {\n      throw new Error('Input \"query\" is expected to have 3 or 5 dimensions when key is empty');\n    }\n    if (query.dims.length === 5 && (query.dims[2] !== attributes.numHeads || query.dims[3] !== 3)) {\n      throw new Error('Expect \"query\" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');\n    }\n\n    qkvFormat = AttentionQkvFormat.qkvBSN3H;\n  }\n\n  if (bias) {\n    if (bias.dims.length !== 1) {\n      throw new Error('Input \"bias\" is expected to have 1 dimension');\n    }\n\n    if (value) {\n      if (query.dims.length === 5 && query.dims[3] === 2) {\n        throw new Error('bias is not allowed for packed kv.');\n      }\n    }\n  }\n\n  let maskType: AttentionMaskType = AttentionMaskType.none;\n  if (keyPaddingMask) {\n    maskType = AttentionMaskType.maskUnknown;\n    const maskDims = keyPaddingMask.dims;\n    if (maskDims.length === 1) {\n      if (maskDims[0] === batchSize) {\n        maskType = AttentionMaskType.mask1dKeySeqLen;\n      } else if (maskDims[0] === 3 * batchSize + 2) {\n        maskType = AttentionMaskType.mask1DKeySeqLenStart;\n      }\n    } else if (maskDims.length === 2 && maskDims[0] === batchSize && maskDims[1] === kvSequenceLength) {\n      maskType = AttentionMaskType.mask2dKeyPadding;\n    }\n    if (maskType === AttentionMaskType.maskUnknown) {\n      throw new Error('Input \"key_padding_mask\" shape shall be (batch_size) or (batch_size, kv_sequence_length)');\n    }\n    throw new Error('Mask not supported');\n  }\n\n  let passPastInKv = false;\n  let vHiddenSize = hiddenSize;\n  if (value) {\n    if (value.dims.length !== 3 && value.dims.length !== 4) {\n      throw new Error('Input \"value\" is expected to have 3 or 4 dimensions');\n    }\n\n    if (query.dims[0] !== value.dims[0]) {\n      throw new Error('Input \"query\" and \"value\" shall have same dim 0 (batch_size)');\n    }\n\n    if (value.dims.length === 3) {\n      if (kvSequenceLength !== value.dims[1]) {\n        throw new Error('Input \"key\" and \"value\" shall have the same dim 1 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[2];\n    } else {\n      if (kvSequenceLength !== value.dims[2]) {\n        throw new Error('Input \"past_key\" and \"past_value\" shall have the same dim 2 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[1] * value.dims[3];\n      passPastInKv = true;\n    }\n  }\n\n  const totalSequenceLength = pastSequenceLength + kvSequenceLength;\n  const broadcastResPosBias = false;\n  // if (extraAddQk) {\n  //   if (extraAddQk.dims[0] === 1) {\n  //     broadcastResPosBias = true;\n  //   }\n  // }\n\n  if (keyPaddingMask) {\n    throw new Error('Key padding mask is not supported');\n  }\n  if (relativePositionBias) {\n    throw new Error('extraAddQk is not supported');\n  }\n  if (pastKey) {\n    throw new Error('pastKey is not supported');\n  }\n  if (pastValue) {\n    throw new Error('pastValue is not supported');\n  }\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize: 0,\n    hiddenSize,\n    vHiddenSize,\n    headSize,\n    vHeadSize: Math.floor(vHiddenSize / attributes.numHeads),\n    numHeads: attributes.numHeads,\n    isUnidirectional: false,\n    pastPresentShareBuffer: false,\n    maskFilterValue: attributes.maskFilterValue,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias,\n    passPastInKv,\n    qkvFormat,\n  };\n};\n\n\nexport const parseMultiHeadAttentionAttributes = (attributes: AttentionAttrs): AttentionAttrs =>\n    createAttributeWithCacheKey({...attributes});\n\nconst weightTransposeAttribute: TransposeAttributes = createAttributeWithCacheKey({perm: [0, 2, 1, 3]});\n\nconst addBiasTranspose =\n    (context: ComputeContext, qkv: TensorView, bias: TensorView, batchSize: number, sequenceLength: number,\n     hiddenSize: number, biasOffset: number) => {\n      const outputShape = [batchSize, sequenceLength, hiddenSize];\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const dataType = tensorTypeToWsglStorageType(qkv.dataType);\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const biasOffset = ${biasOffset}u;\n  const hiddenSize = ${hiddenSize}u;\n\n  @group(0) @binding(0) var<storage, read> qkv: array<${dataType}>;\n  @group(0) @binding(1) var<storage, read> bias: array<${dataType}>;\n  @group(0) @binding(2) var<storage, read_write> qkv_with_bias: array<${dataType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasOffsetIdx = (global_idx % hiddenSize) + biasOffset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[biasOffsetIdx];\n  }`;\n\n      return context.compute(\n          {\n            name: 'MultiHeadAttentionAddBias',\n            shaderCache: {hint: JSON.stringify({batchSize, sequenceLength, hiddenSize, biasOffset})},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: qkv.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n            }),\n            getShaderSource,\n          },\n          {inputs: [qkv, bias], outputs: [-1]})[0];\n    };\n\nconst maybeTransposeToBNSHAndAddBias =\n    (context: ComputeContext, batchSize: number, numHeads: number, sequenceLength: number, headSize: number,\n     input: TensorView, bias?: TensorView, biasOffset?: number) => {\n      // const newDims = [];\n\n      let reshapedInput = input;\n      if (!bias) {\n        if (input.dims.length === 3) {\n          reshapedInput = input.reshape([batchSize, sequenceLength, numHeads, headSize]);\n        }\n        return context.compute(\n            createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm),\n            {inputs: [reshapedInput], outputs: [-1]})[0];\n      } else {\n        if (sequenceLength === 1) {\n          throw new Error('AddBiasReshape is not implemented. Please export your model with packed QKV or KV');\n        } else {\n          reshapedInput =\n              addBiasTranspose(context, input, bias, batchSize, sequenceLength, numHeads * headSize, biasOffset!);\n          reshapedInput = reshapedInput.reshape([batchSize, sequenceLength, numHeads, headSize]);\n          return context.compute(\n              createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm),\n              {inputs: [reshapedInput], outputs: [-1]})[0];\n        }\n      }\n    };\n\nexport const multiHeadAttention = (context: ComputeContext, attributes: AttentionAttrs): void => {\n  const params = validateInputs(context.inputs, attributes);\n\n  if (context.inputs[0].dims.length === 5) {\n    throw new Error('Packed QKV is not implemented');\n  }\n\n  if (context.inputs[1]?.dims.length === 5) {\n    throw new Error('Packed KV is not implemented');\n  }\n\n  // applyAttention expects BNSH inputs\n  const kvBNSH = context.inputs[1] && context.inputs[2] && context.inputs[1].dims.length === 4 &&\n      context.inputs[2].dims.length === 4;\n\n  const Q = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.sequenceLength, params.headSize, context.inputs[0],\n      context.inputs[3], 0);\n\n  if (kvBNSH) {\n    return applyAttention(\n        context, Q, context.inputs[1], context.inputs[2], context.inputs[4], undefined, undefined, undefined,\n        context.inputs[5], params, attributes);\n  }\n\n  const K = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.kvSequenceLength, params.headSize, context.inputs[1],\n      context.inputs[3], params.hiddenSize);\n\n  const V = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.kvSequenceLength, params.vHeadSize, context.inputs[2],\n      context.inputs[3], 2 * params.hiddenSize);\n\n  applyAttention(\n      context, Q, K, V, context.inputs[4], undefined, context.inputs[6], context.inputs[7], context.inputs[5], params,\n      attributes);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface PadAttributes extends AttributeWithCacheKey {\n  // 0-constant, 1-reflect, 2-edge, 3-wrap\n  readonly mode: number;\n  readonly value: number;\n  readonly pads: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('Too few inputs');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Input type must be float.');\n  }\n\n  if (inputs.length >= 2) {\n    let validPads = inputs[0].dims.length * 2 === inputs[1].dims[0];\n    if (inputs.length === 4) {\n      validPads = inputs[3].dims[0] * 2 === inputs[1].dims[0];\n    }\n    if (!validPads) {\n      throw new Error('The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].');\n    }\n  }\n};\n\nconst getPadConstant =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], pads: number[],\n     dataType: string, constantValue: number): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n            k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${inputDims[i]}) {\n              break;\n            }\n            offset += k * ${inputStrides[i]};\n        `;\n      }\n\n      return `\n          value = ${dataType}(${constantValue});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${block}\n            value = x[offset];\n          }\n      `;\n    };\n\nconst getPadReflect =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2 * (inputDims[i] - 1)};\n                  k = k % _2n_1;\n                  if(k >= ${inputDims[i]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadEdge =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${inputDims[i]}) {\n                  k = ${inputDims[i] - 1};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadWrap =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0)  {\n                  k += ${inputDims[i]};\n                }\n                if (k >= ${inputDims[i]}) {\n                  k -= ${inputDims[i]};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadSnippet =\n    (output: IndicesHelper, inputDims: readonly number[], inputStrides: readonly number[], attributes: PadAttributes,\n     dataType: string): string => {\n      switch (attributes.mode) {\n        case 0:\n          return getPadConstant(output, inputDims, inputStrides, attributes.pads, dataType, attributes.value);\n        case 1:\n          return getPadReflect(output, inputDims, inputStrides, attributes.pads);\n        case 2:\n          return getPadEdge(output, inputDims, inputStrides, attributes.pads);\n        case 3:\n          return getPadWrap(output, inputDims, inputStrides, attributes.pads);\n        default:\n          throw new Error('Invalid mode');\n      }\n    };\n\nconst generatePadCode =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: PadAttributes, dataType: string):\n        string => {\n          const inputDims = inputs[0].dims;\n          const outputDims = ShapeUtil.padShape(inputDims.slice(), attributes.pads);\n          const outputSize = ShapeUtil.size(outputDims);\n          const inputStrides = ShapeUtil.computeStrides(inputDims);\n\n          const output = outputVariable('output', inputs[0].dataType, outputDims);\n          const input = inputVariable('x', inputs[0].dataType, inputDims);\n\n          const padSnippet = getPadSnippet(output, inputDims, inputStrides, attributes, dataType);\n          const padCode = `\n              ${shaderHelper.declareVariables(input, output)}\n              ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n\n              var value = ${dataType}(0);\n              ${padSnippet}\n              output[global_idx] = value;\n          }`;\n          return padCode;\n        };\n\nconst createPadProgramInfo = (inputs: readonly TensorView[], attributes: PadAttributes): ProgramInfo => {\n  const outputShape = ShapeUtil.padShape(inputs[0].dims.slice(), attributes.pads);\n  return {\n    name: 'Pad',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n    }),\n    getShaderSource: shaderHelper => generatePadCode(shaderHelper, inputs, attributes, 'f32'),\n  };\n};\n\nconst createPadAttributesFromInputs = (inputs: readonly TensorView[], attributes: PadAttributes): PadAttributes => {\n  if (inputs.length > 1) {\n    const bigInt64Pads = inputs[1].getBigInt64Array();\n    const value = (inputs.length >= 3 && inputs[2].data) ? inputs[2].getFloat32Array()[0] : 0.0;\n\n    const inputRank = inputs[0].dims.length;\n    const updatePads = new Int32Array(2 * inputRank).fill(0);\n    if (inputs.length >= 4) {\n      const axes = inputs[3].getBigInt64Array();\n      for (let i = 0; i < axes.length; i++) {\n        updatePads[Number(axes[i])] = Number(bigInt64Pads[i]);\n        updatePads[Number(axes[i]) + inputRank] = Number(bigInt64Pads[i + axes.length]);\n      }\n    } else {\n      bigInt64Pads.forEach((v, i) => updatePads[Number(i)] = (Number(v)));\n    }\n\n    const pads: number[] = [];\n    updatePads.forEach(v => pads.push(v));\n\n    return createAttributeWithCacheKey({mode: attributes.mode, value, pads});\n  } else {\n    return attributes;\n  }\n};\n\nexport const pad = (context: ComputeContext, attributes: PadAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes = createPadAttributesFromInputs(context.inputs, attributes);\n  context.compute(createPadProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parsePadAttributes = (attributes: Record<string, unknown>): PadAttributes => {\n  const mode = attributes.mode as number;\n  const value = attributes.value as number;\n  const pads = attributes.pads as number[];\n  return createAttributeWithCacheKey({mode, value, pads});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\n// TODO: support:\n// - ceil_mode                 \"test_maxpool_2d_ceil\"\n// - storage_order             \"test_maxpool_with_argmax_2d_precomputed_strides\"\n// - [MaxPool] dilations       \"test_maxpool_2d_dilations\"\n// - [MaxPool] output[1]       \"test_maxpool_with_argmax_2d_precomputed_pads\"\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Pool ops requires 1 input.');\n  }\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('Pool ops supports 1-D or 2-D inputs only for now.');\n  }\n};\n\nconst getAdjustedPoolAttributesAndOutputShape = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    input: TensorView, attributes: AttributeType, isGlobalOperator: boolean): [AttributeType, number[]] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputShapeAsChannelFirst = input.dims.slice();\n  if (isChannelsLast) {\n    inputShapeAsChannelFirst.splice(1, 0, inputShapeAsChannelFirst.pop()!);  // Move channel to the second position.\n  }\n  const hasDilations = Object.hasOwnProperty.call(attributes, 'dilations');\n  const kernelShape = attributes.kernelShape.slice();\n  const strides = attributes.strides.slice();\n  const dilations: number[] = hasDilations ? (attributes as MaxPoolAttributes).dilations.slice() : [];\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPoolAttributes(isGlobalOperator, inputShapeAsChannelFirst, kernelShape, strides, dilations, pads);\n\n  const outputShapeAsChannelFirst = PoolConvUtil.computePoolOutputShape(\n      isGlobalOperator, inputShapeAsChannelFirst, strides, dilations, kernelShape, pads, attributes.autoPad);\n\n  const newAttributes = Object.assign({}, attributes);\n  if (hasDilations) {\n    Object.assign(newAttributes, {kernelShape, strides, pads, dilations, cacheKey: attributes.cacheKey});\n  } else {\n    Object.assign(newAttributes, {kernelShape, strides, pads, cacheKey: attributes.cacheKey});\n  }\n  const outputShapeAsChannelLast = outputShapeAsChannelFirst.slice();\n  outputShapeAsChannelLast.push(outputShapeAsChannelLast.splice(1, 1)[0]);\n  return [newAttributes, isChannelsLast ? outputShapeAsChannelLast : outputShapeAsChannelFirst];\n};\n\nconst generatePoolingCode = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    shaderHelper: ShaderHelper, x: IndicesHelper, xShape: readonly number[], outputShape: readonly number[],\n    attributes: AttributeType, op1: string, op2: string, start: string): string => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputDims = xShape;\n  const dataType = x.type.value;\n  const rank = inputDims.length;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', x.type.tensor, outputShape);\n\n  if (attributes.kernelShape.length <= 2) {\n    const kw = attributes.kernelShape[attributes.kernelShape.length - 1];\n    const sw = attributes.strides[attributes.strides.length - 1];\n    const pwStart = attributes.pads[attributes.pads.length / 2 - 1];\n    const pwEnd = attributes.pads[attributes.pads.length - 1];\n    const dimIdxW = rank - (isChannelsLast ? 2 : 1);\n    let codeW = '';\n    let codeH = '';\n    let codeHEnd = '';\n    if (pwStart + pwEnd !== 0) {\n      codeW = `\n                for (var i: u32 = 0u; i < ${kw}u; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                  if (xIndices[${dimIdxW}] < 0 || xIndices[${dimIdxW}] >= ${inputDims[dimIdxW]}) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    } else {\n      codeW = `\n                for (var i: u32 = 0u; i < ${kw}u; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    }\n\n    if (attributes.kernelShape.length === 2) {\n      const kh = attributes.kernelShape[attributes.kernelShape.length - 2];\n      const sh = attributes.strides[attributes.strides.length - 2];\n      const phStart = attributes.pads[attributes.pads.length / 2 - 2];\n      const phEnd = attributes.pads[attributes.pads.length - 2];\n      const dimIdxH = rank - (isChannelsLast ? 3 : 2);\n      const dimH = inputDims[dimIdxH];\n      if (phStart + phEnd !== 0) {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                  if (xIndices[${dimIdxH}] < 0 || xIndices[${dimIdxH}] >= ${dimH}) {\n                    pad+= ${kw};\n                    continue;\n                  }\n              `;\n      } else {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                `;\n      }\n      codeHEnd = `\n              }\n            `;\n    }\n\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var value: ${dataType} = ${dataType}(${start});\n              var pad = 0;\n              ${codeH}\n              ${codeW}\n              ${codeHEnd}\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const kernelSize = ShapeUtil.size(attributes.kernelShape);\n    const kernelStrides = ShapeUtil.computeStrides(attributes.kernelShape);\n    const stridesRank = kernelStrides.length;\n    const padsRank = attributes.pads.length;\n    const hasPads = attributes.pads.reduce((sum, cur) => sum + cur);\n    let padCode = '';\n    if (hasPads) {\n      padCode = `\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    } else {\n      padCode = `\n              }\n              let x_val = x[${x.indicesToOffset('xIndices')}];\n              ${op1}\n            `;\n    }\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            const pads = array<u32, ${padsRank}>(${attributes.pads.map(i => `${i}u`).join(',')});\n            const inputDims = array<u32, ${rank}>(${inputDims.map(i => `${i}u`).join(',')});\n            const kernelStrides = array<u32, ${stridesRank}>(${kernelStrides.map(i => `${i}u`).join(',')});\n            const strides = array<u32, ${stridesRank}>(${attributes.strides.map(i => `${i}u`).join(',')});\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              let xIndices = ${output.offsetToIndices('global_idx')};\n\n              var offsets: array<u32, ${stridesRank}>;\n\n              var value = ${output.type.value}(${start});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${kernelSize}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${stridesRank - 1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${stridesRank - 1}] = offset;\n\n                isPad = false;\n                for (var j = ${rank - stridesRank}u; j < ${rank}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${rank - stridesRank}u]\n                    + offsets[j - ${rank - stridesRank}u] - pads[j - 2u];\n                  ${padCode}\n              }\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  }\n};\n\nexport interface FormatAttributes {\n  readonly format: 'NHWC'|'NCHW';\n}\n\nexport interface PoolCommonAttributes extends FormatAttributes {\n  readonly autoPad: string;\n  readonly ceilMode: number;\n  readonly kernelShape: readonly number[];\n  readonly strides: readonly number[];\n  readonly pads: readonly number[];\n}\n\nconst parsePoolCommonAttributes = (attributes: Record<string, unknown>): PoolCommonAttributes => ({\n  format: attributes.format as FormatAttributes['format'],\n  autoPad: ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number],\n  ceilMode: attributes.ceil_mode as number,\n  kernelShape: attributes.kernel_shape as [number, number],\n  strides: attributes.strides as [number, number],\n  pads: attributes.pads as [number, number, number, number]\n});\n\nexport interface AveragePoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly countIncludePad: boolean;\n}\n\nconst createAveragePoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: AveragePoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const kernelSize = ShapeUtil.size(adjustedAttributes.kernelShape);\n\n      const x = inputVariable('x', input.dataType, input.dims);\n      const dataType = x.type.value;\n\n      const op1 = 'value += x_val;';\n      let op2 = '';\n      if (adjustedAttributes.countIncludePad) {\n        op2 += `value /= ${dataType}(${kernelSize});`;\n      } else {\n        op2 += `value /= ${dataType}(${kernelSize} - pad);`;\n      }\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '0.0'),\n      };\n    };\n\nexport const parseAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const countIncludePad = (attributes.count_include_pad as number) === 0 ? false : true;\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode'\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for AveragePool');\n  }\n\n  return createAttributeWithCacheKey({countIncludePad, ...attr});\n};\n\nexport const averagePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('AveragePool', context.inputs[0], false, attributes));\n};\n\nconst globalPoolAttributes = {\n  autoPad: '',\n  ceilMode: 0,\n  countIncludePad: false,\n  kernelShape: [],\n  strides: [],\n  pads: [],\n  storageOrder: 0,\n  dilations: [],\n  cacheKey: ''\n};\n\nexport const parseGlobalAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalAveragePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('GlobalAveragePool', context.inputs[0], true, attributes));\n};\n\nexport interface MaxPoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly storageOrder: number;\n  readonly dilations: number[];\n}\n\nconst createMaxPoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: MaxPoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const op1 = `\n      value = max(x_val, value);\n    `;\n      const op2 = '';\n      const x = inputVariable('x', input.dataType, input.dims);\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '-1e5'),\n      };\n    };\n\nexport const maxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('MaxPool', context.inputs[0], false, attributes));\n};\n\nexport const parseMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const storageOrder = attributes.storage_order as number;\n  const dilations = attributes.dilations as [number, number];\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode' and 'storage_order'\n  if (storageOrder !== 0) {\n    throw new Error('column major storage order is not yet supported for MaxPool');\n  }\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for MaxPool');\n  }\n\n  return createAttributeWithCacheKey({storageOrder, dilations, ...attr});\n};\n\nexport const parseGlobalMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalMaxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('GlobalMaxPool', context.inputs[0], true, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {DataType} from '../../../wasm-common';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {outputVariable, ShaderHelper} from './common';\n\nconst validateInputsContent = (start: number, limit: number, delta: number): void => {\n  const sameStartLimit = start === limit;\n  const increasingRangeNegativeStep = start < limit && delta < 0;\n  const decreasingRangePositiveStep = start > limit && delta > 0;\n\n  if (sameStartLimit || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n    throw new Error('Range these inputs\\' contents are invalid.');\n  }\n};\n\nconst createRangeProgramInfo = (start: number, limit: number, delta: number, dataType: DataType): ProgramInfo => {\n  const numElements = Math.abs(Math.ceil((limit - start) / delta));\n  const outputShape: number[] = [numElements];\n  const outputSize = numElements;\n\n  const output = outputVariable('output', dataType, outputShape);\n  const wgslType = output.type.storage;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        output[global_idx] = ${wgslType}(${start}) + ${wgslType}(global_idx) * ${wgslType}(${delta});\n      }`;\n  return {\n    name: 'Range',\n    shaderCache: {hint: [start, limit, delta].map(x => x.toString()).join('_')},\n    getShaderSource,\n    getRunData: () => (\n        {outputs: [{dims: outputShape, dataType}],\n         dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}})\n  };\n};\n\nexport const range = (context: ComputeContext): void => {\n  let start = 0;\n  let limit = 0;\n  let delta = 0;\n  if (context.inputs[0].dataType === DataType.int32) {\n    start = context.inputs[0].getInt32Array()[0];\n    limit = context.inputs[1].getInt32Array()[0];\n    delta = context.inputs[2].getInt32Array()[0];\n  } else if (context.inputs[0].dataType === DataType.float) {\n    start = context.inputs[0].getFloat32Array()[0];\n    limit = context.inputs[1].getFloat32Array()[0];\n    delta = context.inputs[2].getFloat32Array()[0];\n  }\n  if (env.webgpu.validateInputContent) {\n    validateInputsContent(start, limit, delta);\n  }\n\n  context.compute(createRangeProgramInfo(start, limit, delta, context.inputs[0].dataType), {inputs: []});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype CoordinateTransformMode = 'half_pixel'|'asymmetric'|'pytorch_half_pixel'|'tf_half_pixel_for_nn'|'align_corners'|\n    'tf_crop_and_resize'|'half_pixel_symmetric';\n\ntype KeepAspectRatioPolicy = 'stretch'|'not_smaller'|'not_larger';\n\ntype Mode = 'nearest'|'linear'|'cubic';\n\ntype NearestMode = 'round_prefer_floor'|'round_prefer_ceil'|'floor'|'ceil'|'simple';\n\nexport interface ResizeAttributes extends AttributeWithCacheKey {\n  antialias: number;\n  axes: number[];\n  coordinateTransformMode: CoordinateTransformMode;\n  cubicCoeffA: number;\n  excludeOutside: boolean;\n  extrapolationValue: number;\n  keepAspectRatioPolicy: KeepAspectRatioPolicy;\n  mode: Mode;\n  nearestMode: NearestMode;\n}\n\nconst validateScales = (scales: number[], attributes: ResizeAttributes): void => {\n  scales.every((value) => value > 0 || (() => {\n                            throw new Error('Resize requires scales input values to be positive');\n                          }));\n  // Check scales dims based on mode: LINEAR, CUBIC\n  if (scales.length > 0) {\n    if (attributes.mode === 'linear') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for linear mode');\n      }\n    } else if (attributes.mode === 'cubic') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for cubic mode');\n      }\n    }\n  }\n};\n\nconst updateScales = (scales: readonly number[], axes: readonly number[], rank: number): number[] => {\n  axes.every((value) => value >= 0 && value < rank || (() => {\n                          throw new Error('Resize requires axes input values to be positive and less than rank');\n                        }));\n  const newScales = new Array(rank).fill(1.0);\n  axes.forEach((value, index) => newScales[value] = scales[index]);\n  return newScales;\n};\n\nconst validateInputs =\n    (inputs: readonly TensorView[], attributes: ResizeAttributes, opsetVersion: number, scales: number[],\n     sizes: number[], roi: number[]): void => {\n      const [roiInputIndex, scalesInputIndex, sizesInputIndex] =\n          (opsetVersion > 10) ? [1, 2, 3] : [-1, (inputs.length > 1) ? 1 : -1, -1];\n      const rank = inputs[0].dims.length;\n      if (roiInputIndex > 0 && inputs.length > roiInputIndex && inputs[roiInputIndex].dims.length > 0) {\n        inputs[roiInputIndex].getFloat32Array().forEach((value) => roi.push(value));\n\n      } else if (attributes.coordinateTransformMode === 'tf_crop_and_resize') {\n        throw new Error('Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize');\n      }\n\n      if (scalesInputIndex > 0 && inputs.length > scalesInputIndex && inputs[scalesInputIndex].dims.length > 0) {\n        inputs[scalesInputIndex].getFloat32Array().forEach((value) => scales.push(value));\n        if (scales.length !== 0 &&\n            (scales.length !== rank && (opsetVersion >= 18 && scales.length !== attributes.axes.length))) {\n          throw new Error(\n              'Resize requires scales input size to be same as input rank or axes size for opset 18 and up');\n        }\n        validateScales(scales, attributes);\n        if (attributes.axes.length > 0) {\n          updateScales(scales, attributes.axes, rank).forEach((value, index) => scales[index] = value);\n        }\n      }\n      if (sizesInputIndex > 0 && inputs.length > sizesInputIndex) {\n        inputs[sizesInputIndex].getBigInt64Array().forEach((value) => sizes.push(Number(value)));\n        if (sizes.length !== rank || (opsetVersion >= 18 && sizes.length === attributes.axes.length)) {\n          throw new Error('Resize requires sizes input size to be same as input rank or axes size for opset 18 and up');\n        }\n      }\n\n      if (attributes.axes.length > 0) {\n        if (scales.length !== attributes.axes.length) {\n          throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');\n        }\n        if (sizes.length !== attributes.axes.length) {\n          throw new Error(\n              'Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified');\n        }\n      }\n      if (typeof scales !== 'undefined' && typeof sizes !== 'undefined' && scales.length > 0 && sizes.length > rank) {\n        throw new Error('Resize requires only of scales or sizes to be specified');\n      }\n    };\n\nconst getOriginalCoordinateFromResizedCoordinate =\n    (coordinateTransferMode: CoordinateTransformMode, dType: string): string =>\n        `fn getOriginalCoordinateFromResizedCoordinate(xResized: ${dType}, xScale: ${dType}, lengthResized: ${dType},\n     lengthOriginal: ${dType}, roiStart: ${dType}, roiEnd: ${dType}) -> ${dType} { ` +\n    (() => {\n          switch (coordinateTransferMode) {\n            case 'asymmetric':\n              return 'return xResized / xScale;';\n            case 'pytorch_half_pixel':\n              return 'if (lengthResized > 1) { \\\n                    return (xResized + 0.5) / xScale - 0.5; \\\n                  } else { \\\n                    return 0.0; \\\n                  }';\n            case 'tf_half_pixel_for_nn':\n              return 'return (xResized + 0.5) / xScale;';\n            case 'align_corners':\n              return 'if (lengthResized == 1) { \\\n                    return 0.0; \\\n                  } else { \\\n                    return xResized * (lengthOriginal - 1) / (lengthResized - 1); \\\n                  }';\n            case 'tf_crop_and_resize':\n              return `if (lengthResized > 1) { \\\n                    return roiStart * (lengthOriginal - 1) + \\\n                          (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1); \\\n                  } else { \\\n                    return 0.5 * (roiStart + roiEnd) * ${dType}(lengthOriginal - 1); \\\n                  }`;\n            case 'half_pixel_symmetric':\n              return [\n                'const outputWidth = xScale * lengthResized;', 'const adjustment = lengthResized / outputWidth;',\n                'const center = lengthOriginal / 2;', 'const offset = center * (1 - adjustment);',\n                'return offset + ((xResized + 0.5) / xScale) - 0.5;'\n              ].join('\\n');\n            case 'half_pixel':\n              return 'return ((xResized + 0.5) / xScale) - 0.5;';\n            default:\n              throw new Error(`Coordinate transform mode ${coordinateTransferMode} is not supported`);\n          }\n        })() +\n    '}';\n\nconst getNearestPixelFromOriginal = (nearestMode: NearestMode, opsetVersion: number, dType: string): string =>\n    `fn getNearestPixelFromOriginal(xOriginal: ${dType}, isDownSample: bool) -> ${dType} {` + (() => {\n      switch (nearestMode) {\n        case 'round_prefer_ceil':\n          return 'if (fract(xOriginal) == 0.5) { \\\n            return ceil(xOriginal); \\\n          } else { \\\n            return round(xOriginal); \\\n          }';\n        case 'floor':\n          return 'return floor(xOriginal);';\n        case 'ceil':\n          return 'return ceil(xOriginal);';\n        case 'round_prefer_floor':\n          return 'if (fract(xOriginal) == 0.5) { \\\n                    return floor(xOriginal); \\\n                  } else { \\\n                    return round(xOriginal); \\\n                  }';\n        case 'simple':\n        default:\n          if (opsetVersion < 11) {\n            return 'if (isDownSample) \\\n                    { \\\n                      return ceil(xOriginal); \\\n                    } else { \\\n                      return xOriginal; \\\n                    }';\n          }\n          throw new Error(`Nearest mode ${nearestMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst updateRoI = (roi: readonly number[], axes: readonly number[], rank: number): number[] => {\n  const roiTmp = new Array(rank).fill(0).concat(new Array(rank).fill(1));\n  const roiLocal = roi.length === 0 ? roiTmp : roi.slice();\n  if (axes.length > 0) {\n    axes.forEach((v, i) => {\n      roiTmp[v] = roiLocal[i];\n      roiTmp[i + rank] = roiLocal[axes.length + i];\n    });\n    return roiTmp;\n  }\n  return roiLocal;\n};\n\nconst initOutputShape =\n    (inputShape: readonly number[], scales: readonly number[], sizes: readonly number[], axes: readonly number[]):\n        number[] => {\n          let outputShape: number[] = [];\n          if (sizes.length > 0) {\n            if (axes.length > 0) {\n              inputShape.forEach((v) => outputShape.push(v));\n              if (Math.max(...axes) > inputShape.length) {\n                throw new Error('axes is out of bound');\n              }\n              axes.forEach((v, i) => outputShape[v] = sizes[i]);\n            } else {\n              sizes.forEach((v) => outputShape.push(v));\n            }\n          } else {\n            if (scales.length === 0) {\n              throw new Error('Resize requires either scales or sizes.');\n            } else {\n              outputShape = inputShape.map((value, index) => Math.round(value * scales[index]));\n            }\n          }\n          return outputShape;\n        };\n\nconst adjustOutputShape = (inputShape: readonly number[], scales: number[], attributes: ResizeAttributes): number[] => {\n  const scaleInPolicy = (() => {\n    switch (attributes.keepAspectRatioPolicy) {\n      case 'not_larger':\n        return attributes.axes.length > 0 ? Math.min(...attributes.axes.map(i => scales[i]), Number.MAX_VALUE) :\n                                            Math.min(...scales, Number.MAX_VALUE);\n      case 'not_smaller':\n        return attributes.axes.length > 0 ? Math.max(...attributes.axes.map(i => scales[i]), Number.MIN_VALUE) :\n                                            Math.max(...scales, Number.MIN_VALUE);\n      default:\n        throw new Error(`Keep aspect ratio policy ${attributes.keepAspectRatioPolicy} is not supported`);\n    }\n  })();\n  scales.fill(1.0, 0, scales.length);\n  const adjustedOutputShape = inputShape.slice();\n  if (attributes.axes.length > 0) {\n    attributes.axes.forEach((v) => scales[v] = scaleInPolicy);\n    attributes.axes.forEach((v) => adjustedOutputShape[v] = Math.round(inputShape[v] * scales[v]));\n  } else {\n    scales.fill(scaleInPolicy, 0, scales.length);\n    adjustedOutputShape.forEach((v, i) => adjustedOutputShape[i] = Math.round(v * scales[i]));\n  }\n  return adjustedOutputShape;\n};\n\nconst calculateOriginalIndicesFromOutputIndices =\n    (output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[], scales: readonly number[],\n     roi: readonly number[]): string => `\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> array<${\n        output.type.value}, ${outputShape.length}> {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n      const scales = array<${output.type.value}, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n      const roi = array<${output.type.value}, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n      var originalIndices: array<${output.type.value}, ${outputShape.length}>;\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = ${output.type.value}(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(${output.type.value}(outputIndex), scales[i],\n                ${output.type.value}(outputShape[i]), ${output.type.value}(inputShape[i]), roi[i], roi[i + ${\n        inputShape.length}]);\n        }\n      }\n      return originalIndices;\n    }`;\n\nconst calculateInputIndicesFromOutputIndices =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], useExtrapolation: boolean): string => `\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n        const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n        const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n        const scales = array<${input.type.value}, ${scales.length}>(${scales.map(i => `${i}`).join(',')});\n        const roi = array<${input.type.value}, ${roi.length}>(${roi.map(i => `${i}`).join(',')});\n        var inputIndices: ${input.type.indices};\n        for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n          var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(${input.type.value}(outputIndex), scales[i],\n                    ${input.type.value}(outputShape[i]), ${input.type.value}(inputShape[i]), roi[i], roi[i + ${\n        inputShape.length}]);\n            if (!${useExtrapolation} || (original_idx >= 0 && original_idx < ${input.type.value}(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (${input.type.value}(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${input.indicesSet('inputIndices', 'i', 'inputIndex')}\n        }\n        return inputIndices;\n    }`;\n\nconst checkInputIndices = (input: IndicesHelper, inputShape: readonly number[]): string => `\n    fn checkInputIndices(inputIndices: ${input.type.indices}) -> bool {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      for (var i:u32 = 0; i < ${inputShape.length}; i++) {\n        var inputIndex = ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`;\n\nconst bilinearInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], scales: readonly number[],\n     useExtrapolation: boolean, extrapolationValue: number): string => {\n      const [batchIdx, heightIdx, widthIdx, channelIdx] =\n          inputShape.length === 2 ? [-1, 0, 1, -1] : (scales[1] === 1.0 ? [0, 2, 3, 1] : [0, 1, 2, 3]);\n      const dType = input.type.value;\n      return `\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${dType} {\n      var inputIndices: ${input.type.indices};\n      inputIndices[${heightIdx}] = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      inputIndices[${widthIdx}] = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      if (${inputShape.length} > 2) {\n        inputIndices[${channelIdx}] = channel;\n        inputIndices[${batchIdx}] = batch;\n      };\n      return input[${input.indicesToOffset('inputIndices')}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${output.type.indices}) -> ${dType} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:${dType} = originalIndices[${heightIdx}];\n      var col:${dType} = originalIndices[${widthIdx}];\n      if (${useExtrapolation} && (row < 0 || row > (${inputShape[heightIdx]} - 1) || col < 0 || col > ${\n          inputShape[widthIdx]} - 1)) {\n        return ${extrapolationValue};\n      }\n      row = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      col = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${inputShape.length > 2}) {\n        channel = u32(originalIndices[${channelIdx}]);\n        batch = u32(originalIndices[${batchIdx}]);\n      }\n      var x11: ${dType} = getInputValue(batch, channel, row1, col1);\n      var x12: ${dType} = getInputValue(batch, channel, row1, col2);\n      var x21: ${dType} = getInputValue(batch, channel, row2, col1);\n      var x22: ${dType} = getInputValue(batch, channel, row2, col2);\n      var dx1: ${dType} = row - ${dType}(row1);\n      var dx2: ${dType} = ${dType}(row2) - row;\n      var dy1 = col - ${dType}(col1);\n      var dy2 = ${dType}(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`;\n    };\n\nconst bicubicInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], cubicCoeffA: number, useExtrapolation: boolean,\n     extrapolationValue: number, excludeOutside: boolean): string => {\n      const [heightIdx, widthIdx] = inputShape.length === 2 ? [0, 1] : (scales[1] === 1.0) ? [2, 3] : [1, 2];\n      const dType = input.type.value;\n      const createCubicInterpolationFunction = (idx: number): string => {\n        const direction = idx === heightIdx ? 'row' : 'col';\n        return `\n      fn ${direction}CubicInterpolation(inputIndices: ${input.type.indices}, outputIndices: ${\n            output.type.indices}) -> ${dType} {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : `outputIndices[${idx}]`};\n        var originalIdx: ${dType} = getOriginalCoordinateFromResizedCoordinate(${dType}(outputIndex), ${scales[idx]},\n        ${dType}(${outputShape[idx]}), ${dType}(${inputShape[idx]}), ${roi[idx]}, ${roi[idx]} + ${inputShape.length});\n        var fractOriginalIdx: ${dType} = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${useExtrapolation} && (originalIdx < 0 || originalIdx > (${inputShape[idx]} - 1))) {\n          return ${extrapolationValue};\n        }\n        var data: array<${dType}, 4> = array<${dType}, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${direction}: ${dType} = originalIdx + ${dType}(i);\n          if (${direction} < 0 || ${direction} >= ${inputShape[idx]}) {\n            if (${excludeOutside}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${useExtrapolation}) {\n              return ${extrapolationValue};\n            } else {\n              ${direction} = max(0, min(${direction}, ${inputShape[idx]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${input.type.indices} = inputIndices;\n          inputIndicesCopy[${idx}] = u32(${direction});\n          data[i + 1] = ${idx === heightIdx ? `input[${input.indicesToOffset('inputIndicesCopy')}];` : `\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`;\n      };\n\n      return `\n    ${createCubicInterpolationFunction(heightIdx)};\n    ${createCubicInterpolationFunction(widthIdx)};\n  fn getCubicInterpolationCoefs(s: ${dType}) -> array<${dType}, 4> {\n    var absS = abs(s);\n    var coeffs: array<${dType}, 4> = array<${dType}, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: ${dType} = 1.0 - absS;\n    var twoMinusAbsS: ${dType} = 2.0 - absS;\n    var onePlusAbsS: ${dType} = 1.0 + absS;\n    coeffs[0] = ((${cubicCoeffA} * onePlusAbsS - 5 * ${cubicCoeffA}) * onePlusAbsS + 8 * ${\n          cubicCoeffA}) * onePlusAbsS - 4 * ${cubicCoeffA};\n    coeffs[1] = ((${cubicCoeffA} + 2) * absS - (${cubicCoeffA} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${cubicCoeffA} + 2) * oneMinusAbsS - (${cubicCoeffA} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${cubicCoeffA} * twoMinusAbsS - 5 * ${cubicCoeffA}) * twoMinusAbsS + 8 * ${\n          cubicCoeffA}) * twoMinusAbsS - 4 * ${cubicCoeffA};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<${dType}, 4>, coefs: array<${dType}, 4>) -> ${dType} {\n    var coefsSum: ${dType} = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${output.type.indices}) -> ${dType} {\n    var inputIndices: ${input.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `;\n    };\n\nconst createResizeProgramInfo =\n    (inputTensor: TensorView, attributes: ResizeAttributes, opsetVersion: number, scalesInput: readonly number[],\n     sizes: readonly number[], roiInput: readonly number[]): ProgramInfo => {\n      const inputShape = inputTensor.dims;\n      const roi = updateRoI(roiInput, attributes.axes, inputShape.length);\n\n      let outputShape = initOutputShape(inputShape, scalesInput, sizes, attributes.axes);\n      let scales = scalesInput.slice();\n      if (scalesInput.length === 0) {\n        scales = inputShape.map((value, index) => value === 0 ? 1.0 : outputShape[index] / value);\n        if (attributes.keepAspectRatioPolicy !== 'stretch') {\n          outputShape = adjustOutputShape(inputShape, scales, attributes);\n        }\n      }\n      const output = outputVariable('output', inputTensor.dataType, outputShape);\n      const input = inputVariable('input', inputTensor.dataType, inputShape);\n      const outputSize = ShapeUtil.size(outputShape);\n      const noScale = inputShape.length === outputShape.length && inputShape.every((d, i) => d === outputShape[i]);\n      const useExtrapolation = attributes.coordinateTransformMode === 'tf_crop_and_resize';\n      const dataType = input.type.value;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${noScale ? '' : `\n      ${getOriginalCoordinateFromResizedCoordinate(attributes.coordinateTransformMode, dataType)};\n      ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `\n              ${checkInputIndices(input, inputShape)};\n              ${getNearestPixelFromOriginal(attributes.nearestMode, opsetVersion, dataType)};\n              ${\n                calculateInputIndicesFromOutputIndices(\n                    input, output, inputShape, outputShape, scales, roi, useExtrapolation)};\n              `;\n          case 'linear':\n            return `\n              ${calculateOriginalIndicesFromOutputIndices(output, inputShape, outputShape, scales, roi)};\n              ${\n                bilinearInterpolation(\n                    input, output, inputShape, scales, useExtrapolation, attributes.extrapolationValue)};\n              `;\n          case 'cubic':\n            return `\n            ${\n                bicubicInterpolation(\n                    input, output, inputShape, outputShape, scales, roi, attributes.cubicCoeffA, useExtrapolation,\n                    attributes.extrapolationValue, attributes.excludeOutside)};\n            `;\n          default:\n            throw Error('Invalid resize mode');\n        }\n      })()};\n      `}\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        ${noScale ? 'output[global_idx] = input[global_idx];' : `\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        var inputIndices: ${input.type.indices};\n        ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                if (checkInputIndices(inputIndices)) {\n                  output[global_idx] = input[${input.indicesToOffset('inputIndices')}];\n                } else {\n                  output[global_idx] = ${attributes.extrapolationValue};\n                }`;\n          case 'linear':\n            return 'output[global_idx] = bilinearInterpolation(outputIndices);';\n          case 'cubic':\n            return 'output[global_idx] = bicubicInterpolation(outputIndices);';\n          default:\n            throw Error(`Unsupported resize mode: ${attributes.mode}`);\n        }\n      })()};\n        `}\n      }`;\n\n      return {\n        name: 'Resize',\n        shaderCache: {\n          hint: `${attributes.cacheKey}|${opsetVersion}|${scales.length > 0 ? scales : ''}|${\n              sizes.length > 0 ? sizes : ''}|${noScale}`\n        },\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputTensor.dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        })\n      };\n    };\n\nconst getOpsetVersionFromCustomDataBuffer = (context: ComputeContext): number => {\n  const customDataBuffer = context.customDataBuffer;\n  const customDataBuffer32 = new Uint32Array(customDataBuffer, customDataBuffer.byteOffset, 1);\n  const opsetVersion = customDataBuffer32[0];\n  return opsetVersion;\n};\n\nexport const resize = (context: ComputeContext, attributes: ResizeAttributes): void => {\n  const scales: number[] = [];\n  const sizes: number[] = [];\n  const roi: number[] = [];\n  const opsetVersion = getOpsetVersionFromCustomDataBuffer(context);\n  validateInputs(context.inputs, attributes, opsetVersion, scales, sizes, roi);\n  context.compute(\n      createResizeProgramInfo(context.inputs[0], attributes, opsetVersion, scales, sizes, roi), {inputs: [0]});\n};\n\nexport const parseResizeAttributes = (attributes: Record<string, unknown>): ResizeAttributes => {\n  const antialias = attributes.antialias as number;\n  const axes = attributes.axes as number[];\n  const coordinateTransformMode: CoordinateTransformMode =\n      attributes.coordinateTransformMode as CoordinateTransformMode;\n  const cubicCoeffA = attributes.cubicCoeffA as number;\n  const excludeOutside = attributes.excludeOutside as number !== 0;\n  const extrapolationValue = attributes.extrapolationValue as number;\n  const keepAspectRatioPolicy: KeepAspectRatioPolicy = attributes.keepAspectRatioPolicy as KeepAspectRatioPolicy;\n  const mode: Mode = attributes.mode as Mode;\n  // If nearestMode is not specified, use simple mode.\n  const nearestMode: NearestMode = (attributes.nearestMode === '' ? 'simple' : attributes.nearestMode) as NearestMode;\n  return createAttributeWithCacheKey({\n    antialias,\n    axes,\n    coordinateTransformMode,\n    cubicCoeffA,\n    excludeOutside,\n    extrapolationValue,\n    keepAspectRatioPolicy,\n    mode,\n    nearestMode\n  });\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface SkipLayerNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 3) {\n    throw new Error('layerNorm requires at least 3 inputs.');\n  }\n\n  const input: TensorView = inputs[0];\n  const skip: TensorView = inputs[1];\n  const gamma: TensorView = inputs[2];\n\n  if (input.dataType !== skip.dataType || input.dataType !== gamma.dataType) {\n    throw new Error('All inputs must have the same data type');\n  }\n\n  if (input.dims.length !== 3 && input.dims.length !== 2) {\n    throw new Error('Input must be 2D or 3D');\n  }\n\n  if (skip.dims.length !== 3 && skip.dims.length !== 2) {\n    throw new Error('Skip must be 2D or 3D');\n  }\n\n  const hiddenSize = input.dims[input.dims.length - 1];\n  const sequenceLength = input.dims[input.dims.length - 2];\n  if (skip.dims[skip.dims.length - 1] !== hiddenSize) {\n    throw new Error('Skip must have the same hidden size as input');\n  }\n  if (skip.dims[skip.dims.length - 2] !== sequenceLength) {\n    throw new Error('Skip must have the same sequence length as input');\n  }\n\n  if (gamma.dims.length !== 1) {\n    throw new Error('Gamma must be 1D');\n  }\n  if (gamma.dims[gamma.dims.length - 1] !== hiddenSize) {\n    throw new Error('Gamma must have the same hidden size as input');\n  }\n  if (inputs.length > 3) {\n    const beta: TensorView = inputs[3];\n    if (beta.dims.length !== 1) {\n      throw new Error('Beta must be 1D');\n    }\n    if (beta.dims[beta.dims.length - 1] !== hiddenSize) {\n      throw new Error('Beta must have the same hidden size as input');\n    }\n  }\n\n  if (inputs.length > 4) {\n    const bias: TensorView = inputs[4];\n    if (bias.dims.length !== 1) {\n      throw new Error('Bias must be 1D');\n    }\n    if (bias.dims[bias.dims.length - 1] !== hiddenSize) {\n      throw new Error('Bias must have the same hidden size as input');\n    }\n  }\n};\n\nconst createSkipLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: SkipLayerNormAttributes, outputCount: number, isTraining: boolean):\n        ProgramInfo => {\n          const inputShape = inputs[0].dims;\n          const inputSize = ShapeUtil.size(inputShape);\n          const outputShape = inputShape;\n          const outputSize = inputSize;\n          const hiddenSize = inputShape.slice(-1)[0];\n          const meanInvStdDevDim = isTraining ? inputShape.slice(0, -1).concat(1) : [];\n          const hasBetaInput = inputs.length > 3;\n          const hasBiasInput = inputs.length > 4;\n          const hasMeanOutput = isTraining && outputCount > 1;\n          const hasInvStdDevOutput = isTraining && outputCount > 2;\n          const hasInputSkipBiasSumOutput = outputCount > 3;\n\n          const components = getMaxComponents(hiddenSize);\n          const variables = [\n            inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n            inputVariable('skip', inputs[1].dataType, inputs[1].dims, components),\n            inputVariable('gamma', inputs[2].dataType, inputs[2].dims, components),\n          ];\n          if (hasBetaInput) {\n            variables.push(inputVariable('beta', inputs[3].dataType, inputs[3].dims, components));\n          }\n          if (hasBiasInput) {\n            variables.push(inputVariable('bias', inputs[4].dataType, inputs[4].dims, components));\n          }\n          variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n          if (hasMeanOutput) {\n            variables.push(outputVariable('meanOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInvStdDevOutput) {\n            variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInputSkipBiasSumOutput) {\n            variables.push(outputVariable('inputSkipBiasSum', inputs[0].dataType, outputShape, components));\n          }\n          const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n          const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const hiddenSize: f32 = ${hiddenSize};\n      const hiddenSizeVectorized: u32 = ${hiddenSize / components};\n      const epsilon: f32 = ${attributes.epsilon};\n\n      ${shaderHelper.declareVariables(...variables)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize / hiddenSize)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${fillVector('f32', components)};\n        var squareSum = ${fillVector('f32', components)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${hasBiasInput ? 'bias[i]' : '0.0'};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${hasInputSkipBiasSumOutput ? 'inputSkipBiasSum[offset + i] = value;' : ''}\n          output[offset + i] = value;\n          let f32Value = ${castToF32(dataType, components, 'value')};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${sumVector('sum', components)} / hiddenSize;\n        let variance = sqrt(${sumVector('squareSum', components)} / hiddenSize - mean * mean + epsilon);\n        ${hasMeanOutput ? 'meanOutput[global_idx] = mean;' : ''}\n        ${hasInvStdDevOutput ? 'invStdOutput[global_idx] = 1.0 / variance;' : ''}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${dataType}(mean)) / ${dataType}(variance) * gamma[i]\n           + ${hasBetaInput ? 'beta[i]' : '0.0'};\n        }\n      }`;\n          const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n          if (outputCount > 1) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 2) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 3) {\n            outputs.push({dims: inputShape, dataType: inputs[0].dataType});\n          }\n\n          return {\n            name: 'SkipLayerNormalization',\n            shaderCache: {hint: attributes.cacheKey},\n            getShaderSource,\n            getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(outputSize / hiddenSize / 64)}}),\n          };\n        };\n\nexport const skipLayerNorm = (context: ComputeContext, attributes: SkipLayerNormAttributes): void => {\n  // TODO: initialize isTraining from ComputeContext\n  const isTraining = false;\n  validateInputs(context.inputs);\n  // Mean and InvStdDev are only used in training mode and are not required for inference.\n  // They are added here for completeness only.\n  const outputs = [0];\n  if (context.outputCount > 1) {\n    outputs.push(isTraining ? 1 : -3);\n  }\n  if (context.outputCount > 2) {\n    outputs.push(isTraining ? 2 : -3);\n  }\n  if (context.outputCount > 3) {\n    outputs.push(3);\n  }\n  context.compute(\n      createSkipLayerNormProgramInfo(context.inputs, attributes, context.outputCount, isTraining), {outputs});\n};\n\nexport const parseSkipLayerNormAttributes = (attributes: Record<string, unknown>): SkipLayerNormAttributes => {\n  const epsilon = attributes.epsilon as number;\n  return createAttributeWithCacheKey({epsilon});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramUniform, TensorInfo} from '../types';\n\nimport {createTensorShapeVariables, getElementAt, IndicesHelper, inputVariable, outputVariable, ShaderHelper, UniformsArrayType} from './common';\n\nexport interface SliceAttributes extends AttributeWithCacheKey {\n  readonly starts: number[];\n  readonly ends: number[];\n  readonly axes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: SliceAttributes): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n  if (attributes.axes.length !== 0) {\n    if (attributes.axes.length !== attributes.starts.length || attributes.axes.length !== attributes.ends.length) {\n      throw new Error('axes, starts and ends must have the same length');\n    }\n  } else if (attributes.starts.length !== attributes.ends.length) {\n    throw new Error('starts and ends must have the same length');\n  }\n  inputs.slice(1).forEach((_, idx) => {\n    if (inputs[idx + 1].dataType !== DataType.int32 && inputs[idx + 1].dataType !== DataType.int64) {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  });\n};\n\nconst readInput = (inputs: readonly TensorView[], idx: number): number[] => {\n  const input: number[] = [];\n  if (inputs.length > idx) {\n    if (inputs[idx].dataType === DataType.int64) {\n      inputs[idx].getBigInt64Array().forEach(v => input.push(Number(v)));\n    } else if (inputs[idx].dataType === DataType.int32) {\n      inputs[idx].getInt32Array().forEach(v => input.push(Number(v)));\n    } else {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  }\n  return input;\n};\n\nconst createSliceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SliceAttributes): SliceAttributes => {\n      if (inputs.length > 1) {\n        const starts: number[] = readInput(inputs, 1);\n        const ends: number[] = readInput(inputs, 2);\n        let axes: number[] = readInput(inputs, 3);\n        if (axes.length === 0) {\n          axes = [...Array(inputs[0].dims.length).keys()];\n        }\n        return createAttributeWithCacheKey({starts, ends, axes});\n      } else {\n        return attributes;\n      }\n    };\n\nconst fixStartEndValues =\n    (value: number, index: number, inputShape: readonly number[], axes: readonly number[], steps: readonly number[]):\n        number => {\n          let newValue = value;\n          if (value < 0) {\n            newValue += inputShape[axes[index]];\n          }\n          if (steps[index] < 0) {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]] - 1));\n          } else {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]]));\n          }\n        };\n\nconst calculateInputIndicesImpl =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[]):\n        string => `fn calculateInputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n          var inputIndices: ${input.type.indices};\n          var carry = 0u;\n          for (var i = ${inputShape.length}; i >= 0; i--) {\n            let input_shape_i = ${getElementAt('uniforms.input_shape', 'i', inputShape.length)};\n            let steps_i = ${getElementAt('uniforms.steps', 'i', inputShape.length)};\n            let signs_i = ${getElementAt('uniforms.signs', 'i', inputShape.length)};\n            let starts_i = ${getElementAt('uniforms.starts', 'i', inputShape.length)};\n            var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n            var inputIndex = outputIndex * steps_i + starts_i + carry;\n            carry = inputIndex / input_shape_i;\n            inputIndex = inputIndex % input_shape_i;\n            if (signs_i < 0) {\n              inputIndex = input_shape_i - inputIndex - 1u + starts_i;\n            }\n            ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'} = inputIndex;\n          }\n          return inputIndices;\n      }`;\n\nconst createSliceProgramInfo = (inputs: readonly TensorView[], attributes: SliceAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const axes = (attributes.axes.length > 0) ? ShapeUtil.normalizeAxes(attributes.axes, inputShape.length) :\n                                              [...Array(inputShape.length).keys()];\n  let steps = readInput(inputs, 4);\n  steps.forEach((step) => step !== 0 || (() => {\n                            throw new Error('step cannot be 0');\n                          }));\n  if (steps.length === 0) {\n    steps = Array(axes.length).fill(1);\n  }\n  const starts = attributes.starts.map((start, i) => fixStartEndValues(start, i, inputShape, axes, steps));\n\n  const ends = attributes.ends.map((end, i) => fixStartEndValues(end, i, inputShape, axes, steps));\n\n  if (axes.length !== starts.length || axes.length !== ends.length) {\n    throw new Error('start, ends and axes should have the same number of elements');\n  }\n\n  if (axes.length !== inputShape.length) {\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (!axes.includes(i)) {\n        starts.splice(i, 0, 0);\n        ends.splice(i, 0, inputShape[i]);\n        steps.splice(i, 0, 1);\n      }\n    }\n  }\n  const signs = steps.map(step => Math.sign(step));\n  // Convert negative steps to positive steps and reverse starts and ends\n  steps.forEach((step, i, array) => {\n    if (step < 0) {\n      const numSteps = (ends[i] - starts[i]) / step;\n      const newEnd = starts[i];\n      const newStart = newEnd + numSteps * steps[i];\n      starts[i] = newStart;\n      ends[i] = newEnd;\n      array[i] = -step;\n    }\n  });\n  // Output rank is expected to be less than or equal to the input rank.\n  const outputShape = inputShape.slice(0);\n  axes.forEach((axis, _) => {\n    outputShape[axis] = Math.ceil((ends[axis] - starts[axis]) / steps[axis]);\n  });\n  const outputTensorInfo: TensorInfo = {dims: outputShape, dataType: inputs[0].dataType};\n\n  const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims.length);\n  const outputSize = ShapeUtil.size(outputShape);\n  const uniforms: UniformsArrayType = [\n    {name: 'outputSize', type: 'u32'}, {name: 'starts', type: 'u32', length: starts.length},\n    {name: 'signs', type: 'i32', length: signs.length}, {name: 'steps', type: 'u32', length: steps.length}\n  ];\n\n  const programUniforms: ProgramUniform[] = [\n    {type: 'uint32', data: outputSize}, {type: 'uint32', data: starts}, {type: 'int32', data: signs},\n    {type: 'uint32', data: steps}, ...createTensorShapeVariables(inputs[0].dims),\n    ...createTensorShapeVariables(outputShape)\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.registerUniforms(uniforms).declareVariables(input, output)}\n        ${calculateInputIndicesImpl(input, output, inputShape, outputShape)}\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n      }`;\n  return {\n    name: 'Slice',\n    shaderCache: {hint: `${signs.length}_${starts.length}_${steps.length}`, inputDependencies: ['rank']},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [outputTensorInfo],\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n      programUniforms\n    })\n  };\n};\n\nexport const slice = (context: ComputeContext, attributes: SliceAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  const updatedAttributes = createSliceAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSliceProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n  // if (ShapeUtil.size(program.outputs[0].dims) > 0) {\n  //   context.compute(programInfoLoader, {inputs: [0]});\n  // } else {\n  //   // TODO: support empty output\n  //   throw new Error('slice: output size is 0');\n  // }\n};\n\nexport const parseSliceAttributes = (attributes: Record<string, unknown>): SliceAttributes => {\n  const starts = attributes.starts as number[];\n  const ends = attributes.ends as number[];\n  const axes = attributes.axes as number[];\n  return createAttributeWithCacheKey({starts, ends, axes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Softmax op requires 1 input.');\n  }\n};\n\nexport interface SoftmaxAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst createSoftmaxProgramInfo = (input: TensorView, attributes: SoftmaxAttributes): ProgramInfo => {\n  const shape = input.dims;\n  const outputSize = ShapeUtil.size(shape);\n  const WG = 64;\n  let axis = attributes.axis;\n  if (axis < 0) {\n    axis = shape.length + axis;\n  }\n  if (axis < shape.length - 1) {\n    throw new Error('softmax only supports last axis for now.');\n  }\n\n  const cols = shape[axis];\n  const rows = outputSize / cols;\n  const components = getMaxComponents(cols);\n  const packedCols = cols / components;\n\n  const maxVector = (name: string, components: number) => {\n    if (components === 4) {\n      return `max(max(${name}.x, ${name}.y), max(${name}.z, ${name}.w))`;\n    } else if (components === 2) {\n      return `max(${name}.x, ${name}.y)`;\n    } else if (components === 3) {\n      return `max(max(${name}.x, ${name}.y), ${name}.z)`;\n    }\n\n    return name;\n  };\n  const x = inputVariable('x', input.dataType, input.dims, components);\n  const output = outputVariable('result', input.dataType, input.dims, components);\n  const valueType = x.type.value;\n  // 6.2.4 in wgsl spec\n  const threadMaxDecl = tensorTypeToWsglStorageType(input.dataType) === 'f32' ?\n      `var threadMax = ${valueType}(-3.402823e+38f);` :\n      `var threadMax = ${valueType}(-65504.0h);`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      var<workgroup> rowMaxShared : ${valueType};\n      var<workgroup> rowSumShared : ${valueType};\n      var<workgroup> threadShared : array<${valueType}, ${WG}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${valueType} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${valueType}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${shaderHelper.registerUniform('packedCols', 'i32').declareVariables(x, output)}\n      ${shaderHelper.mainStart()}\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${WG};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${threadMaxDecl}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${valueType}(${maxVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${valueType}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${valueType}(${sumVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;\n  return {\n    name: 'Softmax',\n    shaderCache: {hint: `${components}`, inputDependencies: ['type']},\n    getRunData: () => ({\n      outputs: [{dims: shape, dataType: input.dataType}],\n      dispatchGroup: {x: rows},\n      programUniforms: [{type: 'uint32', data: packedCols}]\n    }),\n    getShaderSource,\n  };\n};\n\nexport const softmax = (context: ComputeContext, attributes: SoftmaxAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createSoftmaxProgramInfo(context.inputs[0], attributes));\n};\n\nexport const parseSoftmaxAttributes = (attributes: Record<string, unknown>): SoftmaxAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, TensorInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SplitAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n  readonly numOutputs: number;\n  readonly splitSizes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n};\n\nconst createSplitAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SplitAttributes): SplitAttributes => {\n      const splitSizes: number[] = [];\n      let numOutputs: number = attributes.numOutputs;\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => splitSizes.push(Number(v)));\n        numOutputs = splitSizes.length;\n      }\n      return createAttributeWithCacheKey({numOutputs, axis: attributes.axis, splitSizes});\n    };\n\nconst calculateOutputIndexImpl = (numberOfTensors: number): string => `\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${numberOfTensors}u;\n}`;\nconst writeBufferDataImpl = (outputs: readonly IndicesHelper[]) => {\n  const numberOfTensors = outputs.length;\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = outputs[i].setByIndices('indices', 'input[global_idx]');\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (outputNumber == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (outputNumber == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return `\n      fn writeBufferData(outputNumber: u32, indices: ${outputs[0].type.indices}, global_idx: u32) {\n        ${codeLines.join('\\n')}\n      }`;\n};\n\nconst createSplitProgramInfo = (inputs: readonly TensorView[], attributes: SplitAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const dataType = inputs[0].dataType;\n  const rank = inputShape.length;\n  const axis = attributes.axis;\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  const outputs = new Array<IndicesHelper>(attributes.numOutputs);\n  const input = inputVariable('input', dataType, inputShape);\n  const sizeInConcatAxis = new Array<number>(attributes.numOutputs);\n  const outputsTensorInfo: TensorInfo[] = [];\n  const outputShapes: number[][] = [];\n  let previousSum = 0;\n  for (let i = 0; i < attributes.numOutputs; i++) {\n    previousSum += attributes.splitSizes[i];\n    sizeInConcatAxis[i] = previousSum;\n    const outputShape = inputShape.slice();\n    outputShape[attributes.axis] = attributes.splitSizes[i];\n    outputShapes.push(outputShape);\n    outputs[i] = outputVariable(`output${i}`, dataType, outputShapes[i]);\n    outputsTensorInfo.push({dims: outputShapes[i], dataType: inputs[0].dataType});\n  }\n  const indicesAxis = rank < 2 ? 'indices' : `indices[${adjustedAxis}]`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.declareVariables(input, ...outputs)}\n  const sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}>(${sizeInConcatAxis.map(i => `${i}u`).join(',')});\n  ${calculateOutputIndexImpl(sizeInConcatAxis.length)}\n  ${writeBufferDataImpl(outputs)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(inputSize)}\n\n    var indices = ${input.offsetToIndices('global_idx')};\n    let outputNumber = calculateOutputIndex(${indicesAxis});\n    if (outputNumber != 0) {\n        ${indicesAxis} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;\n  return {\n    name: 'Split',\n    shaderCache: {hint: attributes.cacheKey},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: outputsTensorInfo,\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n    })\n  };\n};\n\nexport const split = (context: ComputeContext, attributes: SplitAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes =\n      context.inputs.length === 1 ? attributes : createSplitAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSplitProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parseSplitAttributes = (attributes: Record<string, unknown>): SplitAttributes => {\n  const axis = attributes.axis as number;\n  const splitSizes: number[] = attributes.splitSizes as number[];\n  const numOutputs = attributes.numOutputs as number < 0 ? splitSizes.length : attributes.numOutputs as number;\n  if (numOutputs !== splitSizes.length) {\n    throw new Error('numOutputs and splitSizes lengh must be equal');\n  }\n  return createAttributeWithCacheKey({axis, numOutputs, splitSizes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst getRepeats = (repeatsTensorView: TensorView): readonly number[] =>\n    Array.from(repeatsTensorView.getBigInt64Array(), Number);\n\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Tile requires 2 inputs.');\n  }\n\n  if (inputs[0].dataType !== DataType.float && inputs[0].dataType !== DataType.int32 &&\n      inputs[0].dataType !== DataType.uint32) {\n    throw new Error('Tile only support float, int32, and uint32 data types');\n  }\n\n  if (inputs[1].dataType !== DataType.int64) {\n    throw new Error('Tile `repeats` input should be of int64 data type');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('Tile `repeats` input should be 1-D');\n  }\n\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n\n  if (repeats.length !== inputs[0].dims.length) {\n    throw new Error('Tile `repeats` input should have same number of elements as rank of input data tensor');\n  }\n};\n\nconst getOutputShape = (inputShape: readonly number[], repeats: readonly number[]): readonly number[] => {\n  const outputShape: number[] = [];\n\n  for (let i = 0; i < inputShape.length; ++i) {\n    outputShape.push(inputShape[i] * repeats[i]);\n  }\n\n  return outputShape;\n};\n\nexport const createTileProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n  const outputShape = getOutputShape(inputShape, repeats);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputShape = ${input.indices(...inputShape)};\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      var inputIndices: ${input.type.indices};\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        let inputDimValue = ${output.indicesGet('outputIndices', 'i')}  % ${input.indicesGet('inputShape', 'i')};\n\n        ${input.indicesSet('inputIndices', 'i', 'inputDimValue')}\n      }\n      ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n    }`;\n\n  return {\n    name: 'Tile',\n    shaderCache: {hint: `${repeats}`},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n    }),\n    getShaderSource,\n  };\n};\n\nexport const tile = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createTileProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst createWhereOpProgramShader =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], dimsOutput: readonly number[], isBroadcast: boolean,\n     typeOutput: number) => {\n      const outputSize = ShapeUtil.size(dimsOutput);\n      const vecSize = Math.ceil(outputSize / 4);\n\n      const output = outputVariable('outputData', typeOutput, dimsOutput, 4);\n      const a = inputVariable('aData', inputs[1].dataType, inputs[1].dims, 4);\n      const b = inputVariable('bData', inputs[2].dataType, inputs[2].dims, 4);\n      const c = inputVariable('cData', inputs[0].dataType, inputs[0].dims, 4);\n\n      let assignment: string;\n      const expression = (a: string, b: string, c: string) => `select(${b}, ${a}, ${c})`;\n      if (!isBroadcast) {\n        assignment = output.setByOffset(\n            'global_idx',\n            expression(a.getByOffset('global_idx'), b.getByOffset('global_idx'), c.getByOffset('global_idx')));\n      } else {\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          // eslint-disable-next-line no-bitwise\n          const expressionC = `bool(cData[indexC${x}] & ${0xff000000 >>> ((3 - x) * 8)}u)`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetC${x} = ${c.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let indexC${x} = offsetC${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expression(expressionA, expressionB, expressionC)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.declareVariables(c, a, b, output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n        ${assignment}\n      }`;\n    };\n\nconst createWhereOpProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const dimsA = inputs[1].dims;\n  const dimsB = inputs[2].dims;\n  const dimsC = inputs[0].dims;\n  const outputDataType = inputs[1].dataType;\n\n  const isBroadcast = !(ShapeUtil.areEqual(dimsA, dimsB) && ShapeUtil.areEqual(dimsB, dimsC));\n  let outputShape = dimsA;\n  let outputSize = ShapeUtil.size(dimsA);\n  // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n  if (isBroadcast) {\n    const calculatedShape = BroadcastUtil.calcShape(BroadcastUtil.calcShape(dimsA, dimsB, false)!, dimsC, false);\n    if (!calculatedShape) {\n      throw new Error('Can\\'t perform where op on the given tensors');\n    }\n    outputShape = calculatedShape;\n    outputSize = ShapeUtil.size(outputShape);\n  }\n\n  return {\n    name: 'Where',\n    getShaderSource: (shaderHelper) =>\n        createWhereOpProgramShader(shaderHelper, inputs, outputShape, isBroadcast, outputDataType),\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: outputDataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* vec size */)}\n    }),\n  };\n};\n\nexport const where = (context: ComputeContext): void => {\n  context.compute(createWhereOpProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {argMax, argMin, parseArgMinMaxAttributes} from './ops/argminmax';\nimport {attention, parseAttentionAttributes} from './ops/attention';\nimport {batchNorm} from './ops/batch-norm';\nimport {biasAdd} from './ops/bias-add';\nimport {biasSplitGelu} from './ops/bias-split-gelu';\nimport * as binaryOps from './ops/binary-op';\nimport {concat, parseConcatAttributes} from './ops/concat';\nimport {conv, parseConvAttributes} from './ops/conv';\nimport {convTranspose, parseConvTransposeAttributes} from './ops/conv-transpose';\nimport {einsum, parseEinsumAttributes} from './ops/einsum';\nimport {expand} from './ops/expand';\nimport {gather, parseGatherAttributes} from './ops/gather';\nimport {gatherElements, parseGatherElementsAttributes} from './ops/gather-elements';\nimport {gemm, parseGemmAttributes} from './ops/gemm';\nimport {instanceNorm, parseInstanceNormAttributes} from './ops/instance-norm';\nimport {layerNorm, parseLayerNormAttributes} from './ops/layer-norm';\nimport {matMul} from './ops/matmul';\nimport {multiHeadAttention, parseMultiHeadAttentionAttributes} from './ops/multi-head-attentiion';\nimport {pad, parsePadAttributes} from './ops/pad';\nimport * as pool from './ops/pool';\nimport {range} from './ops/range';\nimport {parseReduceAttributes, reduceL1, reduceL2, reduceLogSum, reduceLogSumExp, reduceMax, reduceMean, reduceMin, reduceProd, reduceSum, reduceSumSquare} from './ops/reduce';\nimport {parseResizeAttributes, resize} from './ops/resize';\nimport {parseSkipLayerNormAttributes, skipLayerNorm} from './ops/skip-layer-norm';\nimport {parseSliceAttributes, slice} from './ops/slice';\nimport {parseSoftmaxAttributes, softmax} from './ops/softmax';\nimport {parseSplitAttributes, split} from './ops/split';\nimport {tile} from './ops/tile';\nimport {parseTransposeAttributes, transpose} from './ops/transpose';\nimport * as unaryOps from './ops/unary-op';\nimport {where} from './ops/where';\nimport {ComputeContext} from './types';\n\nexport type RunFunction = (context: ComputeContext, attribute?: unknown) => void;\nexport type ParseAttributeFunction = (attributeRaw: unknown) => unknown;\nexport type OperatorImplementation = [RunFunction]|[RunFunction, ParseAttributeFunction];\n\nexport const WEBGPU_OP_RESOLVE_RULES: Map<string, OperatorImplementation> = new Map([\n  ['Abs', [unaryOps.abs]],\n  ['Acos', [unaryOps.acos]],\n  ['Acosh', [unaryOps.acosh]],\n  ['Add', [binaryOps.add]],\n  ['ArgMax', [argMax, parseArgMinMaxAttributes]],\n  ['ArgMin', [argMin, parseArgMinMaxAttributes]],\n  ['Asin', [unaryOps.asin]],\n  ['Asinh', [unaryOps.asinh]],\n  ['Atan', [unaryOps.atan]],\n  ['Atanh', [unaryOps.atanh]],\n  ['Attention', [attention, parseAttentionAttributes]],\n  // TODO: support new attributes for AveragePool-10\n  ['AveragePool', [pool.averagePool, pool.parseAveragePoolAttributes]],\n  ['BatchNormalization', [batchNorm]],\n  ['BiasAdd', [biasAdd]],\n  ['BiasSplitGelu', [biasSplitGelu]],\n  ['Cast', [unaryOps.cast, unaryOps.parseCastAttributes]],\n  ['Ceil', [unaryOps.ceil]],\n  ['Clip', [unaryOps.clip]],\n  ['Concat', [concat, parseConcatAttributes]],\n  ['Conv', [conv, parseConvAttributes]],\n  ['ConvTranspose', [convTranspose, parseConvTransposeAttributes]],\n  ['Cos', [unaryOps.cos]],\n  ['Cosh', [unaryOps.cosh]],\n  ['Div', [binaryOps.div]],\n  ['Einsum', [einsum, parseEinsumAttributes]],\n  ['Elu', [unaryOps.elu, unaryOps.parseAlphaAttributes]],\n  ['Equal', [binaryOps.equal]],\n  ['Erf', [unaryOps.erf]],\n  ['Exp', [unaryOps.exp]],\n  ['Expand', [expand]],\n  ['Floor', [unaryOps.floor]],\n  ['FusedConv', [conv, parseConvAttributes]],\n  ['Gather', [gather, parseGatherAttributes]],\n  ['GatherElements', [gatherElements, parseGatherElementsAttributes]],\n  ['Gelu', [unaryOps.gelu]],\n  ['Gemm', [gemm, parseGemmAttributes]],\n  ['GlobalAveragePool', [pool.globalAveragePool, pool.parseGlobalAveragePoolAttributes]],\n  ['GlobalMaxPool', [pool.globalMaxPool, pool.parseGlobalMaxPoolAttributes]],\n  ['Greater', [binaryOps.greater]],\n  ['GreaterOrEqual', [binaryOps.greaterOrEqual]],\n  ['InstanceNormalization', [instanceNorm, parseInstanceNormAttributes]],\n  ['LayerNormalization', [layerNorm, parseLayerNormAttributes]],\n  ['LeakyRelu', [unaryOps.leakyRelu, unaryOps.parseAlphaAttributes]],\n  ['Less', [binaryOps.less]],\n  ['LessOrEqual', [binaryOps.lessOrEqual]],\n  ['Log', [unaryOps.log]],\n  ['MatMul', [matMul]],\n  // TODO: support new attributes for MaxPool-8 and MaxPool-10\n  ['MaxPool', [pool.maxPool, pool.parseMaxPoolAttributes]],\n  ['Mul', [binaryOps.mul]],\n  ['MultiHeadAttention', [multiHeadAttention, parseMultiHeadAttentionAttributes]],\n  ['Neg', [unaryOps.neg]],\n  ['Not', [unaryOps.not]],\n  ['Pad', [pad, parsePadAttributes]],\n  ['Pow', [binaryOps.pow]],\n  ['Range', [range]],\n  ['Reciprocal', [unaryOps.reciprocal]],\n  ['ReduceMin', [reduceMin, parseReduceAttributes]],\n  ['ReduceMean', [reduceMean, parseReduceAttributes]],\n  ['ReduceMax', [reduceMax, parseReduceAttributes]],\n  ['ReduceSum', [reduceSum, parseReduceAttributes]],\n  ['ReduceProd', [reduceProd, parseReduceAttributes]],\n  ['ReduceL1', [reduceL1, parseReduceAttributes]],\n  ['ReduceL2', [reduceL2, parseReduceAttributes]],\n  ['ReduceLogSum', [reduceLogSum, parseReduceAttributes]],\n  ['ReduceLogSumExp', [reduceLogSumExp, parseReduceAttributes]],\n  ['ReduceSumSquare', [reduceSumSquare, parseReduceAttributes]],\n  ['Relu', [unaryOps.relu]],\n  ['Resize', [resize, parseResizeAttributes]],\n  ['Sigmoid', [unaryOps.sigmoid]],\n  ['Sin', [unaryOps.sin]],\n  ['Sinh', [unaryOps.sinh]],\n  ['Slice', [slice, parseSliceAttributes]],\n  ['SkipLayerNormalization', [skipLayerNorm, parseSkipLayerNormAttributes]],\n  ['Split', [split, parseSplitAttributes]],\n  ['Sqrt', [unaryOps.sqrt]],\n  ['Softmax', [softmax, parseSoftmaxAttributes]],\n  ['Sub', [binaryOps.sub]],\n  ['Tan', [unaryOps.tan]],\n  ['Tanh', [unaryOps.tanh]],\n  ['ThresholdedRelu', [unaryOps.thresholdedRelu, unaryOps.parseAlphaAttributes]],\n  ['Tile', [tile]],\n  ['Transpose', [transpose, parseTransposeAttributes]],\n  ['Where', [where]],\n]);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorDataTypeEnumToString} from '../../wasm-common';\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\nimport {TensorView} from '../tensor-view';\n\nimport {createShaderHelper} from './ops/common';\nimport {Artifact, GpuData, ProgramInfo} from './types';\n\n/**\n * ProgramManager is the main class behind running computations\n * It builds ProgramInfo's into Artifacts\n * It compiles given ProgramInfo's into WebGL Prorams (cached as Artifacts)\n * Uses the artifact to run the computation by calling Draw on\n * the WebGL drawing buffer\n * ProgramManager automatically maps (binds) input variables to their\n * corresponding Location's in the binary program\n */\nexport class ProgramManager {\n  repo: Map<unknown, Artifact>;  // this should be per-session object\n  attributesBound: boolean;\n\n  constructor(private backend: WebGpuBackend) {\n    this.repo = new Map();\n    this.attributesBound = false;\n  }\n  getArtifact(key: unknown): Artifact|undefined {\n    return this.repo.get(key);\n  }\n  setArtifact(key: unknown, artifact: Artifact): void {\n    this.repo.set(key, artifact);\n  }\n  run(buildArtifact: Artifact, inputTensorViews: readonly TensorView[], outputTensorViews: readonly TensorView[],\n      inputs: GpuData[], outputs: GpuData[], dispatchGroup: [number, number, number],\n      uniformBufferBinding: GPUBindingResource|undefined): void {\n    const device = this.backend.device;\n\n    const computePassEncoder = this.backend.getComputePassEncoder();\n    computePassEncoder.setPipeline(buildArtifact.computePipeline);\n    const entries = [];\n    for (const input of inputs) {\n      entries.push({binding: entries.length, resource: {buffer: input.buffer}});\n    }\n    for (const output of outputs) {\n      entries.push({binding: entries.length, resource: {buffer: output.buffer}});\n    }\n    if (uniformBufferBinding) {\n      entries.push({binding: entries.length, resource: uniformBufferBinding});\n    }\n    const bindGroup = device.createBindGroup(\n        {layout: buildArtifact.computePipeline.getBindGroupLayout(0), entries, label: buildArtifact.programInfo.name});\n    computePassEncoder.setBindGroup(0, bindGroup);\n\n    computePassEncoder.dispatchWorkgroups(...dispatchGroup);\n\n    this.backend.pendingDispatchNumber++;\n\n    if (this.backend.isQueryEnabled()) {\n      if (typeof this.backend.queryData === 'undefined') {\n        this.backend.queryData = this.backend.gpuDataManager.create(\n            // eslint-disable-next-line no-bitwise\n            this.backend.querySetCount * 8, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);\n      }\n      const syncData = this.backend.gpuDataManager.create(\n          // eslint-disable-next-line no-bitwise\n          this.backend.querySetCount * 8, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n      this.backend.endComputePass();\n      this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet!, 0, 2, this.backend.queryData.buffer, 0);\n      this.backend.getCommandEncoder().copyBufferToBuffer(\n          this.backend.queryData.buffer, 0, syncData.buffer, 0, this.backend.querySetCount * 8);\n      this.backend.flush();\n\n      const kernelId = this.backend.currentKernelId!;\n      const kernelInfo = this.backend.kernels.get(kernelId)!;\n      const kernelName = `[${kernelInfo[0]}] ${kernelInfo[1]}`;\n\n      void syncData.buffer.mapAsync(GPUMapMode.READ).then(() => {\n        const mappedData = new BigUint64Array(syncData.buffer.getMappedRange());\n        const startTimeU64 = mappedData[0];\n        const endTimeU64 = mappedData[1];\n\n        syncData.buffer.unmap();\n\n        if (typeof this.backend.queryTimeBase === 'undefined') {\n          this.backend.queryTimeBase = startTimeU64;\n        }\n\n        const startTime = Number(startTimeU64 - this.backend.queryTimeBase);\n        const endTime = Number(endTimeU64 - this.backend.queryTimeBase);\n\n        if (!Number.isSafeInteger(startTime) || !Number.isSafeInteger(endTime)) {\n          throw new RangeError('incorrect timestamp range');\n        }\n\n        this.backend.gpuDataManager.release(syncData.id);\n        let inputShapes = '';\n        inputTensorViews.forEach((value, i) => {\n          inputShapes += `input[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        let outputShapes = '';\n        outputTensorViews.forEach((value, i) => {\n          outputShapes += `output[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        // eslint-disable-next-line no-console\n        console.log(`[profiling] kernel \"${kernelId}|${kernelName}|${buildArtifact.programInfo.name}\" ${inputShapes}${\n            outputShapes}execution time: ${endTime - startTime} ns`);\n      });\n    }\n\n    if (this.backend.pendingDispatchNumber >= 16) {\n      this.backend.flush();\n    }\n  }\n  dispose(): void {\n    // this.repo.forEach(a => this.glContext.deleteProgram(a.program));\n  }\n  build(programInfo: ProgramInfo, normalizedDispatchGroupSize: [number, number, number]): Artifact {\n    const device = this.backend.device;\n    const extensions: string[] = [];\n    if (device.features.has('shader-f16')) {\n      extensions.push('enable f16;');\n    }\n    const shaderHelper = createShaderHelper(normalizedDispatchGroupSize);\n    const userCode = programInfo.getShaderSource(shaderHelper);\n    const code = `${extensions.join('\\n')}\\n${shaderHelper.additionalImplementations}\\n${userCode}`;\n    const shaderModule = device.createShaderModule({code, label: programInfo.name});\n    LOG_DEBUG('verbose', () => `[WebGPU] ${programInfo.name} shader code: ${code}`);\n\n    const computePipeline = device.createComputePipeline(\n        {compute: {module: shaderModule, entryPoint: 'main'}, layout: 'auto', label: programInfo.name});\n\n    return {programInfo, computePipeline};\n  }\n\n  normalizeDispatchGroupSize(dispatchGroup: ReturnType<ProgramInfo['getRunData']>['dispatchGroup']):\n      [number, number, number] {\n    const x = typeof dispatchGroup === 'number' ? dispatchGroup : dispatchGroup.x;\n    const y = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.y || 1);\n    const z = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.z || 1);\n    const limitPerDimension = this.backend.device.limits.maxComputeWorkgroupsPerDimension;\n    if (x <= limitPerDimension && y <= limitPerDimension && z <= limitPerDimension) {\n      return [x, y, z];\n    }\n    const size = x * y * z;\n    let dispatchAverage = Math.ceil(Math.sqrt(size));\n    if (dispatchAverage > limitPerDimension) {\n      dispatchAverage = Math.ceil(Math.cbrt(size));\n      if (dispatchAverage > limitPerDimension) {\n        throw new Error('Total dispatch size exceeds WebGPU maximum.');\n      }\n      return [dispatchAverage, dispatchAverage, dispatchAverage];\n    } else {\n      return [dispatchAverage, dispatchAverage, 1];\n    }\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, Tensor} from 'onnxruntime-common';\n\nimport {configureLogger, LOG_DEBUG} from './log';\nimport {createView, TensorView} from './tensor-view';\nimport {createGpuDataManager, downloadGpuData, GpuDataManager} from './webgpu/gpu-data-manager';\nimport {RunFunction, WEBGPU_OP_RESOLVE_RULES} from './webgpu/op-resolve-rules';\nimport {ProgramManager} from './webgpu/program-manager';\nimport {ComputeContext, GpuData, ProgramInfo, ProgramInputTensorInfoDependency} from './webgpu/types';\n\nconst getProgramInputTensorInfoDependencyKey =\n    (inputTensors: readonly TensorView[], inputDependencies: readonly ProgramInputTensorInfoDependency[]): string => {\n      if (inputDependencies.length !== inputTensors.length) {\n        throw new Error(`inputDependencies length ${inputDependencies.length} is not equal to inputTensors length ${\n            inputTensors.length}.`);\n      }\n\n      const inputInfos: string[] = [];\n      for (let i = 0; i < inputTensors.length; ++i) {\n        const type = inputTensors[i].dataType;\n        switch (inputDependencies[i]) {\n          case 'none': {\n            inputInfos.push('');\n            break;\n          }\n          case 'type': {\n            inputInfos.push(`${type}`);\n            break;\n          }\n          case 'rank': {\n            const rank = inputTensors[i].dims.length;\n            inputInfos.push(`${type};${rank}`);\n            break;\n          }\n          case 'dims': {\n            const dims = inputTensors[i].dims.join(',');\n            inputInfos.push(`${type};${dims}`);\n            break;\n          }\n          default:\n            throw new Error(`unsupported input dependency: ${inputDependencies[i]}`);\n        }\n      }\n\n      return inputInfos.join('|');\n    };\n\n/**\n * get a unique key representing the program from the program info, input shapes and types.\n *\n * @returns a unique key is a shorter string than the shader source, which contains all the information to identify a\n * program. if the key is the same, the program shader source should be the same, so we can reuse the program.\n *\n */\nconst getProgramInfoUniqueKey =\n    (programInfo: ProgramInfo, inputTensors: readonly TensorView[], is1DimensionDispatch: boolean): string => {\n      // final key format:\n      // <PROGRAM_NAME>[<PROGRAM_CUSTOM_CACHE_HINT>]:is1DimensionDispatch:<INPUTS_INFO_0>|<INPUTS_INFO_1>|...\n      let key = programInfo.name;\n      if (programInfo.shaderCache?.hint) {\n        key += '[' + programInfo.shaderCache.hint + ']';\n      }\n      key += ':' + is1DimensionDispatch +\n          `:${\n                 getProgramInputTensorInfoDependencyKey(\n                     inputTensors,\n                     programInfo.shaderCache?.inputDependencies ??\n                         new Array<ProgramInputTensorInfoDependency>(inputTensors.length).fill('dims'))}`;\n      return key;\n    };\n\n/**\n * this class is designed to store status and being used as a singleton for JSEP. It will be passed to jsepInit() as\n * the first parameter so that it is stored for future use.\n */\nexport class WebGpuBackend {\n  device: GPUDevice;\n  /**\n   * an instance of GpuDataManager to manage a GpuDataId -> GpuBuffer mapping\n   */\n  gpuDataManager: GpuDataManager;\n  /**\n   * an instance of ProgramManager to build and run WebGPU compute shader program, and manage a ProgramKey -> Program\n   * artifacts mapping\n   */\n  programManager: ProgramManager;\n\n  /**\n   * representing the kernel ID of which is currently being computed (CPU code perspective).\n   * `null` means no kernel is being computed.\n   * only one kernel can be computed at a moment.\n   */\n  currentKernelId: number|null = null;\n  /**\n   * a list of temporary GPU data for the current kernel. should release when the kernel done computation.\n   */\n  private temporaryData: GpuData[];\n  /**\n   * a KernelID -> a GPU data list, which stores persistent GPU data owned by the specific kernel.\n   */\n  private kernelPersistentData: Map<number, GpuData[]>;\n  /**\n   * a KernelID -> a custom data, which stores custom data owned by the specific kernel.\n   */\n  private kernelCustomData: Map<number, {[key: string]: unknown}>;\n  /**\n   * get the custom data of the current kernel\n   */\n  get currentKernelCustomData(): {[key: string]: unknown} {\n    if (this.currentKernelId === null) {\n      throw new Error('currentKernelCustomData(): currentKernelId is null. (should not happen)');\n    }\n\n    let data = this.kernelCustomData.get(this.currentKernelId);\n    if (!data) {\n      data = {};\n      this.kernelCustomData.set(this.currentKernelId, data);\n    }\n\n    return data;\n  }\n\n  /**\n   * a KernelID -> kernel info mapping. value is\n   * [ op_type, name, run function, [optional] preprocess_attribute_once function ]\n   */\n  kernels: Map<number, [string, string, RunFunction, [((attribute: unknown) => unknown) | undefined, unknown]]>;\n\n  private commandEncoder: GPUCommandEncoder|null = null;\n  private computePassEncoder: GPUComputePassEncoder|null = null;\n  pendingDispatchNumber = 0;\n\n  queryData?: GpuData;\n  querySet?: GPUQuerySet;\n  querySetCount = 2;\n  queryTimeBase?: bigint;\n\n  env: Env;\n\n  /**\n   * a SessionID -> a Map of (InputOutputIndex -> [ID, GPUBuffer]) mapping.\n   */\n  sessionExternalDataMapping: Map<number, Map<number, [number, GPUBuffer]>> = new Map();\n\n  async initialize(env: Env): Promise<void> {\n    if (!navigator.gpu) {\n      // WebGPU is not available.\n      throw new Error('WebGpuBackend: WebGPU is not available.');\n    }\n\n    const adapter = await navigator.gpu.requestAdapter();\n    if (!adapter) {\n      throw new Error('WebGpuBackend: Failed to get GPU adapter.');\n    }\n\n    this.env = env;\n    const requiredFeatures: GPUFeatureName[] = [];\n    const deviceDescriptor: GPUDeviceDescriptor = {\n      requiredLimits: {\n        maxComputeWorkgroupStorageSize: adapter.limits.maxComputeWorkgroupStorageSize,\n        maxComputeWorkgroupsPerDimension: adapter.limits.maxComputeWorkgroupsPerDimension,\n        maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,\n        maxBufferSize: adapter.limits.maxBufferSize,\n        maxComputeInvocationsPerWorkgroup: adapter.limits.maxComputeInvocationsPerWorkgroup,\n        maxComputeWorkgroupSizeX: adapter.limits.maxComputeWorkgroupSizeX,\n        maxComputeWorkgroupSizeY: adapter.limits.maxComputeWorkgroupSizeY,\n        maxComputeWorkgroupSizeZ: adapter.limits.maxComputeWorkgroupSizeZ,\n      },\n      requiredFeatures,\n    };\n\n    if (adapter.features.has('timestamp-query')) {\n      requiredFeatures.push('timestamp-query');\n    }\n    if (adapter.features.has('shader-f16')) {\n      requiredFeatures.push('shader-f16');\n    }\n\n    this.device = await adapter.requestDevice(deviceDescriptor);\n    this.gpuDataManager = createGpuDataManager(this);\n    this.programManager = new ProgramManager(this);\n    this.kernels = new Map();\n    this.kernelPersistentData = new Map();\n    this.kernelCustomData = new Map();\n\n    // set up flags for logger\n    configureLogger(env.logLevel!, !!env.debug);\n\n    // TODO: set up flags\n\n    this.device.onuncapturederror = ev => {\n      if (ev.error instanceof GPUValidationError) {\n        // eslint-disable-next-line no-console\n        console.error(`An uncaught WebGPU validation error was raised: ${ev.error.message}`);\n      }\n    };\n\n    Object.defineProperty(this.env.webgpu, 'device', {value: this.device});\n  }\n\n  dispose(): void {\n    if (typeof this.querySet !== 'undefined') {\n      this.querySet.destroy();\n    }\n    this.gpuDataManager.dispose();\n  }\n\n  getCommandEncoder(): GPUCommandEncoder {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n    return this.commandEncoder;\n  }\n\n  getComputePassEncoder(): GPUComputePassEncoder {\n    if (!this.computePassEncoder) {\n      const computePassDescriptor: GPUComputePassDescriptor = {};\n      if (this.isQueryEnabled()) {\n        if (typeof this.querySet === 'undefined') {\n          this.querySet = this.device.createQuerySet({\n            type: 'timestamp',\n            count: this.querySetCount,\n          });\n        }\n        computePassDescriptor.timestampWrites = {\n          querySet: this.querySet,\n          beginningOfPassWriteIndex: 0,\n          endOfPassWriteIndex: 1,\n        };\n      }\n\n      this.computePassEncoder = this.getCommandEncoder().beginComputePass(computePassDescriptor);\n    }\n    return this.computePassEncoder;\n  }\n\n  endComputePass(): void {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  flush(): void {\n    if (this.commandEncoder) {\n      this.endComputePass();\n      this.device.queue.submit([this.getCommandEncoder().finish()]);\n      this.gpuDataManager.refreshPendingBuffers();\n      this.commandEncoder = null;\n      this.pendingDispatchNumber = 0;\n    }\n  }\n\n  isQueryEnabled(): boolean {\n    if (this.device.features.has('timestamp-query') && this.env.webgpu.profilingMode === 'default') {\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  /**\n   * run a WebGPU program.\n   * @param program a ProgramInfo instance\n   * @param inputTensorViews a TensorView array. each element represents a value already exists in GPU.\n   * @param outputIndices an indices array. each element can be either -1 (temporary data), -2 (persistent data) or an\n   * index to the kernel's output.\n   * @param createKernelOutput a callback function that create a value to kernel's output with the given index\n   * @param createIntermediateOutput a callback function that create a value as a intermediate value, either temporary\n   * or persistent (owned by the current kernel)\n   * @returns a TensorView array representing the result.\n   */\n  run(program: ProgramInfo, inputTensorViews: readonly TensorView[], outputIndices: readonly number[],\n      createKernelOutput: (index: number, dataType: number, dims: readonly number[]) => TensorView,\n      createIntermediateOutput: (dataType: number, dims: readonly number[]) => TensorView): TensorView[] {\n    // create info for inputs\n    const inputDatas: GpuData[] = [];\n    for (let i = 0; i < inputTensorViews.length; ++i) {\n      const gpuData = this.gpuDataManager.get(inputTensorViews[i].data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for input: ${inputTensorViews[i].data}`);\n      }\n      inputDatas[i] = gpuData;\n    }\n\n    const {outputs, dispatchGroup, programUniforms} = program.getRunData(inputTensorViews);\n\n    // check output indices\n    const validatedOutputIndices = outputIndices.length === 0 ? outputs.map((_, i) => i) : outputIndices;\n    if (validatedOutputIndices.length !== outputs.length) {\n      throw new Error(`Output size ${validatedOutputIndices.length} must be equal to ${outputs.length}.`);\n    }\n\n    // create info for outputs\n    const outputTensorViews: TensorView[] = [];\n    const outputDatas: GpuData[] = [];\n    for (let i = 0; i < outputs.length; ++i) {\n      // value -1 and -2 are used for creating temporary and persistent outputs.\n      // value -3 is used for placeholder output. So -3, -2, -1 and 0, 1, 2, ... are valid\n      // output indices. see type definition of ComputeContextInputsOutputsMapping for more details.\n      if (!Number.isInteger(validatedOutputIndices[i]) || validatedOutputIndices[i] < -3 ||\n          validatedOutputIndices[i] >= outputs.length) {\n        throw new Error(`Invalid output index: ${validatedOutputIndices[i]}`);\n      }\n      if (validatedOutputIndices[i] === -3) {\n        continue;\n      }\n      const isTemporary = validatedOutputIndices[i] === -1;\n      const isPersistent = validatedOutputIndices[i] === -2;\n      const tensorView = (isTemporary || isPersistent) ?\n          createIntermediateOutput(outputs[i].dataType, outputs[i].dims) :\n          createKernelOutput(validatedOutputIndices[i], outputs[i].dataType, outputs[i].dims);\n      const gpuData = this.gpuDataManager.get(tensorView.data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for output: ${tensorView.data}`);\n      }\n      if (isTemporary) {\n        this.temporaryData.push(gpuData);\n      }\n      if (isPersistent) {\n        let persistentData = this.kernelPersistentData.get(this.currentKernelId!);\n        if (!persistentData) {\n          persistentData = [];\n          this.kernelPersistentData.set(this.currentKernelId!, persistentData);\n        }\n        persistentData.push(gpuData);\n      }\n      outputTensorViews.push(tensorView);\n      outputDatas.push(gpuData);\n    }\n\n\n    // load uniforms\n    // TODO: add cache for uniform (is it necessary?)\n    //\n    let uniformBufferBinding: GPUBindingResource|undefined;\n    if (programUniforms) {\n      let currentOffset = 0;\n      const offsets: number[] = [];\n\n      programUniforms.forEach(v => {\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (data.length === 0) {\n          return;\n        }\n        // https://www.w3.org/TR/WGSL/#alignof\n        const baseAlignment = data.length <= 2 ? data.length * 4 : 16;\n        currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n        offsets.push(currentOffset);\n        // When data.length > 4, the uniform variable is of type array<vec4<i32|u32|f32>,N>, where N =\n        // Math.ceil(data.length / 4) and SizeOf(vec4<i32|u32|f32>) = 16. The total byte length is N *\n        // SizeOf(vec4<i32|u32|f32>).\n        currentOffset += data.length > 4 ? Math.ceil(data.length / 4) * 16 : data.length * 4;\n      });\n\n      // Meet alignment of struct here: https://www.w3.org/TR/WGSL/#alignment-and-size. For simplicity, set\n      // maxAlignmentOfField to 16 since the underlying buffer has been rounded up to 16.\n      const maxAlignmentOfField = 16;\n      currentOffset = Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n      const arrayBuffer = new ArrayBuffer(currentOffset);\n      programUniforms.forEach((v, i) => {\n        const offset = offsets[i];\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (v.type === 'int32') {\n          new Int32Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === 'uint32') {\n          new Uint32Array(arrayBuffer, offset, data.length).set(data);\n        } else {\n          new Float32Array(arrayBuffer, offset, data.length).set(data);\n        }\n      });\n\n      const uniformBufferData =\n          // eslint-disable-next-line no-bitwise\n          this.gpuDataManager.create(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n      this.device.queue.writeBuffer(uniformBufferData.buffer, 0, arrayBuffer, 0, currentOffset);\n      this.gpuDataManager.release(uniformBufferData.id);\n      uniformBufferBinding = {offset: 0, size: currentOffset, buffer: uniformBufferData.buffer};\n    }\n\n    const normalizedDispatchGroup = this.programManager.normalizeDispatchGroupSize(dispatchGroup);\n    const is1DimensionDispatch = normalizedDispatchGroup[1] === 1 && normalizedDispatchGroup[2] === 1;\n    // get program info\n    const key = getProgramInfoUniqueKey(program, inputTensorViews, is1DimensionDispatch);\n    let artifact = this.programManager.getArtifact(key);\n    if (!artifact) {\n      artifact = this.programManager.build(program, normalizedDispatchGroup);\n      this.programManager.setArtifact(key, artifact);\n      LOG_DEBUG('info', () => `[artifact] key: ${key}, programName: ${program.name}`);\n    }\n\n    LOG_DEBUG(\n        'info',\n        () => `[ProgramManager] run \"${program.name}\" (key=${key}) with ${normalizedDispatchGroup[0]}x${\n            normalizedDispatchGroup[1]}x${normalizedDispatchGroup[2]}`);\n    this.programManager.run(\n        artifact, inputTensorViews, outputTensorViews, inputDatas, outputDatas, normalizedDispatchGroup,\n        uniformBufferBinding);\n\n    return outputTensorViews;\n  }\n\n  upload(gpuDataId: number, data: Uint8Array): void {\n    this.gpuDataManager.upload(gpuDataId, data);\n  }\n\n  memcpy(src: number, dst: number): void {\n    this.gpuDataManager.memcpy(src, dst);\n  }\n\n  async download(gpuDataId: number, getTargetBuffer: () => Uint8Array): Promise<void> {\n    // the underlying buffer may be changed after the async function is called. so we use a getter function to make sure\n    // the buffer is up-to-date.\n    await this.gpuDataManager.download(gpuDataId, getTargetBuffer);\n  }\n\n  alloc(size: number): number {\n    return this.gpuDataManager.create(size).id;\n  }\n\n  free(ptr: number): number {\n    return this.gpuDataManager.release(ptr);\n  }\n\n  createKernel(opType: string, kernelId: number, attribute: unknown, nodeName: string): void {\n    const op = WEBGPU_OP_RESOLVE_RULES.get(opType);\n    if (!op) {\n      throw new Error(`kernel not implemented: ${opType}`);\n    }\n\n    this.kernels.set(kernelId, [opType, nodeName, op[0], [op[1], attribute]]);\n  }\n\n  releaseKernel(kernelId: number): void {\n    const persistentData = this.kernelPersistentData.get(kernelId);\n    if (persistentData) {\n      for (const data of persistentData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.kernelPersistentData.delete(kernelId);\n    }\n\n    this.kernelCustomData.delete(kernelId);\n    this.kernels.delete(kernelId);\n  }\n\n  computeKernel(kernelId: number, context: ComputeContext, errors: Array<Promise<string|null>>): number {\n    const kernel = this.kernels.get(kernelId);\n    if (!kernel) {\n      throw new Error(`kernel not created: ${kernelId}`);\n    }\n    const [opType, nodeName, kernelEntry, attributes] = kernel;\n    if (this.currentKernelId !== null) {\n      throw new Error(`kernel \"[${opType}] ${nodeName}\" is not allowed to be called recursively`);\n    }\n    this.currentKernelId = kernelId;\n\n    // parse attributes if necessary\n    if (attributes[0]) {\n      attributes[1] = attributes[0](attributes[1]);\n      attributes[0] = undefined;\n    }\n\n    LOG_DEBUG('info', () => `[WebGPU] Start to run kernel \"[${opType}] ${nodeName}\"...`);\n\n    const useErrorScope = this.env.debug;\n\n    this.temporaryData = [];\n    try {\n      if (useErrorScope) {\n        this.device.pushErrorScope('validation');\n      }\n\n      kernelEntry(context, attributes[1]);\n      return 0;  // ORT_OK\n    } catch (e) {\n      errors.push(Promise.resolve(`[WebGPU] Kernel \"[${opType}] ${nodeName}\" failed. ${e}`));\n      return 1;  // ORT_FAIL\n    } finally {\n      if (useErrorScope) {\n        errors.push(this.device.popErrorScope().then(\n            err => err ? `GPU validation error for kernel \"[${opType}] ${nodeName}\": ${err.message}` : null));\n      }\n\n      for (const data of this.temporaryData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.temporaryData = [];\n      this.currentKernelId = null;\n    }\n  }\n\n  // #region external buffer\n  registerBuffer(sessionId: number, index: number, buffer: GPUBuffer, size: number): number {\n    let sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (!sessionInputOutputMapping) {\n      sessionInputOutputMapping = new Map();\n      this.sessionExternalDataMapping.set(sessionId, sessionInputOutputMapping);\n    }\n\n    const previousBuffer = sessionInputOutputMapping.get(index);\n    const id = this.gpuDataManager.registerExternalBuffer(buffer, size, previousBuffer?.[1]);\n    sessionInputOutputMapping.set(index, [id, buffer]);\n    return id;\n  }\n  unregisterBuffers(sessionId: number): void {\n    const sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (sessionInputOutputMapping) {\n      sessionInputOutputMapping.forEach(bufferInfo => this.gpuDataManager.unregisterExternalBuffer(bufferInfo[1]));\n      this.sessionExternalDataMapping.delete(sessionId);\n    }\n  }\n  getBuffer(gpuDataId: number): GPUBuffer {\n    const gpuData = this.gpuDataManager.get(gpuDataId);\n    if (!gpuData) {\n      throw new Error(`no GPU data for buffer: ${gpuDataId}`);\n    }\n    return gpuData.buffer;\n  }\n  createDownloader(gpuBuffer: GPUBuffer, size: number, type: Tensor.GpuBufferDataTypes):\n      () => Promise<Tensor.DataType> {\n    return async () => {\n      const data = await downloadGpuData(this, gpuBuffer, size);\n      return createView(data.buffer, type);\n    };\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from '../binding/ort-wasm';\nimport {DataType, getTensorElementSize} from '../wasm-common';\n\nimport {WebGpuBackend} from './backend-webgpu';\nimport {LOG_DEBUG} from './log';\nimport {TensorView} from './tensor-view';\nimport {ShapeUtil} from './util';\nimport {ComputeContext, ComputeContextInputsOutputsMapping, ProgramInfo} from './webgpu/types';\n\n/* eslint-disable no-bitwise */\n\nclass TensorViewImpl implements TensorView {\n  constructor(\n      private module: OrtWasmModule, public readonly dataType: number, public readonly data: number,\n      public readonly dims: readonly number[]) {}\n\n  getFloat32Array(): Float32Array {\n    if (this.dataType !== DataType.float) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Float32Array() :\n                                new Float32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getBigInt64Array(): BigInt64Array {\n    if (this.dataType !== DataType.int64) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new BigInt64Array() :\n                                new BigInt64Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getInt32Array(): Int32Array {\n    if (this.dataType !== DataType.int32) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  reshape(newDims: readonly number[]): TensorView {\n    if (ShapeUtil.size(newDims) !== ShapeUtil.size(this.dims)) {\n      throw new Error('Invalid new shape');\n    }\n    return new TensorViewImpl(this.module, this.dataType, this.data, newDims);\n  }\n}\n\nclass ComputeContextImpl implements ComputeContext {\n  readonly opKernelContext: number;\n  readonly inputs: readonly TensorView[];\n  readonly outputCount: number;\n  get kernelCustomData(): {[key: string]: unknown} {\n    return this.backend.currentKernelCustomData;\n  }\n  get customDataBuffer(): Uint8Array {\n    return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);\n  }\n  private customDataOffset = 0;\n  private customDataSize = 0;\n  constructor(private module: OrtWasmModule, private backend: WebGpuBackend, contextDataOffset: number) {\n    const heapU32 = module.HEAPU32;\n\n    // extract context data\n    let dataIndex = (contextDataOffset >> 2);\n    this.opKernelContext = heapU32[dataIndex++];\n    const inputCount = heapU32[dataIndex++];\n    this.outputCount = heapU32[dataIndex++];\n    this.customDataOffset = heapU32[dataIndex++];\n    this.customDataSize = heapU32[dataIndex++];\n\n    const inputs: TensorView[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const dataType = heapU32[dataIndex++];\n      const data = heapU32[dataIndex++];\n      const dim = heapU32[dataIndex++];\n      const dims: number[] = [];\n      for (let d = 0; d < dim; d++) {\n        dims.push(heapU32[dataIndex++]);\n      }\n      inputs.push(new TensorViewImpl(module, dataType, data, dims));\n    }\n    this.inputs = inputs;\n  }\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[] {\n    // prepare inputs. inputs should always be valid data.\n    const mappedInputs =\n        inputsOutputsMapping?.inputs?.map(i => typeof i === 'number' ? this.inputs[i] : i) ?? this.inputs;\n    // prepare outputs.\n    const outputIndices = inputsOutputsMapping?.outputs ?? [];\n    const createKernelOutput = (index: number, dataType: number, dims: readonly number[]): TensorView =>\n        new TensorViewImpl(this.module, dataType, this.output(index, dims), dims);\n    const createTemporaryOutput = (dataType: number, dims: readonly number[]): TensorView => {\n      const elementSize = getTensorElementSize(dataType);\n      if (!elementSize) {\n        throw new Error(`Unsupported data type: ${dataType}`);\n      }\n      const bufferSize = elementSize * ShapeUtil.size(dims);\n      return new TensorViewImpl(this.module, dataType, this.backend.gpuDataManager.create(bufferSize).id, dims);\n    };\n    return this.backend.run(program, mappedInputs, outputIndices, createKernelOutput, createTemporaryOutput);\n  }\n\n  output(index: number, dims: readonly number[]): number {\n    const stack = this.module.stackSave();\n    try {\n      const data = this.module.stackAlloc((1 + dims.length) * 4 /* sizeof(size_t) */);\n      let offset = data >> 2;\n      this.module.HEAPU32[offset++] = dims.length;\n      for (let i = 0; i < dims.length; i++) {\n        this.module.HEAPU32[offset++] = dims[i];\n      }\n      return this.module._JsepOutput(this.opKernelContext, index, data);\n    } catch (e) {\n      throw new Error(\n          `Failed to generate kernel's output[${index}] with dims [${dims}]. ` +\n          'If you are running with pre-allocated output, please make sure the output type/dims are correct. ' +\n          `Error: ${e}`);\n    } finally {\n      this.module.stackRestore(stack);\n    }\n  }\n}\n\nexport const init = async(module: OrtWasmModule, env: Env): Promise<void> => {\n  const init = module.jsepInit;\n  if (init && navigator.gpu) {\n    if (!env.wasm.simd) {\n      throw new Error(\n          'Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP');\n    }\n    const backend = new WebGpuBackend();\n    await backend.initialize(env);\n\n    init(\n        // backend\n        backend,\n\n        // jsepAlloc()\n        (size: number) => backend.alloc(size),\n\n        // jsepFree()\n        (ptr: number) => backend.free(ptr),\n\n        // jsepCopy(src, dst, size, isSourceGpu)\n        (src: number, dst: number, size: number, isSourceGpu = false) => {\n          if (isSourceGpu) {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyGpuToGpu: src=${src}, dst=${dst}, size=${size}`);\n            backend.memcpy(src, dst);\n          } else {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyCpuToGpu: dataOffset=${src}, gpuDataId=${dst}, size=${size}`);\n            const data = module.HEAPU8.subarray(src, src + size);\n            backend.upload(dst, data);\n          }\n        },\n\n        // jsepCopyAsync(src, dst, size)\n        async(gpuDataId: number, dataOffset: number, size: number):\n            Promise<void> => {\n              LOG_DEBUG(\n                  'verbose',\n                  () => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${gpuDataId}, dataOffset=${dataOffset}, size=${size}`);\n\n              await backend.download(gpuDataId, () => module.HEAPU8.subarray(dataOffset, dataOffset + size));\n            },\n\n        // jsepCreateKernel\n        (name: string, kernel: number, attribute: unknown) => backend.createKernel(\n            name, kernel, attribute,\n            env.debug || env.webgpu.profilingMode === 'default' ? module.UTF8ToString(module._JsepGetNodeName(kernel)) :\n                                                                  `${kernel}`),\n\n        // jsepReleaseKernel\n        (kernel: number) => backend.releaseKernel(kernel),\n\n        // jsepRun\n        (kernel: number, contextDataOffset: number, sessionHandle: number, errors: Array<Promise<string|null>>) => {\n          LOG_DEBUG(\n              'verbose',\n              () => `[WebGPU] jsepRun: sessionHandle=${sessionHandle}, kernel=${kernel}, contextDataOffset=${\n                  contextDataOffset}`);\n          const context = new ComputeContextImpl(module, backend, contextDataOffset);\n          return backend.computeKernel(kernel, context, errors);\n        });\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, InferenceSession, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport {setRunOptions} from './run-options';\nimport {setSessionOptions} from './session-options';\nimport {dataLocationStringToEnum, getTensorElementSize, isGpuBufferSupportedType, logLevelStringToEnum, tensorDataTypeEnumToString, tensorDataTypeStringToEnum, tensorTypeToTypedArrayConstructor} from './wasm-common';\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError} from './wasm-utils';\n\nlet ortEnvInitialized = false;\n\n/**\n * get the input/output count of the session.\n * @param sessionHandle the handle representing the session. should be non-zero.\n * @returns a tuple including 2 numbers, representing the input count and output count.\n */\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  try {\n    const dataOffset = wasm.stackAlloc(8);\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + 4);\n    if (errorCode !== 0) {\n      checkLastError('Can\\'t get session input/output count.');\n    }\n    return [wasm.HEAP32[dataOffset / 4], wasm.HEAP32[dataOffset / 4 + 1]];\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * initialize ORT environment.\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\n */\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\n  if (errorCode !== 0) {\n    checkLastError('Can\\'t initialize onnxruntime.');\n  }\n};\n\n/**\n * intialize runtime environment.\n * @param env passed in the environment config object.\n */\nexport const initRuntime = async(env: Env): Promise<void> => {\n  // init ORT\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\n\n  if (!BUILD_DEFS.DISABLE_WEBGPU) {\n    // init JSEP if available\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n    const initJsep = require('./jsep/init').init;\n    await initJsep(getInstance(), env);\n  }\n\n  ortEnvInitialized = true;\n};\n\n/**\n * valid data locations for input/output tensors.\n */\ntype SupportedTensorDataLocationForInputOutput = 'cpu'|'cpu-pinned'|'gpu-buffer';\n\ntype IOBindingState = {\n  /**\n   * the handle of IO binding.\n   */\n  readonly handle: number;\n\n  /**\n   * the preferred location for each output tensor.\n   *\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer'.\n   */\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\n\n  /**\n   * enum value of the preferred location for each output tensor.\n   */\n  readonly outputPreferredLocationsEncoded: readonly number[];\n};\n\n/**\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\n */\ntype SessionMetadata = [\n  inferenceSessionId: number, inputNamesUTF8Encoded: number[], outputNamesUTF8Encoded: number[],\n  bindingState: IOBindingState|null\n];\n\nconst activeSessions = new Map<number, SessionMetadata>();\n\nexport const isOrtEnvInitialized = (): boolean => ortEnvInitialized;\n\n/**\n * allocate the memory and memcpy the model bytes, preparing for creating an instance of InferenceSession.\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\n */\nexport const createSessionAllocate = (model: Uint8Array): [number, number] => {\n  const wasm = getInstance();\n  const modelDataOffset = wasm._malloc(model.byteLength);\n  if (modelDataOffset === 0) {\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\n  }\n  wasm.HEAPU8.set(model, modelDataOffset);\n  return [modelDataOffset, model.byteLength];\n};\n\n/**\n * create an inference session using the prepared buffer containing the model data.\n * @param modelData a 2-elements tuple containing the pointer and size of the model data buffer.\n * @param options an optional session options object.\n * @returns a 3-elements tuple containing [session handle, input names, output names]\n */\nexport const createSessionFinalize =\n    (modelData: SerializableModeldata, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const wasm = getInstance();\n\n      let sessionHandle = 0;\n      let sessionOptionsHandle = 0;\n      let ioBindingHandle = 0;\n      let allocs: number[] = [];\n      const inputNamesUTF8Encoded = [];\n      const outputNamesUTF8Encoded = [];\n\n      try {\n        [sessionOptionsHandle, allocs] = setSessionOptions(options);\n\n        sessionHandle = wasm._OrtCreateSession(modelData[0], modelData[1], sessionOptionsHandle);\n        if (sessionHandle === 0) {\n          checkLastError('Can\\'t create a session.');\n        }\n\n        const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\n\n        const inputNames = [];\n        const outputNames = [];\n        const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\n        for (let i = 0; i < inputCount; i++) {\n          const name = wasm._OrtGetInputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an input name.');\n          }\n          inputNamesUTF8Encoded.push(name);\n          inputNames.push(wasm.UTF8ToString(name));\n        }\n        for (let i = 0; i < outputCount; i++) {\n          const name = wasm._OrtGetOutputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an output name.');\n          }\n          outputNamesUTF8Encoded.push(name);\n          const nameString = wasm.UTF8ToString(name);\n          outputNames.push(nameString);\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            const location = typeof options?.preferredOutputLocation === 'string' ?\n                options.preferredOutputLocation :\n                options?.preferredOutputLocation?.[nameString] ?? 'cpu';\n            if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer') {\n              throw new Error(`Not supported preferred output location: ${location}.`);\n            }\n            outputPreferredLocations.push(location);\n          }\n        }\n\n        // use IO binding only when at least one output is preffered to be on GPU.\n        let bindingState: IOBindingState|null = null;\n        if (!BUILD_DEFS.DISABLE_WEBGPU && outputPreferredLocations.some(l => l === 'gpu-buffer')) {\n          ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\n          if (ioBindingHandle === 0) {\n            checkLastError('Can\\'t create IO binding.');\n          }\n\n          bindingState = {\n            handle: ioBindingHandle,\n            outputPreferredLocations,\n            outputPreferredLocationsEncoded: outputPreferredLocations.map(l => dataLocationStringToEnum(l)),\n          };\n        }\n\n        activeSessions.set(sessionHandle, [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, bindingState]);\n        return [sessionHandle, inputNames, outputNames];\n      } catch (e) {\n        inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n        outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n\n        if (ioBindingHandle !== 0) {\n          wasm._OrtReleaseBinding(ioBindingHandle);\n        }\n\n        if (sessionHandle !== 0) {\n          wasm._OrtReleaseSession(sessionHandle);\n        }\n        throw e;\n      } finally {\n        wasm._free(modelData[0]);\n        if (sessionOptionsHandle !== 0) {\n          wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n        }\n        allocs.forEach(alloc => wasm._free(alloc));\n      }\n    };\n\n\n/**\n * create an instance of InferenceSession.\n * @returns the metadata of InferenceSession. 0-value handle for failure.\n */\nexport const createSession =\n    (model: Uint8Array, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const modelData: SerializableModeldata = createSessionAllocate(model);\n      return createSessionFinalize(modelData, options);\n    };\n\nexport const releaseSession = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  if (ioBindingState) {\n    wasm._OrtReleaseBinding(ioBindingState.handle);\n  }\n\n  wasm.jsepUnregisterBuffers?.(sessionId);\n\n  inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  wasm._OrtReleaseSession(sessionHandle);\n  activeSessions.delete(sessionId);\n};\n\nexport const prepareInputOutputTensor =\n    (tensor: TensorMetadata|null, tensorHandles: number[], allocs: number[], sessionId: number, index: number):\n        void => {\n          if (!tensor) {\n            tensorHandles.push(0);\n            return;\n          }\n\n          const wasm = getInstance();\n\n          const dataType = tensor[0];\n          const dims = tensor[1];\n          const location = tensor[3];\n\n          let rawData: number;\n          let dataByteLength: number;\n\n          if (dataType === 'string' && location === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n\n          if (location === 'gpu-buffer') {\n            const gpuBuffer = tensor[2].gpuBuffer as GPUBuffer;\n            const elementSizeInBytes = getTensorElementSize(tensorDataTypeStringToEnum(dataType))!;\n            dataByteLength = dims.reduce((a, b) => a * b, 1) * elementSizeInBytes;\n            rawData = wasm.jsepRegisterBuffer(sessionId, index, gpuBuffer, dataByteLength);\n          } else {\n            const data = tensor[2];\n\n            if (Array.isArray(data)) {\n              // string tensor\n              dataByteLength = 4 * data.length;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              let dataIndex = rawData / 4;\n              for (let i = 0; i < data.length; i++) {\n                if (typeof data[i] !== 'string') {\n                  throw new TypeError(`tensor data at index ${i} is not a string`);\n                }\n                wasm.HEAPU32[dataIndex++] = allocWasmString(data[i], allocs);\n              }\n            } else {\n              dataByteLength = data.byteLength;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n            }\n          }\n\n          const stack = wasm.stackSave();\n          const dimsOffset = wasm.stackAlloc(4 * dims.length);\n          try {\n            let dimIndex = dimsOffset / 4;\n            dims.forEach(d => wasm.HEAP32[dimIndex++] = d);\n            const tensor = wasm._OrtCreateTensor(\n                tensorDataTypeStringToEnum(dataType), rawData, dataByteLength, dimsOffset, dims.length,\n                dataLocationStringToEnum(location));\n            if (tensor === 0) {\n              checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\n            }\n            tensorHandles.push(tensor);\n          } finally {\n            wasm.stackRestore(stack);\n          }\n        };\n\n/**\n * perform inference run\n */\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputTensors: TensorMetadata[], outputIndices: number[],\n    outputTensors: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  const inputCount = inputIndices.length;\n  const outputCount = outputIndices.length;\n\n  let runOptionsHandle = 0;\n  let runOptionsAllocs: number[] = [];\n\n  const inputTensorHandles: number[] = [];\n  const outputTensorHandles: number[] = [];\n  const inputOutputAllocs: number[] = [];\n\n  const beforeRunStack = wasm.stackSave();\n  const inputValuesOffset = wasm.stackAlloc(inputCount * 4);\n  const inputNamesOffset = wasm.stackAlloc(inputCount * 4);\n  const outputValuesOffset = wasm.stackAlloc(outputCount * 4);\n  const outputNamesOffset = wasm.stackAlloc(outputCount * 4);\n\n  try {\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\n\n    // create input tensors\n    for (let i = 0; i < inputCount; i++) {\n      prepareInputOutputTensor(inputTensors[i], inputTensorHandles, inputOutputAllocs, sessionId, inputIndices[i]);\n    }\n\n    // create output tensors\n    for (let i = 0; i < outputCount; i++) {\n      prepareInputOutputTensor(\n          outputTensors[i], outputTensorHandles, inputOutputAllocs, sessionId, inputCount + outputIndices[i]);\n    }\n\n    let inputValuesIndex = inputValuesOffset / 4;\n    let inputNamesIndex = inputNamesOffset / 4;\n    let outputValuesIndex = outputValuesOffset / 4;\n    let outputNamesIndex = outputNamesOffset / 4;\n    for (let i = 0; i < inputCount; i++) {\n      wasm.HEAPU32[inputValuesIndex++] = inputTensorHandles[i];\n      wasm.HEAPU32[inputNamesIndex++] = inputNamesUTF8Encoded[inputIndices[i]];\n    }\n    for (let i = 0; i < outputCount; i++) {\n      wasm.HEAPU32[outputValuesIndex++] = outputTensorHandles[i];\n      wasm.HEAPU32[outputNamesIndex++] = outputNamesUTF8Encoded[outputIndices[i]];\n    }\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      const {handle, outputPreferredLocations, outputPreferredLocationsEncoded} = ioBindingState;\n\n      if (inputNamesUTF8Encoded.length !== inputCount) {\n        throw new Error(`input count from feeds (${\n            inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`);\n      }\n\n      // process inputs\n      for (let i = 0; i < inputCount; i++) {\n        const index = inputIndices[i];\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\n        if (errorCode !== 0) {\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\n        }\n      }\n\n      // process pre-allocated outputs\n      for (let i = 0; i < outputCount; i++) {\n        const index = outputIndices[i];\n        const location = outputTensors[i]?.[3];  // undefined means output is not pre-allocated.\n\n        if (location) {\n          // output is pre-allocated. bind the tensor.\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\n          }\n        } else {\n          // output is not pre-allocated. reset preferred location.\n          const errorCode =\n              wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], 0, outputPreferredLocationsEncoded[index]);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\n          }\n        }\n      }\n    }\n\n    let errorCode: number;\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      errorCode = await wasm._OrtRunWithBinding(\n          sessionHandle, ioBindingState.handle, outputCount, outputValuesOffset, runOptionsHandle);\n    } else {\n      errorCode = await wasm._OrtRun(\n          sessionHandle, inputNamesOffset, inputValuesOffset, inputCount, outputNamesOffset, outputCount,\n          outputValuesOffset, runOptionsHandle);\n    }\n\n    if (errorCode !== 0) {\n      checkLastError('failed to call OrtRun().');\n    }\n\n    const output: TensorMetadata[] = [];\n\n    for (let i = 0; i < outputCount; i++) {\n      const tensor = wasm.HEAPU32[outputValuesOffset / 4 + i];\n      if (tensor === outputTensorHandles[i]) {\n        // output tensor is pre-allocated. no need to copy data.\n        output.push(outputTensors[i]!);\n        continue;\n      }\n\n      const beforeGetTensorDataStack = wasm.stackSave();\n      // stack allocate 4 pointer value\n      const tensorDataOffset = wasm.stackAlloc(4 * 4);\n\n      let keepOutputTensor = false;\n      let type: Tensor.Type|undefined, dataOffset = 0;\n      try {\n        const errorCode = wasm._OrtGetTensorData(\n            tensor, tensorDataOffset, tensorDataOffset + 4, tensorDataOffset + 8, tensorDataOffset + 12);\n        if (errorCode !== 0) {\n          checkLastError(`Can't access output tensor data on index ${i}.`);\n        }\n        let tensorDataIndex = tensorDataOffset / 4;\n        const dataType = wasm.HEAPU32[tensorDataIndex++];\n        dataOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsLength = wasm.HEAPU32[tensorDataIndex++];\n        const dims = [];\n        for (let i = 0; i < dimsLength; i++) {\n          dims.push(wasm.HEAPU32[dimsOffset / 4 + i]);\n        }\n        wasm._OrtFree(dimsOffset);\n\n        const size = dims.reduce((a, b) => a * b, 1);\n        type = tensorDataTypeEnumToString(dataType);\n\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\n\n        if (type === 'string') {\n          if (preferredLocation === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n          const stringData: string[] = [];\n          let dataIndex = dataOffset / 4;\n          for (let i = 0; i < size; i++) {\n            const offset = wasm.HEAPU32[dataIndex++];\n            const maxBytesToRead = i === size - 1 ? undefined : wasm.HEAPU32[dataIndex] - offset;\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\n          }\n          output.push([type, dims, stringData, 'cpu']);\n        } else {\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\n            const gpuBuffer = wasm.jsepGetBuffer(dataOffset);\n            const elementSize = getTensorElementSize(dataType);\n            if (elementSize === undefined || !isGpuBufferSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            output.push([\n              type, dims, {\n                gpuBuffer,\n                download: wasm.jsepCreateDownloader(gpuBuffer, size * elementSize, type),\n                dispose: () => {\n                  wasm._OrtReleaseTensor(tensor);\n                }\n              },\n              'gpu-buffer'\n            ]);\n          } else {\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\n            const data = new typedArrayConstructor(size);\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength)\n                .set(wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength));\n            output.push([type, dims, data, 'cpu']);\n          }\n        }\n      } finally {\n        wasm.stackRestore(beforeGetTensorDataStack);\n        if (type === 'string' && dataOffset) {\n          wasm._free(dataOffset);\n        }\n        if (!keepOutputTensor) {\n          wasm._OrtReleaseTensor(tensor);\n        }\n      }\n    }\n\n    if (ioBindingState) {\n      wasm._OrtClearBoundOutputs(ioBindingState.handle);\n    }\n\n    return output;\n  } finally {\n    wasm.stackRestore(beforeRunStack);\n\n    inputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    outputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    inputOutputAllocs.forEach(p => wasm._free(p));\n\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    runOptionsAllocs.forEach(p => wasm._free(p));\n  }\n};\n\n/**\n * end profiling\n */\nexport const endProfiling = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error('invalid session id');\n  }\n  const sessionHandle = session[0];\n\n  // profile file name is not used yet, but it must be freed.\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\n  if (profileFileName === 0) {\n    checkLastError('Can\\'t get an profile file name.');\n  }\n  wasm._OrtFree(profileFileName);\n};\n\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\n  const buffers: ArrayBufferLike[] = [];\n  for (const tensor of tensors) {\n    const data = tensor[2];\n    if (!Array.isArray(data) && 'buffer' in data) {\n      buffers.push(data.buffer);\n    }\n  }\n  return buffers;\n};\n", "/*!\n * ONNX Runtime Web v1.17.0\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License.\n */\n\"use strict\";(()=>{var wi=Object.defineProperty;var Zp=Object.getOwnPropertyDescriptor;var Xp=Object.getOwnPropertyNames;var Qp=Object.prototype.hasOwnProperty;var ae=(e,r)=>()=>(e&&(r=e(e=0)),r);var fn=(e,r)=>()=>(r||e((r={exports:{}}).exports,r),r.exports),qn=(e,r)=>{for(var t in r)wi(e,t,{get:r[t],enumerable:!0})},Jp=(e,r,t,u)=>{if(r&&typeof r==\"object\"||typeof r==\"function\")for(let a of Xp(r))!Qp.call(e,a)&&a!==t&&wi(e,a,{get:()=>r[a],enumerable:!(u=Zp(r,a))||u.enumerable});return e};var Sr=e=>Jp(wi({},\"__esModule\",{value:!0}),e);var $i={};qn($i,{readFile:()=>em});var em,Ci=ae(()=>{em=void 0});var Si={};qn(Si,{join:()=>tm});var tm,xi=ae(()=>{tm=void 0});var Ua=fn((Wa,_i)=>{\"use strict\";var Va=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(r={}){var t=r,u,a;t.ready=new Promise((n,i)=>{u=n,a=i}),t.jsepInit=(n,i,o,s,d,f,h,g)=>{t.zh=n,t.ph=i,t.rh=o,t.eh=s,t.qh=d,t.Cd=f,t.sh=h,t.th=g,i=(b,w,$)=>(...I)=>{let E=ft,C=w?.();I=b(...I);let D=w?.();return C!==D&&(b=D,$(C),w=$=null),ft!=E?In():I},o=b=>async(...w)=>{try{if(t.Xg)throw Error(\"Session already started\");let $=t.Xg={uh:w[0],errors:[]},I=await b(...w);if(t.Xg!==$)throw Error(\"Session mismatch\");n.flush();let E=$.errors;if(0<E.length){let C=await Promise.all(E);if(C=C.filter(D=>D),0<C.length)throw Error(C.join(`\n`))}return I}finally{t.Xg=null}},t._OrtRun=o(i(t._OrtRun,()=>t._OrtRun,b=>t._OrtRun=b)),t._OrtRunWithBinding=o(i(t._OrtRunWithBinding,()=>t._OrtRunWithBinding,b=>t._OrtRunWithBinding=b)),t._OrtBindInput=i(t._OrtBindInput,()=>t._OrtBindInput,b=>t._OrtBindInput=b),t.jsepRegisterBuffer=(b,w,$,I)=>n.registerBuffer(b,w,$,I),t.jsepUnregisterBuffers=b=>{n.unregisterBuffers(b)},t.jsepGetBuffer=b=>n.getBuffer(b),t.jsepCreateDownloader=(b,w,$)=>n.createDownloader(b,w,$)};var p=Object.assign({},t),m=\"./this.program\",y=(n,i)=>{throw i},l=typeof window==\"object\",S=typeof importScripts==\"function\",A=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",P=\"\",T,k,O;if(A){var R=(Ci(),Sr($i)),j=(xi(),Sr(Si));P=S?j.dirname(P)+\"/\":__dirname+\"/\",T=(n,i)=>(n=n.startsWith(\"file://\")?new URL(n):j.normalize(n),R.readFileSync(n,i?void 0:\"utf8\")),O=n=>(n=T(n,!0),n.buffer||(n=new Uint8Array(n)),n),k=(n,i,o,s=!0)=>{n=n.startsWith(\"file://\")?new URL(n):j.normalize(n),R.readFile(n,s?void 0:\"utf8\",(d,f)=>{d?o(d):i(s?f.buffer:f)})},!t.thisProgram&&1<process.argv.length&&(m=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),y=(n,i)=>{throw process.exitCode=n,i},t.inspect=()=>\"[Emscripten Module object]\"}else(l||S)&&(S?P=self.location.href:typeof document<\"u\"&&document.currentScript&&(P=document.currentScript.src),e&&(P=e),P.indexOf(\"blob:\")!==0?P=P.substr(0,P.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):P=\"\",T=n=>{var i=new XMLHttpRequest;return i.open(\"GET\",n,!1),i.send(null),i.responseText},S&&(O=n=>{var i=new XMLHttpRequest;return i.open(\"GET\",n,!1),i.responseType=\"arraybuffer\",i.send(null),new Uint8Array(i.response)}),k=(n,i,o)=>{var s=new XMLHttpRequest;s.open(\"GET\",n,!0),s.responseType=\"arraybuffer\",s.onload=()=>{s.status==200||s.status==0&&s.response?i(s.response):o()},s.onerror=o,s.send(null)});var M=t.print||console.log.bind(console),z=t.printErr||console.error.bind(console);Object.assign(t,p),p=null,t.thisProgram&&(m=t.thisProgram),t.quit&&(y=t.quit);var q;t.wasmBinary&&(q=t.wasmBinary);var G=t.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&nt(\"no native wasm support detected\");var Y,_,X=!1,J,re,fe,L,oe,Se,me;function Re(){var n=Y.buffer;t.HEAP8=re=new Int8Array(n),t.HEAP16=new Int16Array(n),t.HEAP32=L=new Int32Array(n),t.HEAPU8=fe=new Uint8Array(n),t.HEAPU16=new Uint16Array(n),t.HEAPU32=oe=new Uint32Array(n),t.HEAPF32=Se=new Float32Array(n),t.HEAPF64=me=new Float64Array(n)}var ue=[],Be=[],Me=[];function De(){var n=t.preRun.shift();ue.unshift(n)}var Ae=0,St=null,rt=null;function nt(n){throw t.onAbort&&t.onAbort(n),n=\"Aborted(\"+n+\")\",z(n),X=!0,J=1,n=new WebAssembly.RuntimeError(n+\". Build with -sASSERTIONS for more info.\"),a(n),n}function ne(n){return n.startsWith(\"data:application/octet-stream;base64,\")}var we;if(we=\"ort-wasm-simd.wasm\",!ne(we)){var Ie=we;we=t.locateFile?t.locateFile(Ie,P):P+Ie}function tt(n){if(n==we&&q)return new Uint8Array(q);if(O)return O(n);throw\"both async and sync fetching of the wasm failed\"}function st(n){if(!q&&(l||S)){if(typeof fetch==\"function\"&&!n.startsWith(\"file://\"))return fetch(n,{credentials:\"same-origin\"}).then(i=>{if(!i.ok)throw\"failed to load wasm binary file at '\"+n+\"'\";return i.arrayBuffer()}).catch(()=>tt(n));if(k)return new Promise((i,o)=>{k(n,s=>i(new Uint8Array(s)),o)})}return Promise.resolve().then(()=>tt(n))}function Fe(n,i,o){return st(n).then(s=>WebAssembly.instantiate(s,i)).then(s=>s).then(o,s=>{z(\"failed to asynchronously prepare wasm: \"+s),nt(s)})}function Qe(n,i){var o=we;return q||typeof WebAssembly.instantiateStreaming!=\"function\"||ne(o)||o.startsWith(\"file://\")||A||typeof fetch!=\"function\"?Fe(o,n,i):fetch(o,{credentials:\"same-origin\"}).then(s=>WebAssembly.instantiateStreaming(s,n).then(i,function(d){return z(\"wasm streaming compile failed: \"+d),z(\"falling back to ArrayBuffer instantiation\"),Fe(o,n,i)}))}var at,xt={1336376:n=>{t.Cd(\"Abs\",n,void 0)},1336427:n=>{t.Cd(\"Neg\",n,void 0)},1336478:n=>{t.Cd(\"Floor\",n,void 0)},1336531:n=>{t.Cd(\"Ceil\",n,void 0)},1336583:n=>{t.Cd(\"Reciprocal\",n,void 0)},1336641:n=>{t.Cd(\"Sqrt\",n,void 0)},1336693:n=>{t.Cd(\"Exp\",n,void 0)},1336744:n=>{t.Cd(\"Erf\",n,void 0)},1336795:n=>{t.Cd(\"Sigmoid\",n,void 0)},1336850:n=>{t.Cd(\"Log\",n,void 0)},1336901:n=>{t.Cd(\"Sin\",n,void 0)},1336952:n=>{t.Cd(\"Cos\",n,void 0)},1337003:n=>{t.Cd(\"Tan\",n,void 0)},1337054:n=>{t.Cd(\"Asin\",n,void 0)},1337106:n=>{t.Cd(\"Acos\",n,void 0)},1337158:n=>{t.Cd(\"Atan\",n,void 0)},1337210:n=>{t.Cd(\"Sinh\",n,void 0)},1337262:n=>{t.Cd(\"Cosh\",n,void 0)},1337314:n=>{t.Cd(\"Asinh\",n,void 0)},1337367:n=>{t.Cd(\"Acosh\",n,void 0)},1337420:n=>{t.Cd(\"Atanh\",n,void 0)},1337473:n=>{t.Cd(\"Tanh\",n,void 0)},1337525:n=>{t.Cd(\"Not\",n,void 0)},1337576:(n,i,o)=>{t.Cd(\"Clip\",n,{min:i,max:o})},1337645:n=>{t.Cd(\"Clip\",n,void 0)},1337697:(n,i)=>{t.Cd(\"Elu\",n,{alpha:i})},1337755:n=>{t.Cd(\"Relu\",n,void 0)},1337807:(n,i)=>{t.Cd(\"LeakyRelu\",n,{alpha:i})},1337871:(n,i)=>{t.Cd(\"ThresholdedRelu\",n,{alpha:i})},1337941:(n,i)=>{t.Cd(\"Cast\",n,{to:i})},1337999:n=>{t.Cd(\"Add\",n,void 0)},1338050:n=>{t.Cd(\"Sub\",n,void 0)},1338101:n=>{t.Cd(\"Mul\",n,void 0)},1338152:n=>{t.Cd(\"Div\",n,void 0)},1338203:n=>{t.Cd(\"Pow\",n,void 0)},1338254:n=>{t.Cd(\"Equal\",n,void 0)},1338307:n=>{t.Cd(\"Greater\",n,void 0)},1338362:n=>{t.Cd(\"GreaterOrEqual\",n,void 0)},1338424:n=>{t.Cd(\"Less\",n,void 0)},1338476:n=>{t.Cd(\"LessOrEqual\",n,void 0)},1338535:(n,i,o,s,d)=>{t.Cd(\"ReduceMean\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1338699:(n,i,o,s,d)=>{t.Cd(\"ReduceMax\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1338862:(n,i,o,s,d)=>{t.Cd(\"ReduceMin\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1339025:(n,i,o,s,d)=>{t.Cd(\"ReduceProd\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1339189:(n,i,o,s,d)=>{t.Cd(\"ReduceSum\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1339352:(n,i,o,s,d)=>{t.Cd(\"ReduceL1\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1339514:(n,i,o,s,d)=>{t.Cd(\"ReduceL2\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1339676:(n,i,o,s,d)=>{t.Cd(\"ReduceLogSum\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1339842:(n,i,o,s,d)=>{t.Cd(\"ReduceSumSquare\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1340011:(n,i,o,s,d)=>{t.Cd(\"ReduceLogSumExp\",n,{keepDims:!!i,noopWithEmptyAxes:!!o,axes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1340180:n=>{t.Cd(\"Where\",n,void 0)},1340233:(n,i,o)=>{t.Cd(\"Transpose\",n,{perm:i?Array.from(L.subarray(o>>>0,o+i>>>0)):[]})},1340346:(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)=>{t.Cd(\"ConvTranspose\",n,{format:b?\"NHWC\":\"NCHW\",autoPad:i,dilations:[o],group:s,kernel_shape:[d],pads:[f,h],strides:[g],wIsConst:()=>!!re[w>>>0],outputPadding:$?Array.from(L.subarray(I>>>0,I+$>>>0)):[],outputShape:E?Array.from(L.subarray(C>>>0,C+E>>>0)):[],activation:it(D)})},1340760:(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>{t.Cd(\"ConvTranspose\",n,{format:g?\"NHWC\":\"NCHW\",autoPad:i,dilations:Array.from(L.subarray(o>>>0,o+2>>>0)),group:s,kernelShape:Array.from(L.subarray(d>>>0,d+2>>>0)),pads:Array.from(L.subarray(f>>>0,f+4>>>0)),strides:Array.from(L.subarray(h>>>0,h+2>>>0)),wIsConst:()=>!!re[b>>>0],outputPadding:0<w?Array.from(L.subarray($>>>0,$+w>>>0)):[],outputShape:0<I?Array.from(L.subarray(E>>>0,E+I>>>0)):[],activation:it(C)})},1341317:(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)=>{t.Cd(\"ConvTranspose\",n,{format:b?\"NHWC\":\"NCHW\",autoPad:i,dilations:[o],group:s,kernel_shape:[d],pads:[f,h],strides:[g],wIsConst:()=>!!re[w>>>0],outputPadding:$?Array.from(L.subarray(I>>>0,I+$>>>0)):[],outputShape:E?Array.from(L.subarray(C>>>0,C+E>>>0)):[],activation:it(D)})},1341731:(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>{t.Cd(\"ConvTranspose\",n,{format:g?\"NHWC\":\"NCHW\",autoPad:i,dilations:Array.from(L.subarray(o>>>0,o+2>>>0)),group:s,kernelShape:Array.from(L.subarray(d>>>0,d+2>>>0)),pads:Array.from(L.subarray(f>>>0,f+4>>>0)),strides:Array.from(L.subarray(h>>>0,h+2>>>0)),wIsConst:()=>!!re[b>>>0],outputPadding:0<w?Array.from(L.subarray($>>>0,$+w>>>0)):[],outputShape:0<I?Array.from(L.subarray(E>>>0,E+I>>>0)):[],activation:it(C)})},1342288:(n,i)=>{t.Cd(\"GlobalAveragePool\",n,{format:i?\"NHWC\":\"NCHW\"})},1342379:(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>{t.Cd(\"AveragePool\",n,{format:V?\"NHWC\":\"NCHW\",auto_pad:i,ceil_mode:o,count_include_pad:s,storage_order:d,dilations:[f,h],kernel_shape:[g,b],pads:[w,$,I,E],strides:[C,D]})},1342663:(n,i)=>{t.Cd(\"GlobalAveragePool\",n,{format:i?\"NHWC\":\"NCHW\"})},1342754:(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>{t.Cd(\"AveragePool\",n,{format:V?\"NHWC\":\"NCHW\",auto_pad:i,ceil_mode:o,count_include_pad:s,storage_order:d,dilations:[f,h],kernel_shape:[g,b],pads:[w,$,I,E],strides:[C,D]})},1343038:(n,i)=>{t.Cd(\"GlobalMaxPool\",n,{format:i?\"NHWC\":\"NCHW\"})},1343125:(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>{t.Cd(\"MaxPool\",n,{format:V?\"NHWC\":\"NCHW\",auto_pad:i,ceil_mode:o,count_include_pad:s,storage_order:d,dilations:[f,h],kernel_shape:[g,b],pads:[w,$,I,E],strides:[C,D]})},1343405:(n,i)=>{t.Cd(\"GlobalMaxPool\",n,{format:i?\"NHWC\":\"NCHW\"})},1343492:(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>{t.Cd(\"MaxPool\",n,{format:V?\"NHWC\":\"NCHW\",auto_pad:i,ceil_mode:o,count_include_pad:s,storage_order:d,dilations:[f,h],kernel_shape:[g,b],pads:[w,$,I,E],strides:[C,D]})},1343772:(n,i,o,s,d)=>{t.Cd(\"Gemm\",n,{alpha:i,beta:o,transA:s,transB:d})},1343876:n=>{t.Cd(\"MatMul\",n,void 0)},1343930:(n,i,o,s)=>{t.Cd(\"ArgMax\",n,{keepDims:!!i,selectLastIndex:!!o,axis:s})},1344038:(n,i,o,s)=>{t.Cd(\"ArgMin\",n,{keepDims:!!i,selectLastIndex:!!o,axis:s})},1344146:(n,i)=>{t.Cd(\"Softmax\",n,{axis:i})},1344209:(n,i)=>{t.Cd(\"Concat\",n,{axis:i})},1344269:(n,i,o,s,d)=>{t.Cd(\"Split\",n,{axis:i,numOutputs:o,splitSizes:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1344414:n=>{t.Cd(\"Expand\",n,void 0)},1344468:(n,i)=>{t.Cd(\"Gather\",n,{axis:Number(i)})},1344539:(n,i)=>{t.Cd(\"GatherElements\",n,{axis:Number(i)})},1344618:(n,i,o,s,d,f,h,g,b,w,$)=>{t.Cd(\"Resize\",n,{antialias:i,axes:o?Array.from(L.subarray(s>>>0,s+o>>>0)):[],coordinateTransformMode:it(d),cubicCoeffA:f,excludeOutside:h,extrapolationValue:g,keepAspectRatioPolicy:it(b),mode:it(w),nearestMode:it($)})},1344969:(n,i,o,s,d,f,h)=>{t.Cd(\"Slice\",n,{starts:i?Array.from(L.subarray(o>>>0,o+i>>>0)):[],ends:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[],axes:f?Array.from(L.subarray(h>>>0,h+f>>>0)):[]})},1345200:n=>{t.Cd(\"Tile\",n,void 0)},1345252:(n,i,o)=>{t.Cd(\"LayerNormalization\",n,{axis:Number(i),epsilon:Number(o)})},1345359:(n,i,o)=>{t.Cd(\"InstanceNormalization\",n,{epsilon:i,format:o?\"NHWC\":\"NCHW\"})},1345473:(n,i,o)=>{t.Cd(\"InstanceNormalization\",n,{epsilon:i,format:o?\"NHWC\":\"NCHW\"})},1345587:n=>{t.Cd(\"Range\",n,void 0)},1345640:(n,i)=>{t.Cd(\"Einsum\",n,{equation:it(i)})},1345721:(n,i,o,s,d)=>{t.Cd(\"Pad\",n,{mode:i,value:o,pads:s?Array.from(L.subarray(d>>>0,d+s>>>0)):[]})},1345853:(n,i,o,s,d,f)=>{t.Cd(\"BatchNormalization\",n,{epsilon:i,momentum:o,spatial:!!d,trainingMode:!!s,format:f?\"NHWC\":\"NCHW\"})},1346022:(n,i,o,s,d,f)=>{t.Cd(\"BatchNormalization\",n,{epsilon:i,momentum:o,spatial:!!d,trainingMode:!!s,format:f?\"NHWC\":\"NCHW\"})},1346191:(n,i,o,s,d,f,h,g,b)=>{t.Cd(\"Attention\",n,{numHeads:i,isUnidirectional:o,maskFilterValue:s,scale:d,doRotary:f,qkvHiddenSizes:h?Array.from(L.subarray(Number(g)>>>0,Number(g)+h>>>0)):[],pastPresentShareBuffer:!!b})},1346463:n=>{t.Cd(\"Gelu\",n,void 0)},1346515:(n,i,o,s,d,f)=>{t.Cd(\"MultiHeadAttention\",n,{numHeads:i,isUnidirectional:o,maskFilterValue:s,scale:d,doRotary:f})},1346674:n=>{t.Cd(\"BiasAdd\",n,void 0)},1346729:n=>{t.Cd(\"BiasSplitGelu\",n,void 0)},1346790:(n,i)=>{t.Cd(\"SkipLayerNormalization\",n,{epsilon:i})},1346871:(n,i,o,s,d,f,h,g,b,w,$,I,E)=>{t.Cd(\"Conv\",n,{format:b?\"NHWC\":\"NCHW\",auto_pad:i,dilations:[o],group:s,kernel_shape:[d],pads:f?Array.from(L.subarray(h>>>0,h+f>>>0)):[],strides:[g],w_is_const:()=>!!re[w>>>0],activation:it($),activation_params:I?Array.from(Se.subarray(E>>>0,E+I>>>0)):[]})},1347252:(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>{t.Cd(\"Conv\",n,{format:I?\"NHWC\":\"NCHW\",auto_pad:i,dilations:[o,s],group:d,kernel_shape:[f,h],pads:g?Array.from(L.subarray(b>>>0,b+g>>>0)):[],strides:[w,$],w_is_const:()=>!!re[E>>>0],activation:it(C),activation_params:D?Array.from(Se.subarray(V>>>0,V+D>>>0)):[]})},1347654:n=>{t.sh(n)},1347688:(n,i)=>t.th(n,i,t.Xg.uh,t.Xg.errors),1347800:n=>t.ph(n),1347833:n=>t.rh(n),1347865:(n,i,o)=>{t.eh(n,i,o,!0)},1347904:(n,i,o)=>{t.eh(n,i,o)}};function dt(n){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${n})`,this.status=n}var Wt=n=>{for(;0<n.length;)n.shift()(t)},_t=[],Ut=0,gt=0;function yt(n){this.Wg=n,this.Sg=n-24,this.mh=function(i){oe[this.Sg+4>>2>>>0]=i},this.bh=function(){return oe[this.Sg+4>>2>>>0]},this.lh=function(i){oe[this.Sg+8>>2>>>0]=i},this.fh=function(i){re[this.Sg+12>>0>>>0]=i?1:0},this.ih=function(){return re[this.Sg+12>>0>>>0]!=0},this.gh=function(i){re[this.Sg+13>>0>>>0]=i?1:0},this.oh=function(){return re[this.Sg+13>>0>>>0]!=0},this.kh=function(i,o){this.dh(0),this.mh(i),this.lh(o)},this.dh=function(i){oe[this.Sg+16>>2>>>0]=i},this.hh=function(){return oe[this.Sg+16>>2>>>0]},this.jh=function(){if(Br(this.bh()))return oe[this.Wg>>2>>>0];var i=this.hh();return i!==0?i:this.Wg}}var Nt=n=>{var i=gt;if(!i)return Dt(0),0;var o=new yt(i);o.dh(i);var s=o.bh();if(!s)return Dt(0),i;for(var d in n){var f=n[d];if(f===0||f===s)break;if(Rr(f,s,o.Sg+16))return Dt(f),i}return Dt(s),i},Mt=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,_r=(n,i,o)=>{i>>>=0;var s=i+o;for(o=i;n[o]&&!(o>=s);)++o;if(16<o-i&&n.buffer&&Mt)return Mt.decode(n.subarray(i,o));for(s=\"\";i<o;){var d=n[i++];if(d&128){var f=n[i++]&63;if((d&224)==192)s+=String.fromCharCode((d&31)<<6|f);else{var h=n[i++]&63;d=(d&240)==224?(d&15)<<12|f<<6|h:(d&7)<<18|f<<12|h<<6|n[i++]&63,65536>d?s+=String.fromCharCode(d):(d-=65536,s+=String.fromCharCode(55296|d>>10,56320|d&1023))}}else s+=String.fromCharCode(d)}return s},it=(n,i)=>(n>>>=0)?_r(fe,n,i):\"\",tr=n=>{for(var i=0,o=0;o<n.length;++o){var s=n.charCodeAt(o);127>=s?i++:2047>=s?i+=2:55296<=s&&57343>=s?(i+=4,++o):i+=3}return i},Ir=(n,i,o,s)=>{if(o>>>=0,!(0<s))return 0;var d=o;s=o+s-1;for(var f=0;f<n.length;++f){var h=n.charCodeAt(f);if(55296<=h&&57343>=h){var g=n.charCodeAt(++f);h=65536+((h&1023)<<10)|g&1023}if(127>=h){if(o>=s)break;i[o++>>>0]=h}else{if(2047>=h){if(o+1>=s)break;i[o++>>>0]=192|h>>6}else{if(65535>=h){if(o+2>=s)break;i[o++>>>0]=224|h>>12}else{if(o+3>=s)break;i[o++>>>0]=240|h>>18,i[o++>>>0]=128|h>>12&63}i[o++>>>0]=128|h>>6&63}i[o++>>>0]=128|h&63}}return i[o>>>0]=0,o-d},ct=n=>n%4===0&&(n%100!==0||n%400===0),rr=[0,31,60,91,121,152,182,213,244,274,305,335],Ht=[0,31,59,90,120,151,181,212,243,273,304,334],nr=n=>{var i=tr(n)+1,o=cr(i);return o&&Ir(n,fe,o,i),o},ir=[],Ar=(n,i)=>{ir.length=0;var o;for(i>>=2;o=fe[n++>>>0];)i+=o!=105&i,ir.push(o==105?L[i>>>0]:me[i++>>>1]),++i;return ir},or={},Tr=()=>{if(!Je){var n={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:m||\"./this.program\"},i;for(i in or)or[i]===void 0?delete n[i]:n[i]=or[i];var o=[];for(i in n)o.push(`${i}=${n[i]}`);Je=o}return Je},Je,Cn=[null,[],[]],ar=[31,29,31,30,31,30,31,31,30,31,30,31],be=[31,28,31,30,31,30,31,31,30,31,30,31];function sr(n){var i=Array(tr(n)+1);return Ir(n,i,0,i.length),i}function Er(n,i,o,s){function d(C,D,V){for(C=typeof C==\"number\"?C.toString():C||\"\";C.length<D;)C=V[0]+C;return C}function f(C,D){return d(C,D,\"0\")}function h(C,D){function V(ie){return 0>ie?-1:0<ie?1:0}var Q;return(Q=V(C.getFullYear()-D.getFullYear()))===0&&(Q=V(C.getMonth()-D.getMonth()))===0&&(Q=V(C.getDate()-D.getDate())),Q}function g(C){switch(C.getDay()){case 0:return new Date(C.getFullYear()-1,11,29);case 1:return C;case 2:return new Date(C.getFullYear(),0,3);case 3:return new Date(C.getFullYear(),0,2);case 4:return new Date(C.getFullYear(),0,1);case 5:return new Date(C.getFullYear()-1,11,31);case 6:return new Date(C.getFullYear()-1,11,30)}}function b(C){var D=C.Ug;for(C=new Date(new Date(C.Vg+1900,0,1).getTime());0<D;){var V=C.getMonth(),Q=(ct(C.getFullYear())?ar:be)[V];if(D>Q-C.getDate())D-=Q-C.getDate()+1,C.setDate(1),11>V?C.setMonth(V+1):(C.setMonth(0),C.setFullYear(C.getFullYear()+1));else{C.setDate(C.getDate()+D);break}}return V=new Date(C.getFullYear()+1,0,4),D=g(new Date(C.getFullYear(),0,4)),V=g(V),0>=h(D,C)?0>=h(V,C)?C.getFullYear()+1:C.getFullYear():C.getFullYear()-1}n>>>=0,i>>>=0,o>>>=0,s>>>=0;var w=L[s+40>>2>>>0];s={xh:L[s>>2>>>0],wh:L[s+4>>2>>>0],Yg:L[s+8>>2>>>0],ah:L[s+12>>2>>>0],Zg:L[s+16>>2>>>0],Vg:L[s+20>>2>>>0],Tg:L[s+24>>2>>>0],Ug:L[s+28>>2>>>0],Ah:L[s+32>>2>>>0],vh:L[s+36>>2>>>0],yh:w?it(w):\"\"},o=it(o),w={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var $ in w)o=o.replace(new RegExp($,\"g\"),w[$]);var I=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),E=\"January February March April May June July August September October November December\".split(\" \");w={\"%a\":C=>I[C.Tg].substring(0,3),\"%A\":C=>I[C.Tg],\"%b\":C=>E[C.Zg].substring(0,3),\"%B\":C=>E[C.Zg],\"%C\":C=>f((C.Vg+1900)/100|0,2),\"%d\":C=>f(C.ah,2),\"%e\":C=>d(C.ah,2,\" \"),\"%g\":C=>b(C).toString().substring(2),\"%G\":C=>b(C),\"%H\":C=>f(C.Yg,2),\"%I\":C=>(C=C.Yg,C==0?C=12:12<C&&(C-=12),f(C,2)),\"%j\":C=>{for(var D=0,V=0;V<=C.Zg-1;D+=(ct(C.Vg+1900)?ar:be)[V++]);return f(C.ah+D,3)},\"%m\":C=>f(C.Zg+1,2),\"%M\":C=>f(C.wh,2),\"%n\":()=>`\n`,\"%p\":C=>0<=C.Yg&&12>C.Yg?\"AM\":\"PM\",\"%S\":C=>f(C.xh,2),\"%t\":()=>\"\t\",\"%u\":C=>C.Tg||7,\"%U\":C=>f(Math.floor((C.Ug+7-C.Tg)/7),2),\"%V\":C=>{var D=Math.floor((C.Ug+7-(C.Tg+6)%7)/7);if(2>=(C.Tg+371-C.Ug-2)%7&&D++,D)D==53&&(V=(C.Tg+371-C.Ug)%7,V==4||V==3&&ct(C.Vg)||(D=1));else{D=52;var V=(C.Tg+7-C.Ug-1)%7;(V==4||V==5&&ct(C.Vg%400-1))&&D++}return f(D,2)},\"%w\":C=>C.Tg,\"%W\":C=>f(Math.floor((C.Ug+7-(C.Tg+6)%7)/7),2),\"%y\":C=>(C.Vg+1900).toString().substring(2),\"%Y\":C=>C.Vg+1900,\"%z\":C=>{C=C.vh;var D=0<=C;return C=Math.abs(C)/60,(D?\"+\":\"-\")+(\"0000\"+(C/60*100+C%60)).slice(-4)},\"%Z\":C=>C.yh,\"%%\":()=>\"%\"},o=o.replace(/%%/g,\"\\0\\0\");for($ in w)o.includes($)&&(o=o.replace(new RegExp($,\"g\"),w[$](s)));return o=o.replace(/\\0\\0/g,\"%\"),$=sr(o),$.length>i?0:(re.set($,n>>>0),$.length-1)}function ur(n){try{n()}catch(i){nt(i)}}function Sn(n){var i={},o;for(o in n)(function(s){var d=n[s];i[s]=typeof d==\"function\"?function(){Gt.push(s);try{return d.apply(null,arguments)}finally{X||(Gt.pop()===s||nt(),ft&&It===1&&Gt.length===0&&(It=0,ur(Ma),typeof Fibers<\"u\"&&Fibers.Bh()))}}:d})(o);return i}var It=0,ft=null,Or=0,Gt=[],kr={},lr={},xn=0,dr=null,_n=[];function In(){return new Promise((n,i)=>{dr={resolve:n,reject:i}})}function An(){var n=cr(65548),i=n+12;oe[n>>2>>>0]=i,oe[n+4>>2>>>0]=i+65536,i=Gt[0];var o=kr[i];return o===void 0&&(o=xn++,kr[i]=o,lr[o]=i),L[n+8>>2>>>0]=o,n}function Tn(n){if(!X){if(It===0){var i=!1,o=!1;n((s=0)=>{if(!X&&(Or=s,i=!0,o)){It=2,ur(()=>Da(ft)),typeof Browser<\"u\"&&Browser.$g.nh&&Browser.$g.resume(),s=!1;try{var d=(0,_[lr[L[ft+8>>2>>>0]]])()}catch(g){d=g,s=!0}var f=!1;if(!ft){var h=dr;h&&(dr=null,(s?h.reject:h.resolve)(d),f=!0)}if(s&&!f)throw d}}),o=!0,i||(It=1,ft=An(),typeof Browser<\"u\"&&Browser.$g.nh&&Browser.$g.pause(),ur(()=>Ba(ft)))}else It===2?(It=0,ur(ja),Pr(ft),ft=null,_n.forEach(s=>{if(!X)try{if(s(),!G)try{J=J=s=J,G||(t.onExit&&t.onExit(s),X=!0),y(s,new dt(s))}catch(d){d instanceof dt||d==\"unwind\"||y(1,d)}}catch(d){d instanceof dt||d==\"unwind\"||y(1,d)}})):nt(`invalid state: ${It}`);return Or}}function En(n){return Tn(i=>{n().then(i)})}var On={Ha:function(n,i,o){return En(async()=>{await t.qh(n,i,o)})},u:function(n){return n=new yt(n>>>0),n.ih()||(n.fh(!0),Ut--),n.gh(!1),_t.push(n),jt(n.Wg),n.jh()},C:function(){W(0,0);var n=_t.pop();Lt(n.Wg),gt=0},a:function(){return Nt([])},k:function(n){return Nt([n>>>0])},w:function(n,i){return Nt([n>>>0,i>>>0])},q:function(n,i,o){return Nt([n>>>0,i>>>0,o>>>0])},pa:function(){var n=_t.pop();n||nt(\"no exception to throw\");var i=n.Wg;throw n.oh()||(_t.push(n),n.gh(!0),n.fh(!1),Ut++),gt=i,gt},s:function(n,i,o){throw n>>>=0,new yt(n).kh(i>>>0,o>>>0),gt=n,Ut++,gt},$:function(){return Ut},g:function(n){throw gt||(gt=n>>>0),gt},qa:function(){return 0},oc:function(){},Pa:function(){},Ra:function(){},Ja:function(){return 0},Ub:function(){},Ta:function(){},Jb:function(){},Ca:function(){},Qa:function(){},Na:function(){},dc:function(){},Oa:function(){},Tc:()=>!0,Oc:function(n,i,o){n=i+2097152>>>0<4194305-!!n?(n>>>0)+4294967296*i:NaN,o>>>=0,n=new Date(1e3*n),L[o>>2>>>0]=n.getUTCSeconds(),L[o+4>>2>>>0]=n.getUTCMinutes(),L[o+8>>2>>>0]=n.getUTCHours(),L[o+12>>2>>>0]=n.getUTCDate(),L[o+16>>2>>>0]=n.getUTCMonth(),L[o+20>>2>>>0]=n.getUTCFullYear()-1900,L[o+24>>2>>>0]=n.getUTCDay(),L[o+28>>2>>>0]=(n.getTime()-Date.UTC(n.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},Pc:function(n,i,o){n=i+2097152>>>0<4194305-!!n?(n>>>0)+4294967296*i:NaN,o>>>=0,n=new Date(1e3*n),L[o>>2>>>0]=n.getSeconds(),L[o+4>>2>>>0]=n.getMinutes(),L[o+8>>2>>>0]=n.getHours(),L[o+12>>2>>>0]=n.getDate(),L[o+16>>2>>>0]=n.getMonth(),L[o+20>>2>>>0]=n.getFullYear()-1900,L[o+24>>2>>>0]=n.getDay(),L[o+28>>2>>>0]=(ct(n.getFullYear())?rr:Ht)[n.getMonth()]+n.getDate()-1|0,L[o+36>>2>>>0]=-(60*n.getTimezoneOffset()),i=new Date(n.getFullYear(),6,1).getTimezoneOffset();var s=new Date(n.getFullYear(),0,1).getTimezoneOffset();L[o+32>>2>>>0]=(i!=s&&n.getTimezoneOffset()==Math.min(s,i))|0},Qc:function(n){n>>>=0;var i=new Date(L[n+20>>2>>>0]+1900,L[n+16>>2>>>0],L[n+12>>2>>>0],L[n+8>>2>>>0],L[n+4>>2>>>0],L[n>>2>>>0],0),o=L[n+32>>2>>>0],s=i.getTimezoneOffset(),d=new Date(i.getFullYear(),6,1).getTimezoneOffset(),f=new Date(i.getFullYear(),0,1).getTimezoneOffset(),h=Math.min(f,d);return 0>o?L[n+32>>2>>>0]=+(d!=f&&h==s):0<o!=(h==s)&&(d=Math.max(f,d),i.setTime(i.getTime()+6e4*((0<o?h:d)-s))),L[n+24>>2>>>0]=i.getDay(),L[n+28>>2>>>0]=(ct(i.getFullYear())?rr:Ht)[i.getMonth()]+i.getDate()-1|0,L[n>>2>>>0]=i.getSeconds(),L[n+4>>2>>>0]=i.getMinutes(),L[n+8>>2>>>0]=i.getHours(),L[n+12>>2>>>0]=i.getDate(),L[n+16>>2>>>0]=i.getMonth(),L[n+20>>2>>>0]=i.getYear(),n=i.getTime()/1e3,Dt((at=n,1<=+Math.abs(at)?0<at?+Math.floor(at/4294967296)>>>0:~~+Math.ceil((at-+(~~at>>>0))/4294967296)>>>0:0)),n>>>0},Mc:function(){return-52},Nc:function(){},La:function(n,i,o){function s(b){return(b=b.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?b[1]:\"GMT\"}o>>>=0;var d=new Date().getFullYear(),f=new Date(d,0,1),h=new Date(d,6,1);d=f.getTimezoneOffset();var g=h.getTimezoneOffset();oe[n>>>0>>2>>>0]=60*Math.max(d,g),L[i>>>0>>2>>>0]=+(d!=g),n=s(f),i=s(h),n=nr(n),i=nr(i),g<d?(oe[o>>2>>>0]=n,oe[o+4>>2>>>0]=i):(oe[o>>2>>>0]=i,oe[o+4>>2>>>0]=n)},ja:()=>{nt(\"\")},x:function(n,i,o){return n>>>=0,i=Ar(i>>>0,o>>>0),xt[n].apply(null,i)},wa:function(n,i,o){return n>>>=0,i=Ar(i>>>0,o>>>0),xt[n].apply(null,i)},Ea:function(){return Date.now()},Ma:function(){return 4294901760},I:()=>performance.now(),yb:function(n,i,o){return i>>>=0,fe.copyWithin(n>>>0>>>0,i>>>0,i+(o>>>0)>>>0)},Ka:function(n){n>>>=0;var i=fe.length;if(4294901760<n)return!1;for(var o=1;4>=o;o*=2){var s=i*(1+.2/o);s=Math.min(s,n+100663296);var d=Math;s=Math.max(n,s);e:{d=d.min.call(d,4294901760,s+(65536-s%65536)%65536)-Y.buffer.byteLength+65535>>>16;try{Y.grow(d),Re();var f=1;break e}catch{}f=void 0}if(f)return!0}return!1},cb:function(n,i){n>>>=0,i>>>=0;var o=0;return Tr().forEach(function(s,d){var f=i+o;for(d=oe[n+4*d>>2>>>0]=f,f=0;f<s.length;++f)re[d++>>0>>>0]=s.charCodeAt(f);re[d>>0>>>0]=0,o+=s.length+1}),0},nb:function(n,i){n>>>=0,i>>>=0;var o=Tr();oe[n>>2>>>0]=o.length;var s=0;return o.forEach(function(d){s+=d.length+1}),oe[i>>2>>>0]=s,0},ma:()=>52,Ba:function(){return 52},Rc:function(){return 70},Aa:function(n,i,o,s){i>>>=0,o>>>=0,s>>>=0;for(var d=0,f=0;f<o;f++){var h=oe[i>>2>>>0],g=oe[i+4>>2>>>0];i+=8;for(var b=0;b<g;b++){var w=fe[h+b>>>0],$=Cn[n];w===0||w===10?((n===1?M:z)(_r($,0)),$.length=0):$.push(w)}d+=g}return oe[s>>2>>>0]=d,0},ia:uc,Sc:uf,M:Mc,K:sc,Uc:sf,Wc:nf,B:Cc,z:ic,b:Zd,Da:ef,aa:Hc,f:Kd,ra:tf,h:qd,F:Jc,i:tc,Vc:of,j:ec,t:Jd,r:ac,n:lc,W:fc,Y:Kc,J:gc,oa:Tc,ba:Oc,la:Yc,vb:wp,fb:Mp,yc:Cf,ab:Vp,db:jp,Sa:Kp,Rb:ep,Dc:yf,ib:Pp,Va:Fp,Nb:ip,eb:Dp,fc:Wf,Lc:lf,nc:Pf,gb:Bp,bb:zp,Bb:hp,jc:Df,mc:Rf,ec:Uf,Kc:df,Za:Np,$a:Wp,qb:_p,mb:Tp,_a:Up,hc:zf,Ib:up,lb:Ep,Ua:qp,Sb:Jf,Ic:ff,zc:$f,sc:Tf,pb:Ip,kc:Mf,Hb:lp,Gb:dp,c:Qd,_:xc,p:Xd,P:rf,Z:Vc,ha:bc,e:Yd,za:hc,G:Qc,da:Ic,O:Dc,ub:$p,fa:vc,d:rc,xa:$c,Fa:Zc,l:nc,va:_c,m:oc,ya:wc,ua:Ac,Ga:Gc,o:dc,V:Rc,ga:Pc,U:Bc,na:Wc,y:cc,A:pc,E:mc,X:Xc,ta:jc,ea:Sc,N:kc,L:Uc,D:Ec,ca:yc,T:zc,ka:af,R:Lc,sa:qc,Q:Fc,S:Nc,ic:jf,zb:yp,rb:xp,Db:pp,Ab:gp,Ac:wf,Mb:op,xb:bp,Eb:fp,Ob:np,cc:Nf,ob:Ap,Lb:ap,sb:Sp,kb:Op,qc:Of,Fc:hf,Ya:Hp,Pb:rp,wc:xf,jb:kp,uc:If,Hc:pf,vc:_f,Bc:vf,Xa:Gp,Ec:gf,wb:vp,Kb:sp,xc:Sf,Jc:cf,hb:Rp,Cb:mp,Xb:Yf,tb:Cp,Gc:mf,Yb:Kf,Qb:tp,gc:Vf,Cc:bf,pc:kf,Fb:cp,Wb:Zf,rc:Ef,lc:Bf,Wa:Lp,tc:Af,Tb:Qf,Vb:Xf,_b:Ff,$b:Lf,bc:Hf,Zb:qf,ac:Gf,v:function(n){return n>>>0},Ia:Er,H:function(n,i,o,s){return Er(n>>>0,i>>>0,o>>>0,s>>>0)}};(function(){function n(o){if(o=o.exports,o=Sn(o),_=o=Yp(o),Y=_.Xc,Re(),Be.unshift(_.Yc),Ae--,t.monitorRunDependencies&&t.monitorRunDependencies(Ae),Ae==0&&(St!==null&&(clearInterval(St),St=null),rt)){var s=rt;rt=null,s()}return o}var i={a:On};if(Ae++,t.monitorRunDependencies&&t.monitorRunDependencies(Ae),t.instantiateWasm)try{return t.instantiateWasm(i,n)}catch(o){z(\"Module.instantiateWasm callback failed with error: \"+o),a(o)}return Qe(i,function(o){n(o.instance)}).catch(a),{}})(),t._OrtInit=(n,i)=>(t._OrtInit=_.Zc)(n,i),t._OrtGetLastError=(n,i)=>(t._OrtGetLastError=_._c)(n,i),t._OrtCreateSessionOptions=(n,i,o,s,d,f,h,g,b,w)=>(t._OrtCreateSessionOptions=_.$c)(n,i,o,s,d,f,h,g,b,w),t._OrtAppendExecutionProvider=(n,i)=>(t._OrtAppendExecutionProvider=_.ad)(n,i),t._OrtAddFreeDimensionOverride=(n,i,o)=>(t._OrtAddFreeDimensionOverride=_.bd)(n,i,o),t._OrtAddSessionConfigEntry=(n,i,o)=>(t._OrtAddSessionConfigEntry=_.cd)(n,i,o),t._OrtReleaseSessionOptions=n=>(t._OrtReleaseSessionOptions=_.dd)(n),t._OrtCreateSession=(n,i,o)=>(t._OrtCreateSession=_.ed)(n,i,o),t._OrtReleaseSession=n=>(t._OrtReleaseSession=_.fd)(n),t._OrtGetInputOutputCount=(n,i,o)=>(t._OrtGetInputOutputCount=_.gd)(n,i,o),t._OrtGetInputName=(n,i)=>(t._OrtGetInputName=_.hd)(n,i),t._OrtGetOutputName=(n,i)=>(t._OrtGetOutputName=_.id)(n,i),t._OrtFree=n=>(t._OrtFree=_.jd)(n),t._OrtCreateTensor=(n,i,o,s,d,f)=>(t._OrtCreateTensor=_.kd)(n,i,o,s,d,f),t._OrtGetTensorData=(n,i,o,s,d)=>(t._OrtGetTensorData=_.ld)(n,i,o,s,d),t._OrtReleaseTensor=n=>(t._OrtReleaseTensor=_.md)(n),t._OrtCreateRunOptions=(n,i,o,s)=>(t._OrtCreateRunOptions=_.nd)(n,i,o,s),t._OrtAddRunConfigEntry=(n,i,o)=>(t._OrtAddRunConfigEntry=_.od)(n,i,o),t._OrtReleaseRunOptions=n=>(t._OrtReleaseRunOptions=_.pd)(n),t._OrtCreateBinding=n=>(t._OrtCreateBinding=_.qd)(n),t._OrtBindInput=(n,i,o)=>(t._OrtBindInput=_.rd)(n,i,o),t._OrtBindOutput=(n,i,o,s)=>(t._OrtBindOutput=_.sd)(n,i,o,s),t._OrtClearBoundOutputs=n=>(t._OrtClearBoundOutputs=_.td)(n),t._OrtReleaseBinding=n=>(t._OrtReleaseBinding=_.ud)(n),t._OrtRunWithBinding=(n,i,o,s,d)=>(t._OrtRunWithBinding=_.vd)(n,i,o,s,d),t._OrtRun=(n,i,o,s,d,f,h,g)=>(t._OrtRun=_.wd)(n,i,o,s,d,f,h,g),t._OrtEndProfiling=n=>(t._OrtEndProfiling=_.xd)(n),t._JsepOutput=(n,i,o)=>(t._JsepOutput=_.yd)(n,i,o),t._JsepGetNodeName=n=>(t._JsepGetNodeName=_.zd)(n);var cr=t._malloc=n=>(cr=t._malloc=_.Ad)(n),Pr=t._free=n=>(Pr=t._free=_.Bd)(n),W=(n,i)=>(W=_.Dd)(n,i),Dt=n=>(Dt=_.Ed)(n),U=()=>(U=_.Fd)(),N=n=>(N=_.Gd)(n),fr=n=>(fr=_.Hd)(n),Lt=n=>(Lt=_.Id)(n),jt=n=>(jt=_.Jd)(n),Rr=(n,i,o)=>(Rr=_.Kd)(n,i,o),Br=n=>(Br=_.Ld)(n),Mr=t.dynCall_vi=(n,i)=>(Mr=t.dynCall_vi=_.Md)(n,i),Dr=t.dynCall_vii=(n,i,o)=>(Dr=t.dynCall_vii=_.Nd)(n,i,o),jr=t.dynCall_iiii=(n,i,o,s)=>(jr=t.dynCall_iiii=_.Od)(n,i,o,s),pr=t.dynCall_iii=(n,i,o)=>(pr=t.dynCall_iii=_.Pd)(n,i,o),zr=t.dynCall_ii=(n,i)=>(zr=t.dynCall_ii=_.Qd)(n,i),kn=t.dynCall_iiiiiii=(n,i,o,s,d,f,h)=>(kn=t.dynCall_iiiiiii=_.Rd)(n,i,o,s,d,f,h),Ve=t.dynCall_v=n=>(Ve=t.dynCall_v=_.Sd)(n),mr=t.dynCall_iiiiii=(n,i,o,s,d,f)=>(mr=t.dynCall_iiiiii=_.Td)(n,i,o,s,d,f),hr=t.dynCall_iiij=(n,i,o,s,d)=>(hr=t.dynCall_iiij=_.Ud)(n,i,o,s,d),Vr=t.dynCall_iiiii=(n,i,o,s,d)=>(Vr=t.dynCall_iiiii=_.Vd)(n,i,o,s,d),gr=t.dynCall_viii=(n,i,o,s)=>(gr=t.dynCall_viii=_.Wd)(n,i,o,s),Wr=t.dynCall_j=n=>(Wr=t.dynCall_j=_.Xd)(n),Ur=t.dynCall_i=n=>(Ur=t.dynCall_i=_.Yd)(n),Nr=t.dynCall_iij=(n,i,o,s)=>(Nr=t.dynCall_iij=_.Zd)(n,i,o,s),Hr=t.dynCall_iiiiij=(n,i,o,s,d,f,h)=>(Hr=t.dynCall_iiiiij=_._d)(n,i,o,s,d,f,h),Gr=t.dynCall_vij=(n,i,o,s)=>(Gr=t.dynCall_vij=_.$d)(n,i,o,s),Pn=t.dynCall_viiiii=(n,i,o,s,d,f)=>(Pn=t.dynCall_viiiii=_.ae)(n,i,o,s,d,f),Lr=t.dynCall_viiii=(n,i,o,s,d)=>(Lr=t.dynCall_viiii=_.be)(n,i,o,s,d),Fr=t.dynCall_iiiiiiii=(n,i,o,s,d,f,h,g)=>(Fr=t.dynCall_iiiiiiii=_.ce)(n,i,o,s,d,f,h,g),qr=t.dynCall_fi=(n,i)=>(qr=t.dynCall_fi=_.de)(n,i),Rn=t.dynCall_fii=(n,i,o)=>(Rn=t.dynCall_fii=_.ee)(n,i,o),Bn=t.dynCall_ji=(n,i)=>(Bn=t.dynCall_ji=_.fe)(n,i),Kr=t.dynCall_di=(n,i)=>(Kr=t.dynCall_di=_.ge)(n,i),Ft=t.dynCall_jii=(n,i,o)=>(Ft=t.dynCall_jii=_.he)(n,i,o),Mn=t.dynCall_dii=(n,i,o)=>(Mn=t.dynCall_dii=_.ie)(n,i,o),bt=t.dynCall_iiiiiiiii=(n,i,o,s,d,f,h,g,b)=>(bt=t.dynCall_iiiiiiiii=_.je)(n,i,o,s,d,f,h,g,b),pt=t.dynCall_viij=(n,i,o,s,d)=>(pt=t.dynCall_viij=_.ke)(n,i,o,s,d),Yr=t.dynCall_viiiiii=(n,i,o,s,d,f,h)=>(Yr=t.dynCall_viiiiii=_.le)(n,i,o,s,d,f,h),qt=t.dynCall_vijj=(n,i,o,s,d,f)=>(qt=t.dynCall_vijj=_.me)(n,i,o,s,d,f),Zr=t.dynCall_viiiiiii=(n,i,o,s,d,f,h,g)=>(Zr=t.dynCall_viiiiiii=_.ne)(n,i,o,s,d,f,h,g),Xr=t.dynCall_iiiiiiiiii=(n,i,o,s,d,f,h,g,b,w)=>(Xr=t.dynCall_iiiiiiiiii=_.oe)(n,i,o,s,d,f,h,g,b,w),Dn=t.dynCall_viiiiiiii=(n,i,o,s,d,f,h,g,b)=>(Dn=t.dynCall_viiiiiiii=_.pe)(n,i,o,s,d,f,h,g,b),yr=t.dynCall_iiiiijiiiii=(n,i,o,s,d,f,h,g,b,w,$,I)=>(yr=t.dynCall_iiiiijiiiii=_.qe)(n,i,o,s,d,f,h,g,b,w,$,I),jn=t.dynCall_vijjjiiij=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(jn=t.dynCall_vijjjiiij=_.re)(n,i,o,s,d,f,h,g,b,w,$,I,E),zn=t.dynCall_viiji=(n,i,o,s,d,f)=>(zn=t.dynCall_viiji=_.se)(n,i,o,s,d,f),Vn=t.dynCall_viijiii=(n,i,o,s,d,f,h,g)=>(Vn=t.dynCall_viijiii=_.te)(n,i,o,s,d,f,h,g),Wn=t.dynCall_viiiiij=(n,i,o,s,d,f,h,g)=>(Wn=t.dynCall_viiiiij=_.ue)(n,i,o,s,d,f,h,g),Un=t.dynCall_viiiiiiiii=(n,i,o,s,d,f,h,g,b,w)=>(Un=t.dynCall_viiiiiiiii=_.ve)(n,i,o,s,d,f,h,g,b,w),Nn=t.dynCall_viid=(n,i,o,s)=>(Nn=t.dynCall_viid=_.we)(n,i,o,s),Hn=t.dynCall_iiiiiiiij=(n,i,o,s,d,f,h,g,b,w)=>(Hn=t.dynCall_iiiiiiiij=_.xe)(n,i,o,s,d,f,h,g,b,w),Gn=t.dynCall_iiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I)=>(Gn=t.dynCall_iiiiiiiiiiii=_.ye)(n,i,o,s,d,f,h,g,b,w,$,I),Kt=t.dynCall_viiiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>(Kt=t.dynCall_viiiiiiiiiiiii=_.ze)(n,i,o,s,d,f,h,g,b,w,$,I,E,C),br=t.dynCall_viijjjiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)=>(br=t.dynCall_viijjjiiiiii=_.Ae)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D),Qr=t.dynCall_viiijiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(Qr=t.dynCall_viiijiiiiiii=_.Be)(n,i,o,s,d,f,h,g,b,w,$,I,E),Jr=t.dynCall_viffiii=(n,i,o,s,d,f,h)=>(Jr=t.dynCall_viffiii=_.Ce)(n,i,o,s,d,f,h),en=t.dynCall_viiijjjii=(n,i,o,s,d,f,h,g,b,w,$,I)=>(en=t.dynCall_viiijjjii=_.De)(n,i,o,s,d,f,h,g,b,w,$,I),vr=t.dynCall_viifiii=(n,i,o,s,d,f,h)=>(vr=t.dynCall_viifiii=_.Ee)(n,i,o,s,d,f,h),wr=t.dynCall_viiiiidiidi=(n,i,o,s,d,f,h,g,b,w,$)=>(wr=t.dynCall_viiiiidiidi=_.Fe)(n,i,o,s,d,f,h,g,b,w,$),tn=t.dynCall_viiiiiiiiidi=(n,i,o,s,d,f,h,g,b,w,$,I)=>(tn=t.dynCall_viiiiiiiiidi=_.Ge)(n,i,o,s,d,f,h,g,b,w,$,I),rn=t.dynCall_vjiiiiii=(n,i,o,s,d,f,h,g,b)=>(rn=t.dynCall_vjiiiiii=_.He)(n,i,o,s,d,f,h,g,b),nn=t.dynCall_jiii=(n,i,o,s)=>(nn=t.dynCall_jiii=_.Ie)(n,i,o,s),$r=t.dynCall_viiid=(n,i,o,s,d)=>($r=t.dynCall_viiid=_.Je)(n,i,o,s,d),Yt=t.dynCall_viiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I)=>(Yt=t.dynCall_viiiiiiiiiii=_.Ke)(n,i,o,s,d,f,h,g,b,w,$,I),Cr=t.dynCall_vijjjjjjjjjjjjji=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt,ht)=>(Cr=t.dynCall_vijjjjjjjjjjjjji=_.Le)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt,ht),on=t.dynCall_viiiji=(n,i,o,s,d,f,h)=>(on=t.dynCall_viiiji=_.Me)(n,i,o,s,d,f,h),an=t.dynCall_vijjjiiji=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(an=t.dynCall_vijjjiiji=_.Ne)(n,i,o,s,d,f,h,g,b,w,$,I,E),sn=t.dynCall_iiiji=(n,i,o,s,d,f)=>(sn=t.dynCall_iiiji=_.Oe)(n,i,o,s,d,f),un=t.dynCall_iiijiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)=>(un=t.dynCall_iiijiiiiiiiiii=_.Pe)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D),ln=t.dynCall_vj=(n,i,o)=>(ln=t.dynCall_vj=_.Qe)(n,i,o),Ln=t.dynCall_jjj=(n,i,o,s,d)=>(Ln=t.dynCall_jjj=_.Re)(n,i,o,s,d),Zt=t.dynCall_iiijiiiiii=(n,i,o,s,d,f,h,g,b,w,$)=>(Zt=t.dynCall_iiijiiiiii=_.Se)(n,i,o,s,d,f,h,g,b,w,$),dn=t.dynCall_viiff=(n,i,o,s,d)=>(dn=t.dynCall_viiff=_.Te)(n,i,o,s,d),c=t.dynCall_viiiiiff=(n,i,o,s,d,f,h,g)=>(c=t.dynCall_viiiiiff=_.Ue)(n,i,o,s,d,f,h,g),v=t.dynCall_vfiii=(n,i,o,s,d)=>(v=t.dynCall_vfiii=_.Ve)(n,i,o,s,d),x=t.dynCall_viiiiff=(n,i,o,s,d,f,h)=>(x=t.dynCall_viiiiff=_.We)(n,i,o,s,d,f,h),B=t.dynCall_viiiiiiiiifiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>(B=t.dynCall_viiiiiiiiifiii=_.Xe)(n,i,o,s,d,f,h,g,b,w,$,I,E,C),H=t.dynCall_viiiiiiiijj=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(H=t.dynCall_viiiiiiiijj=_.Ye)(n,i,o,s,d,f,h,g,b,w,$,I,E),K=t.dynCall_iiiiiiiiiiiiiifii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q)=>(K=t.dynCall_iiiiiiiiiiiiiifii=_.Ze)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q),ee=t.dynCall_viiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(ee=t.dynCall_viiiiiiiiiiii=_._e)(n,i,o,s,d,f,h,g,b,w,$,I,E),pe=t.dynCall_ij=(n,i,o)=>(pe=t.dynCall_ij=_.$e)(n,i,o),de=t.dynCall_iiiiiiiiiiiiiiiiifii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve)=>(de=t.dynCall_iiiiiiiiiiiiiiiiifii=_.af)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve),ce=t.dynCall_vijjiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I)=>(ce=t.dynCall_vijjiiiiii=_.bf)(n,i,o,s,d,f,h,g,b,w,$,I),ge=t.dynCall_iiiijjj=(n,i,o,s,d,f,h,g,b,w)=>(ge=t.dynCall_iiiijjj=_.cf)(n,i,o,s,d,f,h,g,b,w),_e=t.dynCall_viiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$)=>(_e=t.dynCall_viiiiiiiiii=_.df)(n,i,o,s,d,f,h,g,b,w,$),Ee=t.dynCall_iiijjj=(n,i,o,s,d,f,h,g,b)=>(Ee=t.dynCall_iiijjj=_.ef)(n,i,o,s,d,f,h,g,b),F=t.dynCall_fffffff=(n,i,o,s,d,f,h)=>(F=t.dynCall_fffffff=_.ff)(n,i,o,s,d,f,h),ye=t.dynCall_viiiij=(n,i,o,s,d,f,h)=>(ye=t.dynCall_viiiij=_.gf)(n,i,o,s,d,f,h),Te=t.dynCall_viijj=(n,i,o,s,d,f,h)=>(Te=t.dynCall_viijj=_.hf)(n,i,o,s,d,f,h),At=t.dynCall_vjjjjjjffiifiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue)=>(At=t.dynCall_vjjjjjjffiifiiiiii=_.jf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue),cn=t.dynCall_viiiiiiffiifiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q)=>(cn=t.dynCall_viiiiiiffiifiiiii=_.kf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q),io=t.dynCall_viiiiiiffifiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>(io=t.dynCall_viiiiiiffifiiiii=_.lf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V),oo=t.dynCall_viiiiiiffiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)=>(oo=t.dynCall_viiiiiiffiiiiii=_.mf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D),ao=t.dynCall_vjjjjjjjjfffiifiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt,ht)=>(ao=t.dynCall_vjjjjjjjjfffiifiiiiii=_.nf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt,ht),so=t.dynCall_vjjjjjjfffifiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne)=>(so=t.dynCall_vjjjjjjfffifiiiiiii=_.of)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne),uo=t.dynCall_vjjjjjjfffifiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe)=>(uo=t.dynCall_vjjjjjjfffifiiiii=_.pf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe),lo=t.dynCall_vjjjjjjjjfffiifiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt)=>(lo=t.dynCall_vjjjjjjjjfffiifiiiii=_.qf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt),co=t.dynCall_vijjfffiii=(n,i,o,s,d,f,h,g,b,w,$,I)=>(co=t.dynCall_vijjfffiii=_.rf)(n,i,o,s,d,f,h,g,b,w,$,I),fo=t.dynCall_vijiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I)=>(fo=t.dynCall_vijiiiiiiii=_.sf)(n,i,o,s,d,f,h,g,b,w,$,I),po=t.dynCall_vijjjjjjifiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e)=>(po=t.dynCall_vijjjjjjifiiiii=_.tf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e),mo=t.dynCall_vjjjjjiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)=>(mo=t.dynCall_vjjjjjiiii=_.uf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D),ho=t.dynCall_vjjjjfiii=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(ho=t.dynCall_vjjjjfiii=_.vf)(n,i,o,s,d,f,h,g,b,w,$,I,E),go=t.dynCall_viifi=(n,i,o,s,d)=>(go=t.dynCall_viifi=_.wf)(n,i,o,s,d),yo=t.dynCall_iiiiiji=(n,i,o,s,d,f,h,g)=>(yo=t.dynCall_iiiiiji=_.xf)(n,i,o,s,d,f,h,g),bo=t.dynCall_vijjii=(n,i,o,s,d,f,h,g)=>(bo=t.dynCall_vijjii=_.yf)(n,i,o,s,d,f,h,g),vo=t.dynCall_viiijiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I)=>(vo=t.dynCall_viiijiiiiii=_.zf)(n,i,o,s,d,f,h,g,b,w,$,I),wo=t.dynCall_viiiiijjiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)=>(wo=t.dynCall_viiiiijjiiiii=_.Af)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D),$o=t.dynCall_iiiiji=(n,i,o,s,d,f,h)=>($o=t.dynCall_iiiiji=_.Bf)(n,i,o,s,d,f,h),Co=t.dynCall_viiiiijiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>(Co=t.dynCall_viiiiijiiiiii=_.Cf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C),So=t.dynCall_viiiijii=(n,i,o,s,d,f,h,g,b)=>(So=t.dynCall_viiiijii=_.Df)(n,i,o,s,d,f,h,g,b),xo=t.dynCall_viijjiii=(n,i,o,s,d,f,h,g,b,w)=>(xo=t.dynCall_viijjiii=_.Ef)(n,i,o,s,d,f,h,g,b,w),_o=t.dynCall_ijii=(n,i,o,s,d)=>(_o=t.dynCall_ijii=_.Ff)(n,i,o,s,d),Io=t.dynCall_jjjjjjj=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(Io=t.dynCall_jjjjjjj=_.Gf)(n,i,o,s,d,f,h,g,b,w,$,I,E),Ao=t.dynCall_jjjjjj=(n,i,o,s,d,f,h,g,b,w,$)=>(Ao=t.dynCall_jjjjjj=_.Hf)(n,i,o,s,d,f,h,g,b,w,$),To=t.dynCall_vijjjjiij=(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>(To=t.dynCall_vijjjjiij=_.If)(n,i,o,s,d,f,h,g,b,w,$,I,E,C),Eo=t.dynCall_viiiiijij=(n,i,o,s,d,f,h,g,b,w,$)=>(Eo=t.dynCall_viiiiijij=_.Jf)(n,i,o,s,d,f,h,g,b,w,$),Oo=t.dynCall_viiiiiijij=(n,i,o,s,d,f,h,g,b,w,$,I)=>(Oo=t.dynCall_viiiiiijij=_.Kf)(n,i,o,s,d,f,h,g,b,w,$,I),ko=t.dynCall_vijiii=(n,i,o,s,d,f,h)=>(ko=t.dynCall_vijiii=_.Lf)(n,i,o,s,d,f,h),Po=t.dynCall_viiiiiiiiifi=(n,i,o,s,d,f,h,g,b,w,$,I)=>(Po=t.dynCall_viiiiiiiiifi=_.Mf)(n,i,o,s,d,f,h,g,b,w,$,I),Ro=t.dynCall_iiijiiii=(n,i,o,s,d,f,h,g,b)=>(Ro=t.dynCall_iiijiiii=_.Nf)(n,i,o,s,d,f,h,g,b),Bo=t.dynCall_viiiiiijjiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>(Bo=t.dynCall_viiiiiijjiiiii=_.Of)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V),Mo=t.dynCall_viiiiiiijiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>(Mo=t.dynCall_viiiiiiijiiiiii=_.Pf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V),Do=t.dynCall_vif=(n,i,o)=>(Do=t.dynCall_vif=_.Qf)(n,i,o),jo=t.dynCall_viif=(n,i,o,s)=>(jo=t.dynCall_viif=_.Rf)(n,i,o,s),zo=t.dynCall_viiiiiifii=(n,i,o,s,d,f,h,g,b,w)=>(zo=t.dynCall_viiiiiifii=_.Sf)(n,i,o,s,d,f,h,g,b,w),Vo=t.dynCall_viiiiijiiiiiiiiiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe)=>(Vo=t.dynCall_viiiiijiiiiiiiiiiiiiiiiiii=_.Tf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe),Wo=t.dynCall_viijji=(n,i,o,s,d,f,h,g)=>(Wo=t.dynCall_viijji=_.Uf)(n,i,o,s,d,f,h,g),Uo=t.dynCall_iiiiiiiiiiiji=(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>(Uo=t.dynCall_iiiiiiiiiiiji=_.Vf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C),No=t.dynCall_viifiifijjjii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>(No=t.dynCall_viifiifijjjii=_.Wf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V),Ho=t.dynCall_viiiiiiiiiiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e)=>(Ho=t.dynCall_viiiiiiiiiiiiiiiiiiii=_.Xf)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e),Go=t.dynCall_iif=(n,i,o)=>(Go=t.dynCall_iif=_.Yf)(n,i,o),Lo=t.dynCall_viiiiifiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(Lo=t.dynCall_viiiiifiiiiii=_.Zf)(n,i,o,s,d,f,h,g,b,w,$,I,E),Fo=t.dynCall_vijiiiiiiijjii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q)=>(Fo=t.dynCall_vijiiiiiiijjii=_._f)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q),qo=t.dynCall_iiiiid=(n,i,o,s,d,f)=>(qo=t.dynCall_iiiiid=_.$f)(n,i,o,s,d,f),Ko=t.dynCall_viiiijjj=(n,i,o,s,d,f,h,g,b,w,$)=>(Ko=t.dynCall_viiiijjj=_.ag)(n,i,o,s,d,f,h,g,b,w,$),Yo=t.dynCall_viiiiiiiiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le)=>(Yo=t.dynCall_viiiiiiiiiiiiiiiiii=_.bg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le),Zo=t.dynCall_viiiiiiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q)=>(Zo=t.dynCall_viiiiiiiiiiiiiiii=_.cg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q),Xo=t.dynCall_viiiiiiiiiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve)=>(Xo=t.dynCall_viiiiiiiiiiiiiiiiiii=_.dg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve),Qo=t.dynCall_viiiiiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>(Qo=t.dynCall_viiiiiiiiiiiiiii=_.eg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V),Jo=t.dynCall_viiiiiiijjj=(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>(Jo=t.dynCall_viiiiiiijjj=_.fg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C),ea=t.dynCall_iiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$)=>(ea=t.dynCall_iiiiiiiiiii=_.gg)(n,i,o,s,d,f,h,g,b,w,$),ta=t.dynCall_iiiiiiiiiiiiiiiiiifi=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve)=>(ta=t.dynCall_iiiiiiiiiiiiiiiiiifi=_.hg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve),ra=t.dynCall_viiif=(n,i,o,s,d)=>(ra=t.dynCall_viiif=_.ig)(n,i,o,s,d),na=t.dynCall_iijjj=(n,i,o,s,d,f,h,g)=>(na=t.dynCall_iijjj=_.jg)(n,i,o,s,d,f,h,g),ia=t.dynCall_viiiiji=(n,i,o,s,d,f,h,g)=>(ia=t.dynCall_viiiiji=_.kg)(n,i,o,s,d,f,h,g),oa=t.dynCall_iijjji=(n,i,o,s,d,f,h,g,b)=>(oa=t.dynCall_iijjji=_.lg)(n,i,o,s,d,f,h,g,b),aa=t.dynCall_ijijji=(n,i,o,s,d,f,h,g,b)=>(aa=t.dynCall_ijijji=_.mg)(n,i,o,s,d,f,h,g,b),sa=t.dynCall_viiij=(n,i,o,s,d,f)=>(sa=t.dynCall_viiij=_.ng)(n,i,o,s,d,f),ua=t.dynCall_viiijjiii=(n,i,o,s,d,f,h,g,b,w,$)=>(ua=t.dynCall_viiijjiii=_.og)(n,i,o,s,d,f,h,g,b,w,$),la=t.dynCall_iiiiijji=(n,i,o,s,d,f,h,g,b,w)=>(la=t.dynCall_iiiiijji=_.pg)(n,i,o,s,d,f,h,g,b,w),da=t.dynCall_viji=(n,i,o,s,d)=>(da=t.dynCall_viji=_.qg)(n,i,o,s,d),ca=t.dynCall_iiiifi=(n,i,o,s,d,f)=>(ca=t.dynCall_iiiifi=_.rg)(n,i,o,s,d,f),fa=t.dynCall_iiijii=(n,i,o,s,d,f,h)=>(fa=t.dynCall_iiijii=_.sg)(n,i,o,s,d,f,h),pa=t.dynCall_iiiiiiiiijii=(n,i,o,s,d,f,h,g,b,w,$,I,E)=>(pa=t.dynCall_iiiiiiiiijii=_.tg)(n,i,o,s,d,f,h,g,b,w,$,I,E),ma=t.dynCall_iiiijjii=(n,i,o,s,d,f,h,g,b,w)=>(ma=t.dynCall_iiiijjii=_.ug)(n,i,o,s,d,f,h,g,b,w),ha=t.dynCall_iiiiiijjjii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>(ha=t.dynCall_iiiiiijjjii=_.vg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C),ga=t.dynCall_iiijiii=(n,i,o,s,d,f,h,g)=>(ga=t.dynCall_iiijiii=_.wg)(n,i,o,s,d,f,h,g),ya=t.dynCall_iiiiiiiijjjfi=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)=>(ya=t.dynCall_iiiiiiiijjjfi=_.xg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V),ba=t.dynCall_iijiiii=(n,i,o,s,d,f,h,g)=>(ba=t.dynCall_iijiiii=_.yg)(n,i,o,s,d,f,h,g),va=t.dynCall_iijjjii=(n,i,o,s,d,f,h,g,b,w)=>(va=t.dynCall_iijjjii=_.zg)(n,i,o,s,d,f,h,g,b,w),wa=t.dynCall_iiji=(n,i,o,s,d)=>(wa=t.dynCall_iiji=_.Ag)(n,i,o,s,d),$a=t.dynCall_viiijiiiii=(n,i,o,s,d,f,h,g,b,w,$)=>($a=t.dynCall_viiijiiiii=_.Bg)(n,i,o,s,d,f,h,g,b,w,$),Ca=t.dynCall_iid=(n,i,o)=>(Ca=t.dynCall_iid=_.Cg)(n,i,o),Sa=t.dynCall_iiif=(n,i,o,s)=>(Sa=t.dynCall_iiif=_.Dg)(n,i,o,s),xa=t.dynCall_vidi=(n,i,o,s)=>(xa=t.dynCall_vidi=_.Eg)(n,i,o,s),_a=t.dynCall_vjiii=(n,i,o,s,d,f)=>(_a=t.dynCall_vjiii=_.Fg)(n,i,o,s,d,f),Ia=t.dynCall_iiiij=(n,i,o,s,d,f)=>(Ia=t.dynCall_iiiij=_.Gg)(n,i,o,s,d,f),Aa=t.dynCall_viiijii=(n,i,o,s,d,f,h,g)=>(Aa=t.dynCall_viiijii=_.Hg)(n,i,o,s,d,f,h,g),Ta=t.dynCall_viijiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C)=>(Ta=t.dynCall_viijiiiiiiiii=_.Ig)(n,i,o,s,d,f,h,g,b,w,$,I,E,C),Ea=t.dynCall_fiiii=(n,i,o,s,d)=>(Ea=t.dynCall_fiiii=_.Jg)(n,i,o,s,d),Oa=t.dynCall_jfi=(n,i,o)=>(Oa=t.dynCall_jfi=_.Kg)(n,i,o),ka=t.dynCall_viiiiiiiiiiiiii=(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)=>(ka=t.dynCall_viiiiiiiiiiiiii=_.Lg)(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D),Pa=t.dynCall_jiij=(n,i,o,s,d)=>(Pa=t.dynCall_jiij=_.Mg)(n,i,o,s,d),Ra=t.dynCall_fiii=(n,i,o,s)=>(Ra=t.dynCall_fiii=_.Ng)(n,i,o,s),Ba=n=>(Ba=_.Og)(n),Ma=()=>(Ma=_.Pg)(),Da=n=>(Da=_.Qg)(n),ja=()=>(ja=_.Rg)();t.___start_em_js=1347937,t.___stop_em_js=1348098;function qd(n,i,o,s){var d=U();try{return jr(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function Kd(n,i,o){var s=U();try{return pr(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function Yd(n,i,o){var s=U();try{Dr(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function Zd(n,i){var o=U();try{return zr(n,i)}catch(s){if(N(o),s!==s+0)throw s;W(1,0)}}function Xd(n,i){var o=U();try{Mr(n,i)}catch(s){if(N(o),s!==s+0)throw s;W(1,0)}}function Qd(n){var i=U();try{Ve(n)}catch(o){if(N(i),o!==o+0)throw o;W(1,0)}}function Jd(n,i,o,s,d,f,h){var g=U();try{return kn(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function ec(n,i,o,s,d,f){var h=U();try{return mr(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function tc(n,i,o,s,d){var f=U();try{return Vr(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function rc(n,i,o,s){var d=U();try{gr(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function nc(n,i,o,s,d){var f=U();try{Lr(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function ic(n){var i=U();try{return Ur(n)}catch(o){if(N(i),o!==o+0)throw o;W(1,0)}}function oc(n,i,o,s,d,f){var h=U();try{Pn(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function ac(n,i,o,s,d,f,h,g){var b=U();try{return Fr(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function sc(n,i){var o=U();try{return qr(n,i)}catch(s){if(N(o),s!==s+0)throw s;W(1,0)}}function uc(n,i){var o=U();try{return Kr(n,i)}catch(s){if(N(o),s!==s+0)throw s;W(1,0)}}function lc(n,i,o,s,d,f,h,g,b){var w=U();try{return bt(n,i,o,s,d,f,h,g,b)}catch($){if(N(w),$!==$+0)throw $;W(1,0)}}function dc(n,i,o,s,d,f,h){var g=U();try{Yr(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function cc(n,i,o,s,d,f,h,g){var b=U();try{Zr(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function fc(n,i,o,s,d,f,h,g,b,w){var $=U();try{return Xr(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function pc(n,i,o,s,d,f,h,g,b){var w=U();try{Dn(n,i,o,s,d,f,h,g,b)}catch($){if(N(w),$!==$+0)throw $;W(1,0)}}function mc(n,i,o,s,d,f,h,g,b,w){var $=U();try{Un(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function hc(n,i,o,s){var d=U();try{Nn(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function gc(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{return Gn(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function yc(n,i,o,s,d,f,h,g,b,w,$,I,E,C){var D=U();try{Kt(n,i,o,s,d,f,h,g,b,w,$,I,E,C)}catch(V){if(N(D),V!==V+0)throw V;W(1,0)}}function bc(n,i,o,s,d,f,h){var g=U();try{Jr(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function vc(n,i,o,s,d,f,h){var g=U();try{vr(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function wc(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{wr(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function $c(n,i,o,s,d){var f=U();try{$r(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function Cc(n,i,o,s,d){var f=U();try{return Ea(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function Sc(n,i,o,s,d,f,h,g,b,w,$,I,E,C){var D=U();try{B(n,i,o,s,d,f,h,g,b,w,$,I,E,C)}catch(V){if(N(D),V!==V+0)throw V;W(1,0)}}function xc(n,i,o,s,d){var f=U();try{v(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function _c(n,i,o,s,d,f,h){var g=U();try{x(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function Ic(n,i,o,s,d){var f=U();try{dn(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function Ac(n,i,o,s,d,f,h,g){var b=U();try{c(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function Tc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q){var ie=U();try{return K(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q)}catch(le){if(N(ie),le!==le+0)throw le;W(1,0)}}function Ec(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{ee(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function Oc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve){var $e=U();try{return de(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve)}catch(Ce){if(N($e),Ce!==Ce+0)throw Ce;W(1,0)}}function kc(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{_e(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function Pc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q){var ie=U();try{cn(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q)}catch(le){if(N(ie),le!==le+0)throw le;W(1,0)}}function Rc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V){var Q=U();try{io(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)}catch(ie){if(N(Q),ie!==ie+0)throw ie;W(1,0)}}function Bc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D){var V=U();try{oo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)}catch(Q){if(N(V),Q!==Q+0)throw Q;W(1,0)}}function Mc(n,i,o,s,d,f,h){var g=U();try{return F(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function Dc(n,i,o,s,d){var f=U();try{go(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function jc(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{Po(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function zc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D){var V=U();try{ka(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)}catch(Q){if(N(V),Q!==Q+0)throw Q;W(1,0)}}function Vc(n,i,o){var s=U();try{Do(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function Wc(n,i,o,s,d,f,h,g,b,w){var $=U();try{zo(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function Uc(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{Yt(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function Nc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e){var Ce=U();try{Ho(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e)}catch(Oe){if(N(Ce),Oe!==Oe+0)throw Oe;W(1,0)}}function Hc(n,i,o){var s=U();try{return Go(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function Gc(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{Lo(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function Lc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q){var ie=U();try{Zo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q)}catch(le){if(N(ie),le!==le+0)throw le;W(1,0)}}function Fc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve){var $e=U();try{Xo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve)}catch(Ce){if(N($e),Ce!==Ce+0)throw Ce;W(1,0)}}function qc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le){var ve=U();try{Yo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le)}catch($e){if(N(ve),$e!==$e+0)throw $e;W(1,0)}}function Kc(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{return ea(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function Yc(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve){var $e=U();try{return ta(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve)}catch(Ce){if(N($e),Ce!==Ce+0)throw Ce;W(1,0)}}function Zc(n,i,o,s,d){var f=U();try{ra(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function Xc(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{tn(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function Qc(n,i,o,s){var d=U();try{jo(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function Jc(n,i,o,s,d,f){var h=U();try{return ca(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function ef(n,i,o){var s=U();try{return Ca(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function tf(n,i,o,s){var d=U();try{return Sa(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function rf(n,i,o,s){var d=U();try{xa(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function nf(n,i,o,s){var d=U();try{return Ra(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function of(n,i,o,s,d,f){var h=U();try{return qo(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function af(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V){var Q=U();try{Qo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)}catch(ie){if(N(Q),ie!==ie+0)throw ie;W(1,0)}}function sf(n,i,o){var s=U();try{return Rn(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function uf(n,i,o){var s=U();try{return Mn(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function lf(n,i,o,s,d){var f=U();try{return hr(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function df(n,i,o,s){var d=U();try{return Nr(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function cf(n,i,o,s){var d=U();try{Gr(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function ff(n,i){var o=U();try{return Bn(n,i)}catch(s){if(N(o),s!==s+0)throw s;W(1,0)}}function pf(n,i,o,s,d){var f=U();try{pt(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function mf(n,i,o,s,d,f){var h=U();try{qt(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function hf(n,i,o,s,d,f,h,g){var b=U();try{Aa(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function gf(n,i,o,s,d,f,h){var g=U();try{Te(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function yf(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{return yr(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function bf(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{jn(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function vf(n,i,o,s,d,f,h,g){var b=U();try{Vn(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function wf(n,i,o,s,d,f,h,g){var b=U();try{Wn(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function $f(n,i,o){var s=U();try{return Ft(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function Cf(n,i,o,s,d,f,h,g,b,w){var $=U();try{return Hn(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function Sf(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D){var V=U();try{br(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)}catch(Q){if(N(V),Q!==Q+0)throw Q;W(1,0)}}function xf(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{Qr(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function _f(n,i,o,s,d,f){var h=U();try{zn(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function If(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{en(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function Af(n,i,o,s,d,f,h,g,b){var w=U();try{rn(n,i,o,s,d,f,h,g,b)}catch($){if(N(w),$!==$+0)throw $;W(1,0)}}function Tf(n,i,o,s){var d=U();try{return nn(n,i,o,s)}catch(f){if(N(d),f!==f+0)throw f;W(1,0)}}function Ef(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt,ht){var Xt=U();try{Cr(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt,ht)}catch(Qt){if(N(Xt),Qt!==Qt+0)throw Qt;W(1,0)}}function Of(n,i,o,s,d,f,h){var g=U();try{on(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function kf(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{an(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function Pf(n,i,o,s,d,f){var h=U();try{return sn(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function Rf(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D){var V=U();try{return un(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)}catch(Q){if(N(V),Q!==Q+0)throw Q;W(1,0)}}function Bf(n,i,o){var s=U();try{ln(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function Mf(n,i,o,s,d){var f=U();try{return Ln(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function Df(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{return Zt(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function jf(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{H(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function zf(n,i,o){var s=U();try{return pe(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function Vf(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{ce(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function Wf(n,i,o,s,d,f,h,g,b,w){var $=U();try{return ge(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function Uf(n,i,o,s,d,f,h,g,b){var w=U();try{return Ee(n,i,o,s,d,f,h,g,b)}catch($){if(N(w),$!==$+0)throw $;W(1,0)}}function Nf(n,i,o,s,d,f,h){var g=U();try{ye(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function Hf(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue){var Ne=U();try{At(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue)}catch(Ke){if(N(Ne),Ke!==Ke+0)throw Ke;W(1,0)}}function Gf(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt,ht){var Xt=U();try{ao(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt,ht)}catch(Qt){if(N(Xt),Qt!==Qt+0)throw Qt;W(1,0)}}function Lf(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne){var Ke=U();try{so(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne)}catch(Xe){if(N(Ke),Xe!==Xe+0)throw Xe;W(1,0)}}function Ff(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe){var Ue=U();try{uo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe)}catch(Ne){if(N(Ue),Ne!==Ne+0)throw Ne;W(1,0)}}function qf(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt){var ht=U();try{lo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe,mt)}catch(Xt){if(N(ht),Xt!==Xt+0)throw Xt;W(1,0)}}function Kf(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{co(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function Yf(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{fo(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function Zf(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e){var Ce=U();try{po(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e)}catch(Oe){if(N(Ce),Oe!==Oe+0)throw Oe;W(1,0)}}function Xf(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D){var V=U();try{mo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)}catch(Q){if(N(V),Q!==Q+0)throw Q;W(1,0)}}function Qf(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{ho(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function Jf(n,i,o){var s=U();try{return Oa(n,i,o)}catch(d){if(N(s),d!==d+0)throw d;W(1,0)}}function ep(n,i,o,s,d,f,h,g){var b=U();try{return yo(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function tp(n,i,o,s,d,f,h,g){var b=U();try{bo(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function rp(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{vo(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function np(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D){var V=U();try{wo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D)}catch(Q){if(N(V),Q!==Q+0)throw Q;W(1,0)}}function ip(n,i,o,s,d,f,h){var g=U();try{return $o(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function op(n,i,o,s,d,f,h,g,b,w,$,I,E,C){var D=U();try{Co(n,i,o,s,d,f,h,g,b,w,$,I,E,C)}catch(V){if(N(D),V!==V+0)throw V;W(1,0)}}function ap(n,i,o,s,d,f,h,g,b){var w=U();try{So(n,i,o,s,d,f,h,g,b)}catch($){if(N(w),$!==$+0)throw $;W(1,0)}}function sp(n,i,o,s,d,f,h,g,b,w){var $=U();try{xo(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function up(n,i,o,s,d){var f=U();try{return _o(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function lp(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{return Ao(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function dp(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{return Io(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function cp(n,i,o,s,d,f,h,g,b,w,$,I,E,C){var D=U();try{To(n,i,o,s,d,f,h,g,b,w,$,I,E,C)}catch(V){if(N(D),V!==V+0)throw V;W(1,0)}}function fp(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{Eo(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function pp(n,i,o,s,d,f,h,g,b,w,$,I){var E=U();try{Oo(n,i,o,s,d,f,h,g,b,w,$,I)}catch(C){if(N(E),C!==C+0)throw C;W(1,0)}}function mp(n,i,o,s,d,f,h){var g=U();try{ko(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function hp(n,i,o,s,d,f,h,g,b){var w=U();try{return Ro(n,i,o,s,d,f,h,g,b)}catch($){if(N(w),$!==$+0)throw $;W(1,0)}}function gp(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V){var Q=U();try{Bo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)}catch(ie){if(N(Q),ie!==ie+0)throw ie;W(1,0)}}function yp(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V){var Q=U();try{Mo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)}catch(ie){if(N(Q),ie!==ie+0)throw ie;W(1,0)}}function bp(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe){var mt=U();try{Vo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q,ie,le,ve,$e,Ce,Oe,Ue,Ne,Ke,Xe)}catch(ht){if(N(mt),ht!==ht+0)throw ht;W(1,0)}}function vp(n,i,o,s,d,f,h,g){var b=U();try{Wo(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function wp(n,i,o,s,d,f,h,g,b,w,$,I,E,C){var D=U();try{return Uo(n,i,o,s,d,f,h,g,b,w,$,I,E,C)}catch(V){if(N(D),V!==V+0)throw V;W(1,0)}}function $p(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V){var Q=U();try{No(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)}catch(ie){if(N(Q),ie!==ie+0)throw ie;W(1,0)}}function Cp(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q){var ie=U();try{Fo(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V,Q)}catch(le){if(N(ie),le!==le+0)throw le;W(1,0)}}function Sp(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{Ko(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function xp(n,i,o,s,d,f,h,g,b,w,$,I,E,C){var D=U();try{Jo(n,i,o,s,d,f,h,g,b,w,$,I,E,C)}catch(V){if(N(D),V!==V+0)throw V;W(1,0)}}function _p(n,i,o,s,d,f,h,g){var b=U();try{return na(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function Ip(n,i,o,s,d){var f=U();try{return Pa(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function Ap(n,i,o,s,d,f,h,g){var b=U();try{ia(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function Tp(n,i,o,s,d,f,h,g,b){var w=U();try{return oa(n,i,o,s,d,f,h,g,b)}catch($){if(N(w),$!==$+0)throw $;W(1,0)}}function Ep(n,i,o,s,d,f,h,g,b){var w=U();try{return aa(n,i,o,s,d,f,h,g,b)}catch($){if(N(w),$!==$+0)throw $;W(1,0)}}function Op(n,i,o,s,d,f){var h=U();try{sa(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function kp(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{ua(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function Pp(n,i,o,s,d,f,h,g,b,w){var $=U();try{return la(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function Rp(n,i,o,s,d){var f=U();try{da(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function Bp(n,i,o,s,d,f,h){var g=U();try{return fa(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function Mp(n,i,o,s,d,f,h,g,b,w,$,I,E){var C=U();try{return pa(n,i,o,s,d,f,h,g,b,w,$,I,E)}catch(D){if(N(C),D!==D+0)throw D;W(1,0)}}function Dp(n,i,o,s,d,f,h,g,b,w){var $=U();try{return ma(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function jp(n,i,o,s,d,f,h,g,b,w,$,I,E,C){var D=U();try{return ha(n,i,o,s,d,f,h,g,b,w,$,I,E,C)}catch(V){if(N(D),V!==V+0)throw V;W(1,0)}}function zp(n,i,o,s,d,f,h,g){var b=U();try{return ga(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function Vp(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V){var Q=U();try{return ya(n,i,o,s,d,f,h,g,b,w,$,I,E,C,D,V)}catch(ie){if(N(Q),ie!==ie+0)throw ie;W(1,0)}}function Wp(n,i,o,s,d,f,h,g){var b=U();try{return ba(n,i,o,s,d,f,h,g)}catch(w){if(N(b),w!==w+0)throw w;W(1,0)}}function Up(n,i,o,s,d,f,h,g,b,w){var $=U();try{return va(n,i,o,s,d,f,h,g,b,w)}catch(I){if(N($),I!==I+0)throw I;W(1,0)}}function Np(n,i,o,s,d){var f=U();try{return wa(n,i,o,s,d)}catch(h){if(N(f),h!==h+0)throw h;W(1,0)}}function Hp(n,i,o,s,d,f,h,g,b,w,$){var I=U();try{$a(n,i,o,s,d,f,h,g,b,w,$)}catch(E){if(N(I),E!==E+0)throw E;W(1,0)}}function Gp(n,i,o,s,d,f,h,g,b,w,$,I,E,C){var D=U();try{Ta(n,i,o,s,d,f,h,g,b,w,$,I,E,C)}catch(V){if(N(D),V!==V+0)throw V;W(1,0)}}function Lp(n,i,o,s,d,f){var h=U();try{_a(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function Fp(n,i,o,s,d,f){var h=U();try{return Ia(n,i,o,s,d,f)}catch(g){if(N(h),g!==g+0)throw g;W(1,0)}}function qp(n){var i=U();try{return Wr(n)}catch(o){if(N(i),o!==o+0)throw o;W(1,0)}}function Kp(n,i,o,s,d,f,h){var g=U();try{return Hr(n,i,o,s,d,f,h)}catch(b){if(N(g),b!==b+0)throw b;W(1,0)}}function Yp(n){n=Object.assign({},n);var i=s=>()=>s()>>>0,o=s=>d=>s(d)>>>0;return n.__errno_location=i(n.__errno_location),n.malloc=o(n.malloc),n.stackSave=i(n.stackSave),n.stackAlloc=o(n.stackAlloc),n}t.stackAlloc=fr,t.stackSave=U,t.stackRestore=N,t.UTF8ToString=it,t.stringToUTF8=(n,i,o)=>Ir(n,fe,i,o),t.lengthBytesUTF8=tr;var Fn;rt=function n(){Fn||za(),Fn||(rt=n)};function za(){function n(){if(!Fn&&(Fn=!0,t.calledRun=!0,!X)){if(Wt(Be),u(t),t.onRuntimeInitialized&&t.onRuntimeInitialized(),t.postRun)for(typeof t.postRun==\"function\"&&(t.postRun=[t.postRun]);t.postRun.length;){var i=t.postRun.shift();Me.unshift(i)}Wt(Me)}}if(!(0<Ae)){if(t.preRun)for(typeof t.preRun==\"function\"&&(t.preRun=[t.preRun]);t.preRun.length;)De();Wt(ue),0<Ae||(t.setStatus?(t.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){t.setStatus(\"\")},1),n()},1)):n())}}if(t.preInit)for(typeof t.preInit==\"function\"&&(t.preInit=[t.preInit]);0<t.preInit.length;)t.preInit.pop()();return za(),r.ready}})();typeof Wa==\"object\"&&typeof _i==\"object\"?_i.exports=Va:typeof define==\"function\"&&define.amd&&define([],()=>Va)});var Na=fn(()=>{});var Ha=fn(()=>{});var Ga={};qn(Ga,{cpus:()=>rm});var rm,La=ae(()=>{rm=void 0});var Ka=fn((qa,Ii)=>{\"use strict\";var Fa=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(r={}){function t(){return Re.buffer!=Ae.buffer&&Ie(),Ae}function u(){return Re.buffer!=Ae.buffer&&Ie(),St}function a(){return Re.buffer!=Ae.buffer&&Ie(),rt}function p(){return Re.buffer!=Ae.buffer&&Ie(),nt}function m(){return Re.buffer!=Ae.buffer&&Ie(),ne}function y(){return Re.buffer!=Ae.buffer&&Ie(),we}var l=r,S,A;l.ready=new Promise((c,v)=>{S=c,A=v}),l.jsepInit=(c,v,x,B,H,K,ee,pe)=>{l.Qb=c,l.wb=v,l.yb=x,l.jb=B,l.xb=H,l.Ea=K,l.zb=ee,l.Ab=pe,v=(de,ce,ge)=>(..._e)=>{let Ee=pt,F=ce?.();_e=de(..._e);let ye=ce?.();return F!==ye&&(de=ye,ge(F),ce=ge=null),pt!=Ee?zn():_e},x=de=>async(...ce)=>{try{if(l.bb)throw Error(\"Session already started\");let ge=l.bb={Fb:ce[0],errors:[]},_e=await de(...ce);if(l.bb!==ge)throw Error(\"Session mismatch\");c.flush();let Ee=ge.errors;if(0<Ee.length){let F=await Promise.all(Ee);if(F=F.filter(ye=>ye),0<F.length)throw Error(F.join(`\n`))}return _e}finally{l.bb=null}},l._OrtRun=x(v(l._OrtRun,()=>l._OrtRun,de=>l._OrtRun=de)),l._OrtRunWithBinding=x(v(l._OrtRunWithBinding,()=>l._OrtRunWithBinding,de=>l._OrtRunWithBinding=de)),l._OrtBindInput=v(l._OrtBindInput,()=>l._OrtBindInput,de=>l._OrtBindInput=de),l.jsepRegisterBuffer=(de,ce,ge,_e)=>c.registerBuffer(de,ce,ge,_e),l.jsepUnregisterBuffers=de=>{c.unregisterBuffers(de)},l.jsepGetBuffer=de=>c.getBuffer(de),l.jsepCreateDownloader=(de,ce,ge)=>c.createDownloader(de,ce,ge)};var P=Object.assign({},l),T=\"./this.program\",k=(c,v)=>{throw v},O=typeof window==\"object\",R=typeof importScripts==\"function\",j=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",M=l.ENVIRONMENT_IS_PTHREAD||!1,z=\"\";function q(c){return l.locateFile?l.locateFile(c,z):z+c}var G,Y,_;if(j){var X=(Ci(),Sr($i)),J=(xi(),Sr(Si));z=R?J.dirname(z)+\"/\":__dirname+\"/\",G=(v,x)=>(v=v.startsWith(\"file://\")?new URL(v):J.normalize(v),X.readFileSync(v,x?void 0:\"utf8\")),_=v=>(v=G(v,!0),v.buffer||(v=new Uint8Array(v)),v),Y=(v,x,B,H=!0)=>{v=v.startsWith(\"file://\")?new URL(v):J.normalize(v),X.readFile(v,H?void 0:\"utf8\",(K,ee)=>{K?B(K):x(H?ee.buffer:ee)})},!l.thisProgram&&1<process.argv.length&&(T=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),k=(v,x)=>{throw process.exitCode=v,x},l.inspect=()=>\"[Emscripten Module object]\";let c;try{c=Na()}catch(v){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),v}global.Worker=c.Worker}else(O||R)&&(R?z=self.location.href:typeof document<\"u\"&&document.currentScript&&(z=document.currentScript.src),typeof e<\"u\"&&e&&(z=e),z.indexOf(\"blob:\")!==0?z=z.substr(0,z.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):z=\"\",j||(G=c=>{var v=new XMLHttpRequest;return v.open(\"GET\",c,!1),v.send(null),v.responseText},R&&(_=c=>{var v=new XMLHttpRequest;return v.open(\"GET\",c,!1),v.responseType=\"arraybuffer\",v.send(null),new Uint8Array(v.response)}),Y=(c,v,x)=>{var B=new XMLHttpRequest;B.open(\"GET\",c,!0),B.responseType=\"arraybuffer\",B.onload=()=>{B.status==200||B.status==0&&B.response?v(B.response):x()},B.onerror=x,B.send(null)}));j&&typeof performance>\"u\"&&(global.performance=Ha().performance);var re=console.log.bind(console),fe=console.error.bind(console);j&&(re=(...c)=>X.writeSync(1,c.join(\" \")+`\n`),fe=(...c)=>X.writeSync(2,c.join(\" \")+`\n`));var L=l.print||re,oe=l.printErr||fe;Object.assign(l,P),P=null,l.thisProgram&&(T=l.thisProgram),l.quit&&(k=l.quit);var Se;l.wasmBinary&&(Se=l.wasmBinary);var me=l.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&yt(\"no native wasm support detected\");var Re,ue,Be,Me=!1,De,Ae,St,rt,nt,ne,we;function Ie(){var c=Re.buffer;l.HEAP8=Ae=new Int8Array(c),l.HEAP16=new Int16Array(c),l.HEAP32=rt=new Int32Array(c),l.HEAPU8=St=new Uint8Array(c),l.HEAPU16=new Uint16Array(c),l.HEAPU32=nt=new Uint32Array(c),l.HEAPF32=ne=new Float32Array(c),l.HEAPF64=we=new Float64Array(c)}var tt=l.INITIAL_MEMORY||16777216;if(5242880<=tt||yt(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+tt+\"! (STACK_SIZE=5242880)\"),M)Re=l.wasmMemory;else if(l.wasmMemory)Re=l.wasmMemory;else if(Re=new WebAssembly.Memory({initial:tt/65536,maximum:65536,shared:!0}),!(Re.buffer instanceof SharedArrayBuffer))throw oe(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),j&&oe(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),Error(\"bad memory\");Ie(),tt=Re.buffer.byteLength;var st=[],Fe=[],Qe=[],at=0;function xt(){return me||0<at}var dt=0,Wt=null,_t=null;function Ut(){dt++,l.monitorRunDependencies&&l.monitorRunDependencies(dt)}function gt(){if(dt--,l.monitorRunDependencies&&l.monitorRunDependencies(dt),dt==0&&(Wt!==null&&(clearInterval(Wt),Wt=null),_t)){var c=_t;_t=null,c()}}function yt(c){throw l.onAbort&&l.onAbort(c),c=\"Aborted(\"+c+\")\",oe(c),Me=!0,De=1,c=new WebAssembly.RuntimeError(c+\". Build with -sASSERTIONS for more info.\"),A(c),c}function Nt(c){return c.startsWith(\"data:application/octet-stream;base64,\")}var Mt;Mt=\"ort-wasm-simd-threaded.wasm\",Nt(Mt)||(Mt=q(Mt));function _r(c){if(c==Mt&&Se)return new Uint8Array(Se);if(_)return _(c);throw\"both async and sync fetching of the wasm failed\"}function it(c){if(!Se&&(O||R)){if(typeof fetch==\"function\"&&!c.startsWith(\"file://\"))return fetch(c,{credentials:\"same-origin\"}).then(v=>{if(!v.ok)throw\"failed to load wasm binary file at '\"+c+\"'\";return v.arrayBuffer()}).catch(()=>_r(c));if(Y)return new Promise((v,x)=>{Y(c,B=>v(new Uint8Array(B)),x)})}return Promise.resolve().then(()=>_r(c))}function tr(c,v,x){return it(c).then(B=>WebAssembly.instantiate(B,v)).then(B=>B).then(x,B=>{oe(\"failed to asynchronously prepare wasm: \"+B),yt(B)})}function Ir(c,v){var x=Mt;return Se||typeof WebAssembly.instantiateStreaming!=\"function\"||Nt(x)||x.startsWith(\"file://\")||j||typeof fetch!=\"function\"?tr(x,c,v):fetch(x,{credentials:\"same-origin\"}).then(B=>WebAssembly.instantiateStreaming(B,c).then(v,function(H){return oe(\"wasm streaming compile failed: \"+H),oe(\"falling back to ArrayBuffer instantiation\"),tr(x,c,v)}))}var ct,rr={913596:c=>{l.Ea(\"Abs\",c,void 0)},913647:c=>{l.Ea(\"Neg\",c,void 0)},913698:c=>{l.Ea(\"Floor\",c,void 0)},913751:c=>{l.Ea(\"Ceil\",c,void 0)},913803:c=>{l.Ea(\"Reciprocal\",c,void 0)},913861:c=>{l.Ea(\"Sqrt\",c,void 0)},913913:c=>{l.Ea(\"Exp\",c,void 0)},913964:c=>{l.Ea(\"Erf\",c,void 0)},914015:c=>{l.Ea(\"Sigmoid\",c,void 0)},914070:c=>{l.Ea(\"Log\",c,void 0)},914121:c=>{l.Ea(\"Sin\",c,void 0)},914172:c=>{l.Ea(\"Cos\",c,void 0)},914223:c=>{l.Ea(\"Tan\",c,void 0)},914274:c=>{l.Ea(\"Asin\",c,void 0)},914326:c=>{l.Ea(\"Acos\",c,void 0)},914378:c=>{l.Ea(\"Atan\",c,void 0)},914430:c=>{l.Ea(\"Sinh\",c,void 0)},914482:c=>{l.Ea(\"Cosh\",c,void 0)},914534:c=>{l.Ea(\"Asinh\",c,void 0)},914587:c=>{l.Ea(\"Acosh\",c,void 0)},914640:c=>{l.Ea(\"Atanh\",c,void 0)},914693:c=>{l.Ea(\"Tanh\",c,void 0)},914745:c=>{l.Ea(\"Not\",c,void 0)},914796:(c,v,x)=>{l.Ea(\"Clip\",c,{min:v,max:x})},914865:c=>{l.Ea(\"Clip\",c,void 0)},914917:(c,v)=>{l.Ea(\"Elu\",c,{alpha:v})},914975:c=>{l.Ea(\"Relu\",c,void 0)},915027:(c,v)=>{l.Ea(\"LeakyRelu\",c,{alpha:v})},915091:(c,v)=>{l.Ea(\"ThresholdedRelu\",c,{alpha:v})},915161:(c,v)=>{l.Ea(\"Cast\",c,{to:v})},915219:c=>{l.Ea(\"Add\",c,void 0)},915270:c=>{l.Ea(\"Sub\",c,void 0)},915321:c=>{l.Ea(\"Mul\",c,void 0)},915372:c=>{l.Ea(\"Div\",c,void 0)},915423:c=>{l.Ea(\"Pow\",c,void 0)},915474:c=>{l.Ea(\"Equal\",c,void 0)},915527:c=>{l.Ea(\"Greater\",c,void 0)},915582:c=>{l.Ea(\"GreaterOrEqual\",c,void 0)},915644:c=>{l.Ea(\"Less\",c,void 0)},915696:c=>{l.Ea(\"LessOrEqual\",c,void 0)},915755:(c,v,x,B,H)=>{l.Ea(\"ReduceMean\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},915919:(c,v,x,B,H)=>{l.Ea(\"ReduceMax\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},916082:(c,v,x,B,H)=>{l.Ea(\"ReduceMin\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},916245:(c,v,x,B,H)=>{l.Ea(\"ReduceProd\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},916409:(c,v,x,B,H)=>{l.Ea(\"ReduceSum\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},916572:(c,v,x,B,H)=>{l.Ea(\"ReduceL1\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},916734:(c,v,x,B,H)=>{l.Ea(\"ReduceL2\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},916896:(c,v,x,B,H)=>{l.Ea(\"ReduceLogSum\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},917062:(c,v,x,B,H)=>{l.Ea(\"ReduceSumSquare\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},917231:(c,v,x,B,H)=>{l.Ea(\"ReduceLogSumExp\",c,{keepDims:!!v,noopWithEmptyAxes:!!x,axes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},917400:c=>{l.Ea(\"Where\",c,void 0)},917453:(c,v,x)=>{l.Ea(\"Transpose\",c,{perm:v?Array.from(a().subarray(x>>>0,x+v>>>0)):[]})},917566:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F,ye)=>{l.Ea(\"ConvTranspose\",c,{format:de?\"NHWC\":\"NCHW\",autoPad:v,dilations:[x],group:B,kernel_shape:[H],pads:[K,ee],strides:[pe],wIsConst:()=>!!t()[ce>>>0],outputPadding:ge?Array.from(a().subarray(_e>>>0,_e+ge>>>0)):[],outputShape:Ee?Array.from(a().subarray(F>>>0,F+Ee>>>0)):[],activation:Je(ye)})},917980:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F)=>{l.Ea(\"ConvTranspose\",c,{format:pe?\"NHWC\":\"NCHW\",autoPad:v,dilations:Array.from(a().subarray(x>>>0,x+2>>>0)),group:B,kernelShape:Array.from(a().subarray(H>>>0,H+2>>>0)),pads:Array.from(a().subarray(K>>>0,K+4>>>0)),strides:Array.from(a().subarray(ee>>>0,ee+2>>>0)),wIsConst:()=>!!t()[de>>>0],outputPadding:0<ce?Array.from(a().subarray(ge>>>0,ge+ce>>>0)):[],outputShape:0<_e?Array.from(a().subarray(Ee>>>0,Ee+_e>>>0)):[],activation:Je(F)})},918537:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F,ye)=>{l.Ea(\"ConvTranspose\",c,{format:de?\"NHWC\":\"NCHW\",autoPad:v,dilations:[x],group:B,kernel_shape:[H],pads:[K,ee],strides:[pe],wIsConst:()=>!!t()[ce>>>0],outputPadding:ge?Array.from(a().subarray(_e>>>0,_e+ge>>>0)):[],outputShape:Ee?Array.from(a().subarray(F>>>0,F+Ee>>>0)):[],activation:Je(ye)})},918951:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F)=>{l.Ea(\"ConvTranspose\",c,{format:pe?\"NHWC\":\"NCHW\",autoPad:v,dilations:Array.from(a().subarray(x>>>0,x+2>>>0)),group:B,kernelShape:Array.from(a().subarray(H>>>0,H+2>>>0)),pads:Array.from(a().subarray(K>>>0,K+4>>>0)),strides:Array.from(a().subarray(ee>>>0,ee+2>>>0)),wIsConst:()=>!!t()[de>>>0],outputPadding:0<ce?Array.from(a().subarray(ge>>>0,ge+ce>>>0)):[],outputShape:0<_e?Array.from(a().subarray(Ee>>>0,Ee+_e>>>0)):[],activation:Je(F)})},919508:(c,v)=>{l.Ea(\"GlobalAveragePool\",c,{format:v?\"NHWC\":\"NCHW\"})},919599:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F,ye,Te)=>{l.Ea(\"AveragePool\",c,{format:Te?\"NHWC\":\"NCHW\",auto_pad:v,ceil_mode:x,count_include_pad:B,storage_order:H,dilations:[K,ee],kernel_shape:[pe,de],pads:[ce,ge,_e,Ee],strides:[F,ye]})},919883:(c,v)=>{l.Ea(\"GlobalAveragePool\",c,{format:v?\"NHWC\":\"NCHW\"})},919974:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F,ye,Te)=>{l.Ea(\"AveragePool\",c,{format:Te?\"NHWC\":\"NCHW\",auto_pad:v,ceil_mode:x,count_include_pad:B,storage_order:H,dilations:[K,ee],kernel_shape:[pe,de],pads:[ce,ge,_e,Ee],strides:[F,ye]})},920258:(c,v)=>{l.Ea(\"GlobalMaxPool\",c,{format:v?\"NHWC\":\"NCHW\"})},920345:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F,ye,Te)=>{l.Ea(\"MaxPool\",c,{format:Te?\"NHWC\":\"NCHW\",auto_pad:v,ceil_mode:x,count_include_pad:B,storage_order:H,dilations:[K,ee],kernel_shape:[pe,de],pads:[ce,ge,_e,Ee],strides:[F,ye]})},920625:(c,v)=>{l.Ea(\"GlobalMaxPool\",c,{format:v?\"NHWC\":\"NCHW\"})},920712:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F,ye,Te)=>{l.Ea(\"MaxPool\",c,{format:Te?\"NHWC\":\"NCHW\",auto_pad:v,ceil_mode:x,count_include_pad:B,storage_order:H,dilations:[K,ee],kernel_shape:[pe,de],pads:[ce,ge,_e,Ee],strides:[F,ye]})},920992:(c,v,x,B,H)=>{l.Ea(\"Gemm\",c,{alpha:v,beta:x,transA:B,transB:H})},921096:c=>{l.Ea(\"MatMul\",c,void 0)},921150:(c,v,x,B)=>{l.Ea(\"ArgMax\",c,{keepDims:!!v,selectLastIndex:!!x,axis:B})},921258:(c,v,x,B)=>{l.Ea(\"ArgMin\",c,{keepDims:!!v,selectLastIndex:!!x,axis:B})},921366:(c,v)=>{l.Ea(\"Softmax\",c,{axis:v})},921429:(c,v)=>{l.Ea(\"Concat\",c,{axis:v})},921489:(c,v,x,B,H)=>{l.Ea(\"Split\",c,{axis:v,numOutputs:x,splitSizes:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},921634:c=>{l.Ea(\"Expand\",c,void 0)},921688:(c,v)=>{l.Ea(\"Gather\",c,{axis:Number(v)})},921759:(c,v)=>{l.Ea(\"GatherElements\",c,{axis:Number(v)})},921838:(c,v,x,B,H,K,ee,pe,de,ce,ge)=>{l.Ea(\"Resize\",c,{antialias:v,axes:x?Array.from(a().subarray(B>>>0,B+x>>>0)):[],coordinateTransformMode:Je(H),cubicCoeffA:K,excludeOutside:ee,extrapolationValue:pe,keepAspectRatioPolicy:Je(de),mode:Je(ce),nearestMode:Je(ge)})},922189:(c,v,x,B,H,K,ee)=>{l.Ea(\"Slice\",c,{starts:v?Array.from(a().subarray(x>>>0,x+v>>>0)):[],ends:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[],axes:K?Array.from(a().subarray(ee>>>0,ee+K>>>0)):[]})},922420:c=>{l.Ea(\"Tile\",c,void 0)},922472:(c,v,x)=>{l.Ea(\"LayerNormalization\",c,{axis:Number(v),epsilon:Number(x)})},922579:(c,v,x)=>{l.Ea(\"InstanceNormalization\",c,{epsilon:v,format:x?\"NHWC\":\"NCHW\"})},922693:(c,v,x)=>{l.Ea(\"InstanceNormalization\",c,{epsilon:v,format:x?\"NHWC\":\"NCHW\"})},922807:c=>{l.Ea(\"Range\",c,void 0)},922860:(c,v)=>{l.Ea(\"Einsum\",c,{equation:Je(v)})},922941:(c,v,x,B,H)=>{l.Ea(\"Pad\",c,{mode:v,value:x,pads:B?Array.from(a().subarray(H>>>0,H+B>>>0)):[]})},923073:(c,v,x,B,H,K)=>{l.Ea(\"BatchNormalization\",c,{epsilon:v,momentum:x,spatial:!!H,trainingMode:!!B,format:K?\"NHWC\":\"NCHW\"})},923242:(c,v,x,B,H,K)=>{l.Ea(\"BatchNormalization\",c,{epsilon:v,momentum:x,spatial:!!H,trainingMode:!!B,format:K?\"NHWC\":\"NCHW\"})},923411:(c,v,x)=>{l.Ea(\"CumSum\",c,{exclusive:Number(v),reverse:Number(x)})},923508:(c,v,x,B,H,K,ee,pe,de)=>{l.Ea(\"Attention\",c,{numHeads:v,isUnidirectional:x,maskFilterValue:B,scale:H,doRotary:K,qkvHiddenSizes:ee?Array.from(a().subarray(Number(pe)>>>0,Number(pe)+ee>>>0)):[],pastPresentShareBuffer:!!de})},923780:c=>{l.Ea(\"Gelu\",c,void 0)},923832:(c,v,x,B,H,K)=>{l.Ea(\"MultiHeadAttention\",c,{numHeads:v,isUnidirectional:x,maskFilterValue:B,scale:H,doRotary:K})},923991:c=>{l.Ea(\"BiasAdd\",c,void 0)},924046:c=>{l.Ea(\"BiasSplitGelu\",c,void 0)},924107:(c,v)=>{l.Ea(\"SkipLayerNormalization\",c,{epsilon:v})},924188:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee)=>{l.Ea(\"Conv\",c,{format:de?\"NHWC\":\"NCHW\",auto_pad:v,dilations:[x],group:B,kernel_shape:[H],pads:K?Array.from(a().subarray(ee>>>0,ee+K>>>0)):[],strides:[pe],w_is_const:()=>!!t()[ce>>>0],activation:Je(ge),activation_params:_e?Array.from(m().subarray(Ee>>>0,Ee+_e>>>0)):[]})},924569:(c,v,x,B,H,K,ee,pe,de,ce,ge,_e,Ee,F,ye,Te)=>{l.Ea(\"Conv\",c,{format:_e?\"NHWC\":\"NCHW\",auto_pad:v,dilations:[x,B],group:H,kernel_shape:[K,ee],pads:pe?Array.from(a().subarray(de>>>0,de+pe>>>0)):[],strides:[ce,ge],w_is_const:()=>!!t()[Ee>>>0],activation:Je(F),activation_params:ye?Array.from(m().subarray(Te>>>0,Te+ye>>>0)):[]})},924971:c=>{l.zb(c)},925005:(c,v)=>l.Ab(c,v,l.bb.Fb,l.bb.errors),925117:c=>l.wb(c),925150:c=>l.yb(c),925182:(c,v,x)=>{l.jb(c,v,x,!0)},925221:(c,v,x)=>{l.jb(c,v,x)}};function Ht(c){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${c})`,this.status=c}function nr(c){c.terminate(),c.onmessage=()=>{}}function ir(c){(c=be.Qa[c])||yt(),be.Eb(c)}function Ar(c){var v=be.tb();if(!v)return 6;be.Ya.push(v),be.Qa[c.Xa]=v,v.Xa=c.Xa;var x={cmd:\"run\",start_routine:c.Gb,arg:c.rb,pthread_ptr:c.Xa};return j&&v.unref(),v.postMessage(x,c.Mb),0}var or=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,Tr=(c,v,x)=>{v>>>=0;var B=v+x;for(x=v;c[x]&&!(x>=B);)++x;if(16<x-v&&c.buffer&&or)return or.decode(c.buffer instanceof SharedArrayBuffer?c.slice(v,x):c.subarray(v,x));for(B=\"\";v<x;){var H=c[v++];if(H&128){var K=c[v++]&63;if((H&224)==192)B+=String.fromCharCode((H&31)<<6|K);else{var ee=c[v++]&63;H=(H&240)==224?(H&15)<<12|K<<6|ee:(H&7)<<18|K<<12|ee<<6|c[v++]&63,65536>H?B+=String.fromCharCode(H):(H-=65536,B+=String.fromCharCode(55296|H>>10,56320|H&1023))}}else B+=String.fromCharCode(H)}return B},Je=(c,v)=>(c>>>=0)?Tr(u(),c,v):\"\";function Cn(c){if(M)return Ve(1,1,c);De=c,xt()||(be.Hb(),l.onExit&&l.onExit(c),Me=!0),k(c,new Ht(c))}var ar=c=>{if(De=c,M)throw Er(c),\"unwind\";Cn(c)},be={ab:[],Ya:[],mb:[],Qa:{},gb:function(){M?be.vb():be.ub()},ub:function(){st.unshift(()=>{Ut(),be.Bb(()=>gt())})},vb:function(){be.receiveObjectTransfer=be.Db,be.threadInitTLS=be.lb,be.setExitStatus=be.kb,me=!1},kb:function(c){De=c},Sb:[\"$terminateWorker\"],Hb:function(){for(var c of be.Ya)nr(c);for(c of be.ab)nr(c);be.ab=[],be.Ya=[],be.Qa=[]},Eb:function(c){var v=c.Xa;delete be.Qa[v],be.ab.push(c),be.Ya.splice(be.Ya.indexOf(c),1),c.Xa=0,vr(v)},Db:function(){},lb:function(){be.mb.forEach(c=>c())},Cb:c=>new Promise(v=>{c.onmessage=K=>{K=K.data;var ee=K.cmd;if(K.targetThread&&K.targetThread!=Kt()){var pe=be.Qa[K.Rb];pe?pe.postMessage(K,K.transferList):oe('Internal error! Worker sent a message \"'+ee+'\" to target pthread '+K.targetThread+\", but that thread no longer exists!\")}else ee===\"checkMailbox\"?Lt():ee===\"spawnThread\"?Ar(K):ee===\"cleanupThread\"?ir(K.thread):ee===\"killThread\"?(K=K.thread,ee=be.Qa[K],delete be.Qa[K],nr(ee),vr(K),be.Ya.splice(be.Ya.indexOf(ee),1),ee.Xa=0):ee===\"cancelThread\"?be.Qa[K.thread].postMessage({cmd:\"cancel\"}):ee===\"loaded\"?(c.loaded=!0,v(c)):ee===\"alert\"?alert(\"Thread \"+K.threadId+\": \"+K.text):K.target===\"setimmediate\"?c.postMessage(K):ee===\"callHandler\"?l[K.handler](...K.args):ee&&oe(\"worker sent an unknown command \"+ee)},c.onerror=K=>{throw oe(\"worker sent an error! \"+K.filename+\":\"+K.lineno+\": \"+K.message),K},j&&(c.on(\"message\",function(K){c.onmessage({data:K})}),c.on(\"error\",function(K){c.onerror(K)}));var x=[],B=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],H;for(H of B)l.hasOwnProperty(H)&&x.push(H);c.postMessage({cmd:\"load\",handlers:x,urlOrBlob:l.mainScriptUrlOrBlob||e,wasmMemory:Re,wasmModule:Be})}),Bb:function(c){c()},qb:function(){var c=q(\"ort-wasm-simd-threaded.worker.js\");c=new Worker(c),be.ab.push(c)},tb:function(){return be.ab.length==0&&(be.qb(),be.Cb(be.ab[0])),be.ab.pop()}};l.PThread=be;var sr=c=>{for(;0<c.length;)c.shift()(l)};l.establishStackSpace=function(){var c=Kt(),v=a()[c+52>>2>>>0];c=a()[c+56>>2>>>0],nn(v,v-c),Yt(v)};function Er(c){if(M)return Ve(2,0,c);ar(c)}l.invokeEntryPoint=function(c,v){c=on.apply(null,[c,v]),xt()?be.kb(c):wr(c)};function ur(c){this.fb=c-24,this.pb=function(v){p()[this.fb+4>>2>>>0]=v},this.ob=function(v){p()[this.fb+8>>2>>>0]=v},this.gb=function(v,x){this.nb(),this.pb(v),this.ob(x)},this.nb=function(){p()[this.fb+16>>2>>>0]=0}}var Sn=0,It=0;function ft(c,v,x,B){return M?Ve(3,1,c,v,x,B):Or(c,v,x,B)}function Or(c,v,x,B){if(c>>>=0,v>>>=0,x>>>=0,B>>>=0,typeof SharedArrayBuffer>\"u\")return oe(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var H=[];return M&&H.length===0?ft(c,v,x,B):(c={Gb:x,Xa:c,rb:B,Mb:H},M?(c.Ob=\"spawnThread\",postMessage(c,H),0):Ar(c))}function Gt(c,v,x){return M?Ve(4,1,c,v,x):0}function kr(c,v){if(M)return Ve(5,1,c,v)}var lr=c=>{for(var v=0,x=0;x<c.length;++x){var B=c.charCodeAt(x);127>=B?v++:2047>=B?v+=2:55296<=B&&57343>=B?(v+=4,++x):v+=3}return v},xn=(c,v,x,B)=>{if(x>>>=0,!(0<B))return 0;var H=x;B=x+B-1;for(var K=0;K<c.length;++K){var ee=c.charCodeAt(K);if(55296<=ee&&57343>=ee){var pe=c.charCodeAt(++K);ee=65536+((ee&1023)<<10)|pe&1023}if(127>=ee){if(x>=B)break;v[x++>>>0]=ee}else{if(2047>=ee){if(x+1>=B)break;v[x++>>>0]=192|ee>>6}else{if(65535>=ee){if(x+2>=B)break;v[x++>>>0]=224|ee>>12}else{if(x+3>=B)break;v[x++>>>0]=240|ee>>18,v[x++>>>0]=128|ee>>12&63}v[x++>>>0]=128|ee>>6&63}v[x++>>>0]=128|ee&63}}return v[x>>>0]=0,x-H},dr=(c,v,x)=>xn(c,u(),v,x);function _n(c,v){if(M)return Ve(6,1,c,v)}function In(c,v,x){if(M)return Ve(7,1,c,v,x)}function An(c,v,x){return M?Ve(8,1,c,v,x):0}function Tn(c,v){if(M)return Ve(9,1,c,v)}function En(c,v,x){if(M)return Ve(10,1,c,v,x)}function On(c,v,x,B){if(M)return Ve(11,1,c,v,x,B)}function cr(c,v,x,B){if(M)return Ve(12,1,c,v,x,B)}function Pr(c,v,x,B){if(M)return Ve(13,1,c,v,x,B)}function W(c){if(M)return Ve(14,1,c)}function Dt(c,v){if(M)return Ve(15,1,c,v)}function U(c,v,x){if(M)return Ve(16,1,c,v,x)}var N=c=>{if(!Me)try{if(c(),!xt())try{M?wr(De):ar(De)}catch(v){v instanceof Ht||v==\"unwind\"||k(1,v)}}catch(v){v instanceof Ht||v==\"unwind\"||k(1,v)}};function fr(c){c>>>=0,typeof Atomics.Nb==\"function\"&&(Atomics.Nb(a(),c>>2,c).value.then(Lt),c+=128,Atomics.store(a(),c>>2,1))}l.__emscripten_thread_mailbox_await=fr;function Lt(){var c=Kt();c&&(fr(c),N(()=>tn()))}l.checkMailbox=Lt;var jt=c=>c%4===0&&(c%100!==0||c%400===0),Rr=[0,31,60,91,121,152,182,213,244,274,305,335],Br=[0,31,59,90,120,151,181,212,243,273,304,334];function Mr(c,v,x,B,H,K,ee,pe){return M?Ve(17,1,c,v,x,B,H,K,ee,pe):-52}function Dr(c,v,x,B,H,K,ee){if(M)return Ve(18,1,c,v,x,B,H,K,ee)}var jr=c=>{var v=lr(c)+1,x=br(v);return x&&dr(c,x,v),x},pr=[],zr=(c,v)=>{pr.length=0;var x;for(v>>=2;x=u()[c++>>>0];)v+=x!=105&v,pr.push(x==105?a()[v>>>0]:y()[v++>>>1]),++v;return pr},kn=c=>{var v=$r();return c=c(),Yt(v),c};function Ve(c,v){var x=arguments.length-2,B=arguments;return kn(()=>{for(var H=Cr(8*x),K=H>>3,ee=0;ee<x;ee++){var pe=B[2+ee];y()[K+ee>>>0]=pe}return en(c,x,H,v)})}var mr=[],hr={},Vr=()=>{if(!gr){var c={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:T||\"./this.program\"},v;for(v in hr)hr[v]===void 0?delete c[v]:c[v]=hr[v];var x=[];for(v in c)x.push(`${v}=${c[v]}`);gr=x}return gr},gr;function Wr(c,v){if(M)return Ve(19,1,c,v);c>>>=0,v>>>=0;var x=0;return Vr().forEach(function(B,H){var K=v+x;for(H=p()[c+4*H>>2>>>0]=K,K=0;K<B.length;++K)t()[H++>>0>>>0]=B.charCodeAt(K);t()[H>>0>>>0]=0,x+=B.length+1}),0}function Ur(c,v){if(M)return Ve(20,1,c,v);c>>>=0,v>>>=0;var x=Vr();p()[c>>2>>>0]=x.length;var B=0;return x.forEach(function(H){B+=H.length+1}),p()[v>>2>>>0]=B,0}function Nr(c){return M?Ve(21,1,c):52}function Hr(c,v,x,B){return M?Ve(22,1,c,v,x,B):52}function Gr(c,v,x,B,H){return M?Ve(23,1,c,v,x,B,H):70}var Pn=[null,[],[]];function Lr(c,v,x,B){if(M)return Ve(24,1,c,v,x,B);v>>>=0,x>>>=0,B>>>=0;for(var H=0,K=0;K<x;K++){var ee=p()[v>>2>>>0],pe=p()[v+4>>2>>>0];v+=8;for(var de=0;de<pe;de++){var ce=u()[ee+de>>>0],ge=Pn[c];ce===0||ce===10?((c===1?L:oe)(Tr(ge,0)),ge.length=0):ge.push(ce)}H+=pe}return p()[B>>2>>>0]=H,0}var Fr=[31,29,31,30,31,30,31,31,30,31,30,31],qr=[31,28,31,30,31,30,31,31,30,31,30,31];function Rn(c){var v=Array(lr(c)+1);return xn(c,v,0,v.length),v}var Bn=(c,v)=>{t().set(c,v>>>0)};function Kr(c,v,x,B){function H(F,ye,Te){for(F=typeof F==\"number\"?F.toString():F||\"\";F.length<ye;)F=Te[0]+F;return F}function K(F,ye){return H(F,ye,\"0\")}function ee(F,ye){function Te(cn){return 0>cn?-1:0<cn?1:0}var At;return(At=Te(F.getFullYear()-ye.getFullYear()))===0&&(At=Te(F.getMonth()-ye.getMonth()))===0&&(At=Te(F.getDate()-ye.getDate())),At}function pe(F){switch(F.getDay()){case 0:return new Date(F.getFullYear()-1,11,29);case 1:return F;case 2:return new Date(F.getFullYear(),0,3);case 3:return new Date(F.getFullYear(),0,2);case 4:return new Date(F.getFullYear(),0,1);case 5:return new Date(F.getFullYear()-1,11,31);case 6:return new Date(F.getFullYear()-1,11,30)}}function de(F){var ye=F.Za;for(F=new Date(new Date(F.$a+1900,0,1).getTime());0<ye;){var Te=F.getMonth(),At=(jt(F.getFullYear())?Fr:qr)[Te];if(ye>At-F.getDate())ye-=At-F.getDate()+1,F.setDate(1),11>Te?F.setMonth(Te+1):(F.setMonth(0),F.setFullYear(F.getFullYear()+1));else{F.setDate(F.getDate()+ye);break}}return Te=new Date(F.getFullYear()+1,0,4),ye=pe(new Date(F.getFullYear(),0,4)),Te=pe(Te),0>=ee(ye,F)?0>=ee(Te,F)?F.getFullYear()+1:F.getFullYear():F.getFullYear()-1}c>>>=0,v>>>=0,x>>>=0,B>>>=0;var ce=a()[B+40>>2>>>0];B={Kb:a()[B>>2>>>0],Jb:a()[B+4>>2>>>0],cb:a()[B+8>>2>>>0],ib:a()[B+12>>2>>>0],eb:a()[B+16>>2>>>0],$a:a()[B+20>>2>>>0],Wa:a()[B+24>>2>>>0],Za:a()[B+28>>2>>>0],Tb:a()[B+32>>2>>>0],Ib:a()[B+36>>2>>>0],Lb:ce?Je(ce):\"\"},x=Je(x),ce={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var ge in ce)x=x.replace(new RegExp(ge,\"g\"),ce[ge]);var _e=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),Ee=\"January February March April May June July August September October November December\".split(\" \");ce={\"%a\":F=>_e[F.Wa].substring(0,3),\"%A\":F=>_e[F.Wa],\"%b\":F=>Ee[F.eb].substring(0,3),\"%B\":F=>Ee[F.eb],\"%C\":F=>K((F.$a+1900)/100|0,2),\"%d\":F=>K(F.ib,2),\"%e\":F=>H(F.ib,2,\" \"),\"%g\":F=>de(F).toString().substring(2),\"%G\":F=>de(F),\"%H\":F=>K(F.cb,2),\"%I\":F=>(F=F.cb,F==0?F=12:12<F&&(F-=12),K(F,2)),\"%j\":F=>{for(var ye=0,Te=0;Te<=F.eb-1;ye+=(jt(F.$a+1900)?Fr:qr)[Te++]);return K(F.ib+ye,3)},\"%m\":F=>K(F.eb+1,2),\"%M\":F=>K(F.Jb,2),\"%n\":()=>`\n`,\"%p\":F=>0<=F.cb&&12>F.cb?\"AM\":\"PM\",\"%S\":F=>K(F.Kb,2),\"%t\":()=>\"\t\",\"%u\":F=>F.Wa||7,\"%U\":F=>K(Math.floor((F.Za+7-F.Wa)/7),2),\"%V\":F=>{var ye=Math.floor((F.Za+7-(F.Wa+6)%7)/7);if(2>=(F.Wa+371-F.Za-2)%7&&ye++,ye)ye==53&&(Te=(F.Wa+371-F.Za)%7,Te==4||Te==3&&jt(F.$a)||(ye=1));else{ye=52;var Te=(F.Wa+7-F.Za-1)%7;(Te==4||Te==5&&jt(F.$a%400-1))&&ye++}return K(ye,2)},\"%w\":F=>F.Wa,\"%W\":F=>K(Math.floor((F.Za+7-(F.Wa+6)%7)/7),2),\"%y\":F=>(F.$a+1900).toString().substring(2),\"%Y\":F=>F.$a+1900,\"%z\":F=>{F=F.Ib;var ye=0<=F;return F=Math.abs(F)/60,(ye?\"+\":\"-\")+(\"0000\"+(F/60*100+F%60)).slice(-4)},\"%Z\":F=>F.Lb,\"%%\":()=>\"%\"},x=x.replace(/%%/g,\"\\0\\0\");for(ge in ce)x.includes(ge)&&(x=x.replace(new RegExp(ge,\"g\"),ce[ge](B)));return x=x.replace(/\\0\\0/g,\"%\"),ge=Rn(x),ge.length>v?0:(Bn(ge,c),ge.length-1)}function Ft(c){try{c()}catch(v){yt(v)}}function Mn(c){var v={},x;for(x in c)(function(B){var H=c[B];v[B]=typeof H==\"function\"?function(){qt.push(B);try{return H.apply(null,arguments)}finally{Me||(qt.pop()===B||yt(),pt&&bt===1&&qt.length===0&&(bt=0,at+=1,Ft(sn),typeof Fibers<\"u\"&&Fibers.Ub()))}}:H})(x);return v}var bt=0,pt=null,Yr=0,qt=[],Zr={},Xr={},Dn=0,yr=null,jn=[];function zn(){return new Promise((c,v)=>{yr={resolve:c,reject:v}})}function Vn(){var c=br(65548),v=c+12;p()[c>>2>>>0]=v,p()[c+4>>2>>>0]=v+65536,v=qt[0];var x=Zr[v];return x===void 0&&(x=Dn++,Zr[v]=x,Xr[x]=v),v=x,a()[c+8>>2>>>0]=v,c}function Wn(){var c=a()[pt+8>>2>>>0];return c=ue[Xr[c]],--at,c()}function Un(c){if(!Me){if(bt===0){var v=!1,x=!1;c((B=0)=>{if(!Me&&(Yr=B,v=!0,x)){bt=2,Ft(()=>un(pt)),typeof Browser<\"u\"&&Browser.hb.sb&&Browser.hb.resume(),B=!1;try{var H=Wn()}catch(pe){H=pe,B=!0}var K=!1;if(!pt){var ee=yr;ee&&(yr=null,(B?ee.reject:ee.resolve)(H),K=!0)}if(B&&!K)throw H}}),x=!0,v||(bt=1,pt=Vn(),typeof Browser<\"u\"&&Browser.hb.sb&&Browser.hb.pause(),Ft(()=>an(pt)))}else bt===2?(bt=0,Ft(ln),Qr(pt),pt=null,jn.forEach(B=>N(B))):yt(`invalid state: ${bt}`);return Yr}}function Nn(c){return Un(v=>{c().then(v)})}be.gb();var Hn=[null,Cn,Er,ft,Gt,kr,_n,In,An,Tn,En,On,cr,Pr,W,Dt,U,Mr,Dr,Wr,Ur,Nr,Hr,Gr,Lr],Gn={r:function(c,v,x){return Nn(async()=>{await l.xb(c,v,x)})},b:function(c,v,x){throw c>>>=0,new ur(c).gb(v>>>0,x>>>0),Sn=c,It++,Sn},O:function(c){Jr(c>>>0,!R,1,!O,131072,!1),be.lb()},l:function(c){c>>>=0,M?postMessage({cmd:\"cleanupThread\",thread:c}):ir(c)},I:Or,i:Gt,U:kr,E:_n,G:In,V:An,S:Tn,K:En,R:On,p:cr,F:Pr,C:W,T:Dt,D:U,q:()=>!0,A:function(c,v){c>>>=0,c==v>>>0?setTimeout(()=>Lt()):M?postMessage({targetThread:c,cmd:\"checkMailbox\"}):(c=be.Qa[c])&&c.postMessage({cmd:\"checkMailbox\"})},M:function(){return-1},N:fr,X:function(c){j&&be.Qa[c>>>0].ref()},u:function(c,v,x){c=v+2097152>>>0<4194305-!!c?(c>>>0)+4294967296*v:NaN,x>>>=0,c=new Date(1e3*c),a()[x>>2>>>0]=c.getUTCSeconds(),a()[x+4>>2>>>0]=c.getUTCMinutes(),a()[x+8>>2>>>0]=c.getUTCHours(),a()[x+12>>2>>>0]=c.getUTCDate(),a()[x+16>>2>>>0]=c.getUTCMonth(),a()[x+20>>2>>>0]=c.getUTCFullYear()-1900,a()[x+24>>2>>>0]=c.getUTCDay(),c=(c.getTime()-Date.UTC(c.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,a()[x+28>>2>>>0]=c},v:function(c,v,x){c=v+2097152>>>0<4194305-!!c?(c>>>0)+4294967296*v:NaN,x>>>=0,c=new Date(1e3*c),a()[x>>2>>>0]=c.getSeconds(),a()[x+4>>2>>>0]=c.getMinutes(),a()[x+8>>2>>>0]=c.getHours(),a()[x+12>>2>>>0]=c.getDate(),a()[x+16>>2>>>0]=c.getMonth(),a()[x+20>>2>>>0]=c.getFullYear()-1900,a()[x+24>>2>>>0]=c.getDay(),v=(jt(c.getFullYear())?Rr:Br)[c.getMonth()]+c.getDate()-1|0,a()[x+28>>2>>>0]=v,a()[x+36>>2>>>0]=-(60*c.getTimezoneOffset()),v=new Date(c.getFullYear(),6,1).getTimezoneOffset();var B=new Date(c.getFullYear(),0,1).getTimezoneOffset();c=(v!=B&&c.getTimezoneOffset()==Math.min(B,v))|0,a()[x+32>>2>>>0]=c},w:function(c){c>>>=0;var v=new Date(a()[c+20>>2>>>0]+1900,a()[c+16>>2>>>0],a()[c+12>>2>>>0],a()[c+8>>2>>>0],a()[c+4>>2>>>0],a()[c>>2>>>0],0),x=a()[c+32>>2>>>0],B=v.getTimezoneOffset(),H=new Date(v.getFullYear(),6,1).getTimezoneOffset(),K=new Date(v.getFullYear(),0,1).getTimezoneOffset(),ee=Math.min(K,H);return 0>x?a()[c+32>>2>>>0]=+(H!=K&&ee==B):0<x!=(ee==B)&&(H=Math.max(K,H),v.setTime(v.getTime()+6e4*((0<x?ee:H)-B))),a()[c+24>>2>>>0]=v.getDay(),x=(jt(v.getFullYear())?Rr:Br)[v.getMonth()]+v.getDate()-1|0,a()[c+28>>2>>>0]=x,a()[c>>2>>>0]=v.getSeconds(),a()[c+4>>2>>>0]=v.getMinutes(),a()[c+8>>2>>>0]=v.getHours(),a()[c+12>>2>>>0]=v.getDate(),a()[c+16>>2>>>0]=v.getMonth(),a()[c+20>>2>>>0]=v.getYear(),c=v.getTime()/1e3,rn((ct=c,1<=+Math.abs(ct)?0<ct?+Math.floor(ct/4294967296)>>>0:~~+Math.ceil((ct-+(~~ct>>>0))/4294967296)>>>0:0)),c>>>0},s:Mr,t:Dr,z:function(c,v,x){function B(ce){return(ce=ce.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?ce[1]:\"GMT\"}c>>>=0,v>>>=0,x>>>=0;var H=new Date().getFullYear(),K=new Date(H,0,1),ee=new Date(H,6,1);H=K.getTimezoneOffset();var pe=ee.getTimezoneOffset(),de=Math.max(H,pe);p()[c>>2>>>0]=60*de,a()[v>>2>>>0]=+(H!=pe),c=B(K),v=B(ee),c=jr(c),v=jr(v),pe<H?(p()[x>>2>>>0]=c,p()[x+4>>2>>>0]=v):(p()[x>>2>>>0]=v,p()[x+4>>2>>>0]=c)},d:()=>{yt(\"\")},c:function(c,v,x){return c>>>=0,v=zr(v>>>0,x>>>0),rr[c].apply(null,v)},k:function(c,v,x){return c>>>=0,v=zr(v>>>0,x>>>0),rr[c].apply(null,v)},m:function(){},j:function(){return Date.now()},W:()=>{throw at+=1,\"unwind\"},B:function(){return 4294901760},f:()=>performance.timeOrigin+performance.now(),g:function(){return j?(La(),Sr(Ga)).cpus().length:navigator.hardwareConcurrency},L:function(c,v,x,B){for(be.Pb=v>>>0,mr.length=x,v=B>>>0>>3,B=0;B<x;B++)mr[B]=y()[v+B>>>0];return(0>c?rr[-c-1]:Hn[c]).apply(null,mr)},y:function(c){c>>>=0;var v=u().length;if(c<=v||4294901760<c)return!1;for(var x=1;4>=x;x*=2){var B=v*(1+.2/x);B=Math.min(B,c+100663296);var H=Math;B=Math.max(c,B);e:{H=H.min.call(H,4294901760,B+(65536-B%65536)%65536)-Re.buffer.byteLength+65535>>>16;try{Re.grow(H),Ie();var K=1;break e}catch{}K=void 0}if(K)return!0}return!1},P:Wr,Q:Ur,H:ar,h:Nr,o:Hr,x:Gr,n:Lr,a:Re||l.wasmMemory,J:Kr,e:function(c,v,x,B){return Kr(c>>>0,v>>>0,x>>>0,B>>>0)}};(function(){function c(x,B){return x=x.exports,x=Mn(x),ue=x=Ln(x),be.mb.push(ue.Da),Fe.unshift(ue.Y),Be=B,gt(),x}var v={a:Gn};if(Ut(),l.instantiateWasm)try{return l.instantiateWasm(v,c)}catch(x){oe(\"Module.instantiateWasm callback failed with error: \"+x),A(x)}return Ir(v,function(x){c(x.instance,x.module)}).catch(A),{}})(),l._OrtInit=(c,v)=>(l._OrtInit=ue.Z)(c,v),l._OrtGetLastError=(c,v)=>(l._OrtGetLastError=ue._)(c,v),l._OrtCreateSessionOptions=(c,v,x,B,H,K,ee,pe,de,ce)=>(l._OrtCreateSessionOptions=ue.$)(c,v,x,B,H,K,ee,pe,de,ce),l._OrtAppendExecutionProvider=(c,v)=>(l._OrtAppendExecutionProvider=ue.aa)(c,v),l._OrtAddFreeDimensionOverride=(c,v,x)=>(l._OrtAddFreeDimensionOverride=ue.ba)(c,v,x),l._OrtAddSessionConfigEntry=(c,v,x)=>(l._OrtAddSessionConfigEntry=ue.ca)(c,v,x),l._OrtReleaseSessionOptions=c=>(l._OrtReleaseSessionOptions=ue.da)(c),l._OrtCreateSession=(c,v,x)=>(l._OrtCreateSession=ue.ea)(c,v,x),l._OrtReleaseSession=c=>(l._OrtReleaseSession=ue.fa)(c),l._OrtGetInputOutputCount=(c,v,x)=>(l._OrtGetInputOutputCount=ue.ga)(c,v,x),l._OrtGetInputName=(c,v)=>(l._OrtGetInputName=ue.ha)(c,v),l._OrtGetOutputName=(c,v)=>(l._OrtGetOutputName=ue.ia)(c,v),l._OrtFree=c=>(l._OrtFree=ue.ja)(c),l._OrtCreateTensor=(c,v,x,B,H,K)=>(l._OrtCreateTensor=ue.ka)(c,v,x,B,H,K),l._OrtGetTensorData=(c,v,x,B,H)=>(l._OrtGetTensorData=ue.la)(c,v,x,B,H),l._OrtReleaseTensor=c=>(l._OrtReleaseTensor=ue.ma)(c),l._OrtCreateRunOptions=(c,v,x,B)=>(l._OrtCreateRunOptions=ue.na)(c,v,x,B),l._OrtAddRunConfigEntry=(c,v,x)=>(l._OrtAddRunConfigEntry=ue.oa)(c,v,x),l._OrtReleaseRunOptions=c=>(l._OrtReleaseRunOptions=ue.pa)(c),l._OrtCreateBinding=c=>(l._OrtCreateBinding=ue.qa)(c),l._OrtBindInput=(c,v,x)=>(l._OrtBindInput=ue.ra)(c,v,x),l._OrtBindOutput=(c,v,x,B)=>(l._OrtBindOutput=ue.sa)(c,v,x,B),l._OrtClearBoundOutputs=c=>(l._OrtClearBoundOutputs=ue.ta)(c),l._OrtReleaseBinding=c=>(l._OrtReleaseBinding=ue.ua)(c),l._OrtRunWithBinding=(c,v,x,B,H)=>(l._OrtRunWithBinding=ue.va)(c,v,x,B,H),l._OrtRun=(c,v,x,B,H,K,ee,pe)=>(l._OrtRun=ue.wa)(c,v,x,B,H,K,ee,pe),l._OrtEndProfiling=c=>(l._OrtEndProfiling=ue.xa)(c),l._JsepOutput=(c,v,x)=>(l._JsepOutput=ue.ya)(c,v,x),l._JsepGetNodeName=c=>(l._JsepGetNodeName=ue.za)(c);var Kt=l._pthread_self=()=>(Kt=l._pthread_self=ue.Aa)(),br=l._malloc=c=>(br=l._malloc=ue.Ba)(c),Qr=l._free=c=>(Qr=l._free=ue.Ca)(c);l.__emscripten_tls_init=()=>(l.__emscripten_tls_init=ue.Da)();var Jr=l.__emscripten_thread_init=(c,v,x,B,H,K)=>(Jr=l.__emscripten_thread_init=ue.Fa)(c,v,x,B,H,K);l.__emscripten_thread_crashed=()=>(l.__emscripten_thread_crashed=ue.Ga)();var en=(c,v,x,B)=>(en=ue.Ha)(c,v,x,B),vr=c=>(vr=ue.Ia)(c),wr=l.__emscripten_thread_exit=c=>(wr=l.__emscripten_thread_exit=ue.Ja)(c),tn=l.__emscripten_check_mailbox=()=>(tn=l.__emscripten_check_mailbox=ue.Ka)(),rn=c=>(rn=ue.La)(c),nn=(c,v)=>(nn=ue.Ma)(c,v),$r=()=>($r=ue.Na)(),Yt=c=>(Yt=ue.Oa)(c),Cr=c=>(Cr=ue.Pa)(c),on=l.dynCall_ii=(c,v)=>(on=l.dynCall_ii=ue.Ra)(c,v),an=c=>(an=ue.Sa)(c),sn=()=>(sn=ue.Ta)(),un=c=>(un=ue.Ua)(c),ln=()=>(ln=ue.Va)();l.___start_em_js=925254,l.___stop_em_js=925415;function Ln(c){c=Object.assign({},c);var v=B=>()=>B()>>>0,x=B=>H=>B(H)>>>0;return c.__errno_location=v(c.__errno_location),c.pthread_self=v(c.pthread_self),c.malloc=x(c.malloc),c.stackSave=v(c.stackSave),c.stackAlloc=x(c.stackAlloc),c}l.keepRuntimeAlive=xt,l.wasmMemory=Re,l.stackAlloc=Cr,l.stackSave=$r,l.stackRestore=Yt,l.UTF8ToString=Je,l.stringToUTF8=dr,l.lengthBytesUTF8=lr,l.ExitStatus=Ht,l.PThread=be;var Zt;_t=function c(){Zt||dn(),Zt||(_t=c)};function dn(){function c(){if(!Zt&&(Zt=!0,l.calledRun=!0,!Me)&&(M||sr(Fe),S(l),l.onRuntimeInitialized&&l.onRuntimeInitialized(),!M)){if(l.postRun)for(typeof l.postRun==\"function\"&&(l.postRun=[l.postRun]);l.postRun.length;){var v=l.postRun.shift();Qe.unshift(v)}sr(Qe)}}if(!(0<dt))if(M)S(l),M||sr(Fe),startWorker(l);else{if(l.preRun)for(typeof l.preRun==\"function\"&&(l.preRun=[l.preRun]);l.preRun.length;)st.unshift(l.preRun.shift());sr(st),0<dt||(l.setStatus?(l.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){l.setStatus(\"\")},1),c()},1)):c())}}if(l.preInit)for(typeof l.preInit==\"function\"&&(l.preInit=[l.preInit]);0<l.preInit.length;)l.preInit.pop()();return dn(),r.ready}})();typeof qa==\"object\"&&typeof Ii==\"object\"?Ii.exports=Fa:typeof define==\"function\"&&define.amd&&define([],()=>Fa)});var Ya=fn((Xg,nm)=>{nm.exports='\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason??e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(\"worker.js received unknown command \"+e.data.cmd),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\\n'});var Ei,mn,hn,Yn,gn,ts,Oi,Ze=ae(()=>{\"use strict\";Ei=e=>{switch(e){case\"int8\":return 3;case\"uint8\":return 2;case\"bool\":return 9;case\"int16\":return 5;case\"uint16\":return 4;case\"int32\":return 6;case\"uint32\":return 12;case\"float16\":return 10;case\"float32\":return 1;case\"float64\":return 11;case\"string\":return 8;case\"int64\":return 7;case\"uint64\":return 13;default:throw new Error(`unsupported data type: ${e}`)}},mn=e=>{switch(e){case 3:return\"int8\";case 2:return\"uint8\";case 9:return\"bool\";case 5:return\"int16\";case 4:return\"uint16\";case 6:return\"int32\";case 12:return\"uint32\";case 10:return\"float16\";case 1:return\"float32\";case 11:return\"float64\";case 8:return\"string\";case 7:return\"int64\";case 13:return\"uint64\";default:throw new Error(`unsupported data type: ${e}`)}},hn=e=>[void 0,4,1,1,2,2,4,8,void 0,1,2,8,4,8,void 0,void 0,void 0][e],Yn=e=>{switch(e){case\"float16\":return Uint16Array;case\"float32\":return Float32Array;case\"uint8\":return Uint8Array;case\"int8\":return Int8Array;case\"uint16\":return Uint16Array;case\"int16\":return Int16Array;case\"int32\":return Int32Array;case\"bool\":return Uint8Array;case\"float64\":return Float64Array;case\"uint32\":return Uint32Array;case\"int64\":return BigInt64Array;case\"uint64\":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},gn=e=>{switch(e){case\"verbose\":return 0;case\"info\":return 1;case\"warning\":return 2;case\"error\":return 3;case\"fatal\":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},ts=e=>e===\"float32\"||e===\"int32\"||e===\"int64\"||e===\"bool\"||e===\"float16\"||e===\"uint32\",Oi=e=>{switch(e){case\"none\":return 0;case\"cpu\":return 1;case\"cpu-pinned\":return 2;case\"texture\":return 3;case\"gpu-buffer\":return 4;default:throw new Error(`unsupported data location: ${e}`)}}});var fm,pm,rs,ns,is,mm,Ge,zt=ae(()=>{\"use strict\";Ze();fm=[\"V\",\"I\",\"W\",\"E\",\"F\"],pm=(e,r)=>{console.log(`[${fm[e]},${new Date().toISOString()}]${r}`)},is=(e,r)=>{rs=e,ns=r},mm=(e,r)=>{let t=gn(e),u=gn(rs);t>=u&&pm(t,typeof r==\"function\"?r():r)},Ge=(...e)=>{ns&&mm(...e)}});var os,as=ae(()=>{\"use strict\";Ze();os=(e,r)=>new(Yn(r))(e)});var Zn=ae(()=>{\"use strict\"});var Xn,hm,ss,Pi,ki,ls,ds=ae(()=>{\"use strict\";zt();Zn();Xn=e=>Math.ceil(e/16)*16,hm=1,ss=()=>hm++,Pi=async(e,r,t,u)=>{let a=Xn(t),p=e.device.createBuffer({size:a,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ});try{let m=e.getCommandEncoder();e.endComputePass(),m.copyBufferToBuffer(r,0,p,0,a),e.flush(),await p.mapAsync(GPUMapMode.READ);let y=p.getMappedRange();if(u){let l=u();return l.set(new Uint8Array(y,0,t)),l}else return new Uint8Array(y.slice(0,t))}finally{p.destroy()}},ki=class{constructor(r){this.backend=r;this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.buffersForUploadingPending=[],this.buffersPending=[],this.externalBuffers=new Map}upload(r,t){let u=t.buffer,a=t.byteOffset,p=t.byteLength,m=Xn(p),y=this.storageCache.get(r);if(!y)throw new Error(\"gpu data for uploading does not exist\");if(y.originalSize!==p)throw new Error(`inconsistent data size. gpu data size=${y.originalSize}, data size=${p}`);let l=this.backend.device.createBuffer({mappedAtCreation:!0,size:m,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC}),S=l.getMappedRange();new Uint8Array(S).set(new Uint8Array(u,a,p)),l.unmap();let A=this.backend.getCommandEncoder();this.backend.endComputePass(),A.copyBufferToBuffer(l,0,y.gpuData.buffer,0,m),Ge(\"verbose\",()=>`[WebGPU] GpuDataManager.upload(id=${r})`),this.buffersForUploadingPending.push(l)}memcpy(r,t){let u=this.storageCache.get(r);if(!u)throw new Error(\"source gpu data for memcpy does not exist\");let a=this.storageCache.get(t);if(!a)throw new Error(\"destination gpu data for memcpy does not exist\");if(u.originalSize!==a.originalSize)throw new Error(\"inconsistent source and destination gpu data size\");let p=Xn(u.originalSize),m=this.backend.getCommandEncoder();this.backend.endComputePass(),m.copyBufferToBuffer(u.gpuData.buffer,0,a.gpuData.buffer,0,p)}registerExternalBuffer(r,t,u){let a;if(u){if(a=this.externalBuffers.get(u),a===void 0)throw new Error(\"previous buffer is not registered\");if(r===u)return Ge(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${t}) => id=${a}, buffer is the same, skip.`),a;this.externalBuffers.delete(u)}else a=ss();return this.storageCache.set(a,{gpuData:{id:a,type:0,buffer:r},originalSize:t}),this.externalBuffers.set(r,a),Ge(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${t}) => id=${a}, registered.`),a}unregisterExternalBuffer(r){let t=this.externalBuffers.get(r);t!==void 0&&(this.storageCache.delete(t),this.externalBuffers.delete(r),Ge(\"verbose\",()=>`[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${t}`))}create(r,t=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){let u=Xn(r),a,p=(t&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE,m=(t&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM;if(p||m){let l=p?this.freeBuffers:this.freeUniformBuffers,S=l.get(u);S||(S=[],l.set(u,S)),S.length>0?a=S.pop():a=this.backend.device.createBuffer({size:u,usage:t})}else a=this.backend.device.createBuffer({size:u,usage:t});let y={id:ss(),type:0,buffer:a};return this.storageCache.set(y.id,{gpuData:y,originalSize:r}),Ge(\"verbose\",()=>`[WebGPU] GpuDataManager.create(size=${r}) => id=${y.id}`),y}get(r){return this.storageCache.get(r)?.gpuData}release(r){let t=this.storageCache.get(r);if(!t)throw new Error(\"releasing data does not exist\");return Ge(\"verbose\",()=>`[WebGPU] GpuDataManager.release(id=${r}), gpuDataId=${t.gpuData.id}`),this.storageCache.delete(r),this.buffersPending.push(t.gpuData.buffer),t.originalSize}async download(r,t){let u=this.storageCache.get(r);if(!u)throw new Error(\"data does not exist\");await Pi(this.backend,u.gpuData.buffer,u.originalSize,t)}refreshPendingBuffers(){for(let r of this.buffersForUploadingPending)r.destroy();this.buffersForUploadingPending=[];for(let r of this.buffersPending)(r.usage&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE?this.freeBuffers.get(r.size).push(r):(r.usage&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM?this.freeUniformBuffers.get(r.size).push(r):r.destroy();this.buffersPending=[]}dispose(){this.freeBuffers.forEach(r=>{r.forEach(t=>{t.destroy()})}),this.freeUniformBuffers.forEach(r=>{r.forEach(t=>{t.destroy()})}),this.storageCache.forEach(r=>{r.gpuData.buffer.destroy()}),this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map}},ls=(...e)=>new ki(...e)});var Ri,he,Le=ae(()=>{\"use strict\";Ri=class{constructor(r){Object.assign(this,r)}get cacheKey(){return this.key||(this.key=Object.getOwnPropertyNames(this).sort().map(r=>`${this[r]}`).join(\";\")),this.key}},he=e=>new Ri(e)});var Bi,Tt,Z,Jt,Qn,Jn,ei,ke=ae(()=>{\"use strict\";Bi=class{static calcMatMulShape(r,t){return r[1]!==t[0]?void 0:[r[0],t[1]]}},Tt=class{static calcShape(r,t,u=!1){let a=r.length,p=t.length;if(a===0)return t;if(p===0)return r;let m=Math.max(r.length,t.length),y=new Array(m);if(u){if(a<2||p<2)return;let l=Bi.calcMatMulShape([r[a-2],r[a-1]],[t[p-2],t[p-1]]);if(l===void 0)return;[y[m-2],y[m-1]]=l}for(let l=u?3:1;l<=m;l++){let S=a-l<0?1:r[a-l],A=p-l<0?1:t[p-l];if(S!==A&&S>1&&A>1)return;y[m-l]=Math.max(S,A)}return y}static isValidBroadcast(r,t){let u=r.length,a=t.length;if(u>a)return!1;for(let p=1;p<=u;p++)if(r[u-p]!==1&&r[u-p]!==t[a-p])return!1;return!0}},Z=class e{static size(r){return e.getSizeFromDimensionRange(r,0,r.length)}static sizeFromDimension(r,t){if(t<0||t>r.length)throw new Error(`invalid dimension of ${t} for sizeFromDimension as Tensor has ${r.length} dimensions.`);return e.getSizeFromDimensionRange(r,t,r.length)}static sizeToDimension(r,t){if(t<0||t>r.length)throw new Error(`invalid dimension of ${t} for sizeToDimension as Tensor has ${r.length} dimensions.`);return e.getSizeFromDimensionRange(r,0,t)}static getSizeFromDimensionRange(r,t,u){let a=1;for(let p=t;p<u;p++){if(r[p]<0)throw new Error(\"cannot get valid size from specified dimension range. Most likely the range contains negative values in them.\");a*=r[p]}return a}static computeStrides(r){let t=r.length;if(t===0)return[];if(t===1)return[1];let u=new Array(t);u[t-1]=1,u[t-2]=r[t-1];for(let a=t-3;a>=0;--a)u[a]=u[a+1]*r[a+1];return u}static normalizeAxis(r,t){if(r<-t&&r>=t)throw new Error(\"unsupported axis for this operation.\");return r<0?r+t:r}static normalizeAxes(r,t){return r.map(u=>this.normalizeAxis(u,t??r.length))}static sortBasedOnPerm(r,t){return t?t.map(u=>r[u]):r.slice().reverse()}static padShape(r,t){let u=r.length;return r.map((a,p)=>a+t[p]+t[p+u])}static areEqual(r,t){return r.length!==t.length?!1:r.every((u,a)=>u===t[a])}},Jt=class e{static adjustPoolAttributes(r,t,u,a,p,m){if(!r&&u.length!==t.length-2)throw new Error(\"length of specified kernel shapes should be 2 less than length of input dimensions\");if(r)for(let y=0;y<t.length-2;y++)y>=u.length?u.push(t[y+2]):u[y]=t[y+2];for(let y=0;y<u.length;y++)if(y<a.length){if(a[y]<0)throw new Error(\"strides should be greater than or equal to 1\")}else a.push(1);for(let y=0;y<u.length;y++)if(y<p.length){if(p[y]<0)throw new Error(\"dilations should be greater than or equal to 1\")}else p.push(1);for(let y=0;y<u.length*2;y++)if(y<m.length){if(m[y]<0)throw new Error(\"pad should be greater than or equal to 1\")}else m.push(0);for(let y=0;y<u.length;y++){if(u[y]<=0)throw new Error(\"kernel shapes need to be greater than 0\");if(m[y]>=u[y]||m[y+u.length]>=u[y])throw new Error(\"pads should be smaller than kernel\")}}static adjustPadsBasedOnAutoPad(r,t,u,a,p,m,y){if(y){if(p.length!==2*(r.length-2))throw new Error(\"length of pads should be twice the length of data dimensions\");if(t.length!==r.length-2)throw new Error(\"length of strides should be the length of data dimensions\");if(a.length!==r.length-2)throw new Error(\"length of kernel shapes should be the length of data dimensions\");for(let l=0;l<r.length-2;l++)e.adjustPadAndReturnShape(r[l+(m?1:2)],t[l],u[l],a[l],p,l,l+r.length-2,y)}}static computePoolOutputShape(r,t,u,a,p,m,y){if(t.length<=0)throw new Error(\"input shape must be of size greater than 0\");let l=[t[0],t[1]];return e.computeShapeHelper(r,t,l,u,a,p,m,y),l}static computeConvOutputShape(r,t,u,a,p,m,y){if(r.length<=0||t.length<=0)throw new Error(\"invalid input tensor dims or invalid filter tensor dims\");let l=[r[0],t[0]];return e.computeShapeHelper(!1,r,l,u,a,p,m,y),l}static computeShapeHelper(r,t,u,a,p,m,y,l){if(r)for(let S=0;S<t.length-2;S++)u.push(1);else for(let S=0;S<t.length-2;S++)u.push(e.adjustPadAndReturnShape(t[S+2],a[S],p[S],m[S],y,S,S+t.length-2,l))}static adjustPadAndReturnShape(r,t,u,a,p,m,y,l){let S=u*(a-1)+1;if(l&&l!==\"NOTSET\")switch(l){case\"VALID\":return p[m]=0,p[y]=0,Math.floor((r-S)/t+1);case\"SAME_LOWER\":case\"SAME_UPPER\":if(u!==1)throw new Error(\"Dilation not supported for SAME_UPPER or SAME_LOWER\");{let P=((r+t-1)/t-1)*t+a-r;return p[m]=Math.floor(l===\"SAME_LOWER\"?(P+1)/2:P/2),p[y]=P-p[m],Math.floor((r+P-a)/t+1)}default:throw new Error(\"Unsupported AutoPad type\")}else return Math.floor((r+p[m]+p[y]-S)/t+1)}},Qn=class{static getShapeOfGemmResult(r,t,u,a,p){if(r.length!==2||u.length!==2)throw new Error(\"shape need to be of size 2\");let m,y,l;t?(m=r[1],y=r[0]):(m=r[0],y=r[1]);let S=-1;if(a?(l=u[0],S=1):(l=u[1],S=0),u[S]!==y)throw new Error(\"dimension mismatch\");if(m<=0||l<=0||y<=0)throw new Error(\"invalid shape specified\");if(p&&!Tt.isValidBroadcast(p,[m,l]))throw new Error(\"gemm: invalid bias shape for broadcast\");return[m,l,y]}},Jn=-34028234663852886e22,ei=34028234663852886e22});var gm,cs,je,xe,lt,ot,vt,wt,Et,Di,te,se,fs,Mi,ps,ji,He,Pe=ae(()=>{\"use strict\";Ze();ke();gm=64,cs=(e,r)=>{if(r===3)throw new Error(\"vec3 has same alignment as vec4, use vec4 instead\");switch(e){case 10:return r>1?`vec${r}<f16>`:\"f16\";case 1:return r>1?`vec${r}<f32>`:\"f32\";case 6:return r>1?`vec${r}<i32>`:\"i32\";case 12:return r>1?`vec${r}<u32>`:\"u32\";case 7:if(r>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"i32\"];case 13:if(r>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"u32\"];case 9:if(r!==4)throw new Error(\"bool must be vec4\");return[\"u32\",\"vec4<bool>\"];default:throw new Error(`Unknown data type: ${e}`)}},je=(e,r=1)=>{let t=cs(e,r);return typeof t==\"string\"?t:t[0]},xe=e=>e.length===0?[]:[{type:\"uint32\",data:e},{type:\"uint32\",data:Z.computeStrides(e)}],lt=e=>e%4===0?4:e%2===0?2:1,ot=(e=\"f32\",r,t=\"0\")=>!r||r===1?`${e}(${t})`:`vec${r}<${e}>(${t})`,vt=(e,r,t)=>e===\"f32\"?t:r===1?`f32(${t})`:`vec${r}f(${t})`,wt=(e,r)=>r===4?`(${e}.x + ${e}.y + ${e}.z + ${e}.w)`:r===2?`(${e}.x + ${e}.y)`:r===3?`(${e}.x + ${e}.y + ${e}.z)`:e,Et=(e,r,t)=>e.startsWith(\"uniforms.\")&&t>4?typeof r==\"string\"?`${e}[(${r}) / 4][(${r}) % 4]`:`${e}[${Math.floor(r/4)}][${r%4}]`:t>1?`${e}[${r}]`:e,Di=(e,r,t,u,a)=>{let p=typeof t==\"number\",m=p?t:t.length,y=[...new Array(m).keys()],l=m<2?\"u32\":m<=4?`vec${m}<u32>`:`array<u32, ${m}>`,S=cs(r,a),A=typeof S==\"string\"?S:S[1],P=typeof S==\"string\"?S:S[0],T={indices:l,value:A,storage:P,tensor:r},k=ne=>typeof ne==\"string\"?ne:`${ne}u`,O={offsetToIndices:!1,indicesToOffset:!1,broadcastedIndicesToOffset:!1,set:!1,setByIndices:!1,get:!1,getByIndices:!1},R=p?\"uniforms.\":\"\",j=`${R}${e}_shape`,M=`${R}${e}_strides`,z=\"\";for(let ne=0;ne<m-1;ne++)z+=`\n    let dim${ne} = current / ${Et(M,ne,m)};\n    let rest${ne} = current % ${Et(M,ne,m)};\n    indices[${ne}] = dim${ne};\n    current = rest${ne};\n    `;z+=`indices[${m-1}] = current;`;let q=m<2?\"\":`\n  fn o2i_${e}(offset: u32) -> ${T.indices} {\n    var indices: ${T.indices};\n    var current = offset;\n    ${z}\n    return indices;\n  }`,G=ne=>(O.offsetToIndices=!0,m<2?ne:`o2i_${e}(${ne})`),Y=[];if(m>=2)for(let ne=m-1;ne>=0;ne--)Y.push(`${Et(M,ne,m)} * (indices[${ne}])`);let _=m<2?\"\":`\n  fn i2o_${e}(indices: ${T.indices}) -> u32 {\n    return ${Y.join(\"+\")};\n  }`,X=ne=>(O.indicesToOffset=!0,m<2?ne:`i2o_${e}(${ne})`),J=(...ne)=>m===0?\"0u\":`${T.indices}(${ne.map(k).join(\",\")})`,re=(ne,we)=>m<2?`${ne}`:`${Et(ne,we,m)}`,fe=(ne,we,Ie)=>m<2?`${ne}=${Ie};`:`${Et(ne,we,m)}=${Ie};`,L={},oe=(ne,we)=>{O.broadcastedIndicesToOffset=!0;let Ie=`${we.name}broadcastedIndicesTo${e}Offset`;if(Ie in L)return`${Ie}(${ne})`;let tt=[];for(let st=m-1;st>=0;st--){let Fe=we.indicesGet(\"outputIndices\",st+we.rank-m);tt.push(`${re(M,st)} * (${Fe} % ${re(j,st)})`)}return L[Ie]=`fn ${Ie}(outputIndices: ${we.type.indices}) -> u32 {\n             return ${tt.length>0?tt.join(\"+\"):\"0u\"};\n           }`,`${Ie}(${ne})`},Se=(ne,we)=>(()=>{if(T.storage===T.value)return`${e}[${ne}]=${we};`;if(T.storage===\"vec2<u32>\"&&T.value===\"i32\")return`${e}[${ne}]=vec2<u32>(u32(${we}), select(0u, 0xFFFFFFFFu, ${we} < 0));`;if(T.storage===\"vec2<u32>\"&&T.value===\"u32\")return`${e}[${ne}]=vec2<u32>(u32(${we}), 0u);`;if(T.storage===\"u32\"&&T.value===\"vec4<bool>\")return`${e}[${ne}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${we}));`;throw new Error(`not supported combination of storage type ${T.storage} and value type ${T.value} yet`)})(),me=ne=>(()=>{if(T.storage===T.value)return`${e}[${ne}]`;if(T.storage===\"vec2<u32>\"&&T.value===\"i32\")return`i32(${e}[${ne}].x)`;if(T.storage===\"vec2<u32>\"&&T.value===\"u32\")return`u32(${e}[${ne}].x)`;if(T.storage===\"u32\"&&T.value===\"vec4<bool>\")return`vec4<bool>(bool(${e}[${ne}] & 0xFFu), bool(${e}[${ne}] & 0xFF00u), bool(${e}[${ne}] & 0xFF0000u), bool(${e}[${ne}] & 0xFF000000u))`;throw new Error(`not supported combination of storage type ${T.storage} and value type ${T.value} yet`)})(),Re=m<2?\"\":`\n  fn get_${e}ByIndices(indices: ${T.indices}) -> ${A} {\n    return ${me(`i2o_${e}(indices)`)};\n  }`,ue=m<2?\"\":(()=>{let ne=y.map(Ie=>`d${Ie}: u32`).join(\", \"),we=y.map(Ie=>`d${Ie}`).join(\", \");return`\n  fn get_${e}(${ne}) -> ${A} {\n    return get_${e}ByIndices(${J(we)});\n  }`})(),Be=(...ne)=>{if(ne.length!==m)throw new Error(`indices length must be ${m}`);let we=ne.map(k).join(\",\");return m===0?me(\"0u\"):m===1?me(we[0]):(O.get=!0,O.getByIndices=!0,O.indicesToOffset=!0,`get_${e}(${we})`)},Me=ne=>m<2?me(ne):(O.getByIndices=!0,O.indicesToOffset=!0,`get_${e}ByIndices(${ne})`),De=m<2?\"\":`\n  fn set_${e}ByIndices(indices: ${T.indices}, value: ${A}) {\n    ${Se(`i2o_${e}(indices)`,\"value\")}\n  }`,Ae=m<2?\"\":(()=>{let ne=y.map(Ie=>`d${Ie}: u32`).join(\", \"),we=y.map(Ie=>`d${Ie}`).join(\", \");return`\n  fn set_${e}(${ne}, value: ${A}) {\n    set_${e}ByIndices(${J(we)}, value);\n  }`})();return{impl:()=>{let ne=[];return p||(ne.push(`const ${j} = ${T.indices}(${t.join(\",\")});`),ne.push(`const ${M} = ${T.indices}(${Z.computeStrides(t).join(\",\")});`)),O.offsetToIndices&&ne.push(q),O.indicesToOffset&&ne.push(_),O.broadcastedIndicesToOffset&&Object.values(L).forEach(we=>ne.push(we)),O.set&&ne.push(Ae),O.setByIndices&&ne.push(De),O.get&&ne.push(ue),O.getByIndices&&ne.push(Re),ne.join(`\n`)},type:T,offsetToIndices:G,indicesToOffset:X,broadcastedIndicesToOffset:oe,indices:J,indicesGet:re,indicesSet:fe,set:(...ne)=>{if(ne.length!==m+1)throw new Error(`indices length must be ${m}`);let we=ne[m];if(typeof we!=\"string\")throw new Error(\"value must be string\");let Ie=ne.slice(0,m).map(k).join(\",\");return m===0?Se(\"0u\",we):m===1?Se(Ie[0],we):(O.set=!0,O.setByIndices=!0,O.indicesToOffset=!0,`set_${e}(${Ie}, ${we})`)},setByOffset:Se,setByIndices:(ne,we)=>m<2?Se(ne,we):(O.setByIndices=!0,O.indicesToOffset=!0,`set_${e}ByIndices(${ne}, ${we});`),get:Be,getByOffset:me,getByIndices:Me,usage:u,name:e,strides:M,shape:j,rank:m}},te=(e,r,t,u=1)=>Di(e,r,t,\"input\",u),se=(e,r,t,u=1)=>Di(e,r,t,\"output\",u),fs=(e,r,t,u=1)=>Di(e,r,t,\"internal\",u),Mi=class{constructor(r){this.normalizedDispatchGroup=r;this.internalVariables=[];this.variables=[];this.uniforms=[];this.variableIndex=0}guardAgainstOutOfBoundsWorkgroupSizes(r){return`if (global_idx >= ${typeof r==\"number\"?`${r}u`:r}) { return; }`}mainStart(r=gm){let t=typeof r==\"number\"?r:r[0],u=typeof r==\"number\"?1:r[1],a=typeof r==\"number\"?1:r[2],p=this.normalizedDispatchGroup[1]===1&&this.normalizedDispatchGroup[2]===1,m=p?`@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>`:`@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`,y=p?\"let global_idx = global_id.x;\":`let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${t*u*a}u + local_index;`;return`@compute @workgroup_size(${t}, ${u}, ${a})\n  fn main(${m}) {\n    ${y}\n  `}appendVariableUniforms(r){r.rank!==0&&(r.shape.startsWith(\"uniforms.\")&&this.uniforms.push({name:r.shape.replace(\"uniforms.\",\"\"),type:\"u32\",length:r.rank}),r.strides.startsWith(\"uniforms.\")&&this.uniforms.push({name:r.strides.replace(\"uniforms.\",\"\"),type:\"u32\",length:r.rank}))}declareVariable(r,t){if(r.usage===\"internal\")throw new Error(\"cannot use internal variable with declareVariable(). use registerInternalVariables() instead.\");this.variables.push(r),this.appendVariableUniforms(r);let u=r.usage===\"input\"?\"read\":\"read_write\",a=r.type.storage;return`@group(0) @binding(${t}) var<storage, ${u}> ${r.name}: array<${a}>;`}declareVariables(...r){return r.map(t=>this.declareVariable(t,this.variableIndex++)).join(`\n`)}registerInternalVariable(r){if(r.usage!==\"internal\")throw new Error(\"cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.\");this.internalVariables.push(r),this.appendVariableUniforms(r)}registerInternalVariables(...r){return r.forEach(t=>this.registerInternalVariable(t)),this}registerUniform(r,t,u=1){return this.uniforms.push({name:r,type:t,length:u}),this}registerUniforms(r){return this.uniforms=this.uniforms.concat(r),this}uniformDeclaration(){if(this.uniforms.length===0)return\"\";let r=[];for(let{name:t,type:u,length:a}of this.uniforms)if(a&&a>4)r.push(`${t}:array<vec4<${u}>, ${Math.ceil(a/4)}>`);else{let p=a==null||a===1?u:`vec${a}<${u}>`;r.push(`${t}:${p}`)}return`\n      struct Uniforms { ${r.join(\", \")} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`}get additionalImplementations(){return this.uniformDeclaration()+this.variables.map(r=>r.impl()).join(`\n`)+this.internalVariables.map(r=>r.impl()).join(`\n`)}},ps=e=>new Mi(e),ji=(e,r)=>{let t=e.length,u=[];for(let a=0;a<t;a++){let p=t-1-a,m=e[p]||1;(r[r.length-1-a]||1)>1&&m===1&&u.unshift(p)}return u},He=e=>!0});var ym,ms,bm,vm,$t,hs,gs,xr=ae(()=>{\"use strict\";ke();Le();Pe();ym=e=>{if(!e||e.length!==1)throw new Error(\"Transpose requires 1 input.\")},ms=(e,r)=>r&&r.length!==e?[...new Array(e).keys()].reverse():r,bm=(e,r)=>Z.sortBasedOnPerm(e,ms(e.length,r)),vm=(e,r,t,u)=>{let a=[];a.push(`fn perm(i: ${u.type.indices}) -> ${t.type.indices} {\n    var a: ${t.type.indices};`);for(let p=0;p<r;++p)a.push(t.indicesSet(\"a\",e[p],`i[${p}]`));return a.push(\"return a;}\"),a.join(`\n`)},$t=(e,r)=>{let t=e.dataType,u=e.dims.length,a=ms(u,r),p=He(u),m=bm(e.dims,a),y=p?m.length:m,l=p?u:e.dims,S=se(\"output\",t,y),A=te(\"a\",t,l),P=T=>`\n  ${T.registerUniform(\"output_size\",\"u32\").declareVariables(A,S)}\n\n  ${vm(a,u,A,S)}\n\n  ${T.mainStart()}\n    ${T.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n\n    let indices = ${S.offsetToIndices(\"global_idx\")};\n    let aIndices = perm(indices);\n\n    ${S.setByOffset(\"global_idx\",A.getByIndices(\"aIndices\"))}\n  }`;return{name:\"Transpose\",shaderCache:{hint:`${r}`,inputDependencies:p?[\"rank\"]:[\"dims\"]},getRunData:T=>{let k=Z.size(m);return{outputs:[{dims:m,dataType:T[0].dataType}],dispatchGroup:{x:Math.ceil(k/64)},programUniforms:p?[{type:\"uint32\",data:k},...xe(T[0].dims),...xe(m)]:[{type:\"uint32\",data:k}]}},getShaderSource:P}},hs=(e,r)=>{ym(e.inputs),e.compute($t(e.inputs[0],r.perm))},gs=e=>he({perm:e.perm})});var wm,$m,Cm,Sm,xm,_m,Im,Am,Tm,Em,Ot,ys,bs,vs,ws,$s,Cs,Ss,xs,_s,Is,As=ae(()=>{\"use strict\";ke();Pe();ti();xr();wm={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate * candidate\",logSumExp:\"bestValue + exp(candidate)\",l1:\"bestValue + abs(candidate)\",l2:\"bestValue + candidate * candidate\",logSum:\"bestValue + candidate\"},$m={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate\",logSumExp:\"bestValue + candidate\",l1:\"bestValue + candidate\",l2:\"bestValue + candidate\",logSum:\"bestValue + candidate\"},Cm={max:\"_A[offset]\",min:\"_A[offset]\",mean:\"0\",sum:\"0\",prod:\"1\",sumSquare:\"0\",logSumExp:\"0\",l1:\"0\",l2:\"0\",logSum:\"0\"},Sm={max:\"bestValue\",min:\"bestValue\",sum:\"bestValue\",prod:\"bestValue\",sumSquare:\"bestValue\",logSumExp:\"log(bestValue)\",l1:\"bestValue\",l2:\"sqrt(bestValue)\",logSum:\"log(bestValue)\"},xm=(e,r)=>{let t=[];for(let u=r-e;u<r;++u)t.push(u);return t},_m=(e,r)=>{let t=[],u=e.length;for(let p=0;p<u;p++)r.indexOf(p)===-1&&t.push(e[p]);let a=r.map(p=>e[p]);return[t,a]},Im=(e,r)=>{let t=e.length+r.length,u=[],a=0;for(let p=0;p<t;p++)r.indexOf(p)===-1?u.push(e[a++]):u.push(1);return u},Am=(e,r)=>{for(let t=0;t<e.length;++t)if(e[e.length-t-1]!==r-1-t)return!1;return!0},Tm=(e,r)=>{let t=[];if(!Am(e,r)){for(let u=0;u<r;++u)e.indexOf(u)===-1&&t.push(u);e.forEach(u=>t.push(u))}return t},Em=(e,r,t,u,a,p,m)=>{let y=t[0].dims,l=Z.size(p),S=Z.size(m),A=te(\"_A\",t[0].dataType,y),P=se(\"output\",a,p),T=32,k=`\n          var<workgroup> aBestValues : array<${P.type.storage}, ${T}>;\n       `;return{name:e,shaderCache:r,getShaderSource:R=>`\n        ${R.registerUniform(\"reduceSize\",\"u32\").declareVariables(A,P)}\n        ${k}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${R.mainStart(T)}\n          let local_idx = local_id.x;\n\n          let outputIndex = global_idx / ${T};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${P.type.storage}(${Cm[u]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${T}) {\n           let candidate = ${P.type.storage}(${A.getByOffset(\"offset + k\")});\n           bestValue = ${wm[u]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${T}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${$m[u]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${P.setByOffset(\"outputIndex\",`${u===\"mean\"?`bestValue / ${P.type.storage}(uniforms.reduceSize)`:`${Sm[u]}`}`)};\n         }\n        }`,getRunData:()=>({outputs:[{dims:p,dataType:a}],dispatchGroup:{x:l},programUniforms:[{type:\"uint32\",data:S}]})}},Ot=(e,r,t,u)=>{let a=e.inputs.length===1?t:zi(e.inputs,t),p=a.axes;p.length===0&&!a.noopWithEmptyAxes&&(p=e.inputs[0].dims.map((k,O)=>O));let m=Z.normalizeAxes(p,e.inputs[0].dims.length),y=m,l=e.inputs[0],S=Tm(y,e.inputs[0].dims.length);S.length>0&&(l=e.compute($t(e.inputs[0],S),{inputs:[0],outputs:[-1]})[0],y=xm(y.length,l.dims.length));let[A,P]=_m(l.dims,y),T=A;a.keepDims&&(T=Im(A,m)),e.compute(Em(r,{hint:a.cacheKey,inputDependencies:[\"type\"]},[l],u,e.inputs[0].dataType,T,P),{inputs:[l]})},ys=(e,r)=>{Ot(e,\"ReduceMeanShared\",r,\"mean\")},bs=(e,r)=>{Ot(e,\"ReduceL1Shared\",r,\"l1\")},vs=(e,r)=>{Ot(e,\"ReduceL2Shared\",r,\"l2\")},ws=(e,r)=>{Ot(e,\"ReduceLogSumExpShared\",r,\"logSumExp\")},$s=(e,r)=>{Ot(e,\"ReduceMaxShared\",r,\"max\")},Cs=(e,r)=>{Ot(e,\"ReduceMinShared\",r,\"min\")},Ss=(e,r)=>{Ot(e,\"ReduceProdShared\",r,\"prod\")},xs=(e,r)=>{Ot(e,\"ReduceSumShared\",r,\"sum\")},_s=(e,r)=>{Ot(e,\"ReduceSumSquareShared\",r,\"sumSquare\")},Is=(e,r)=>{Ot(e,\"ReduceLogSumShared\",r,\"logSum\")}});var kt,Om,ri,zi,Pt,km,Pm,Rm,Bm,Mm,Dm,jm,zm,Vm,Wm,Rt,Ts,Es,Os,ks,Ps,Rs,Bs,Ms,Ds,js,Ct,ti=ae(()=>{\"use strict\";ke();Le();Pe();As();kt=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"Reduce op requires 1 or 2 inputs.\");if(e.length===2&&e[1].dims.length!==1)throw new Error(\"Invalid axes input dims.\")},Om=e=>[\"\",\"\",`var value = ${e.getByOffset(\"inputOffset\")};`,\"\"],ri=(e,r,t,u,a,p,m=!1,y=!1)=>{let l=[],S=t[0].dims,A=Z.normalizeAxes(a,t[0].dims.length),P=!y&&A.length===0;S.forEach((X,J)=>{P||A.indexOf(J)>=0?m&&l.push(1):l.push(X)});let T=[],k=te(\"_A\",t[0].dataType,S),O=se(\"output\",p,l),R=u(k,O,A),j=`inputOffset = ${k.indicesToOffset(\"inputIndices\")};`,M=`let ${j};`,z=`var ${j};`,q=R[1]===\"\"?\"\":z,G=(R[1]===\"\"?M:j)+`\n`+R[2];for(let X=0,J=0;X<t[0].dims.length;X++)P||A.indexOf(X)>=0?(m&&J++,G=`for(var j${X}: u32 = 0; j${X} < ${t[0].dims[X]}; j${X}++) {\n                ${R[2].includes(\"lastIndex\")?`let lastIndex = j${X};`:\"\"}\n                ${k.indicesSet(\"inputIndices\",X,`j${X}`)}\n                ${G}\n              }`):(T.push(`${k.indicesSet(\"inputIndices\",X,O.indicesGet(\"outputIndices\",J))};`),J++);let Y=Z.size(l);return{name:e,shaderCache:r,getShaderSource:X=>`\n        ${X.declareVariables(k,O)}\n\n        ${X.mainStart()}\n          ${X.guardAgainstOutOfBoundsWorkgroupSizes(Y)}\n          var inputIndices: ${k.type.indices};\n          let outputIndices = ${O.offsetToIndices(\"global_idx\")};\n\n          ${T.join(`\n`)}\n          ${R[0]}       // init ops for reduce max/min\n          ${q}\n          ${R[1]}\n          ${G}\n          ${R[3]}\n          ${R.length===4?O.setByOffset(\"global_idx\",\"value\"):R.slice(4).join(`\n`)}\n        }`,getRunData:()=>({outputs:[{dims:l,dataType:p}],dispatchGroup:{x:Math.ceil(Y/64)}})}},zi=(e,r)=>{let t=[];return e[1].dims[0]>0&&e[1].getBigInt64Array().forEach(u=>t.push(Number(u))),he({axes:t,keepDims:r.keepDims,noopWithEmptyAxes:r.noopWithEmptyAxes})},Pt=(e,r,t,u)=>{let a=e.inputs,p=a.length===1?t:zi(a,t);e.compute(ri(r,{hint:p.cacheKey},[a[0]],p.noopWithEmptyAxes&&p.axes.length===0?Om:u,p.axes,a[0].dataType,p.keepDims,p.noopWithEmptyAxes),{inputs:[0]})},km=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceLogSum\",r,(u,a)=>[`var value = ${a.type.storage}(0);`,\"\",`value += ${u.getByOffset(\"inputOffset\")};`,\"value = log(value);\"])},Pm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceL1\",r,(u,a)=>[`var value = ${a.type.storage}(0);`,\"\",`value += abs(${u.getByOffset(\"inputOffset\")});`,\"\"])},Rm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceL2\",r,(u,a)=>[`var t = ${a.type.value}(0); var value = ${a.type.value}(0);`,\"\",`t = ${u.getByOffset(\"inputOffset\")}; value += (t * t);`,\"value = sqrt(value);\"])},Bm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceLogSumExp\",r,(u,a)=>[`var value = ${a.type.storage}(0);`,\"\",`value += exp(${u.getByOffset(\"inputOffset\")});`,\"value = log(value);\"])},Mm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceMax\",r,(u,a,p)=>{let m=[];for(let y=0;y<u.rank;y++)(p.indexOf(y)>=0||p.length===0)&&m.push(u.indicesSet(\"inputIndices\",y,0));return[`${m.join(`\n`)}`,`var value = ${u.getByOffset(\"inputOffset\")};`,`value = max(value, ${u.getByOffset(\"inputOffset\")});`,\"\"]})},Dm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceMean\",r,(u,a,p)=>{let m=1;for(let y=0;y<u.rank;y++)(p.indexOf(y)>=0||p.length===0)&&(m*=e.inputs[0].dims[y]);return[\"var sum = f32(0);\",\"\",`sum += f32(${u.getByOffset(\"inputOffset\")});`,`let value = ${a.type.value}(sum / ${m});`]})},jm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceMin\",r,(u,a,p)=>{let m=[];for(let y=0;y<u.rank;y++)(p.indexOf(y)>=0||p.length===0)&&m.push(`inputIndices[${y}] = 0;`);return[`${m.join(`\n`)}`,`var value = ${u.getByOffset(\"inputOffset\")};`,`value = min(value, ${u.getByOffset(\"inputOffset\")});`,\"\"]})},zm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceProd\",r,(u,a)=>[`var value = ${a.type.storage}(1);`,\"\",`value *= ${u.getByOffset(\"inputOffset\")};`,\"\"])},Vm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceSum\",r,(u,a)=>[`var value = ${a.type.storage}(0);`,\"\",`value += ${u.getByOffset(\"inputOffset\")};`,\"\"])},Wm=(e,r)=>{kt(e.inputs),Pt(e,\"ReduceSumSquare\",r,(u,a)=>[`var t = ${a.type.value}(0); var value = ${a.type.value}(0);`,\"\",`t = ${u.getByOffset(\"inputOffset\")}; value += t * t;`,\"\"])},Rt=(e,r,t)=>{if(r.length===0)return!!t;let u=1,a=1;for(let p=0;p<r.length;p++)r.indexOf(p)===-1?u*=e[p]:a*=e[p];return a<32&&u>1024},Ts=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?Dm(e,r):ys(e,r)},Es=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?Pm(e,r):bs(e,r)},Os=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?Rm(e,r):vs(e,r)},ks=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?Bm(e,r):ws(e,r)},Ps=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?Mm(e,r):$s(e,r)},Rs=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?jm(e,r):Cs(e,r)},Bs=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?zm(e,r):Ss(e,r)},Ms=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?Vm(e,r):xs(e,r)},Ds=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?Wm(e,r):_s(e,r)},js=(e,r)=>{Rt(e.inputs[0].dims,r.axes,r.noopWithEmptyAxes)?km(e,r):Is(e,r)},Ct=e=>he(e)});var zs,Vs,Ws,Vi,Us=ae(()=>{\"use strict\";Ze();Le();ti();zs=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"ArgMinMaxOp op requires 1 or 2 inputs.\");if(e[0].dataType!==1)throw new Error(\"Invalid input type.\")},Vs=(e,r)=>{zs(e.inputs);let t=(u,a,p)=>{let m=[];for(let y=0;y<u.rank;y++)(p.indexOf(y)>=0||p.length===0)&&m.push(`inputIndices[${y}] = 0;`);return[`${m.join(`\n`)}`,`var value = ${u.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${u.getByOffset(\"inputOffset\")} ${r.selectLastIndex>0?\"<=\":\"<\"} value) {\n         value = ${u.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",a.setByOffset(\"global_idx\",\"bestIndex\")]};e.compute(ri(\"ArgMin\",{hint:r.cacheKey},[e.inputs[0]],t,[r.axis],7,r.keepDims),{inputs:[0]})},Ws=(e,r)=>{zs(e.inputs);let t=(u,a,p)=>{let m=[];for(let y=0;y<u.rank;y++)(p.indexOf(y)>=0||p.length===0)&&m.push(`inputIndices[${y}] = 0;`);return[`${m.join(`\n`)}`,`var value = ${u.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${u.getByOffset(\"inputOffset\")} ${r.selectLastIndex>0?\">=\":\">\"} value) {\n         value = ${u.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",a.setByOffset(\"global_idx\",\"bestIndex\")]};e.compute(ri(\"argMax\",{hint:r.cacheKey},[e.inputs[0]],t,[r.axis],7,r.keepDims),{inputs:[0]})},Vi=e=>he(e)});var Um,Ns,Nm,Hm,Gm,ni,Lm,Hs,Wi=ae(()=>{\"use strict\";Le();Zn();Pe();Um=(e,r)=>{let t=e[0],u=e[1],a=e[2],p=e[3],m=e[4],y=e[5];if(m&&y)throw new Error(\"Attention cannot have both past and relative_position_bias\");if(t.dims.length!==3)throw new Error('Input \"input\" must have 3 dimensions');let l=t.dims[0],S=t.dims[1],A=t.dims[2];if(a.dims.length!==1)throw new Error('Input \"bias\" is expected to have 1 dimensions');if(u.dims.length!==2)throw new Error('Input \"weights\" is expected to have 2 dimensions');if(u.dims[0]!==A)throw new Error(\"Input 1 dimension 0 should have same length as dimension 2 of input 0\");if(a.dims[0]!==u.dims[1])throw new Error('Input \"bias\" dimension 0 should have same length as dimension 1 of input \"weights\"');let P=a.dims[0]/3,T=P,k=T;if(r.qkvHiddenSizes.length>0){if(r.qkvHiddenSizes.length!==3)throw new Error(\"qkv_hidden_sizes attribute should have 3 elements\");for(let q of r.qkvHiddenSizes)if(q%r.numHeads!==0)throw new Error(\"qkv_hidden_sizes should be divisible by num_heads\");P=r.qkvHiddenSizes[0],T=r.qkvHiddenSizes[1],k=r.qkvHiddenSizes[2]}let O=S;if(P!==T)throw new Error(\"qkv_hidden_sizes first element should be same as the second\");if(a.dims[0]!==P+T+k)throw new Error('Input \"bias\" dimension 0 should have same length as sum of Q/K/V hidden sizes');let R=0;if(m){if(T!==k)throw new Error('Input \"past\" expect k_hidden_size == v_hidden_size');if(m.dims.length!==5)throw new Error('Input \"past\" must have 5 dimensions');if(m.dims[0]!==2)throw new Error('Input \"past\" first dimension must be 2');if(m.dims[1]!==l)throw new Error('Input \"past\" second dimension must be batch_size');if(m.dims[2]!==r.numHeads)throw new Error('Input \"past\" third dimension must be num_heads');if(m.dims[4]!==T/r.numHeads)throw new Error('Input \"past\" fifth dimension must be k_hidden_size / num_heads');r.pastPresentShareBuffer||(R=m.dims[3])}let j=O+R,M=-1,z=0;if(p)throw new Error(\"Mask not supported\");if(m)throw new Error(\"past is not supported\");if(y)throw new Error(\"relativePositionBias is not supported\");return{batchSize:l,sequenceLength:S,pastSequenceLength:R,kvSequenceLength:O,totalSequenceLength:j,maxSequenceLength:M,inputHiddenSize:A,hiddenSize:P,vHiddenSize:k,headSize:Math.floor(P/r.numHeads),vHeadSize:Math.floor(k/r.numHeads),numHeads:r.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:r.maskFilterValue,maskType:z,scale:r.scale,broadcastResPosBias:!1,passPastInKv:!1,qkvFormat:1}},Ns=e=>he({...e}),Nm=(e,r,t,u)=>{let a=lt(u),p=se(\"x\",r.dataType,r.dims,a),m=\"threadMaxVector\";a===2?m=\"max(threadMaxVector.x, threadMaxVector.y)\":a===4&&(m=\"max(max(threadMaxVector.x, threadMaxVector.y), max(threadMaxVector.z, threadMaxVector.w))\");let y=je(r.dataType),l=64,S=u/a;S<l?l=1:S/8<64&&(l=Math.ceil(S/8));let A=Math.ceil(u/a/l),P=T=>`\n  const dInv: ${y} = 1 / ${u};\n  const dComp = ${u/a};\n  var<workgroup> wgMax: array<f32, ${l}>;\n  var<workgroup> wgSum: array<f32, ${l}>;\n\n  ${T.declareVariables(p)}\n  @compute @workgroup_size(${l}, 1, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_index) local_index : u32) {\n    let localOffset = local_index * ${A};\n    let offset: u32 = workgroup_id.x * dComp + localOffset;\n\n    var threadMaxVector = ${ot(\"f32\",a,\"-3.402823e+38f\")};\n    for (var i: u32 = 0; i < ${A} && i + localOffset < dComp; i++) {\n      threadMaxVector = max(${vt(y,a,\"x[offset + i]\")}, threadMaxVector);\n    }\n    wgMax[local_index] = ${m};\n    workgroupBarrier();\n\n    var maxValue = -3.402823e+38f;\n    for (var i = 0u; i < ${l}; i++) {\n      maxValue = max(wgMax[i], maxValue);\n    }\n\n    var sumVector = ${ot(\"f32\",a,\"0\")};\n    for (var i: u32 = 0; i < ${A} && i + localOffset < dComp; i++) {\n      sumVector += exp(${vt(y,a,\"x[offset + i]\")} - maxValue);\n    }\n    wgSum[local_index] = ${wt(\"sumVector\",a)};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${l}; i++) {\n      sum += wgSum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < ${A} && i + localOffset < dComp; i++) {\n        x[offset + i] = ${ot(y,a,\"dInv\")};\n      }\n    } else {\n      for (var i: u32 = 0; i < ${A} && i + localOffset < dComp; i++) {\n        let f32input = ${vt(y,a,\"x[offset + i]\")};\n        x[offset + i] = ${p.type.value}(exp(f32input - maxValue) / sum);\n      }\n    }\n  }`;e.compute({name:\"AttentionProbsSoftmax\",shaderCache:{hint:`${u}`},getShaderSource:P,getRunData:()=>({outputs:[],dispatchGroup:{x:t}})},{inputs:[r],outputs:[]})},Hm=(e,r,t,u,a,p)=>{let m=[a.batchSize,a.numHeads,a.sequenceLength,a.kvSequenceLength+a.pastSequenceLength],y=p.scale===0?1/Math.sqrt(a.headSize):p.scale,l=je(r.dataType),S=lt(a.headSize),A=te(\"q\",r.dataType,r.dims,S),P=te(\"key\",t.dataType,t.dims,S),T=se(\"output\",r.dataType,m),k=a.headSize/S,O=a.sequenceLength,R=a.totalSequenceLength,j=k,M=12,z={x:Math.ceil(a.totalSequenceLength/M),y:Math.ceil(a.sequenceLength/M),z:a.batchSize*a.numHeads},q=[r,t],G=_=>`\n  const M: u32 = ${O}u;\n  const N: u32 = ${R}u;\n  const K: u32 = ${j}u;\n  const alpha: ${l} = ${y};\n  const beta: ${l} = 1.0;\n  const TILE_SIZE = ${M}u;\n\n  var<workgroup> tileQ: array<${A.type.storage}, ${M*M}>;\n  var<workgroup> tileK: array<${A.type.storage}, ${M*M}>;\n\n  ${_.declareVariables(A,P,T)}\n\n  @compute @workgroup_size(${M}, ${M}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${z.x*z.y}u +\n          workgroup_id.y * ${z.x}u + workgroup_id.x) * ${M*M}u + local_index;\n\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let lm = m + local_id.y;\n    let ln = n + local_id.x;\n\n    let qOffset = ${a.sequenceLength*k} * headIdx + m * K;\n    let kOffset = ${a.kvSequenceLength*k} * headIdx + n * K;\n\n    var value = ${ot(l,S)};\n    for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n      if (m + local_id.y < M && w + local_id.x < K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * K + w + local_id.x];\n      }\n      if (n + local_id.y < N && w + local_id.x < K) {\n        tileK[TILE_SIZE * local_id.y + local_id.x] = key[kOffset + local_id.y * K + w + local_id.x];\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n        value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = headIdx * M * N;\n    if (lm < M && ln < N) {\n      let outputIdx = headOffset + lm * N + ln;\n      output[outputIdx] = ${wt(\"value\",S)} * alpha;\n    }\n  }`,Y=e.compute({name:\"AttentionProbs\",shaderCache:{hint:JSON.stringify(a)},getRunData:()=>({outputs:[{dims:m,dataType:r.dataType,gpuDataType:0}],dispatchGroup:z}),getShaderSource:G},{inputs:q,outputs:[-1]})[0];return Nm(e,Y,a.batchSize*a.numHeads*a.sequenceLength,a.totalSequenceLength),Y},Gm=(e,r,t,u)=>{let a=[u.batchSize,u.sequenceLength,u.vHiddenSize],p=te(\"probs\",r.dataType,r.dims),m=te(\"v\",t.dataType,t.dims),y=se(\"output\",r.dataType,a),l=je(r.dataType),S=12,A={x:Math.ceil(u.vHeadSize/S),y:Math.ceil(u.sequenceLength/S),z:u.batchSize*u.numHeads},P=T=>`\n  const M: u32 = ${u.sequenceLength}u;\n  const N: u32 = ${u.vHeadSize}u;\n  const K: u32 = ${u.totalSequenceLength}u;\n  const numHeads: u32 = ${u.numHeads}u;\n  const TILE_SIZE = ${S}u;\n\n  var<workgroup> tileQ: array<${p.type.storage}, ${S*S}>;\n  var<workgroup> tileK: array<${p.type.storage}, ${S*S}>;\n\n  ${T.declareVariables(p,m,y)}\n\n  @compute @workgroup_size(${S}, ${S}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${A.x*A.y}u +\n          workgroup_id.y * ${A.x}u + workgroup_id.x) * ${S*S}u + local_index;\n\n   let headIdx = workgroup_id.z;\n   let m = workgroup_id.y * TILE_SIZE + local_id.y;\n   let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n   let offsetA = headIdx * (M * K) + m * K;\n   let offsetB = headIdx * (N * K) + n;\n\n   var value = ${l}(0);\n   for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n     if (m < M && w + local_id.x < K) {\n       tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n     }\n     if (n < N && w + local_id.y < K) {\n       tileK[TILE_SIZE * local_id.y + local_id.x] = v[offsetB + (w + local_id.y) * N];\n     }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   let batchIdx = workgroup_id.z / ${u.numHeads};\n   let currentBatchHeadNumber = workgroup_id.z % ${u.numHeads};\n   let headOffset = (batchIdx * M * ${u.numHeads} + currentBatchHeadNumber) * ${u.vHeadSize};\n   if (m < M && n < N) {\n     let outputIdx = batchIdx * ${u.sequenceLength*u.vHiddenSize} + m * ${u.vHiddenSize}\n       + currentBatchHeadNumber * ${u.vHeadSize} + n;\n     output[outputIdx] = value;\n   }\n  }`;return e.compute({name:\"AttentionScore\",shaderCache:{hint:JSON.stringify(u)},getRunData:()=>({outputs:[{dims:a,dataType:r.dataType,gpuDataType:0}],dispatchGroup:A}),getShaderSource:P},{inputs:[r,t],outputs:[0]})[0]},ni=(e,r,t,u,a,p,m,y,l,S,A)=>{let P=Hm(e,r,t,l,S,A);Gm(e,P,u,S)},Lm=(e,r)=>{let t=[r.batchSize,r.numHeads,r.sequenceLength,r.headSize],u=je(e.inputs[0].dataType),a=r.sequenceLength,p=r.inputHiddenSize,m=r.headSize,y=12,l={x:Math.ceil(r.headSize/y),y:Math.ceil(r.sequenceLength/y),z:r.batchSize*r.numHeads},S=()=>`\n  const M: u32 = ${a}u;\n  const K: u32 = ${p}u;\n  const N: u32 = ${m}u;\n  const numHeads: u32 = ${r.numHeads};\n  const ldb = ${r.hiddenSize+r.hiddenSize+r.vHiddenSize}u;\n  const TILE_SIZE = ${y}u;\n\n  var<workgroup> tileInput: array<${u}, ${y*y}>;\n  var<workgroup> tileWeightQ: array<${u}, ${y*y}>;\n  var<workgroup> tileWeightK: array<${u}, ${y*y}>;\n  var<workgroup> tileWeightV: array<${u}, ${y*y}>;\n\n  @group(0) @binding(0) var<storage, read> input: array<${u}>;\n  @group(0) @binding(1) var<storage, read> weight: array<${u}>;\n  @group(0) @binding(2) var<storage, read> bias: array<${u}>;\n  @group(0) @binding(3) var<storage, read_write> outputQ: array<${u}>;\n  @group(0) @binding(4) var<storage, read_write> outputK: array<${u}>;\n  @group(0) @binding(5) var<storage, read_write> outputV: array<${u}>;\n\n  @compute @workgroup_size(${y}, ${y}, 1)\n  fn main(@builtin(workgroup_id) workgroup_id : vec3<u32>,\n   @builtin(local_invocation_id) local_id : vec3<u32>, @builtin(local_invocation_index) local_index : u32) {\n   let global_idx = (workgroup_id.z * ${l.x*l.y}u +\n          workgroup_id.y * ${l.x}u + workgroup_id.x) * ${y*y}u + local_index;\n\n    let batchIndex = workgroup_id.z / ${r.numHeads};\n    let headNumber = workgroup_id.z % ${r.numHeads};\n    let m = workgroup_id.y * TILE_SIZE + local_id.y;\n    let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n    let inputOffset = batchIndex * (M * K) + m * K;\n    let biasOffsetQ = headNumber * ${r.headSize};\n    let biasOffsetK = ${r.hiddenSize} + biasOffsetQ;\n    let biasOffsetV = ${r.hiddenSize} + biasOffsetK;\n\n    var valueQ = ${u}(0);\n    var valueK = ${u}(0);\n    var valueV = ${u}(0);\n    for (var w: u32 = 0u; w < K; w += TILE_SIZE) {\n      if (m < M && w + local_id.x < K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < N && w + local_id.y < K) {\n        let offset = n + (w + local_id.y) * ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * N + n) % ${r.headSize};\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * M * N;\n    if (m < M && n < N) {\n      let outputIdx = offset + m * N + n;\n      outputQ[outputIdx] = valueQ;\n      outputK[outputIdx] = valueK;\n      outputV[outputIdx] = valueV;\n    }\n  }`,A=[e.inputs[0],e.inputs[1],e.inputs[2]];return e.compute({name:\"AttentionPrepare\",shaderCache:{hint:JSON.stringify(r)},getRunData:()=>({outputs:[{dims:t,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:t,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:t,dataType:e.inputs[0].dataType,gpuDataType:0}],dispatchGroup:l}),getShaderSource:S},{inputs:A,outputs:[-1,-1,-1]})},Hs=(e,r)=>{let t=Um(e.inputs,r),[u,a,p]=Lm(e,t);return ni(e,u,a,p,e.inputs[4],void 0,void 0,void 0,e.inputs[5],t,r)}});var ii=ae(()=>{\"use strict\"});var Gs=ae(()=>{\"use strict\";ii()});var Ls,Fs=ae(()=>{\"use strict\";Ls=\"1.17.0\"});var qs,Ui,Ks=ae(()=>{\"use strict\";Fs();qs=\"warning\",Ui={wasm:{},webgl:{},webgpu:{},versions:{common:Ls},set logLevel(e){if(e!==void 0){if(typeof e!=\"string\"||[\"verbose\",\"info\",\"warning\",\"error\",\"fatal\"].indexOf(e)===-1)throw new Error(`Unsupported logging level: ${e}`);qs=e}},get logLevel(){return qs}};Object.defineProperty(Ui,\"logLevel\",{enumerable:!0})});var oi,Ys=ae(()=>{\"use strict\";Ks();oi=Ui});var Zs=ae(()=>{\"use strict\"});var Xs=ae(()=>{\"use strict\";ai()});var Js=ae(()=>{\"use strict\"});var eu=ae(()=>{\"use strict\";ai()});var ai=ae(()=>{\"use strict\";Zs();Xs();Js();eu()});var si=ae(()=>{\"use strict\";ai()});var tu=ae(()=>{\"use strict\";ii();si()});var ru=ae(()=>{\"use strict\";tu()});var nu=ae(()=>{\"use strict\"});var iu=ae(()=>{\"use strict\";ii();si()});var ou=ae(()=>{\"use strict\";iu()});var Ni=ae(()=>{\"use strict\";Gs();Ys();ru();si();nu();ou()});var Km,Ym,Zm,au,su=ae(()=>{\"use strict\";Ni();ke();Le();Pe();Km=(e,r)=>{if(!e||e.length!==5)throw new Error(\"BatchNormalization requires 5 inputs\");let t=(u,a,p)=>{let m=a.length;if(m!==u.length)throw new Error(`${p}: num dimensions != ${m}`);a.forEach((y,l)=>{if(y!==u[l])throw new Error(`${p}: dim[${l}] do not match`)})};if(e[0].dims.length>1){let u=r.format===\"NHWC\"?r.spatial?e[0].dims.slice(-1):e[0].dims.slice(-1).concat(e[0].dims.slice(1,e[0].dims.length-1)):e[0].dims.slice(1,r.spatial?2:void 0);t(e[1].dims,u,\"Invalid input scale\"),t(e[2].dims,u,\"Invalid input B\"),t(e[3].dims,u,\"Invalid input mean\"),t(e[4].dims,u,\"Invalid input var\")}else t(e[1].dims,[1],\"Invalid input scale\"),t(e[2].dims,[1],\"Invalid input B\"),t(e[3].dims,[1],\"Invalid input mean\"),t(e[4].dims,[1],\"Invalid input var\")},Ym=(e,r)=>{let{epsilon:t,spatial:u,format:a}=r,p=e[0].dims,m=u?lt(p[p.length-1]):1,y=a===\"NHWC\"&&p.length>1?m:1,l=Z.size(p)/m,S=He(p.length)&&u,A=S?p.length:p,P=te(\"x\",e[0].dataType,e[0].dims,m),T=te(\"scale\",e[1].dataType,e[1].dims,y),k=te(\"bias\",e[2].dataType,e[2].dims,y),O=te(\"inputMean\",e[3].dataType,e[3].dims,y),R=te(\"inputVar\",e[4].dataType,e[4].dims,y),j=se(\"y\",e[0].dataType,A,m),M=()=>{let q=\"\";if(u)q=`let cOffset = ${p.length===1?\"0u\":a===\"NHWC\"?`outputIndices[${p.length-1}] / ${m}`:\"outputIndices[1]\"};`;else if(a===\"NCHW\")q=`\n            ${j.indicesSet(\"outputIndices\",\"0\",\"0\")}\n            let cOffset = ${j.indicesToOffset(\"outputIndices\")};`;else{q=`var cIndices = ${T.type.indices}(0);\n                       cIndices[0] = outputIndices[${p.length-1}];`;for(let G=1;G<T.rank;G++)q+=`cIndices[${G}] = outputIndices[${G}];`;q+=`let cOffset = ${T.indicesToOffset(\"cIndices\")};`}return q},z=q=>`\n  const epsilon = ${t};\n  ${q.registerUniform(\"outputSize\",\"u32\").declareVariables(P,T,k,O,R,j)}\n  ${q.mainStart()}\n  ${q.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n    var outputIndices = ${j.offsetToIndices(`global_idx * ${m}`)};\n    ${M()}\n    let scale = ${T.getByOffset(\"cOffset\")};\n    let bias = ${k.getByOffset(\"cOffset\")};\n    let inputMean = ${O.getByOffset(\"cOffset\")};\n    let inputVar = ${R.getByOffset(\"cOffset\")};\n    let x = ${P.getByOffset(\"global_idx\")};\n    let value = (x - inputMean) / sqrt(inputVar + epsilon) * scale + bias;\n    ${j.setByOffset(\"global_idx\",\"value\")}\n  }`;return{name:\"BatchNormalization\",shaderCache:{hint:`${r.epsilon}_${r.format}_${u}_${m}`,inputDependencies:S?[\"rank\",\"type\",\"type\",\"type\",\"type\"]:void 0},getShaderSource:z,getRunData:()=>({outputs:[{dims:e[0].dims,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(l/64)},programUniforms:S?[{type:\"uint32\",data:l},...xe(p)]:[{type:\"uint32\",data:l}]})}},Zm=e=>he(e),au=(e,r)=>{let{inputs:t,outputCount:u}=e,a=Zm({...r,outputCount:u});if(oi.webgpu.validateInputContent&&Km(t,a),r.trainingMode)throw new Error(\"BatchNormalization trainingMode is not supported yet.\");e.compute(Ym(t,a))}});var Xm,Qm,uu,lu=ae(()=>{\"use strict\";ke();Pe();Xm=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![320,640,1280].includes(e[0].dims[2]))throw new Error(\"number of channels should be 320, 640 or 1280\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},Qm=e=>{let r=e[0].dims,t=e[0].dims[2],u=Z.size(r)/4,a=e[0].dataType,p=te(\"input\",a,r,4),m=te(\"bias\",a,[t],4),y=te(\"residual\",a,r,4),l=se(\"output\",a,r,4);return{name:\"BiasAdd\",getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)}}),getShaderSource:A=>`\n  const channels = ${t}u / 4;\n  ${A.declareVariables(p,m,y,l)}\n\n  ${A.mainStart()}\n    ${A.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n    let value = ${p.getByOffset(\"global_idx\")}\n      + ${m.getByOffset(\"global_idx % channels\")} + ${y.getByOffset(\"global_idx\")};\n    ${l.setByOffset(\"global_idx\",\"value\")}\n  }`}},uu=e=>{Xm(e.inputs),e.compute(Qm(e.inputs))}});var Jm,ze,du,cu,fu,pu,mu,hu,gu,yu,bu,eh,vu,wu,$u,Cu,ui,Su,li,xu,_u,Iu,Au,Tu,Eu,Ou,ku,Pu,Ru,Bu,Mu,Du,ju,zu,Vu,Wu,Hi=ae(()=>{\"use strict\";Ze();ke();Le();Pe();Jm=(e,r,t,u,a,p)=>{let m=Math.ceil(r/4),y=\"\";typeof a==\"string\"?y=`${a}(a)`:y=a(\"a\");let l=te(\"inputData\",t,[m],4),S=se(\"outputData\",u,[m],4);return`\n      ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(l,S)}\n\n  ${p??\"\"}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n\n    let a = ${l.getByOffset(\"global_idx\")};\n    ${S.setByOffset(\"global_idx\",y)}\n  }`},ze=(e,r,t,u,a,p=e.dataType)=>({name:r,shaderCache:{hint:a,inputDependencies:[\"type\"]},getShaderSource:m=>Jm(m,Z.size(e.dims),e.dataType,p,t,u),getRunData:m=>({outputs:[{dims:e.dims,dataType:p}],dispatchGroup:{x:Math.ceil(Z.size(m[0].dims)/64/4)},programUniforms:[{type:\"uint32\",data:Math.ceil(Z.size(e.dims)/4)}]})}),du=e=>{e.compute(ze(e.inputs[0],\"Abs\",\"abs\"))},cu=e=>{e.compute(ze(e.inputs[0],\"Acos\",\"acos\"))},fu=e=>{e.compute(ze(e.inputs[0],\"Acosh\",\"acosh\"))},pu=e=>{e.compute(ze(e.inputs[0],\"Asin\",\"asin\"))},mu=e=>{e.compute(ze(e.inputs[0],\"Asinh\",\"asinh\"))},hu=e=>{e.compute(ze(e.inputs[0],\"Atan\",\"atan\"))},gu=e=>{e.compute(ze(e.inputs[0],\"Atanh\",\"atanh\"))},yu=e=>he(e),bu=(e,r)=>{let t;switch(r.to){case 10:t=\"vec4<f16>\";break;case 1:t=\"vec4<f32>\";break;case 12:t=\"vec4<u32>\";break;case 6:t=\"vec4<i32>\";break;case 9:t=\"vec4<bool>\";break;default:throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${r.to}`)}e.compute(ze(e.inputs[0],\"Cast\",t,void 0,r.cacheKey,r.to))},eh=e=>{let r=e.length>=2?e[1].getFloat32Array()[0]:Jn,t=e.length>=3?e[2].getFloat32Array()[0]:ei;return he({min:r,max:t})},vu=(e,r)=>{let t=e.inputs.length===1?r:eh(e.inputs),u=je(e.inputs[0].dataType);e.compute(ze(e.inputs[0],\"Clip\",a=>`clamp(${a}, clip_min_, clip_max_)`,`\n    const clip_min_: vec4<${u}> = vec4(${u}(${t.min}));\n    const clip_max_: vec4<${u}> = vec4(${u}(${t.max}));\n`,t.cacheKey),{inputs:[0]})},wu=e=>{e.compute(ze(e.inputs[0],\"Ceil\",\"ceil\"))},$u=e=>{e.compute(ze(e.inputs[0],\"Cos\",\"cos\"))},Cu=e=>{e.compute(ze(e.inputs[0],\"Cosh\",\"cosh\"))},ui=e=>he(e),Su=(e,r)=>{e.compute(ze(e.inputs[0],\"Elu\",t=>`elu_vf32(${t})`,`\n  const elu_alpha_: f32 = f32(${r.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,r.cacheKey))},li=(e,r=\"f32\")=>`\nconst r0: ${r} = 0.3275911;\nconst r1: ${r} = 0.254829592;\nconst r2: ${r} = -0.284496736;\nconst r3: ${r} = 1.421413741;\nconst r4: ${r} = -1.453152027;\nconst r5: ${r} = 1.061405429;\n\nfn erf_vf32(v: ${e}) -> ${e} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`,xu=e=>{let r=je(e.inputs[0].dataType);e.compute(ze(e.inputs[0],\"Erf\",t=>`erf_vf32(${t})`,li(`vec4<${r}>`,r)))},_u=e=>{e.compute(ze(e.inputs[0],\"Exp\",\"exp\"))},Iu=e=>{e.compute(ze(e.inputs[0],\"Floor\",\"floor\"))},Au=e=>{let r=je(e.inputs[0].dataType);e.compute(ze(e.inputs[0],\"Gelu\",t=>`0.5 * ${t} * (1.0 + erf_vf32(${t} * 0.7071067811865475))`,li(`vec4<${r}>`,r)))},Tu=(e,r)=>{e.compute(ze(e.inputs[0],\"LeakyRelu\",t=>`select(leaky_relu_alpha_ * ${t}, ${t}, ${t} >= vec4<f32>(0.0))`,`const leaky_relu_alpha_: f32 = f32(${r.alpha});`,r.cacheKey))},Eu=e=>{e.compute(ze(e.inputs[0],\"Not\",r=>`!${r}`))},Ou=e=>{e.compute(ze(e.inputs[0],\"Neg\",r=>`-${r}`))},ku=e=>{e.compute(ze(e.inputs[0],\"Reciprocal\",r=>`1.0/${r}`))},Pu=e=>{e.compute(ze(e.inputs[0],\"Relu\",r=>`select(vec4<f32>(0.0), ${r}, ${r} > vec4<f32>(0.0))`))},Ru=e=>{e.compute(ze(e.inputs[0],\"Sigmoid\",r=>`(1.0 / (1.0 + exp(-${r})))`))},Bu=e=>{e.compute(ze(e.inputs[0],\"Sin\",\"sin\"))},Mu=e=>{e.compute(ze(e.inputs[0],\"Sinh\",\"sinh\"))},Du=e=>{e.compute(ze(e.inputs[0],\"Sqrt\",\"sqrt\"))},ju=e=>{e.compute(ze(e.inputs[0],\"Tan\",\"tan\"))},zu=e=>{e.compute(ze(e.inputs[0],\"Tanh\",\"tanh\"))},Vu=(e,r)=>(e.compute(ze(e.inputs[0],\"ThresholdedRelu\",t=>`select(vec4<f32>(0.0), ${t}, ${t} > thresholded_relu_alpha_)`,`const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${r.alpha});`,r.cacheKey)),0),Wu=e=>{e.compute(ze(e.inputs[0],\"Log\",\"log\"))}});var rh,nh,Uu,Nu=ae(()=>{\"use strict\";ke();Pe();Hi();rh=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![2560,5120,10240].includes(e[0].dims[2]))throw new Error(\"hidden state should be 2560, 5120 or 10240\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},nh=e=>{let r=e[0].dims.slice();r[2]=r[2]/2;let t=te(\"input\",e[0].dataType,e[0].dims,4),u=te(\"bias\",e[0].dataType,[e[0].dims[2]],4),a=se(\"output\",e[0].dataType,r,4),p=Z.size(r)/4,m=je(e[0].dataType);return{name:\"BiasSplitGelu\",getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(p/64)}}),getShaderSource:l=>`\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${e[0].dims[2]/4/2}u;\n\n  ${l.declareVariables(t,u,a)}\n\n  ${li(`vec4<${m}>`,m)}\n\n  ${l.mainStart()}\n    ${l.guardAgainstOutOfBoundsWorkgroupSizes(p)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${a.setByOffset(\"global_idx\",\"valueLeft * geluRight\")}\n  }`}},Uu=e=>{rh(e.inputs),e.compute(nh(e.inputs))}});var ih,oh,Bt,Hu,Gu,Lu,Fu,qu,Ku,Yu,Zu,Xu,Qu,Ju=ae(()=>{\"use strict\";Ze();ke();Pe();ih=(e,r,t,u,a,p,m,y,l,S,A,P,T)=>{let k,O;typeof y==\"string\"?k=O=(_,X)=>`${y}((${_}),(${X}))`:typeof y==\"function\"?k=O=y:(k=y.scalar,O=y.vector);let R=P?r.length:r,j=P?t.length:t,M=P?u.length:u,z=se(\"outputData\",A,M,4),q=te(\"aData\",l,R,4),G=te(\"bData\",S,j,4),Y;if(a)if(p){let _=Z.size(r)===1,X=Z.size(t)===1,J=r.length>0&&r[r.length-1]%4===0,re=t.length>0&&t[t.length-1]%4===0;_||X?Y=z.setByOffset(\"global_idx\",O(_?`${q.type.value}(${q.getByOffset(\"0\")}.x)`:q.getByOffset(\"global_idx\"),X?`${G.type.value}(${G.getByOffset(\"0\")}.x)`:G.getByOffset(\"global_idx\"))):Y=`\n            let outputIndices = ${z.offsetToIndices(\"global_idx * 4u\")};\n            let offsetA = ${q.broadcastedIndicesToOffset(\"outputIndices\",z)};\n            let offsetB = ${G.broadcastedIndicesToOffset(\"outputIndices\",z)};\n            ${z.setByOffset(\"global_idx\",O(m||J?q.getByOffset(\"offsetA / 4u\"):`${q.type.value}(${q.getByOffset(\"offsetA / 4u\")}[offsetA % 4u])`,m||re?G.getByOffset(\"offsetB / 4u\"):`${G.type.value}(${G.getByOffset(\"offsetB / 4u\")}[offsetB % 4u])`))}\n          `}else Y=z.setByOffset(\"global_idx\",O(q.getByOffset(\"global_idx\"),G.getByOffset(\"global_idx\")));else{if(!p)throw new Error(\"no necessary to use scalar implementation for element-wise binary op implementation.\");let _=(X,J,re=\"\")=>{let fe=`aData[indexA${J}][componentA${J}]`,L=`bData[indexB${J}][componentB${J}]`;return`\n            let outputIndices${J} = ${z.offsetToIndices(`global_idx * 4u + ${J}u`)};\n            let offsetA${J} = ${q.broadcastedIndicesToOffset(`outputIndices${J}`,z)};\n            let offsetB${J} = ${G.broadcastedIndicesToOffset(`outputIndices${J}`,z)};\n            let indexA${J} = offsetA${J} / 4u;\n            let indexB${J} = offsetB${J} / 4u;\n            let componentA${J} = offsetA${J} % 4u;\n            let componentB${J} = offsetB${J} % 4u;\n            ${X}[${J}] = ${re}(${k(fe,L)});\n          `};A===9?Y=`\n            var data = vec4<u32>(0);\n            ${_(\"data\",0,\"u32\")}\n            ${_(\"data\",1,\"u32\")}\n            ${_(\"data\",2,\"u32\")}\n            ${_(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:Y=`\n            ${_(\"outputData[global_idx]\",0)}\n            ${_(\"outputData[global_idx]\",1)}\n            ${_(\"outputData[global_idx]\",2)}\n            ${_(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(q,G,z)}\n\n        ${T??\"\"}\n\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n        ${Y}\n      }`},oh=(e,r,t,u,a,p,m=t.dataType)=>{let y=!Z.areEqual(t.dims,u.dims),l=t.dims,S=Z.size(t.dims),A=!1,P=!1,T=[y];if(y){let O=Tt.calcShape(t.dims,u.dims,!1);if(!O)throw new Error(\"Can't perform binary op on the given tensors\");l=O,S=Z.size(l);let R=Z.size(t.dims)===1,j=Z.size(u.dims)===1,M=t.dims.length>0&&t.dims[t.dims.length-1]%4===0,z=u.dims.length>0&&u.dims[u.dims.length-1]%4===0;T.push(R),T.push(j),T.push(M),T.push(z);let q=1;for(let G=1;G<l.length;G++){let Y=t.dims[t.dims.length-G]??1,_=u.dims[u.dims.length-G]??1;if(Y===_)q*=Y;else break}q%4===0?(P=!0,A=!0):(R||j||M||z)&&(A=!0)}else A=!0;T.push(A);let k=He(t.dims.length)&&He(u.dims.length)&&He(l.length);return{name:e,shaderCache:{hint:r+T.map(O=>O.toString()).join(\"_\"),inputDependencies:k?[\"rank\",\"rank\"]:[\"dims\",\"dims\"]},getShaderSource:O=>ih(O,t.dims,u.dims,l,A,y,P,a,t.dataType,u.dataType,m,k,p),getRunData:()=>({outputs:[{dims:l,dataType:m}],dispatchGroup:{x:Math.ceil(S/64/4)},programUniforms:k?[{type:\"uint32\",data:Math.ceil(Z.size(l)/4)},...xe(t.dims),...xe(u.dims),...xe(l)]:[{type:\"uint32\",data:Math.ceil(Z.size(l)/4)}]})}},Bt=(e,r,t,u,a,p)=>{e.compute(oh(r,a??\"\",e.inputs[0],e.inputs[1],t,u,p))},Hu=e=>{Bt(e,\"Add\",(r,t)=>`${r}+${t}`)},Gu=e=>{Bt(e,\"Div\",(r,t)=>`${r}/${t}`)},Lu=e=>{Bt(e,\"Equal\",{scalar:(r,t)=>`u32(${r}==${t})`,vector:(r,t)=>`vec4<u32>(${r}==${t})`},void 0,void 0,9)},Fu=e=>{Bt(e,\"Mul\",(r,t)=>`${r}*${t}`)},qu=e=>{let r=te(\"input\",e.inputs[0].dataType,e.inputs[0].dims).type.value;Bt(e,\"Pow\",{scalar:(u,a)=>`pow_custom(${u},${a})`,vector:(u,a)=>`pow_vector_custom(${u},${a})`},`\n    fn pow_custom(a : ${r}, b : ${r}) -> ${r} {\n      if (b == ${r}(0.0)) {\n        return ${r}(1.0);\n      } else if (a < ${r}(0.0) && f32(b) != floor(f32(b))) {\n        return ${r}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${r}(1.0), round(f32(abs(b) % ${r}(2.0))) != 1.0) * ${r}(${r===\"i32\"?\"round\":\"\"}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${r}>, b : vec4<${r}>) -> vec4<${r}> {\n      // TODO: implement vectorized pow\n      return vec4<${r}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `)},Ku=e=>{Bt(e,\"Sub\",(r,t)=>`${r}-${t}`)},Yu=e=>{Bt(e,\"Greater\",{scalar:(r,t)=>`u32(${r}>${t})`,vector:(r,t)=>`vec4<u32>(${r}>${t})`},void 0,void 0,9)},Zu=e=>{Bt(e,\"Less\",{scalar:(r,t)=>`u32(${r}<${t})`,vector:(r,t)=>`vec4<u32>(${r}<${t})`},void 0,void 0,9)},Xu=e=>{Bt(e,\"GreaterOrEqual\",{scalar:(r,t)=>`u32(${r}>=${t})`,vector:(r,t)=>`vec4<u32>(${r}>=${t})`},void 0,void 0,9)},Qu=e=>{Bt(e,\"LessOrEqual\",{scalar:(r,t)=>`u32(${r}<=${t})`,vector:(r,t)=>`vec4<u32>(${r}<=${t})`},void 0,void 0,9)}});var sh,uh,lh,dh,el,tl,rl=ae(()=>{\"use strict\";ke();Le();Pe();sh=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\");let r=e[0].dataType,t=e[0].dims.length;for(let u of e){if(u.dataType!==r)throw new Error(\"input tensors should be one type\");if(u.dims.length!==t)throw new Error(\"input tensors should have the same shape\")}},uh=(e,r)=>`\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${e}u>(${r});\n    for (var i: u32 = 0u; i < ${e}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${e}u;\n  }`,lh=(e,r)=>{let t=e.length,u=[];for(let a=0;a<t;++a){let p=r.setByOffset(\"global_idx\",e[a].getByIndices(\"indices\"));t===1?u.push(p):a===0?u.push(`if (inputIndex == ${a}u) { ${p} }`):a===t-1?u.push(`else { ${p} }`):u.push(`else if (inputIndex == ${a}) { ${p} }`)}return u.join(`\n`)},dh=(e,r)=>{let t=e[0].dims.slice();if(r>=t.length||r<-1*t.length)throw new Error(\"axis specified for concat doesn't match input dimensionality\");let u=r<0?t.length+r:r,a=t.slice(0);for(let G=1;G<e.length;G++){let Y=e[G].dims.slice();for(let _=0;_<t.length;_++)if(_===u)a[u]+=Y[_];else if(t[_]!==Y[_])throw new Error(\"non concat dimensions must match\")}let p=Z.size(a),m=new Array(e.length),y=new Array(e.length),l=e[0].dataType,S=0,A=[],P=[],T=[],k=[{type:\"uint32\",data:p}];for(let G=0;G<e.length;++G)S+=e[G].dims[u],m[G]=S,T.push(He(e[G].dims.length)),P.push(T[G]?e[G].dims.length:e[G].dims),y[G]=te(`input${G}`,l,P[G]),A.push(T[G]?\"rank\":\"dims\"),k.push({type:\"uint32\",data:m[G]});for(let G=0;G<e.length;++G)T[G]&&k.push(...xe(e[G].dims));let O=He(a.length);O&&k.push(...xe(a));let R=O?a.length:a,j=se(\"output\",l,R),M=j.indicesGet(\"indices\",u),z=Array.from(Array(m.length).keys()).map(G=>`uniforms.sizeInConcatAxis${G}`).join(\",\"),q=G=>`\n\n  ${(()=>{G.registerUniform(\"outputSize\",\"u32\");for(let Y=0;Y<e.length;Y++)G.registerUniform(`sizeInConcatAxis${Y}`,\"u32\");return G.declareVariables(...y,j)})()}\n\n  ${uh(m.length,z)}\n\n  ${G.mainStart()}\n    ${G.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n\n    var indices = ${j.offsetToIndices(\"global_idx\")};\n\n    let inputIndex = calculateInputIndex(${M});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${m.length}u>(${z});\n      ${M} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${lh(y,j)}\n  }`;return{name:\"Concat\",shaderCache:{hint:`${r}`,inputDependencies:A},getRunData:()=>({outputs:[{dims:a,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(p/64)},programUniforms:k}),getShaderSource:q}},el=(e,r)=>{sh(e.inputs),e.compute(dh(e.inputs,r.axis))},tl=e=>he({axis:e.axis})});var Vt,di,er=ae(()=>{\"use strict\";ke();Vt=(e,r)=>{switch(e.activation){case\"Relu\":return{activationFunction:\"\",applyActivation:`value = max(value, ${r}(0.0));`};case\"Sigmoid\":return{activationFunction:\"\",applyActivation:`value = (${r}(1.0) / (${r}(1.0) + exp(-value)));`};case\"Clip\":return{activationFunction:`const clip_min_=${r}(${e.clipMin});const clip_max_=${r}(${e.clipMax});`,applyActivation:\"value = clamp(value, clip_min_, clip_max_);\"};default:return{activationFunction:\"\",applyActivation:\"\"}}},di=e=>{let r=e?.activation||\"\";if(r===\"Clip\"){let[t,u]=e?.activation_params||[Jn,ei];return{activation:r,clipMax:u,clipMin:t,activationCacheKey:`${r}:${t},${u}`}}return{activation:r,activationCacheKey:r}}});var et,ci,fi=ae(()=>{\"use strict\";et=(e,r)=>{switch(e){case 1:return r;case 2:return`vec2<${r}>`;case 3:return`vec3<${r}>`;case 4:return`vec4<${r}>`;default:throw new Error(`${e}-component is not supported.`)}},ci=e=>`\n      ${e?\"value = value + getBiasByOutputCoords(coords);\":\"\"}\n      `});var pi,Gi=ae(()=>{\"use strict\";pi=e=>`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    i32(${e}.x), i32(${e}.y), i32(${e}.z), 1));\n}\n`});var ch,fh,yn,nl,ph,bn,mh,mi,vn=ae(()=>{\"use strict\";ke();Pe();er();fi();ch=(e,r)=>e?`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${r?\", batchIndices\":\"\"});\n        `:`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${r?\", batchIndices\":\"\"});\n        `,fh=(e,r)=>e?`\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${r===3?\"\":\"let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];\"}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${r===3?\"\":\"acc[i] = BCached3 * ACached3[i] + acc[i];\"}\n        }`:`\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${r===3?\"\":\"acc[i] = BCached3 * ACached.w + acc[i];\"}\n        }`,yn=(e,r,t=\"f32\",u,a=!1,p=32,m=!1,y=32)=>{let l=r[1]*e[1],S=r[0]*e[0],A=a?l:p,P=a?p:l,T=A/r[0],k=p/r[1];if(!((a&&T===4&&e[1]===4||!a&&(T===3||T===4))&&A%r[0]===0&&p%r[1]===0&&e[0]===4))throw new Error(`If transposeA ${a} is true, innerElementSize ${T} and workPerThread[1] ${e[1]} must be 4.\n      Otherwise, innerElementSize ${T} must be 3 or 4.\n  tileAWidth ${A} must be divisible by workgroupSize[0]${r[0]}. tileInner ${p} must be divisible by workgroupSize[1] ${r[1]}. colPerThread ${e[0]} must be 4.`);return`\nvar<workgroup> mm_Asub: array<array<vec${T}<${t}>, ${A/T}>, ${P}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${t}>, ${S/e[0]}>, ${p}>;\n\nconst rowPerThread = ${e[1]};\nconst colPerThread = ${e[0]};\nconst innerElementSize = ${T};\nconst tileInner = ${p};\n\n@compute @workgroup_size(${r[0]}, ${r[1]}, ${r[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${m?\"0\":\"i32(globalId.z)\"};\n  ${u?`let batchIndices = ${u.offsetToIndices(\"u32(batch)\")};`:\"\"}\n  let globalRowStart = i32(workgroupId.y) * ${l};\n\n  let numTiles = ${m?`${Math.ceil(y/p)}`:\"(uniforms.dimInner - 1) / tileInner + 1\"};\n  var kStart = ${m?`i32(globalId.z) * ${y}`:\"0\"};\n\n  var acc: array<vec4<${t}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${k};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${ch(a,u)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${k}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${u?\", batchIndices\":\"\"});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${T===3?\"\":\"let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];\"}\n\n          ${fh(a,T)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`},nl=(e,r)=>e?`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${r?\", batchIndices\":\"\"});\n            `:`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${r?\", batchIndices\":\"\"});\n            `,ph=e=>e?\"let ACached = mm_Asub[k][tileRow + innerRow];\":\"let ACached = mm_Asub[tileRow + innerRow][k];\",bn=(e,r,t=\"f32\",u,a=!1,p=32,m=!1,y=32,l=!1)=>{let S=e[1]*r[1],A=e[0]*r[0],P=a?S:p,T=a?p:S;if(!(T%r[1]===0&&P%r[0]===0&&p%r[1]===0))throw new Error(`tileAHight ${T} must be divisible by workgroupSize[1]${r[1]}, tileAWidth ${P} must be divisible by workgroupSize[0]${r[0]}, tileInner ${p} must be divisible by workgroupSize[1]${r[1]}`);let k=T/r[1],O=P/r[0],R=p/r[1],j=l?`\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${S};\n    let globalColStart = i32(workgroupId.x) * ${A};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${T}; inputRow = inputRow + ${r[1]}) {\n        for (var inputCol = localCol; inputCol < ${P}; inputCol = inputCol + ${r[0]}) {\n          ${nl(a,u)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${p}; inputRow = inputRow + ${r[1]}) {\n            for (var inputCol = localCol; inputCol < ${A}; inputCol = inputCol + ${r[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${u?\", batchIndices\":\"\"});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${t}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${r[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${a?`mm_Asub[k][localRow + innerRow * ${r[1]}];`:`mm_Asub[localRow + innerRow * ${r[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${r[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${r[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `:`\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${S};\n\nlet tileRowA = i32(localId.y) * ${k};\nlet tileColA = i32(localId.x) * ${O};\nlet tileRowB = i32(localId.y) * ${R};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${k}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${O}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${nl(a,u)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${R}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${u?\", batchIndices\":\"\"});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${t}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${ph(a)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;return`\n  var<workgroup> mm_Asub : array<array<${t}, ${P}>, ${T}>;\n  var<workgroup> mm_Bsub : array<array<${t}, ${A}>, ${p}>;\n  const rowPerThread = ${e[1]};\n  const colPerThread = ${e[0]};\n  const tileInner = ${p};\n\n@compute @workgroup_size(${r[0]}, ${r[1]}, ${r[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${m?\"0\":\"i32(globalId.z)\"};\n    ${u?`let batchIndices = ${u.offsetToIndices(\"u32(batch)\")};`:\"\"}\n    let numTiles = ${m?`${Math.ceil(y/p)}`:\"(uniforms.dimInner - 1) / tileInner + 1\"};\n    var kStart = ${m?`i32(globalId.z) * ${y}`:\"0\"};\n\n    var acc : array<array<${t}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${j}\n  }\n`},mh=(e,r,t,u,a,p=!1)=>{let[m,y,l]=a,[S,A,P,T]=u,k=ji(m,l),O=ji(y,l),R=je(u[0].type.tensor),j=()=>{let q=A.rank,G=S.rank,Y=`var aIndices: ${A.type.indices};`;for(let _=q-2-1,X=G-1;_>=0;_--,X--)Y+=`\naIndices[${_}] = ${G>1?`batchIndices[${X}]`:\"batchIndices\"};`;return k.forEach(_=>{Y+=`\naIndices[${_}] = 0;`}),Y+=`\naIndices[${q-2}] = u32(row);\n                   aIndices[${q-1}] = u32(colIn);`,Y},M=()=>{let q=P.rank,G=S.rank,Y=`var bIndices: ${P.type.indices};`;for(let _=q-2-1,X=G-1;_>=0;_--,X--)Y+=`\nbIndices[${_}] = ${G>1?`batchIndices[${X}]`:\"batchIndices\"};`;return O.forEach(_=>{Y+=`\nbIndices[${_}] = 0;`}),Y+=`\nbIndices[${q-2}] = u32(row);\n                   bIndices[${q-1}] = u32(colIn);`,Y};return`\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${S.type.indices}) -> ${et(e,R)} {\n      var value = ${et(e,R)}(0.0);\n      let col = colIn * ${e};\n      if(row < uniforms.dimAOuter && col < uniforms.dimInner)\n      {\n        ${j()}\n        value = ${A.getByIndices(\"aIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${S.type.indices}) -> ${et(e,R)} {\n      var value = ${et(e,R)}(0.0);\n      let col = colIn * ${e};\n      if(row < uniforms.dimInner && col < uniforms.dimBOuter)\n      {\n        ${M()}\n        value = ${P.getByIndices(\"bIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${et(e,R)}) {\n      let col = colIn * ${e};\n      if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${r?`value = value + ${p?\"bias[colIn]\":`${et(e,R)}(bias[row])`};`:\"\"}\n        ${t}\n        ${T.setByIndices(\"vec3<u32>(coords)\",\"value\")}\n      }\n    }\n    `},mi=(e,r,t,u,a=!1)=>{let p=e[0].dims,m=e[1].dims,y=p.slice(0,-2),l=m.slice(0,-2),S=u?u.slice(0,-2):t.slice(0,-2),A=He(S.length),P=A?S.length:S,T=fs(\"batchDims\",e[0].dataType,P,1),k=Z.size(S),O=p[p.length-2],R=p[p.length-1],j=m[m.length-1],M=R%4===0&&j%4===0,z=O<=8?[4,1,1]:[4,4,1],q=[8,8,1],G=[Math.ceil(j/q[0]/z[0]),Math.ceil(O/q[1]/z[1]),Math.ceil(k/q[2]/z[2])],Y=je(e[0].dataType),_=M?4:1,X=[...y,O,R/_],J=He(X.length),re=J?X.length:X,fe=[...l,R,j/_],L=He(fe.length),oe=L?fe.length:fe,Se=[k,O,j/_],me=te(\"a\",e[0].dataType,re,_),Re=te(\"b\",e[1].dataType,oe,_),ue=se(\"result\",e[0].dataType,Se.length,_),Be=[me,Re],Me=[{type:\"int32\",data:O},{type:\"int32\",data:j},{type:\"int32\",data:R}];A&&Me.push(...xe(S)),J&&Me.push(...xe(X)),L&&Me.push(...xe(fe));let De=[];De.push(J?\"rank\":\"dims\"),De.push(L?\"rank\":\"dims\");let Ae=e.length>2,{activationFunction:St,applyActivation:rt}=Vt(r,ue.type.value),nt=mh(_,Ae,rt,[T,me,Re,ue],[y,l,S],a);if(Ae){let we=a?_:1;Be.push(te(\"bias\",e[2].dataType,e[2].dims.length,we)),Me.push(...xe(e[2].dims)),De.push(\"rank\")}Me.push(...xe(Se));let ne=we=>`\n  ${we.registerUniform(\"dimAOuter\",\"i32\").registerUniform(\"dimBOuter\",\"i32\").registerUniform(\"dimInner\",\"i32\").registerInternalVariables(T).declareVariables(...Be,ue)}\n  ${St}\n  ${nt}\n  ${M?yn(z,q,Y,T):bn(z,q,Y,T)}\n                   `;return{name:\"MatMul\",shaderCache:{hint:r.activationCacheKey+`${z}${r.activation}${r.clipMax}${r.clipMin}${M}${Ae}${a}`,inputDependencies:De},getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:G[0],y:G[1],z:G[2]},programUniforms:Me}),getShaderSource:ne}}});var hh,il,ol=ae(()=>{\"use strict\";zt();Pe();er();fi();Gi();vn();hh=(e,r,t,u,a=!1,p,m=4,y=4,l=4,S=\"f32\")=>{let A=L=>{switch(L){case 1:return\"resData = x[xIndex];\";case 3:return`resData = vec3<${S}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;case 4:return\"resData = x[xIndex / 4];\";default:throw new Error(`innerElementSize ${L} is not supported.`)}},P=L=>{switch(L){case 1:return\"return w[row * i32(uniforms.w_shape[3]) + colIn];\";case 4:return\"return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];\";default:throw new Error(`innerElementSize ${L} is not supported.`)}},T=e?`\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    `:`\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `,k=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,O=e?\"i32(uniforms.x_shape[1])\":\"i32(uniforms.x_shape[2])\",R=e?\"i32(uniforms.x_shape[2])\":\"i32(uniforms.x_shape[3])\",j=e?\"row\":\"col\",M=e?\"col\":\"row\",z=`\n    let inChannels = i32(uniforms.w_shape[2]);\n    let outWidth = ${e?\"i32(uniforms.result_shape[2])\":\"i32(uniforms.result_shape[3])\"};\n    let outRow = ${j} / outWidth;\n    let outCol = ${j} % outWidth;\n\n    let WRow = ${M} / (filterDims[1] * inChannels);\n    let WCol = ${M} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${M} % inChannels;\n    var resData = ${et(m,S)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${O} && xCol >= 0 && xCol < ${R}) {\n      ${T}\n      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));\n      ${A(m)}\n    }\n    return resData;`,q=e?r&&u?`\n    let col = colIn * ${m};\n    ${z}`:`\n    let col = colIn * ${m};\n    if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n      ${z}\n    }\n    return ${et(m,S)}(0.0);`:u&&t?`\n    let col = colIn * ${m};\n    ${z}`:`\n    let col = colIn * ${m};\n    if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n      ${z}\n    }\n    return ${et(m,S)}(0.0);`,G=`${P(y)}`,Y=et(l,S),_=e?et(m,S):et(y,S),X=e?et(y,S):et(m,S),{activationFunction:J,applyActivation:re}=Vt(p,Y);return`\n    ${J}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${_} {\n      ${e?q:G}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${X} {\n      ${e?G:q}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${Y}) {\n      let col = colIn * ${l};\n      if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${e?\"i32(uniforms.result_shape[2])\":\"i32(uniforms.result_shape[3])\"};\n      ${k}\n      ${ci(a)}\n      ${re}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`},il=(e,r,t,u,a,p,m,y)=>{let l=r.format===\"NHWC\",S=l?e[0].dims[3]:e[0].dims[1],A=t[0],P=l?t[2]:t[3],T=l?t[1]:t[2],k=l?t[3]:t[1],O=l&&(S%4===0||S%3===0)&&k%4===0,R=l?k:P*T,j=l?P*T:k,M=[8,8,1],z=u<=8?[4,1,1]:[4,4,1],q=[Math.ceil(R/M[0]/z[0]),Math.ceil(j/M[1]/z[1]),Math.ceil(A/M[2]/z[2])];Ge(\"verbose\",()=>`[conv2d_mm_webgpu] dispatch = ${q}`);let G=O?l&&S%4!==0?3:4:1,Y=M[1]*z[1],_=M[0]*z[0],X=Math.max(M[0]*G,M[1]),J=u%Y===0,re=a%_===0,fe=p%X===0,L=O?[G,4,4]:[1,1,1],oe=je(e[0].dataType),Se=O?4:1,me=[{type:\"int32\",data:u},{type:\"int32\",data:a},{type:\"int32\",data:p}],Re=te(\"x\",e[0].dataType,e[0].dims.length,G===3?1:G),ue=te(\"w\",e[1].dataType,e[1].dims.length,Se),Be=[Re,ue];me.push(...xe(e[0].dims)),me.push(...xe(e[1].dims));let Me=`\n      fn setOutputAtIndex(flatIndex : i32, value : ${O?`vec4<${oe}>`:oe}) {\n        result[flatIndex] = ${O?`vec4<${oe}>`:oe}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${O?`vec4<${oe}>`:oe}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${O?\"/ 4\":\"\"}, value);\n      }`;if(m){let Ae=te(\"bias\",e[2].dataType,e[2].dims.length,Se);Be.push(Ae),me.push(...xe(e[2].dims)),Me+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${O?`vec4<${oe}>`:oe} {\n          return bias[coords.${l?\"w\":\"y\"}${O?\"/ 4\":\"\"}];\n        }`}let De=se(\"result\",e[0].dataType,t.length,Se);return me.push(...xe(t)),{name:\"Conv2DMatMul\",shaderCache:{hint:r.cacheKey},getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:q[0],y:q[1],z:q[2]},programUniforms:me}),getShaderSource:Ae=>`\n        ${pi(\"uniforms.result_strides\")}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${Ae.registerUniform(\"dimAOuter\",\"i32\").registerUniform(\"dimBOuter\",\"i32\").registerUniform(\"dimInner\",\"i32\").declareVariables(...Be,De)}\n        const filterDims : vec2<i32> = vec2<i32>(${r.kernelShape[0]}, ${r.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${r.pads[0]}, ${r.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${r.strides[0]}, ${r.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${r.dilations[0]}, ${r.dilations[1]});\n        ${Me}\n        ${hh(l,J,re,fe,m,r,L[0],L[1],L[2],oe)}\n            ${O?yn(z,M,oe,void 0,!l,X):bn(z,M,oe,void 0,!l,X,!1,void 0,y)}`}}});var Li,al=ae(()=>{\"use strict\";ke();Pe();qi();er();Li=(e,r,t)=>{let u=e.length>2,a=u?\"value += b[output_channel];\":\"\",p=e[0].dims,m=e[1].dims,y=m[0]/r.group,l=r.format===\"NHWC\",S=Fi(p,m,r.dilations,r.pads,r.strides,l),A=Z.size(S),P=se(\"output\",e[0].dataType,S),{activationFunction:T,applyActivation:k}=Vt(r,P.type.value),O=te(\"x\",e[0].dataType,p),R=te(\"w\",e[1].dataType,m),j=[O,R];u&&j.push(te(\"b\",e[2].dataType,e[2].dims));let M=z=>`\n  const strides: vec2<u32> = vec2(${r.strides[0]}u, ${r.strides[1]}u);\n  const pads: vec2<u32> = vec2(${r.pads[0]}u, ${r.pads[1]}u);\n\n  ${z.declareVariables(...j,P)}\n\n  ${T}\n\n  ${z.mainStart()}\n    ${z.guardAgainstOutOfBoundsWorkgroupSizes(A)}\n\n    let outputIndices = ${P.offsetToIndices(\"global_idx\")};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${l?3:1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${l?1:2}], outputIndices[${l?2:3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${y}u;\n\n    var value: ${P.type.value} = ${P.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${m[1]}u; wInChannel++) {\n      let input_channel = group_id * ${m[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${m[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${r.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${p[l?1:2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${m[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${r.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${p[l?2:3]}u) {\n            continue;\n          }\n\n          let xVal = ${l?O.get(\"batch\",\"xHeight\",\"xWidth\",\"input_channel\"):O.get(\"batch\",\"input_channel\",\"xHeight\",\"xWidth\")};\n          let wVal = ${R.get(\"output_channel\",\"wInChannel\",\"wHeight\",\"wWidth\")};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${a}\n    ${k}\n    ${P.setByOffset(\"global_idx\",\"value\")}\n  }`;return{name:\"GroupedConv\",shaderCache:{hint:r.cacheKey},getRunData:()=>({outputs:[{dims:t?t(S):S,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(A/64)}}),getShaderSource:M}}});var Fi,sl,gh,ul,Ki,yh,bh,Yi,qi=ae(()=>{\"use strict\";ke();Le();ol();vn();al();er();xr();Fi=(e,r,t,u,a,p)=>{let m=e[0],y=e.slice(p?1:2,p?3:4),l=y.length,S=r[0],P=r.slice(2).map((O,R)=>O+(O-1)*(t[R]-1)),k=y.map((O,R)=>O+u[R]+u[R+l]).map((O,R)=>Math.floor((O-P[R]+a[R])/a[R]));return k.splice(0,0,m),k.splice(p?3:1,0,S),k},sl=[2,3,1,0],gh=(e,r)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support conv 1D and 2D\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let t=e[0].dims[r.format===\"NHWC\"?e[0].dims.length-1:1],u=e[1].dims[1]*r.group;if(t!==u)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");if(e.length===3&&(e[2].dims.length!==1||e[1].dims[0]!==e[2].dims[0]))throw new Error(\"invalid bias\");let a=e[0].dims.length-2;if(r.dilations.length!==a)throw new Error(`dilations should be ${a}D`);if(r.strides.length!==a)throw new Error(`strides should be ${a}D`);if(r.pads.length!==a*2)throw new Error(`pads should be ${a*2}D`);if(r.kernelShape.length!==0&&r.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\")},ul=(e,r)=>{let t=e.kernelShape.slice();for(let p=2;p<r[1].dims.length;++p)t[p-2]===0&&(t[p-2]=r[1].dims[p]);let u=e.pads.slice();Jt.adjustPadsBasedOnAutoPad(r[0].dims,e.strides,e.dilations,t,u,e.format===\"NHWC\",e.autoPad);let a=Object.assign({},e);return Object.assign(a,{kernelShape:t,pads:u,cacheKey:e.cacheKey}),a},Ki=e=>{let r=di(e),t=e.format,u=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],a=e.dilations,p=e.group,m=e.kernel_shape,y=e.pads,l=e.strides,S=e.w_is_const();return he({autoPad:u,format:t,dilations:a,group:p,kernelShape:m,pads:y,strides:l,wIsConst:S,...r})},yh=(e,r,t)=>{let u=ul(t,r);if(t.group!==1){e.compute(Li(r,u));return}let a=t.format===\"NHWC\",p=r.length===3,m=r[0].dims[a?1:2],y=r[0].dims[a?2:3],l=r[0].dims[a?3:1],S=r[1].dims[2],A=r[1].dims[3],P=Fi(r[0].dims,r[1].dims,t.dilations,u.pads,t.strides,a),T=P[a?1:2],k=P[a?2:3],O=P[a?3:1],R=a&&S===m&&A===y&&t.pads[0]===0&&t.pads[1]===0;if(R||S===1&&A===1&&t.dilations[0]===1&&t.dilations[1]===1&&t.strides[0]===1&&t.strides[1]===1&&t.pads[0]===0&&t.pads[1]===0){let _=P[0],X,J,re,fe=[];if(a){let L=e.kernelCustomData.wT??e.compute($t(r[1],sl),{inputs:[1],outputs:[t.wIsConst?-2:-1]})[0];if(t.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=L),R){let oe=m*y*l;X=r[0].reshape([1,_,oe]),J=L.reshape([1,oe,O]),re=[1,_,O]}else X=r[0].reshape([_,m*y,l]),J=L.reshape([1,l,O]),re=[_,T*k,O];fe.push(X),fe.push(J)}else X=r[0].reshape([_,l,m*y]),J=r[1].reshape([1,O,l]),re=[_,O,T*k],fe.push(J),fe.push(X);p&&fe.push(r[2]),e.compute(mi(fe,u,P,re,a),{inputs:fe});return}let j=!0,M=e.kernelCustomData.wT??e.compute($t(r[1],sl),{inputs:[1],outputs:[t.wIsConst?-2:-1]})[0];t.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=M);let z=[r[0],M];p&&z.push(r[2]);let q=a?T*k:O,G=a?O:T*k,Y=S*A*l;e.compute(il(z,u,P,q,G,Y,p,j),{inputs:z})},bh=(e,r)=>{let t=r.format===\"NHWC\",u=[e.inputs[0].reshape(t?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];e.inputs.length===3&&u.push(e.inputs[2]);let a=[0,r.pads[0],0,r.pads[1]],p=[1].concat(r.strides),m=[1].concat(r.dilations),y=[1].concat(r.kernelShape),l=ul({...r,pads:a,strides:p,dilations:m,kernelShape:y},u);e.compute(Li(u,l,S=>t?[S[0],S[2],S[3]]:[]))},Yi=(e,r)=>{gh(e.inputs,r),e.inputs[0].dims.length===3?bh(e,r):yh(e,e.inputs,r)}});var vh,ll,dl=ae(()=>{\"use strict\";zt();Pe();er();fi();Gi();vn();vh=(e,r=!1,t,u=4)=>{let a=et(u,\"f32\"),p=z=>{switch(z){case 1:return\"return w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];\";case 4:return`\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];\n            let v1 = w[getIndexFromCoords4D(coord1, vec4<i32>(uniforms.w_shape))];\n            let v2 = w[getIndexFromCoords4D(coord2, vec4<i32>(uniforms.w_shape))];\n            let v3 = w[getIndexFromCoords4D(coord3, vec4<i32>(uniforms.w_shape))];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;default:throw new Error(`innerElementSize ${z} is not supported.`)}},m=e?`\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      `:`\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `,y=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,l=e?\"outBackprop[1]\":\"outBackprop[2]\",S=e?\"outBackprop[2]\":\"outBackprop[3]\",A=e?\"row\":\"col\",P=e?\"col\":\"row\",T=`\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let outWidth = ${e?\"i32(uniforms.result_shape[2])\":\"i32(uniforms.result_shape[3])\"};\n      let outRow = ${A} / outWidth;\n      let outCol = ${A} % outWidth;\n\n      let WRow = ${P} / (filterDims[1] * inChannels);\n      let WCol = ${P} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${l}) || fract(xR) > 0.0) {\n        return ${a}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${S}) || fract(xC) > 0.0) {\n        return ${a}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${P} % inChannels;\n      ${m}\n      return x[getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape))/${u}];`,k=e?`\n      let col = colIn * ${u};\n      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${T}\n      }\n      return ${a}(0.0);`:`\n      let col = colIn * ${u};\n      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n        ${T}\n      }\n      return ${a}(0.0);`,O=`\n      let col = colIn * ${u};\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${e?\"row < uniforms.dimInner && col < uniforms.dimBOuter\":\"row < uniforms.dimInner && col < uniforms.dimAOuter\"}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${p(u)}\n      }\n      return ${a}(0.0);\n      `,{activationFunction:R,applyActivation:j}=Vt(t,a);return`\n      ${R}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${a} {\n    ${e?k:O}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${a} {\n    ${e?O:k}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${a}) {\n    let col = colIn * ${u};\n    if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${e?\"i32(uniforms.result_shape[2])\":\"i32(uniforms.result_shape[3])\"};\n      ${y}\n      ${ci(r)}\n      ${j}\n      result[getIndexFromCoords4D(coords, vec4<i32>(uniforms.result_shape))/${u}] = value;\n    }\n  }`},ll=(e,r,t,u,a,p,m,y)=>{let l=r.format===\"NHWC\",S=l?e[0].dims[3]:e[0].dims[1],A=t[0],P=l?t[2]:t[3],T=l?t[1]:t[2],k=l?t[3]:t[1],O=l?S%4===0&&k%4===0:P%4===0&&k%4===0,R=l?k:P*T,j=l?P*T:k,M=O?[8,8,1]:[R<=4||j<=4?4:16,R>4&&j<=4?4:16,1],z=O?[4,4,1]:[R<=4?1:4,R>4&&j<=4?1:4,1],q=[Math.ceil(R/M[0]/z[0]),Math.ceil(j/M[1]/z[1]),Math.ceil(A/M[2]/z[2])];Ge(\"verbose\",()=>`[conv_backprop_mm_webgpu] dispatch = ${q}`);let G=O?4:1,Y=Math.max(M[0]*G,M[1]),_=O?4:1,X=[{type:\"int32\",data:u},{type:\"int32\",data:a},{type:\"int32\",data:p}],J=te(\"x\",e[0].dataType,e[0].dims.length,_),re=te(\"w\",e[1].dataType,e[1].dims.length,1),fe=se(\"result\",e[0].dataType,t.length,_),L=[J,re];X.push(...xe(e[0].dims)),X.push(...xe(e[1].dims));let oe=\"\";if(m){let Se=te(\"bias\",e[2].dataType,e[2].dims.length,_);L.push(Se),X.push(...xe(e[2].dims)),oe+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${O?\"vec4<f32>\":\"f32\"} {\n          return bias[coords.${l?\"w\":\"y\"}${O?\"/ 4\":\"\"}];\n        }`}return X.push(...xe(t)),{name:\"Conv2DTransposeMatMul\",shaderCache:{hint:r.cacheKey},getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:q[0],y:q[1],z:q[2]},programUniforms:X}),getShaderSource:Se=>`\n        ${pi(\"uniforms.result_strides\")}\n        ${Se.registerUniform(\"dimAOuter\",\"i32\").registerUniform(\"dimBOuter\",\"i32\").registerUniform(\"dimInner\",\"i32\").declareVariables(...L,fe)};\n        const outBackprop : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${r.kernelShape[l?1:2]}, ${r.kernelShape[l?2:3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${r.dilations[0]<=1?0:(r.kernelShape[l?1:2]-1)*(r.dilations[0]-1)},\n              ${r.dilations[1]<=1?0:(r.kernelShape[l?2:3]-1)*(r.dilations[1]-1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${r.pads[0]+r.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${r.pads[1]+r.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${r.strides[0]}, ${r.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${r.dilations[0]}, ${r.dilations[1]});\n        const dimAOuter : i32 = ${u};\n        const dimBOuter : i32 = ${a};\n        const dimInner : i32 = ${p};\n        ${oe}\n        ${vh(l,m,r,G)}\n        ${O?yn(z,M,\"f32\",void 0,!l,Y):bn(z,M,\"f32\",void 0,!l,Y,!1,void 0,y)}`}}});var wh,Zi,cl=ae(()=>{\"use strict\";zt();ke();Pe();wh=(e,r,t,u,a,p,m=!1,y)=>{let l=t.format===\"NHWC\",S=l?1:2,A=l?2:3,P=l?3:1,T=Z.size(u),k=m?2:1,O=t.group,R=r[1].dims,j=R[0]/O,M=R[1],z=`\n  fn setOutputAtIndex(flatIndex : u32, value : ${m?`vec4<${y}>`:y}) {\n    result[flatIndex] = ${m?`vec4<${y}>`:y}(value);\n  }`;a&&(z+=`\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${m?`vec4<${y}>`:y} {\n      return bias[coords.${l?\"w\":\"y\"}${m?\"/ 4\":\"\"}];\n    }`);let q=m?4:1,G=te(\"W\",r[1].dataType,r[1].dims,q),Y=te(\"Dy\",r[0].dataType,r[0].dims,q),_=[Y,G];a&&_.push(te(\"bias\",r[2].dataType,[u[P]],q));let X=se(\"result\",r[0].dataType,u,q),J=`{\n        let batch: u32 = ${p?\"global_id.z\":\"workgroup_id.z\"} / outShape[1];\n        let r = ${p?\"global_id.z\":\"workgroup_id.z\"} % outShape[1];\n        let c = ${p?\"global_id.y\":\"workgroup_id.y\"} * ${k};\n        let d1: u32 = ${p?\"global_id.x\":\"workgroup_id.x\"} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${y}>, ${k}>;\n        for (var i = 0; i < ${k}; i++) {\n          dotProd[i] = vec4<${y}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${y}(dyCorner.x) + ${y}(wR)) / ${y}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${y}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${y}(dyCorner.y) + ${y}(wC)) / ${y}(strides.y);\n            let dyC2 = (${y}(dyCorner.y) + 1.0 + ${y}(wC)) / ${y}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${y}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${y}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${Y.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${y}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${Y.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n\n                dotProd[1] = dotProd[1] + vec4<${y}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${P}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${Y.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${y}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${G.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${Y.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n                let tmpval = vec4<${y}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${k}; i = i + 1) {\n          let value = dotProd[i] + ${a?\"bias[c+i]\":\"0.0\"};\n          ${X.set(\"batch\",\"r\",\"c + i\",\"d1\",\"value\")};\n        }\n      }`,re=`\n          let outputIndices = ${X.offsetToIndices(\"global_idx\")};\n          let batch = ${X.indicesGet(\"outputIndices\",0)};\n          let d1 = ${X.indicesGet(\"outputIndices\",P)};\n          let r = ${X.indicesGet(\"outputIndices\",S)};\n          let c = ${X.indicesGet(\"outputIndices\",A)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${M};\n          let wOutChannel = d1 - groupId * ${M};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${y}(dyRCorner) + ${y}(wR)) / ${y}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${y}(outBackprop[${S}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${y}(dyCCorner) + ${y}(wC)) / ${y}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${y}(outBackprop[${A}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${j};\n              for (var d2: u32 = 0; d2 < ${j}; d2 = d2 + 1) {\n                let xValue = ${l?Y.get(\"batch\",\"idyR\",\"idyC\",\"inputChannel\"):Y.get(\"batch\",\"inputChannel\",\"idyR\",\"idyC\")};\n                let wValue = ${G.get(\"inputChannel\",\"wOutChannel\",\"u32(wRPerm)\",\"u32(wCPerm)\")};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${a?\"bias[d1]\":\"0.0\"};\n          ${X.setByOffset(\"global_idx\",\"value\")};\n        `;return`\n  ${e.declareVariables(..._,X)}\n  ${z}\n  const outShape : vec4<u32> = vec4<u32>(${u.join(\",\")});\n  const outBackprop : vec4<u32> = vec4<u32>(${r[0].dims.join(\",\")});\n  const strides : vec2<u32> = vec2<u32>(${t.strides[0]}, ${t.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${t.kernelShape[l?1:2]}, ${t.kernelShape[l?2:3]});\n  const dilations : vec2<u32> = vec2<u32>(${t.dilations[0]}, ${t.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${t.dilations[0]<=1?0:(t.kernelShape[l?1:2]-1)*(t.dilations[0]-1)},\n          ${t.dilations[1]<=1?0:(t.kernelShape[l?2:3]-1)*(t.dilations[1]-1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${t.pads[0]+t.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${t.pads[1]+t.pads[3]})/2);\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(T)};\n  ${m?J:re}}`},Zi=(e,r,t)=>{let u=e.length>2,a=r.outputShape,p=Z.size(a),m=[Math.ceil(p/64),1,1];Ge(\"verbose\",()=>`[conv2d_backprop_webgpu] dispatch = ${m}`);let y=je(e[0].dataType);return{name:\"ConvTranspose2D\",shaderCache:{hint:r.cacheKey},getRunData:()=>({dispatchGroup:{x:m[0],y:m[1],z:m[2]},outputs:[{dims:t?t(a):a,dataType:e[0].dataType}]}),getShaderSource:l=>wh(l,e,r,a,u,m[1]===1&&m[2]===1,!1,y)}}});var $h,Ch,Sh,fl,pl,xh,_h,Ih,Ah,ml,hl=ae(()=>{\"use strict\";Le();dl();cl();er();xr();$h=(e,r,t,u,a,p)=>(e-1)*r+t+(u-1)*a+1-p,Ch=(e,r,t,u,a)=>{let p=Math.floor(e/2);r===\"SAME_UPPER\"?(t[u]=p,t[a]=e-p):r===\"SAME_LOWER\"&&(t[u]=e-p,t[a]=p)},Sh=(e,r,t,u,a,p,m,y,l,S)=>{let A=e.length-2,P=S.length===0;if(l.length===0)for(let O=0;O<A;++O)l.push(0);let T=e[0],k=r[y?3:1]*a;for(let O=0,R=e.length-A-(y?1:0);O<A;++O,++R){let j=e[R],M=P?j*m[O]:S[O],z=$h(j,m[O],p[O],r[R],t[O],M);Ch(z,u,p,O,O+A),P&&S.push(m[O]*(j-1)+l[O]+(r[R]-1)*t[O]+1-p[O]-p[O+A])}S.splice(0,0,T),S.splice(y?3:1,0,k)},fl=(e,r)=>{let t=e.kernelShape.slice();if(e.kernelShape.length===0||e.kernelShape.reduce((T,k)=>T*k,1)===0){t.length=0;for(let T=2;T<r[1].dims.length;++T)t.push(r[1].dims[T])}let u=e.format===\"NHWC\";t.splice(0,0,r[1].dims[0]),t.splice(u?3:1,0,r[1].dims[1]);let a=e.pads.slice(),p=e.outputShape.slice(),m=e.outputPadding.slice(),y=r[0].dims,l=e.dilations.slice();if(l.reduce((T,k)=>T+k,0)===0){let T=r[0].dims.length-2;l=new Array(T).fill(1)}let S=e.strides.slice();if(S.reduce((T,k)=>T+k,0)===0){let T=r[0].dims.length-2;S=new Array(T).fill(1)}Sh(y,t,l,e.autoPad,e.group,a,S,u,m,p);let A=Object.assign({},e),P=e.cacheKey+[t.join(\"n,\"),a.join(\",\"),S.join(\",\"),m.join(\",\"),p.join(\",\"),l.join(\",\")].join(\"_\");return Object.assign(A,{kernelShape:t,pads:a,outputPadding:m,outputShape:p,dilations:l,strides:S,cacheKey:P}),A},pl=e=>{let r=di(e),t=e.format,u=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][typeof e.autoPad>\"u\"?0:e.autoPad],a=e.dilations,p=e.group,m=e.kernelShape,y=e.pads,l=e.strides,S=e.wIsConst(),A=e.outputPadding,P=e.outputShape;return he({autoPad:u,format:t,dilations:a,group:p,kernelShape:m,outputPadding:A,outputShape:P,pads:y,strides:l,wIsConst:S,...r})},xh=(e,r)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support 2-dimensional conv\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let t=e[0].dims[r.format===\"NHWC\"?e[0].dims.length-1:1],u=e[1].dims[0];if(t!==u)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");let a=e[1].dims[1]*r.group;if(e.length===3&&(e[2].dims.length!==1||e[2].dims[0]!==a))throw new Error(\"invalid bias\");let p=e[0].dims.length-2;if(r.dilations.reduce((A,P)=>A+P,0)>0&&r.dilations.length!==p)throw new Error(`dilations should be ${p}D`);if(r.strides.reduce((A,P)=>A+P,0)>0&&r.strides.length!==p)throw new Error(`strides should be ${p}D`);if(r.pads.reduce((A,P)=>A+P,0)>0&&r.pads.length!==p*2)throw new Error(`pads should be ${p*2}D`);if(r.outputPadding.length!==p&&r.outputPadding.length!==0)throw new Error(`output_padding should be ${p}D`);if(r.kernelShape.reduce((A,P)=>A+P,0)>0&&r.kernelShape.length!==0&&r.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\");if(r.outputShape.length!==0&&r.outputShape.length!==e[0].dims.length-2)throw new Error(\"invalid output shape\")},_h=[2,3,1,0],Ih=(e,r,t)=>{let u=fl(t,r),a=t.format===\"NHWC\",p=r.length===3;if(u.group!==1){e.compute(Zi(r,u));return}let m=u.outputShape,y=m[a?1:2],l=m[a?2:3],S=m[a?3:1],A=r[1].dims[2],P=r[1].dims[3],T=r[0].dims[a?3:1],k=a?y*l:S,O=a?S:y*l,R=A*P*T,j=!0,M=e.kernelCustomData.wT??e.compute($t(r[1],_h),{inputs:[1],outputs:[t.wIsConst?-2:-1]})[0];t.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=M);let z=[r[0],M];p&&(!a&&r[2].dims.length===1?z.push(r[2].reshape([r[2].dims[0],1,1])):z.push(r[2])),e.compute(ll(z,u,m,k,O,R,p,j),{inputs:z})},Ah=(e,r)=>{let t=r.format===\"NHWC\",u=[e.inputs[0].reshape(t?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];u.length===3&&u.push(e.inputs[2]);let a=r.kernelShape;(a.length===0||a[0]===0)&&(a=[e.inputs[1].dims[2]]);let p=r.dilations;(p.length===0||p[0]===0)&&(p=[1]);let m=r.strides;(m.length===0||m[0]===0)&&(m=[1]);let y=r.pads;y.length===0&&(y=[0,0]),y=[0,y[0],0,y[1]],m=[1].concat(m),p=[1].concat(p),a=[1].concat(a);let l=fl({...r,pads:y,strides:m,dilations:p,kernelShape:a},u);e.compute(Zi(u,l,S=>t?[S[0],S[2],S[3]]:[S[0],S[1],S[3]]))},ml=(e,r)=>{xh(e.inputs,r),e.inputs[0].dims.length===3?Ah(e,r):Ih(e,e.inputs,r)}});var Xi,hi,gl,Th,Eh,Qi,Ji,yl,Oh,bl,vl,wl=ae(()=>{\"use strict\";ke();Le();Pe();Xi=\"[a-zA-Z]|\\\\.\\\\.\\\\.\",hi=\"(\"+Xi+\")+\",gl=\"^\"+hi+\"$\",Th=\"(\"+hi+\",)*\"+hi,Eh=\"^\"+Th+\"$\",Qi=class{constructor(r=-1){this.symbolToIndices=new Map,this.inputIndex=r}addSymbol(r,t){let u=this.symbolToIndices.get(r);u===void 0?u=[t]:u.push(t),this.symbolToIndices.set(r,u)}},Ji=class{constructor(r,t){this.equation=t;this.hasEllipsis=!1,this.symbolToInfo=new Map,this.lhs=new Array,this.outputDims=[];let[u,a]=t.includes(\"->\")?t.split(\"->\",2):[t,\"\"];if(!u.match(RegExp(Eh)))throw new Error(\"Invalid LHS term\");if(u.split(\",\").forEach((y,l)=>{let S=r[l].dims.slice();if(!y.match(RegExp(gl)))throw new Error(\"Invalid LHS term\");let A=this.processTerm(y,!0,S,l);this.lhs.push(A)}),a===\"\")a+=[...this.symbolToInfo.entries()].filter(([y,l])=>l.count===1||y===\"...\").map(([y])=>y).join(\"\");else if(!a.match(RegExp(hi)))throw new Error(\"Invalid RHS\");a.match(RegExp(Xi,\"g\"))?.forEach(y=>{if(y===\"...\")this.outputDims=this.outputDims.concat(this.ellipsisDims);else{let l=this.symbolToInfo.get(y);if(l===void 0)throw new Error(\"Invalid RHS symbol\");this.outputDims.push(l.dimValue)}}),this.rhs=this.processTerm(a,!1,this.outputDims)}addSymbol(r,t,u){let a=this.symbolToInfo.get(r);if(a!==void 0){if(a.dimValue!==t&&a.count!==1)throw new Error(\"Dimension mismatch\");a.count++,a.inputIndices.push(u)}else a={count:1,dimValue:t,inputIndices:[u]};this.symbolToInfo.set(r,a)}processTerm(r,t,u,a=-1){let p=u.length,m=!1,y=[],l=0;if(!r.match(RegExp(gl))&&!t&&r!==\"\")throw new Error(\"Invalid LHS term\");let S=r.match(RegExp(Xi,\"g\")),A=new Qi(a);return S?.forEach((P,T)=>{if(P===\"...\"){if(m)throw new Error(\"Only one ellipsis is allowed per input term\");m=!0;let k=p-S.length+1;if(k<0)throw new Error(\"Ellipsis out of bounds\");if(y=u.slice(l,l+k),this.hasEllipsis){if(this.ellipsisDims.length!==y.length||this.ellipsisDims.toString()!==y.toString())throw new Error(\"Ellipsis dimensions mismatch\")}else if(t)this.hasEllipsis=!0,this.ellipsisDims=y;else throw new Error(\"Ellipsis must be specified in the LHS\");for(let O=0;O<y.length;O++){let R=String.fromCharCode(\"0\".charCodeAt(0)+O);A.addSymbol(R,T+O),this.addSymbol(R,u[l++],a)}}else A.addSymbol(P,T+(this.hasEllipsis?this.ellipsisDims.length-1:0)),this.addSymbol(P,u[l++],a)}),A}},yl=e=>e+\"_max\",Oh=(e,r,t,u,a)=>{let m=r.map((k,O)=>e[O]?k.length:k).map((k,O)=>te(`input${O}`,t,k)),y=Z.size(a),l=He(a.length),S=l?a.length:a,A=se(\"output\",t,S),P=[...u.symbolToInfo.keys()].filter(k=>!u.rhs.symbolToIndices.has(k)),T=k=>{let O=[],R=\"var prod = 1.0;\",j=\"var sum = 0.0;\",M=\"sum += prod;\",z=[],q=[],G=[],Y=[],_=u.symbolToInfo.size===u.rhs.symbolToIndices.size;u.symbolToInfo.forEach((J,re)=>{if(u.rhs.symbolToIndices.has(re)){let fe=u.rhs.symbolToIndices.get(re)?.[0];fe!==void 0&&u.lhs.forEach((L,oe)=>{if(J.inputIndices.includes(oe)){let Se=L.symbolToIndices.get(re);if(Se===void 0)throw new Error(\"Invalid symbol error\");Se.forEach(me=>{O.push(`${m[oe].indicesSet(`input${oe}Indices`,me,A.indicesGet(\"outputIndices\",fe))}`)})}})}else u.lhs.forEach((fe,L)=>{if(J.inputIndices.includes(L)){let oe=fe.symbolToIndices.get(re);if(oe===void 0)throw new Error(\"Invalid symbol error\");oe.forEach(Se=>{z.push(`${m[L].indicesSet(`input${L}Indices`,Se,`${re}`)}`)}),Y.push(`prod *= ${m[L].getByIndices(`input${L}Indices`)};`)}}),q.push(`for(var ${re}: u32 = 0; ${re} < uniforms.${yl(re)}; ${re}++) {`),G.push(\"}\")});let X=_?[...O,`let sum = ${m.map((J,re)=>J.getByIndices(`input${re}Indices`)).join(\" * \")};`]:[...O,j,...q,...z,R,...Y,M,...G];return`\n            ${k.registerUniforms(P.map(J=>({name:`${yl(J)}`,type:\"u32\"}))).registerUniform(\"outputSize\",\"u32\").declareVariables(...m,A)}\n\n            ${k.mainStart()}\n            ${k.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n            var outputIndices = ${A.offsetToIndices(\"global_idx\")};\n            ${m.map((J,re)=>`var input${re}Indices: ${m[re].type.indices};`).join(`\n`)}\n            ${X.join(`\n`)};\n            ${A.setByOffset(\"global_idx\",\"sum\")};\n          }`};return{name:\"Einsum\",shaderCache:{hint:u.equation,inputDependencies:e.map(k=>k?\"rank\":\"dims\")},getRunData:()=>{let k=P.filter(R=>u.symbolToInfo.has(R)).map(R=>({type:\"uint32\",data:u.symbolToInfo.get(R)?.dimValue||0}));k.push({type:\"uint32\",data:y});let O=r.filter((R,j)=>e[j]).map((R,j)=>[...xe(R)]).reduce((R,j)=>R.concat(j),k);return l&&O.push(...xe(a)),{outputs:[{dims:a,dataType:t}],dispatchGroup:{x:Math.ceil(y/64)},programUniforms:O}},getShaderSource:T}},bl=(e,r)=>{let t=new Ji(e.inputs,r.equation),u=e.inputs.map((m,y)=>He(m.dims.length)),a=t.outputDims,p=e.inputs.map((m,y)=>m.dims);e.compute(Oh(u,p,e.inputs[0].dataType,t,a))},vl=e=>{let r=e.equation.replace(/\\s+/g,\"\");return he({equation:r})}});var kh,$l,Ph,Rh,Cl,Sl=ae(()=>{\"use strict\";Ze();ke();Pe();kh=e=>{if(!e||e.length!==2)throw new Error(\"Expand requires 2 input.\");let r=e[0].dims,t=Array.from(e[1].getBigInt64Array(),Number),u=t.length<r.length?0:t.length-r.length,a=r.length<t.length?0:r.length-t.length;for(;u<t.length&&a<r.length;++u,++a)if(t[u]!==r[a]&&t[u]!==1&&r[a]!==1)throw new Error(\"Expand requires shape to be broadcastable to input\")},$l=(e,r)=>{let t=e.length-r.length,u=[];for(let a=0;a<t;++a)u.push(e[a]);for(let a=0;a<r.length;++a)u.push(r[a]===1?e[a+t]:r[a]);return u},Ph=(e,r)=>e.length>r.length?$l(e,r):$l(r,e),Rh=e=>{let r=e[0].dims,t=Array.from(e[1].getBigInt64Array(),Number),u=Ph(r,t),a=e[0].dataType,p=a===9?4:1,m=Z.size(u)/p,y=He(r.length),l=He(u.length),S=P=>{let T=y?r.length:r,k=l?u.length:u,O=te(\"input\",a,T,p),R=se(\"output\",a,k,p),j;if(a===9){let M=(z,q,G=\"\")=>`\n          let outputIndices${q} = ${R.offsetToIndices(`outputOffset + ${q}u`)};\n          let offset${q} = ${O.broadcastedIndicesToOffset(`outputIndices${q}`,R)};\n          let index${q} = offset${q} / 4u;\n          let component${q} = offset${q} % 4u;\n          ${z}[${q}] = ${G}(${O.getByOffset(`index${q}`)}[component${q}]);\n        `;j=`\n        let outputOffset = global_idx * ${p};\n        var data = vec4<u32>(0);\n        ${M(\"data\",0,\"u32\")}\n        ${M(\"data\",1,\"u32\")}\n        ${M(\"data\",2,\"u32\")}\n        ${M(\"data\",3,\"u32\")}\n        ${R.setByOffset(\"global_idx\",\"data\")}\n      }`}else j=`\n        let outputIndices = ${R.offsetToIndices(\"global_idx\")};\n        let inputOffset = ${O.broadcastedIndicesToOffset(\"outputIndices\",R)};\n        ${R.setByOffset(\"global_idx\",O.getByOffset(\"inputOffset\"))}\n      }`;return`\n    ${P.registerUniform(\"vec_size\",\"u32\").declareVariables(O,R)}\n    ${P.mainStart()}\n    ${P.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n    ${j}`},A=[{type:\"uint32\",data:m}];return y&&A.push(...xe(r)),l&&A.push(...xe(u)),{name:\"Expand\",shaderCache:{hint:`${u.length}`,inputDependencies:[y?\"rank\":\"dims\"]},getShaderSource:S,getRunData:()=>({outputs:[{dims:u,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(m/64)},programUniforms:A})}},Cl=e=>{kh(e.inputs),e.compute(Rh(e.inputs),{inputs:[0]})}});var Bh,Mh,xl,_l,Il=ae(()=>{\"use strict\";Ze();ke();Le();Pe();Bh=e=>{if(!e||e.length!==2)throw new Error(\"Gather requires 2 inputs.\")},Mh=(e,r)=>{let t=e[0].dims,u=e[1].dims,a=t.length,p=Z.normalizeAxis(r.axis,a),m=t.slice(0);m.splice(p,1,...u);let y=t[p],l=e[0].dataType===9?4:1,S=Z.size(m)/l,A=He(e[0].dims.length),P=A?e[0].dims.length:e[0].dims,T=He(e[1].dims.length),k=T?e[1].dims.length:e[1].dims,O=He(m.length),R=O?m.length:m,j=[{type:\"uint32\",data:S},{type:\"int32\",data:y},{type:\"uint32\",data:p}];A&&j.push(...xe(e[0].dims)),T&&j.push(...xe(e[1].dims)),O&&j.push(...xe(m));let M=[];M.push(A?\"rank\":\"dims\"),M.push(T?\"rank\":\"dims\");let z=q=>{let G=te(\"data\",e[0].dataType,P,l),Y=te(\"inputIndices\",e[1].dataType,k),_=se(\"output\",e[0].dataType,R,l),X=re=>{let fe=u.length,L=`var indicesIndices${re}  = ${Y.type.indices}(0);`;for(let oe=0;oe<fe;oe++)L+=`${fe>1?`indicesIndices${re}[${oe}]`:`indicesIndices${re}`} = ${m.length>1?`outputIndices${re}[uniforms.axis + ${oe}]`:`outputIndices${re}`};`;L+=`\n          var idx${re} = ${Y.getByIndices(`indicesIndices${re}`)};\n          if (idx${re} < 0) {\n            idx${re} = idx${re} + uniforms.axisDimLimit;\n          }\n          var dataIndices${re} = ${G.type.indices}(0);\n        `;for(let oe=0,Se=0;oe<a;oe++)oe===p?(L+=`${a>1?`dataIndices${re}[${oe}]`:`dataIndices${re}`} = u32(idx${re});`,Se+=fe):(L+=`${a>1?`dataIndices${re}[${oe}]`:`dataIndices${re}`} = ${m.length>1?`outputIndices${re}[${Se}]`:`outputIndices${re}`};`,Se++);return L},J;if(e[0].dataType===9){let re=(fe,L,oe=\"\")=>`\n          let outputIndices${L} = ${_.offsetToIndices(`outputOffset + ${L}u`)};\n          ${X(L)};\n          let offset${L} = ${G.indicesToOffset(`dataIndices${L}`)};\n          let index${L} = offset${L} / 4u;\n          let component${L} = offset${L} % 4u;\n          ${fe}[${L}] = ${oe}(${G.getByOffset(`index${L}`)}[component${L}]);\n        `;J=`\n        let outputOffset = global_idx * ${l};\n        var value = vec4<u32>(0);\n        ${re(\"value\",0,\"u32\")}\n        ${re(\"value\",1,\"u32\")}\n        ${re(\"value\",2,\"u32\")}\n        ${re(\"value\",3,\"u32\")}\n        ${_.setByOffset(\"global_idx\",\"value\")}\n      `}else J=`\n      let outputIndices = ${_.offsetToIndices(\"global_idx\")};\n      ${X(\"\")};\n      let value = ${G.getByIndices(\"dataIndices\")};\n      ${_.setByOffset(\"global_idx\",\"value\")};\n      `;return`\n      ${q.registerUniform(\"outputSize\",\"u32\").registerUniform(\"axisDimLimit\",\"i32\").registerUniform(\"axis\",\"u32\").declareVariables(G,Y,_)}\n      ${q.mainStart()}\n        ${q.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n        ${J}\n      }`};return{name:\"Gather\",shaderCache:{hint:r.cacheKey,inputDependencies:M},getRunData:()=>({outputs:[{dims:m,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(S/64)},programUniforms:j}),getShaderSource:z}},xl=e=>he({axis:e.axis}),_l=(e,r)=>{let t=e.inputs;Bh(t),e.compute(Mh(e.inputs,r))}});var Dh,jh,Al,Tl,El=ae(()=>{\"use strict\";ke();Le();Pe();Dh=e=>{if(!e||e.length!==2)throw new Error(\"GatherElements requires 2 inputs.\");if(e[0].dims.length<1)throw new Error(\"GatherElements requires that the data input be rank >= 1.\");if(e[0].dims.length!==e[1].dims.length)throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`)},jh=(e,r)=>{let t=e[0].dims,u=e[0].dataType,a=t.length,p=Z.computeStrides(t),m=Z.size(t),y=e[1].dims,l=e[1].dataType,S=Z.size(y),A=Z.normalizeAxis(r.axis,a),P=t[A],T=y.slice(0),k=Z.size(T),O=te(\"input\",u,t),R=te(\"indices\",l,[S]),j=se(\"output\",u,T),M=z=>`\n      const inputStrides = array<u32, ${p.length}>(${p.map(q=>`${q}u`).join(\",\")});\n      ${z.declareVariables(O,R,j)}\n      ${z.mainStart()}\n      ${z.guardAgainstOutOfBoundsWorkgroupSizes(k)}\n\n      let outputIndices = ${j.offsetToIndices(\"global_idx\")};\n\n      var idx = ${R.getByOffset(\"global_idx\")};\n      if (idx < 0) {\n        idx = idx + ${P};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${t.length}; i++) {\n        if (i == ${A}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${j.indicesGet(\"outputIndices\",\"i\")} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${m}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;return{name:\"GatherElements\",shaderCache:{hint:r.cacheKey},getRunData:()=>({outputs:[{dims:T,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(k/64)}}),getShaderSource:M}},Al=e=>he({axis:e.axis}),Tl=(e,r)=>{let t=e.inputs;Dh(t),e.compute(jh(e.inputs,r))}});var zh,Vh,Wh,Ol,kl,Pl=ae(()=>{\"use strict\";ke();Le();Pe();zh=e=>{if(!e)throw new Error(\"Input is missing\");if(e.length<2||e.length>3)throw new Error(\"Invaid input number.\");if(e.length===3&&e[2].dims.length>2)throw new Error(\"Invalid input shape of C\");if(e[0].dataType!==e[1].dataType||e.length===3&&e[0].dataType!==e[2].dataType)throw new Error(\"Input types are mismatched\")},Vh=(e,r,t)=>{if(t.length===0)return\"0u\";let u=t.length===1&&e!==1||t.length===2&&t[0]!==e,a=t[t.length-1]!==r,p=\"0u\";return u||(p+=`+ m * ${t[t.length-1]}u`),a||(p+=\"+n\"),p},Wh=(e,r)=>{let t=e[0].dims.slice(),u=e[1].dims.slice(),[a,p,m]=Qn.getShapeOfGemmResult(t,r.transA,u,r.transB,e.length===3?e[2].dims:void 0),y=[a,p];if(!y)throw new Error(\"Can't use gemm on the given tensors\");let l=Z.size(y),S=\"\";r.transA&&r.transB?S=\"value += a[k * M + m] * b[n * K + k];\":r.transA&&!r.transB?S=\"value += a[k * M + m] * b[k * N + n];\":!r.transA&&r.transB?S=\"value += a[m * K + k] * b[n * K + k];\":!r.transA&&!r.transB&&(S=\"value += a[m * K + k] * b[k * N + n];\");let A=je(e[0].dataType),P=r.alpha===1?\"\":\"value *= alpha;\",T=e.length===3?`value += beta * c[${Vh(a,p,e[2].dims)}];`:\"\",k=[`@group(0) @binding(0) var<storage, read> a : array<${A}>;`,`@group(0) @binding(1) var<storage, read> b : array<${A}>;`];e.length===3&&k.push(`@group(0) @binding(2) var<storage, read> c : array<${A}>;`);let O=R=>`\n  const M: u32 = ${a}u;\n  const N: u32 = ${p}u;\n  const K: u32 = ${m}u;\n  const alpha = ${A}(${r.alpha});\n  const beta = ${A}(${r.beta});\n\n  ${k.join(`\n`)}\n  @group(0) @binding(${e.length}) var<storage, read_write> output : array<${A}>;\n\n  ${R.mainStart()}\n    ${R.guardAgainstOutOfBoundsWorkgroupSizes(l)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${A}(0);\n    for (var k: u32 = 0u; k<${m}u; k++) {\n      ${S}\n    }\n\n    ${P}\n    ${T}\n    output[global_id.x] = value;\n\n  }`;return{name:\"Gemm\",shaderCache:{hint:r.cacheKey},getRunData:()=>({outputs:[{dims:y,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(l/64)}}),getShaderSource:O}},Ol=(e,r)=>{zh(e.inputs),e.compute(Wh(e.inputs,r))},kl=e=>he(e)});var Uh,Nh,Hh,Gh,Rl,Bl,Ml=ae(()=>{\"use strict\";Ze();ke();Le();Pe();Uh={name:\"InstanceNormalization\"},Nh=(e,r)=>{let t=e[0].dims,u=t,a=2,p=Z.sizeToDimension(t,a),m=Z.sizeFromDimension(t,a),y=t[1],l=te(\"x\",e[0].dataType,[t[0],t[1],m]),S=te(\"scale\",e[1].dataType,e[1].dims),A=te(\"bias\",e[2].dataType,e[2].dims),P=se(\"output\",e[0].dataType,[t[0],t[1],m]),T=[l,S,A,P],k=l.type.value,O=64,R=j=>`\n\n  const C: u32 = ${y};\n  const normSize: u32 = ${m};\n  const epsilon: f32 = ${r.epsilon};\n  var<workgroup> meanShared : ${k};\n  var<workgroup> squaredNormShared : ${k};\n  var<workgroup> workgroupShared : array<${k}, ${O}>;\n  const workgroupSize = ${O}u;\n  ${j.declareVariables(...T)}\n  ${j.mainStart(O)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${k} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${l.get(\"batch\",\"channel\",\"h\")};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${k}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${l.get(\"batch\",\"channel\",\"h\")} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${k}(normSize) + epsilon);\n    let channelScale = invStdDev * ${S.getByOffset(\"channel\")};\n    let channelShift = ${A.getByOffset(\"channel\")} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${l.get(\"batch\",\"channel\",\"h\")} * channelScale + channelShift;\n      ${P.set(\"batch\",\"channel\",\"h\",\"value\")};\n    }\n  }`;return{...Uh,shaderCache:{hint:r.cacheKey},getRunData:()=>({outputs:[{dims:u,dataType:e[0].dataType}],dispatchGroup:{x:p}}),getShaderSource:R}},Hh=(e,r,t,u,a,p,m,y)=>{let l=lt(m),S=te(\"input\",r.dataType,r.dims,l),A=te(\"scale\",t.dataType,t.dims,l),P=te(\"bias\",u.dataType,u.dims,l),T=64,k=l===1?\"vec2f\":`mat2x${l}f`,O=l===1?\"f32\":`vec${l}f`,R=(Y,_)=>`${k}(${Y}, ${_})`,j=a*m/l,M=Math.ceil(p/T),z=Y=>`\n  const H: u32 = ${p};\n  const C: u32 = ${m/l};\n  const imageSize: u32 = ${p*m/l};\n\n  ${Y.declareVariables(S)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${k}>;\n\n  ${Y.mainStart(T)}\n    let currentImageNumber = global_idx / ${T} / C;\n    let currentChannelNumber = (global_idx / ${T}) % C;\n    let wgId = global_idx % ${T};\n    let wgOffset = wgId * ${M};\n    if (wgOffset >= H) {\n        return;\n    }\n    let wgMax = min(wgOffset + ${M}, H);\n\n    let offset = currentImageNumber * imageSize + currentChannelNumber;\n    var sum = ${ot(\"f32\",l)};\n    var squaredSum = ${ot(\"f32\",l)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${O}(input[offset + i * C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${R(\"sum\",\"squaredSum\")};\n  }`,q=e.compute({name:\"InstanceNormComputeMean\",shaderCache:{hint:JSON.stringify({components:l,n:a,h:p,c:m})},getRunData:()=>({outputs:[{dims:[a,m,T,2],dataType:1}],dispatchGroup:{x:a*m/l}}),getShaderSource:z},{inputs:[r],outputs:[-1]})[0],G=Y=>`\n  const H: u32 = ${p};\n  const C: u32 = ${m/l};\n  const imageSize: u32 = ${T*m/l};\n  const epsilon: f32 = ${y};\n\n  @group(0) @binding(0) var<storage, read> input : array<${k}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${A.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${P.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${k}>;\n\n  ${Y.mainStart()}\n    ${Y.guardAgainstOutOfBoundsWorkgroupSizes(j)}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    let offset = currentImageNumber * imageSize;\n    var sum = ${ot(\"f32\",l)};\n    var squaredSum = ${ot(\"f32\",l)};\n    for (var i: u32 = 0; i < ${T}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${T}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(H);\n    squaredSum = squaredSum / f32(H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + epsilon);\n    let channelScale = invStdDev * ${O}(scale[currentChannelNumber]);\n    let channelShift = ${O}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${R(\"channelScale\",\"channelShift\")};\n  }`;return e.compute({name:\"InstanceNormComputeChannelScaleShift\",shaderCache:{hint:JSON.stringify({components:l,n:a,h:p,c:m,epsilon:y})},getRunData:()=>({outputs:[{dims:[a,m,2],dataType:1}],dispatchGroup:{x:Math.ceil(j/64)}}),getShaderSource:G},{inputs:[q,t,u],outputs:[-1]})[0]},Gh=(e,r,t)=>{let u=r[0].dims,a=u,p=u[0],m=u[u.length-1],y=Z.sizeFromDimension(u,1)/m,l=lt(m),S=Z.size(a)/l,A=te(\"input\",r[0].dataType,r[0].dims,l),P=se(\"output\",r[0].dataType,a,l),T=je(r[0].dataType),k=l===1?\"vec2f\":`mat2x${l}f`,O=l===1?T:`vec${l}<${T}>`,R=Hh(e,r[0],r[1],r[2],p,y,m,t.epsilon),j=M=>`\n  const H: u32 = ${y};\n  const C: u32 = ${m/l};\n\n  @group(0) @binding(0) var<storage, read> input : array<${A.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${k}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${P.type.storage}>;\n\n  ${M.mainStart()}\n    let currentImageNumber = global_idx / (C * H);\n    let currentChannelNumber = global_idx % C;\n\n    let scaleOffset = currentImageNumber * C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${O}(scale[0]), ${O}(scale[1]));\n  }`;e.compute({name:\"InstanceNormalization\",shaderCache:{hint:`${t.cacheKey}`},getRunData:()=>({outputs:[{dims:a,dataType:r[0].dataType}],dispatchGroup:{x:Math.ceil(S/64)}}),getShaderSource:j},{inputs:[r[0],R]})},Rl=e=>he({epsilon:e.epsilon,format:e.format}),Bl=(e,r)=>{r.format===\"NHWC\"?Gh(e,e.inputs,r):e.compute(Nh(e.inputs,r))}});var Lh,Fh,Dl,jl,zl=ae(()=>{\"use strict\";Ze();ke();Le();Pe();Lh=e=>{if(!e||e.length<2)throw new Error(\"layerNorm requires at least 2 inputs.\")},Fh=(e,r,t)=>{let u=e[0].dims,a=e[1],p=e[2],m=u,y=Z.normalizeAxis(r.axis,u.length),l=Z.sizeToDimension(u,y),S=Z.sizeFromDimension(u,y),A=Z.size(a.dims),P=p?Z.size(p.dims):0;if(A!==S||p&&P!==S)throw new Error(`Size of X.shape()[axis:] == ${S}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${A} and bias size of ${P}`);let T=[];for(let G=0;G<u.length;++G)G<y?T.push(u[G]):T.push(1);let k=lt(S),O=je(e[0].dataType),R=[te(\"x\",e[0].dataType,e[0].dims,k),te(\"scale\",a.dataType,a.dims,k)];p&&R.push(te(\"bias\",p.dataType,p.dims,k)),R.push(se(\"output\",e[0].dataType,m,k));let j=t>1,M=t>2;j&&R.push(se(\"meanDataOutput\",1,T)),M&&R.push(se(\"invStdOutput\",1,T));let z=G=>`\n  const normSize: f32 = ${S};\n  const normSizeVectorized: u32 = ${S/k};\n  const epsilon: f32 = ${r.epsilon};\n\n  ${G.declareVariables(...R)}\n  ${G.mainStart()}\n    ${G.guardAgainstOutOfBoundsWorkgroupSizes(l)}\n    let offset = global_idx * normSizeVectorized;\n    var meanVector = ${ot(\"f32\",k)};\n    var meanSquareVector = ${ot(\"f32\",k)};\n\n    for (var h: u32 = 0u; h < normSizeVectorized; h++) {\n      let value = ${vt(O,k,\"x[h + offset]\")};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${wt(\"meanVector\",k)} / normSize;\n    let meanSquare = sqrt(${wt(\"meanSquareVector\",k)} \n      / normSize - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSizeVectorized; j++) {\n      let f32input = ${vt(O,k,\"x[j + offset]\")};\n      let f32scale = ${vt(O,k,\"scale[j]\")};\n      output[j + offset] = ${R[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${p?`+ ${vt(O,k,\"bias[j]\")}`:\"\"}\n      );\n    }\n\n    ${j?\"meanDataOutput[global_idx] = mean\":\"\"};\n    ${M?\"invStdOutput[global_idx] = 1 / meanSquare\":\"\"};\n  }`,q=[{dims:m,dataType:e[0].dataType}];return j&&q.push({dims:T,dataType:1}),M&&q.push({dims:T,dataType:1}),{name:\"LayerNormalization\",shaderCache:{hint:`${r.cacheKey}|${t}|${e.length}`},getRunData:()=>({outputs:q,dispatchGroup:{x:Math.ceil(l/64)}}),getShaderSource:z}},Dl=e=>he({axis:e.axis,epsilon:e.epsilon}),jl=(e,r)=>{Lh(e.inputs),e.compute(Fh(e.inputs,r,e.outputCount))}});var qh,Vl,Wl=ae(()=>{\"use strict\";ke();vn();qh=e=>{if(!e||e.length!==2)throw new Error(\"MatMul requires 2 inputs.\");if(e[0].dims[e[0].dims.length-1]!==e[1].dims[e[1].dims.length-2])throw new Error(\"shared dimension does not match.\")},Vl=e=>{qh(e.inputs);let r=Tt.calcShape(e.inputs[0].dims,e.inputs[1].dims,!0);if(!r)throw new Error(\"Can't use matmul on the given tensors\");e.compute(mi(e.inputs,{activation:\"\",activationCacheKey:\"\"},r))}});var Kh,Nl,Ul,Yh,eo,Hl,Gl=ae(()=>{\"use strict\";ke();Le();Zn();Wi();Pe();xr();Kh=(e,r)=>{let t=e[0],u=e[1],a=e[2],p=e[3],m=e[4],y=e[5],l=e[6],S=e[7];if(t.dims.length!==3&&t.dims.length!==5)throw new Error(\"Input query is expected to have 3 or 5 dimensions\");let A=!1,P=t.dims[0],T=t.dims[1],k=t.dims.length===3?A?t.dims[2]/3:t.dims[2]:r.numHeads*t.dims[4],O=T,R=0,j=0,M=Math.floor(k/r.numHeads);if(l&&S){if(l.dims.length!==4)throw new Error('Input \"past_key\" is expected to have 4 dimensions');if(S.dims.length!==4)throw new Error('Input \"past_value\" is expected to have 4 dimensions');R=l.dims[2],j=l.dims[2]}else if(l||S)throw new Error('Input \"past_key\" and \"past_value\" shall be both present or both absent');let z;if(u){if(t.dims.length!==3)throw new Error('Input \"query\" is expected to have 3 dimensions when key is given');if(u.dims.length<3||u.dims.length>5)throw new Error('Input \"key\" is expected to have 3, 4, or 5 dimensions');if(t.dims[0]!==u.dims[0])throw new Error('Input \"query\" and \"key\" shall have same dim 0 (batch size)');if(u.dims.length===3){if(u.dims[2]!==t.dims[2])throw new Error('Input \"query\" and \"key\" shall have same dim 2 (hidden_size)');z=2,O=u.dims[1]}else if(u.dims.length===5){if(u.dims[2]!==r.numHeads||u.dims[3]!==2||u.dims[4]!==M)throw new Error('Expect \"key\" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');if(a)throw new Error('Expect \"value\" be none when \"key\" has packed kv format.');z=5,O=u.dims[1]}else{if(u.dims[1]!==r.numHeads||u.dims[3]!==M)throw new Error('Expect \"key\" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');z=0,O=u.dims[2]}}else{if(t.dims.length!==3&&t.dims.length!==5)throw new Error('Input \"query\" is expected to have 3 or 5 dimensions when key is empty');if(t.dims.length===5&&(t.dims[2]!==r.numHeads||t.dims[3]!==3))throw new Error('Expect \"query\" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');z=3}if(p){if(p.dims.length!==1)throw new Error('Input \"bias\" is expected to have 1 dimension');if(a&&t.dims.length===5&&t.dims[3]===2)throw new Error(\"bias is not allowed for packed kv.\")}let q=0;if(m){q=8;let J=m.dims;throw J.length===1?J[0]===P?q=1:J[0]===3*P+2&&(q=3):J.length===2&&J[0]===P&&J[1]===O&&(q=5),q===8?new Error('Input \"key_padding_mask\" shape shall be (batch_size) or (batch_size, kv_sequence_length)'):new Error(\"Mask not supported\")}let G=!1,Y=k;if(a){if(a.dims.length!==3&&a.dims.length!==4)throw new Error('Input \"value\" is expected to have 3 or 4 dimensions');if(t.dims[0]!==a.dims[0])throw new Error('Input \"query\" and \"value\" shall have same dim 0 (batch_size)');if(a.dims.length===3){if(O!==a.dims[1])throw new Error('Input \"key\" and \"value\" shall have the same dim 1 (kv_sequence_length)');Y=a.dims[2]}else{if(O!==a.dims[2])throw new Error('Input \"past_key\" and \"past_value\" shall have the same dim 2 (kv_sequence_length)');Y=a.dims[1]*a.dims[3],G=!0}}let _=R+O,X=!1;if(m)throw new Error(\"Key padding mask is not supported\");if(y)throw new Error(\"extraAddQk is not supported\");if(l)throw new Error(\"pastKey is not supported\");if(S)throw new Error(\"pastValue is not supported\");return{batchSize:P,sequenceLength:T,pastSequenceLength:R,kvSequenceLength:O,totalSequenceLength:_,maxSequenceLength:j,inputHiddenSize:0,hiddenSize:k,vHiddenSize:Y,headSize:M,vHeadSize:Math.floor(Y/r.numHeads),numHeads:r.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:r.maskFilterValue,maskType:q,scale:r.scale,broadcastResPosBias:X,passPastInKv:G,qkvFormat:z}},Nl=e=>he({...e}),Ul=he({perm:[0,2,1,3]}),Yh=(e,r,t,u,a,p,m)=>{let y=[u,a,p],l=Z.size(y),S=je(r.dataType),A=P=>`\n  const biasOffset = ${m}u;\n  const hiddenSize = ${p}u;\n\n  @group(0) @binding(0) var<storage, read> qkv: array<${S}>;\n  @group(0) @binding(1) var<storage, read> bias: array<${S}>;\n  @group(0) @binding(2) var<storage, read_write> qkv_with_bias: array<${S}>;\n\n  ${P.mainStart()}\n    ${P.guardAgainstOutOfBoundsWorkgroupSizes(l)}\n    let biasOffsetIdx = (global_idx % hiddenSize) + biasOffset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[biasOffsetIdx];\n  }`;return e.compute({name:\"MultiHeadAttentionAddBias\",shaderCache:{hint:JSON.stringify({batchSize:u,sequenceLength:a,hiddenSize:p,biasOffset:m})},getRunData:()=>({outputs:[{dims:y,dataType:r.dataType,gpuDataType:0}],dispatchGroup:{x:Math.ceil(l/64)}}),getShaderSource:A},{inputs:[r,t],outputs:[-1]})[0]},eo=(e,r,t,u,a,p,m,y)=>{let l=p;if(m){if(u===1)throw new Error(\"AddBiasReshape is not implemented. Please export your model with packed QKV or KV\");return l=Yh(e,p,m,r,u,t*a,y),l=l.reshape([r,u,t,a]),e.compute($t(l,Ul.perm),{inputs:[l],outputs:[-1]})[0]}else return p.dims.length===3&&(l=p.reshape([r,u,t,a])),e.compute($t(l,Ul.perm),{inputs:[l],outputs:[-1]})[0]},Hl=(e,r)=>{let t=Kh(e.inputs,r);if(e.inputs[0].dims.length===5)throw new Error(\"Packed QKV is not implemented\");if(e.inputs[1]?.dims.length===5)throw new Error(\"Packed KV is not implemented\");let u=e.inputs[1]&&e.inputs[2]&&e.inputs[1].dims.length===4&&e.inputs[2].dims.length===4,a=eo(e,t.batchSize,t.numHeads,t.sequenceLength,t.headSize,e.inputs[0],e.inputs[3],0);if(u)return ni(e,a,e.inputs[1],e.inputs[2],e.inputs[4],void 0,void 0,void 0,e.inputs[5],t,r);let p=eo(e,t.batchSize,t.numHeads,t.kvSequenceLength,t.headSize,e.inputs[1],e.inputs[3],t.hiddenSize),m=eo(e,t.batchSize,t.numHeads,t.kvSequenceLength,t.vHeadSize,e.inputs[2],e.inputs[3],2*t.hiddenSize);ni(e,a,p,m,e.inputs[4],void 0,e.inputs[6],e.inputs[7],e.inputs[5],t,r)}});var Zh,Xh,Qh,Jh,eg,tg,rg,ng,ig,Ll,Fl,ql=ae(()=>{\"use strict\";Ze();ke();Le();Pe();Zh=e=>{if(!e||e.length<1)throw new Error(\"Too few inputs\");if(e[0].dataType!==1)throw new Error(\"Input type must be float.\");if(e.length>=2){let r=e[0].dims.length*2===e[1].dims[0];if(e.length===4&&(r=e[3].dims[0]*2===e[1].dims[0]),!r)throw new Error(\"The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].\")}},Xh=(e,r,t,u,a,p)=>{let m=r.length,y=\"\";for(let l=m-1;l>=0;--l)y+=`\n            k = i32(${e.indicesGet(\"indices\",l)}) - ${u[l]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${r[l]}) {\n              break;\n            }\n            offset += k * ${t[l]};\n        `;return`\n          value = ${a}(${p});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${y}\n            value = x[offset];\n          }\n      `},Qh=(e,r,t,u)=>{let a=r.length,p=\"\";for(let m=a-1;m>=0;--m)p+=`\n                k = i32(${e.indicesGet(\"indices\",m)}) - ${u[m]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2*(r[m]-1)};\n                  k = k % _2n_1;\n                  if(k >= ${r[m]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${t[m]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${p}\n              value = x[offset];\n          `},Jh=(e,r,t,u)=>{let a=r.length,p=\"\";for(let m=a-1;m>=0;--m)p+=`\n                k = i32(${e.indicesGet(\"indices\",m)}) - ${u[m]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${r[m]}) {\n                  k = ${r[m]-1};\n                }\n                offset += k * ${t[m]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${p}\n              value = x[offset];\n          `},eg=(e,r,t,u)=>{let a=r.length,p=\"\";for(let m=a-1;m>=0;--m)p+=`\n                k = i32(${e.indicesGet(\"indices\",m)}) - ${u[m]};\n                if (k < 0)  {\n                  k += ${r[m]};\n                }\n                if (k >= ${r[m]}) {\n                  k -= ${r[m]};\n                }\n                offset += k * ${t[m]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${p}\n              value = x[offset];\n          `},tg=(e,r,t,u,a)=>{switch(u.mode){case 0:return Xh(e,r,t,u.pads,a,u.value);case 1:return Qh(e,r,t,u.pads);case 2:return Jh(e,r,t,u.pads);case 3:return eg(e,r,t,u.pads);default:throw new Error(\"Invalid mode\")}},rg=(e,r,t,u)=>{let a=r[0].dims,p=Z.padShape(a.slice(),t.pads),m=Z.size(p),y=Z.computeStrides(a),l=se(\"output\",r[0].dataType,p),S=te(\"x\",r[0].dataType,a),A=tg(l,a,y,t,u);return`\n              ${e.declareVariables(S,l)}\n              ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(m)}\n\n              let indices = ${l.offsetToIndices(\"global_idx\")};\n\n              var value = ${u}(0);\n              ${A}\n              output[global_idx] = value;\n          }`},ng=(e,r)=>{let t=Z.padShape(e[0].dims.slice(),r.pads);return{name:\"Pad\",shaderCache:{hint:r.cacheKey},getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(Z.size(t)/64)}}),getShaderSource:u=>rg(u,e,r,\"f32\")}},ig=(e,r)=>{if(e.length>1){let t=e[1].getBigInt64Array(),u=e.length>=3&&e[2].data?e[2].getFloat32Array()[0]:0,a=e[0].dims.length,p=new Int32Array(2*a).fill(0);if(e.length>=4){let y=e[3].getBigInt64Array();for(let l=0;l<y.length;l++)p[Number(y[l])]=Number(t[l]),p[Number(y[l])+a]=Number(t[l+y.length])}else t.forEach((y,l)=>p[Number(l)]=Number(y));let m=[];return p.forEach(y=>m.push(y)),he({mode:r.mode,value:u,pads:m})}else return r},Ll=(e,r)=>{Zh(e.inputs);let t=ig(e.inputs,r);e.compute(ng(e.inputs,t),{inputs:[0]})},Fl=e=>{let r=e.mode,t=e.value,u=e.pads;return he({mode:r,value:t,pads:u})}});var gi,Kl,Yl,Zl,Xl,Ql,Jl,ed,td,rd,nd,id,od,ad,sd,ud=ae(()=>{\"use strict\";ke();Le();Pe();gi=e=>{if(!e||e.length!==1)throw new Error(\"Pool ops requires 1 input.\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"Pool ops supports 1-D or 2-D inputs only for now.\")},Kl=(e,r,t)=>{let u=r.format===\"NHWC\",a=e.dims.slice();u&&a.splice(1,0,a.pop());let p=Object.hasOwnProperty.call(r,\"dilations\"),m=r.kernelShape.slice(),y=r.strides.slice(),l=p?r.dilations.slice():[],S=r.pads.slice();Jt.adjustPoolAttributes(t,a,m,y,l,S);let A=Jt.computePoolOutputShape(t,a,y,l,m,S,r.autoPad),P=Object.assign({},r);p?Object.assign(P,{kernelShape:m,strides:y,pads:S,dilations:l,cacheKey:r.cacheKey}):Object.assign(P,{kernelShape:m,strides:y,pads:S,cacheKey:r.cacheKey});let T=A.slice();return T.push(T.splice(1,1)[0]),[P,u?T:A]},Yl=(e,r,t,u,a,p,m,y)=>{let l=a.format===\"NHWC\",S=t,A=r.type.value,P=S.length,T=Z.size(u),k=se(\"output\",r.type.tensor,u);if(a.kernelShape.length<=2){let O=a.kernelShape[a.kernelShape.length-1],R=a.strides[a.strides.length-1],j=a.pads[a.pads.length/2-1],M=a.pads[a.pads.length-1],z=P-(l?2:1),q=\"\",G=\"\",Y=\"\";if(j+M!==0?q=`\n                for (var i: u32 = 0u; i < ${O}u; i++) {\n                  xIndices[${z}] = indices[${z}] * ${R} - ${j} + i;\n                  if (xIndices[${z}] < 0 || xIndices[${z}] >= ${S[z]}) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${r.indicesToOffset(\"xIndices\")}];\n                  ${p}\n                }`:q=`\n                for (var i: u32 = 0u; i < ${O}u; i++) {\n                  xIndices[${z}] = indices[${z}] * ${R} - ${j} + i;\n                  let x_val = x[${r.indicesToOffset(\"xIndices\")}];\n                  ${p}\n                }`,a.kernelShape.length===2){let X=a.kernelShape[a.kernelShape.length-2],J=a.strides[a.strides.length-2],re=a.pads[a.pads.length/2-2],fe=a.pads[a.pads.length-2],L=P-(l?3:2),oe=S[L];re+fe!==0?G=`\n                for (var j: u32 = 0u; j < ${X}u; j++) {\n                  xIndices[${L}] = indices[${L}] * ${J} - ${re} + j;\n                  if (xIndices[${L}] < 0 || xIndices[${L}] >= ${oe}) {\n                    pad+= ${O};\n                    continue;\n                  }\n              `:G=`\n                for (var j: u32 = 0u; j < ${X}u; j++) {\n                  xIndices[${L}] = indices[${L}] * ${J} - ${re} + j;\n                `,Y=`\n              }\n            `}return`\n            ${e.declareVariables(r,k)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(T)}\n\n              let indices = ${k.offsetToIndices(\"global_idx\")};\n              var xIndices = ${k.offsetToIndices(\"global_idx\")};\n\n              var value: ${A} = ${A}(${y});\n              var pad = 0;\n              ${G}\n              ${q}\n              ${Y}\n              ${m}\n\n              output[global_idx] = value;\n            }`}else{if(l)throw new Error(\"Pooling with kernelShape.length > 2 is not supported for NHWC format.\");let O=Z.size(a.kernelShape),R=Z.computeStrides(a.kernelShape),j=R.length,M=a.pads.length,z=a.pads.reduce((Y,_)=>Y+_),q=\"\";return z?q=`\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${r.indicesToOffset(\"xIndices\")}];\n                ${p}\n              }`:q=`\n              }\n              let x_val = x[${r.indicesToOffset(\"xIndices\")}];\n              ${p}\n            `,`\n            ${e.declareVariables(r,k)}\n\n            const pads = array<u32, ${M}>(${a.pads.map(Y=>`${Y}u`).join(\",\")});\n            const inputDims = array<u32, ${P}>(${S.map(Y=>`${Y}u`).join(\",\")});\n            const kernelStrides = array<u32, ${j}>(${R.map(Y=>`${Y}u`).join(\",\")});\n            const strides = array<u32, ${j}>(${a.strides.map(Y=>`${Y}u`).join(\",\")});\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(T)}\n\n              let indices = ${k.offsetToIndices(\"global_idx\")};\n              let xIndices = ${k.offsetToIndices(\"global_idx\")};\n\n              var offsets: array<u32, ${j}>;\n\n              var value = ${k.type.value}(${y});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${O}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${j-1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${j-1}] = offset;\n\n                isPad = false;\n                for (var j = ${P-j}u; j < ${P}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${P-j}u]\n                    + offsets[j - ${P-j}u] - pads[j - 2u];\n                  ${q}\n              }\n              ${m}\n\n              output[global_idx] = value;\n            }`}},Zl=e=>({format:e.format,autoPad:[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],ceilMode:e.ceil_mode,kernelShape:e.kernel_shape,strides:e.strides,pads:e.pads}),Xl=(e,r,t,u)=>{let[a,p]=Kl(r,u,t),m=Z.size(a.kernelShape),y=te(\"x\",r.dataType,r.dims),l=y.type.value,S=\"value += x_val;\",A=\"\";return a.countIncludePad?A+=`value /= ${l}(${m});`:A+=`value /= ${l}(${m} - pad);`,{name:e,shaderCache:{hint:u.cacheKey},getRunData:()=>({outputs:[{dims:p,dataType:r.dataType}],dispatchGroup:{x:Math.ceil(Z.size(p)/64)}}),getShaderSource:P=>Yl(P,y,r.dims,p,a,S,A,\"0.0\")}},Ql=e=>{let r=e.count_include_pad!==0,t=Zl(e);if(t.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for AveragePool\");return he({countIncludePad:r,...t})},Jl=(e,r)=>{gi(e.inputs),e.compute(Xl(\"AveragePool\",e.inputs[0],!1,r))},ed={autoPad:\"\",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[],cacheKey:\"\"},td=e=>{let r=e.format;return{format:r,...ed,cacheKey:r}},rd=(e,r)=>{gi(e.inputs),e.compute(Xl(\"GlobalAveragePool\",e.inputs[0],!0,r))},nd=(e,r,t,u)=>{let[a,p]=Kl(r,u,t),m=`\n      value = max(x_val, value);\n    `,y=\"\",l=te(\"x\",r.dataType,r.dims);return{name:e,shaderCache:{hint:u.cacheKey},getRunData:()=>({outputs:[{dims:p,dataType:r.dataType}],dispatchGroup:{x:Math.ceil(Z.size(p)/64)}}),getShaderSource:S=>Yl(S,l,r.dims,p,a,m,y,\"-1e5\")}},id=(e,r)=>{gi(e.inputs),e.compute(nd(\"MaxPool\",e.inputs[0],!1,r))},od=e=>{let r=e.storage_order,t=e.dilations,u=Zl(e);if(r!==0)throw new Error(\"column major storage order is not yet supported for MaxPool\");if(u.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for MaxPool\");return he({storageOrder:r,dilations:t,...u})},ad=e=>{let r=e.format;return{format:r,...ed,cacheKey:r}},sd=(e,r)=>{gi(e.inputs),e.compute(nd(\"GlobalMaxPool\",e.inputs[0],!0,r))}});var ag,sg,ld,dd=ae(()=>{\"use strict\";Ni();Ze();Pe();ag=(e,r,t)=>{let u=e===r,a=e<r&&t<0,p=e>r&&t>0;if(u||a||p)throw new Error(\"Range these inputs' contents are invalid.\")},sg=(e,r,t,u)=>{let a=Math.abs(Math.ceil((r-e)/t)),p=[a],m=a,y=se(\"output\",u,p),l=y.type.storage,S=A=>`\n        ${A.declareVariables(y)}\n        ${A.mainStart()}\n        ${A.guardAgainstOutOfBoundsWorkgroupSizes(m)}\n        output[global_idx] = ${l}(${e}) + ${l}(global_idx) * ${l}(${t});\n      }`;return{name:\"Range\",shaderCache:{hint:[e,r,t].map(A=>A.toString()).join(\"_\")},getShaderSource:S,getRunData:()=>({outputs:[{dims:p,dataType:u}],dispatchGroup:{x:Math.ceil(m/64)}})}},ld=e=>{let r=0,t=0,u=0;e.inputs[0].dataType===6?(r=e.inputs[0].getInt32Array()[0],t=e.inputs[1].getInt32Array()[0],u=e.inputs[2].getInt32Array()[0]):e.inputs[0].dataType===1&&(r=e.inputs[0].getFloat32Array()[0],t=e.inputs[1].getFloat32Array()[0],u=e.inputs[2].getFloat32Array()[0]),oi.webgpu.validateInputContent&&ag(r,t,u),e.compute(sg(r,t,u,e.inputs[0].dataType),{inputs:[]})}});var ug,lg,dg,cg,fg,pg,mg,hg,gg,yg,bg,vg,wg,$g,Cg,cd,fd,pd=ae(()=>{\"use strict\";ke();Le();Pe();ug=(e,r)=>{if(e.every(t=>t>0||(()=>{throw new Error(\"Resize requires scales input values to be positive\")})),e.length>0){if(r.mode===\"linear\"){if(!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for linear mode\")}else if(r.mode===\"cubic\"&&!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for cubic mode\")}},lg=(e,r,t)=>{r.every(a=>a>=0&&a<t||(()=>{throw new Error(\"Resize requires axes input values to be positive and less than rank\")}));let u=new Array(t).fill(1);return r.forEach((a,p)=>u[a]=e[p]),u},dg=(e,r,t,u,a,p)=>{let[m,y,l]=t>10?[1,2,3]:[-1,e.length>1?1:-1,-1],S=e[0].dims.length;if(m>0&&e.length>m&&e[m].dims.length>0)e[m].getFloat32Array().forEach(A=>p.push(A));else if(r.coordinateTransformMode===\"tf_crop_and_resize\")throw new Error(\"Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize\");if(y>0&&e.length>y&&e[y].dims.length>0){if(e[y].getFloat32Array().forEach(A=>u.push(A)),u.length!==0&&u.length!==S&&t>=18&&u.length!==r.axes.length)throw new Error(\"Resize requires scales input size to be same as input rank or axes size for opset 18 and up\");ug(u,r),r.axes.length>0&&lg(u,r.axes,S).forEach((A,P)=>u[P]=A)}if(l>0&&e.length>l&&(e[l].getBigInt64Array().forEach(A=>a.push(Number(A))),a.length!==S||t>=18&&a.length===r.axes.length))throw new Error(\"Resize requires sizes input size to be same as input rank or axes size for opset 18 and up\");if(r.axes.length>0){if(u.length!==r.axes.length)throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');if(a.length!==r.axes.length)throw new Error('Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified')}if(typeof u<\"u\"&&typeof a<\"u\"&&u.length>0&&a.length>S)throw new Error(\"Resize requires only of scales or sizes to be specified\")},cg=(e,r)=>`fn getOriginalCoordinateFromResizedCoordinate(xResized: ${r}, xScale: ${r}, lengthResized: ${r},\n     lengthOriginal: ${r}, roiStart: ${r}, roiEnd: ${r}) -> ${r} { `+(()=>{switch(e){case\"asymmetric\":return\"return xResized / xScale;\";case\"pytorch_half_pixel\":return\"if (lengthResized > 1) {                     return (xResized + 0.5) / xScale - 0.5;                   } else {                     return 0.0;                   }\";case\"tf_half_pixel_for_nn\":return\"return (xResized + 0.5) / xScale;\";case\"align_corners\":return\"if (lengthResized == 1) {                     return 0.0;                   } else {                     return xResized * (lengthOriginal - 1) / (lengthResized - 1);                   }\";case\"tf_crop_and_resize\":return`if (lengthResized > 1) {                     return roiStart * (lengthOriginal - 1) +                           (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1);                   } else {                     return 0.5 * (roiStart + roiEnd) * ${r}(lengthOriginal - 1);                   }`;case\"half_pixel_symmetric\":return[\"const outputWidth = xScale * lengthResized;\",\"const adjustment = lengthResized / outputWidth;\",\"const center = lengthOriginal / 2;\",\"const offset = center * (1 - adjustment);\",\"return offset + ((xResized + 0.5) / xScale) - 0.5;\"].join(`\n`);case\"half_pixel\":return\"return ((xResized + 0.5) / xScale) - 0.5;\";default:throw new Error(`Coordinate transform mode ${e} is not supported`)}})()+\"}\",fg=(e,r,t)=>`fn getNearestPixelFromOriginal(xOriginal: ${t}, isDownSample: bool) -> ${t} {`+(()=>{switch(e){case\"round_prefer_ceil\":return\"if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }\";case\"floor\":return\"return floor(xOriginal);\";case\"ceil\":return\"return ceil(xOriginal);\";case\"round_prefer_floor\":return\"if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }\";case\"simple\":default:if(r<11)return\"if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }\";throw new Error(`Nearest mode ${e} is not supported`)}})()+\"}\",pg=(e,r,t)=>{let u=new Array(t).fill(0).concat(new Array(t).fill(1)),a=e.length===0?u:e.slice();return r.length>0?(r.forEach((p,m)=>{u[p]=a[m],u[m+t]=a[r.length+m]}),u):a},mg=(e,r,t,u)=>{let a=[];if(t.length>0)if(u.length>0){if(e.forEach(p=>a.push(p)),Math.max(...u)>e.length)throw new Error(\"axes is out of bound\");u.forEach((p,m)=>a[p]=t[m])}else t.forEach(p=>a.push(p));else{if(r.length===0)throw new Error(\"Resize requires either scales or sizes.\");a=e.map((p,m)=>Math.round(p*r[m]))}return a},hg=(e,r,t)=>{let u=(()=>{switch(t.keepAspectRatioPolicy){case\"not_larger\":return t.axes.length>0?Math.min(...t.axes.map(p=>r[p]),Number.MAX_VALUE):Math.min(...r,Number.MAX_VALUE);case\"not_smaller\":return t.axes.length>0?Math.max(...t.axes.map(p=>r[p]),Number.MIN_VALUE):Math.max(...r,Number.MIN_VALUE);default:throw new Error(`Keep aspect ratio policy ${t.keepAspectRatioPolicy} is not supported`)}})();r.fill(1,0,r.length);let a=e.slice();return t.axes.length>0?(t.axes.forEach(p=>r[p]=u),t.axes.forEach(p=>a[p]=Math.round(e[p]*r[p]))):(r.fill(u,0,r.length),a.forEach((p,m)=>a[m]=Math.round(p*r[m]))),a},gg=(e,r,t,u,a)=>`\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${e.type.indices}) -> array<${e.type.value}, ${t.length}> {\n      const inputShape = array<u32, ${r.length}>(${r.map(p=>`${p}u`).join(\",\")});\n      const outputShape = array<u32, ${t.length}>(${t.map(p=>`${p}u`).join(\",\")});\n      const scales = array<${e.type.value}, ${u.length}>(${u.map(p=>`${p}f`).join(\",\")});\n      const roi = array<${e.type.value}, ${a.length}>(${a.map(p=>`${p}f`).join(\",\")});\n      var originalIndices: array<${e.type.value}, ${t.length}>;\n      for (var i:u32 = 0; i < ${t.length}; i++) {\n        var outputIndex = ${t.length===1?\"outputIndices\":\"outputIndices[i]\"};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = ${e.type.value}(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(${e.type.value}(outputIndex), scales[i],\n                ${e.type.value}(outputShape[i]), ${e.type.value}(inputShape[i]), roi[i], roi[i + ${r.length}]);\n        }\n      }\n      return originalIndices;\n    }`,yg=(e,r,t,u,a,p,m)=>`\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${r.type.indices}) -> ${e.type.indices} {\n        const inputShape = array<u32, ${t.length}>(${t.map(y=>`${y}u`).join(\",\")});\n        const outputShape = array<u32, ${u.length}>(${u.map(y=>`${y}u`).join(\",\")});\n        const scales = array<${e.type.value}, ${a.length}>(${a.map(y=>`${y}`).join(\",\")});\n        const roi = array<${e.type.value}, ${p.length}>(${p.map(y=>`${y}`).join(\",\")});\n        var inputIndices: ${e.type.indices};\n        for (var i:u32 = 0; i < ${u.length}; i++) {\n          var outputIndex = ${u.length===1?\"outputIndices\":\"outputIndices[i]\"};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(${e.type.value}(outputIndex), scales[i],\n                    ${e.type.value}(outputShape[i]), ${e.type.value}(inputShape[i]), roi[i], roi[i + ${t.length}]);\n            if (!${m} || (original_idx >= 0 && original_idx < ${e.type.value}(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (${e.type.value}(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${e.indicesSet(\"inputIndices\",\"i\",\"inputIndex\")}\n        }\n        return inputIndices;\n    }`,bg=(e,r)=>`\n    fn checkInputIndices(inputIndices: ${e.type.indices}) -> bool {\n      const inputShape = array<u32, ${r.length}>(${r.map(t=>`${t}u`).join(\",\")});\n      for (var i:u32 = 0; i < ${r.length}; i++) {\n        var inputIndex = ${r.length===1?\"inputIndices\":\"inputIndices[i]\"};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`,vg=(e,r,t,u,a,p)=>{let[m,y,l,S]=t.length===2?[-1,0,1,-1]:u[1]===1?[0,2,3,1]:[0,1,2,3],A=e.type.value;return`\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${A} {\n      var inputIndices: ${e.type.indices};\n      inputIndices[${y}] = max(0, min(row, ${t[y]} - 1));\n      inputIndices[${l}] = max(0, min(col, ${t[l]} - 1));\n      if (${t.length} > 2) {\n        inputIndices[${S}] = channel;\n        inputIndices[${m}] = batch;\n      };\n      return input[${e.indicesToOffset(\"inputIndices\")}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${r.type.indices}) -> ${A} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:${A} = originalIndices[${y}];\n      var col:${A} = originalIndices[${l}];\n      if (${a} && (row < 0 || row > (${t[y]} - 1) || col < 0 || col > ${t[l]} - 1)) {\n        return ${p};\n      }\n      row = max(0, min(row, ${t[y]} - 1));\n      col = max(0, min(col, ${t[l]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${t.length>2}) {\n        channel = u32(originalIndices[${S}]);\n        batch = u32(originalIndices[${m}]);\n      }\n      var x11: ${A} = getInputValue(batch, channel, row1, col1);\n      var x12: ${A} = getInputValue(batch, channel, row1, col2);\n      var x21: ${A} = getInputValue(batch, channel, row2, col1);\n      var x22: ${A} = getInputValue(batch, channel, row2, col2);\n      var dx1: ${A} = row - ${A}(row1);\n      var dx2: ${A} = ${A}(row2) - row;\n      var dy1 = col - ${A}(col1);\n      var dy2 = ${A}(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`},wg=(e,r,t,u,a,p,m,y,l,S)=>{let[A,P]=t.length===2?[0,1]:a[1]===1?[2,3]:[1,2],T=e.type.value,k=O=>{let R=O===A?\"row\":\"col\";return`\n      fn ${R}CubicInterpolation(inputIndices: ${e.type.indices}, outputIndices: ${r.type.indices}) -> ${T} {\n        var outputIndex = ${u.length===1?\"outputIndices\":`outputIndices[${O}]`};\n        var originalIdx: ${T} = getOriginalCoordinateFromResizedCoordinate(${T}(outputIndex), ${a[O]},\n        ${T}(${u[O]}), ${T}(${t[O]}), ${p[O]}, ${p[O]} + ${t.length});\n        var fractOriginalIdx: ${T} = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${y} && (originalIdx < 0 || originalIdx > (${t[O]} - 1))) {\n          return ${l};\n        }\n        var data: array<${T}, 4> = array<${T}, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${R}: ${T} = originalIdx + ${T}(i);\n          if (${R} < 0 || ${R} >= ${t[O]}) {\n            if (${S}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${y}) {\n              return ${l};\n            } else {\n              ${R} = max(0, min(${R}, ${t[O]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${e.type.indices} = inputIndices;\n          inputIndicesCopy[${O}] = u32(${R});\n          data[i + 1] = ${O===A?`input[${e.indicesToOffset(\"inputIndicesCopy\")}];`:`\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`};return`\n    ${k(A)};\n    ${k(P)};\n  fn getCubicInterpolationCoefs(s: ${T}) -> array<${T}, 4> {\n    var absS = abs(s);\n    var coeffs: array<${T}, 4> = array<${T}, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: ${T} = 1.0 - absS;\n    var twoMinusAbsS: ${T} = 2.0 - absS;\n    var onePlusAbsS: ${T} = 1.0 + absS;\n    coeffs[0] = ((${m} * onePlusAbsS - 5 * ${m}) * onePlusAbsS + 8 * ${m}) * onePlusAbsS - 4 * ${m};\n    coeffs[1] = ((${m} + 2) * absS - (${m} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${m} + 2) * oneMinusAbsS - (${m} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${m} * twoMinusAbsS - 5 * ${m}) * twoMinusAbsS + 8 * ${m}) * twoMinusAbsS - 4 * ${m};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<${T}, 4>, coefs: array<${T}, 4>) -> ${T} {\n    var coefsSum: ${T} = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${r.type.indices}) -> ${T} {\n    var inputIndices: ${e.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `},$g=(e,r,t,u,a,p)=>{let m=e.dims,y=pg(p,r.axes,m.length),l=mg(m,u,a,r.axes),S=u.slice();u.length===0&&(S=m.map((M,z)=>M===0?1:l[z]/M),r.keepAspectRatioPolicy!==\"stretch\"&&(l=hg(m,S,r)));let A=se(\"output\",e.dataType,l),P=te(\"input\",e.dataType,m),T=Z.size(l),k=m.length===l.length&&m.every((M,z)=>M===l[z]),O=r.coordinateTransformMode===\"tf_crop_and_resize\",R=P.type.value,j=M=>`\n      ${k?\"\":`\n      ${cg(r.coordinateTransformMode,R)};\n      ${(()=>{switch(r.mode){case\"nearest\":return`\n              ${bg(P,m)};\n              ${fg(r.nearestMode,t,R)};\n              ${yg(P,A,m,l,S,y,O)};\n              `;case\"linear\":return`\n              ${gg(A,m,l,S,y)};\n              ${vg(P,A,m,S,O,r.extrapolationValue)};\n              `;case\"cubic\":return`\n            ${wg(P,A,m,l,S,y,r.cubicCoeffA,O,r.extrapolationValue,r.excludeOutside)};\n            `;default:throw Error(\"Invalid resize mode\")}})()};\n      `}\n      ${M.declareVariables(P,A)}\n      ${M.mainStart()}\n        ${M.guardAgainstOutOfBoundsWorkgroupSizes(T)}\n        ${k?\"output[global_idx] = input[global_idx];\":`\n        let outputIndices = ${A.offsetToIndices(\"global_idx\")};\n        var inputIndices: ${P.type.indices};\n        ${(()=>{switch(r.mode){case\"nearest\":return`inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                if (checkInputIndices(inputIndices)) {\n                  output[global_idx] = input[${P.indicesToOffset(\"inputIndices\")}];\n                } else {\n                  output[global_idx] = ${r.extrapolationValue};\n                }`;case\"linear\":return\"output[global_idx] = bilinearInterpolation(outputIndices);\";case\"cubic\":return\"output[global_idx] = bicubicInterpolation(outputIndices);\";default:throw Error(`Unsupported resize mode: ${r.mode}`)}})()};\n        `}\n      }`;return{name:\"Resize\",shaderCache:{hint:`${r.cacheKey}|${t}|${S.length>0?S:\"\"}|${a.length>0?a:\"\"}|${k}`},getShaderSource:j,getRunData:()=>({outputs:[{dims:l,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(T/64)}})}},Cg=e=>{let r=e.customDataBuffer;return new Uint32Array(r,r.byteOffset,1)[0]},cd=(e,r)=>{let t=[],u=[],a=[],p=Cg(e);dg(e.inputs,r,p,t,u,a),e.compute($g(e.inputs[0],r,p,t,u,a),{inputs:[0]})},fd=e=>{let r=e.antialias,t=e.axes,u=e.coordinateTransformMode,a=e.cubicCoeffA,p=e.excludeOutside!==0,m=e.extrapolationValue,y=e.keepAspectRatioPolicy,l=e.mode,S=e.nearestMode===\"\"?\"simple\":e.nearestMode;return he({antialias:r,axes:t,coordinateTransformMode:u,cubicCoeffA:a,excludeOutside:p,extrapolationValue:m,keepAspectRatioPolicy:y,mode:l,nearestMode:S})}});var Sg,xg,md,hd,gd=ae(()=>{\"use strict\";Ze();ke();Le();Pe();Sg=e=>{if(!e||e.length<3)throw new Error(\"layerNorm requires at least 3 inputs.\");let r=e[0],t=e[1],u=e[2];if(r.dataType!==t.dataType||r.dataType!==u.dataType)throw new Error(\"All inputs must have the same data type\");if(r.dims.length!==3&&r.dims.length!==2)throw new Error(\"Input must be 2D or 3D\");if(t.dims.length!==3&&t.dims.length!==2)throw new Error(\"Skip must be 2D or 3D\");let a=r.dims[r.dims.length-1],p=r.dims[r.dims.length-2];if(t.dims[t.dims.length-1]!==a)throw new Error(\"Skip must have the same hidden size as input\");if(t.dims[t.dims.length-2]!==p)throw new Error(\"Skip must have the same sequence length as input\");if(u.dims.length!==1)throw new Error(\"Gamma must be 1D\");if(u.dims[u.dims.length-1]!==a)throw new Error(\"Gamma must have the same hidden size as input\");if(e.length>3){let m=e[3];if(m.dims.length!==1)throw new Error(\"Beta must be 1D\");if(m.dims[m.dims.length-1]!==a)throw new Error(\"Beta must have the same hidden size as input\")}if(e.length>4){let m=e[4];if(m.dims.length!==1)throw new Error(\"Bias must be 1D\");if(m.dims[m.dims.length-1]!==a)throw new Error(\"Bias must have the same hidden size as input\")}},xg=(e,r,t,u)=>{let a=e[0].dims,p=Z.size(a),m=a,y=p,l=a.slice(-1)[0],S=u?a.slice(0,-1).concat(1):[],A=e.length>3,P=e.length>4,T=u&&t>1,k=u&&t>2,O=t>3,R=lt(l),j=[te(\"x\",e[0].dataType,e[0].dims,R),te(\"skip\",e[1].dataType,e[1].dims,R),te(\"gamma\",e[2].dataType,e[2].dims,R)];A&&j.push(te(\"beta\",e[3].dataType,e[3].dims,R)),P&&j.push(te(\"bias\",e[4].dataType,e[4].dims,R)),j.push(se(\"output\",e[0].dataType,m,R)),T&&j.push(se(\"meanOutput\",1,S)),k&&j.push(se(\"invStdOutput\",1,S)),O&&j.push(se(\"inputSkipBiasSum\",e[0].dataType,m,R));let M=je(e[0].dataType),z=G=>`\n      const hiddenSize: f32 = ${l};\n      const hiddenSizeVectorized: u32 = ${l/R};\n      const epsilon: f32 = ${r.epsilon};\n\n      ${G.declareVariables(...j)}\n\n      ${G.mainStart()}\n        ${G.guardAgainstOutOfBoundsWorkgroupSizes(y/l)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${ot(\"f32\",R)};\n        var squareSum = ${ot(\"f32\",R)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${P?\"bias[i]\":\"0.0\"};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${O?\"inputSkipBiasSum[offset + i] = value;\":\"\"}\n          output[offset + i] = value;\n          let f32Value = ${vt(M,R,\"value\")};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${wt(\"sum\",R)} / hiddenSize;\n        let variance = sqrt(${wt(\"squareSum\",R)} / hiddenSize - mean * mean + epsilon);\n        ${T?\"meanOutput[global_idx] = mean;\":\"\"}\n        ${k?\"invStdOutput[global_idx] = 1.0 / variance;\":\"\"}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${M}(mean)) / ${M}(variance) * gamma[i]\n           + ${A?\"beta[i]\":\"0.0\"};\n        }\n      }`,q=[{dims:m,dataType:e[0].dataType}];return t>1&&q.push({dims:S,dataType:1}),t>2&&q.push({dims:S,dataType:1}),t>3&&q.push({dims:a,dataType:e[0].dataType}),{name:\"SkipLayerNormalization\",shaderCache:{hint:r.cacheKey},getShaderSource:z,getRunData:()=>({outputs:q,dispatchGroup:{x:Math.ceil(y/l/64)}})}},md=(e,r)=>{Sg(e.inputs);let u=[0];e.outputCount>1&&u.push(-3),e.outputCount>2&&u.push(-3),e.outputCount>3&&u.push(3),e.compute(xg(e.inputs,r,e.outputCount,!1),{outputs:u})},hd=e=>{let r=e.epsilon;return he({epsilon:r})}});var _g,yi,Ig,yd,Ag,Tg,bd,vd,wd=ae(()=>{\"use strict\";Ze();ke();Le();Pe();_g=(e,r)=>{if(!e||e.length<1)throw new Error(\"too few inputs\");if(r.axes.length!==0){if(r.axes.length!==r.starts.length||r.axes.length!==r.ends.length)throw new Error(\"axes, starts and ends must have the same length\")}else if(r.starts.length!==r.ends.length)throw new Error(\"starts and ends must have the same length\");e.slice(1).forEach((t,u)=>{if(e[u+1].dataType!==6&&e[u+1].dataType!==7)throw new Error(`Input ${u} must be an array of int32 or int64`)})},yi=(e,r)=>{let t=[];if(e.length>r)if(e[r].dataType===7)e[r].getBigInt64Array().forEach(u=>t.push(Number(u)));else if(e[r].dataType===6)e[r].getInt32Array().forEach(u=>t.push(Number(u)));else throw new Error(`Input ${r} must be an array of int32 or int64`);return t},Ig=(e,r)=>{if(e.length>1){let t=yi(e,1),u=yi(e,2),a=yi(e,3);return a.length===0&&(a=[...Array(e[0].dims.length).keys()]),he({starts:t,ends:u,axes:a})}else return r},yd=(e,r,t,u,a)=>{let p=e;return e<0&&(p+=t[u[r]]),a[r]<0?Math.max(0,Math.min(p,t[u[r]]-1)):Math.max(0,Math.min(p,t[u[r]]))},Ag=(e,r,t,u)=>`fn calculateInputIndices(outputIndices: ${r.type.indices}) -> ${e.type.indices} {\n          var inputIndices: ${e.type.indices};\n          var carry = 0u;\n          for (var i = ${t.length}; i >= 0; i--) {\n            let input_shape_i = ${Et(\"uniforms.input_shape\",\"i\",t.length)};\n            let steps_i = ${Et(\"uniforms.steps\",\"i\",t.length)};\n            let signs_i = ${Et(\"uniforms.signs\",\"i\",t.length)};\n            let starts_i = ${Et(\"uniforms.starts\",\"i\",t.length)};\n            var outputIndex = ${u.length===1?\"outputIndices\":\"outputIndices[i]\"};\n            var inputIndex = outputIndex * steps_i + starts_i + carry;\n            carry = inputIndex / input_shape_i;\n            inputIndex = inputIndex % input_shape_i;\n            if (signs_i < 0) {\n              inputIndex = input_shape_i - inputIndex - 1u + starts_i;\n            }\n            ${t.length===1?\"inputIndices\":\"inputIndices[i]\"} = inputIndex;\n          }\n          return inputIndices;\n      }`,Tg=(e,r)=>{let t=e[0].dims,u=Z.size(t),a=r.axes.length>0?Z.normalizeAxes(r.axes,t.length):[...Array(t.length).keys()],p=yi(e,4);p.forEach(M=>M!==0||(()=>{throw new Error(\"step cannot be 0\")})),p.length===0&&(p=Array(a.length).fill(1));let m=r.starts.map((M,z)=>yd(M,z,t,a,p)),y=r.ends.map((M,z)=>yd(M,z,t,a,p));if(a.length!==m.length||a.length!==y.length)throw new Error(\"start, ends and axes should have the same number of elements\");if(a.length!==t.length)for(let M=0;M<t.length;++M)a.includes(M)||(m.splice(M,0,0),y.splice(M,0,t[M]),p.splice(M,0,1));let l=p.map(M=>Math.sign(M));p.forEach((M,z,q)=>{if(M<0){let G=(y[z]-m[z])/M,Y=m[z],_=Y+G*p[z];m[z]=_,y[z]=Y,q[z]=-M}});let S=t.slice(0);a.forEach((M,z)=>{S[M]=Math.ceil((y[M]-m[M])/p[M])});let A={dims:S,dataType:e[0].dataType},P=se(\"output\",e[0].dataType,S.length),T=te(\"input\",e[0].dataType,e[0].dims.length),k=Z.size(S),O=[{name:\"outputSize\",type:\"u32\"},{name:\"starts\",type:\"u32\",length:m.length},{name:\"signs\",type:\"i32\",length:l.length},{name:\"steps\",type:\"u32\",length:p.length}],R=[{type:\"uint32\",data:k},{type:\"uint32\",data:m},{type:\"int32\",data:l},{type:\"uint32\",data:p},...xe(e[0].dims),...xe(S)],j=M=>`\n      ${M.registerUniforms(O).declareVariables(T,P)}\n        ${Ag(T,P,t,S)}\n        ${M.mainStart()}\n          ${M.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n          let outputIndices = ${P.offsetToIndices(\"global_idx\")};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${P.setByOffset(\"global_idx\",T.getByIndices(\"inputIndices\"))}\n      }`;return{name:\"Slice\",shaderCache:{hint:`${l.length}_${m.length}_${p.length}`,inputDependencies:[\"rank\"]},getShaderSource:j,getRunData:()=>({outputs:[A],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:R})}},bd=(e,r)=>{_g(e.inputs,r);let t=Ig(e.inputs,r);e.compute(Tg(e.inputs,t),{inputs:[0]})},vd=e=>{let r=e.starts,t=e.ends,u=e.axes;return he({starts:r,ends:t,axes:u})}});var Eg,Og,$d,Cd,Sd=ae(()=>{\"use strict\";ke();Le();Pe();Eg=e=>{if(!e||e.length!==1)throw new Error(\"Softmax op requires 1 input.\")},Og=(e,r)=>{let t=e.dims,u=Z.size(t),a=64,p=r.axis;if(p<0&&(p=t.length+p),p<t.length-1)throw new Error(\"softmax only supports last axis for now.\");let m=t[p],y=u/m,l=lt(m),S=m/l,A=(j,M)=>M===4?`max(max(${j}.x, ${j}.y), max(${j}.z, ${j}.w))`:M===2?`max(${j}.x, ${j}.y)`:M===3?`max(max(${j}.x, ${j}.y), ${j}.z)`:j,P=te(\"x\",e.dataType,e.dims,l),T=se(\"result\",e.dataType,e.dims,l),k=P.type.value,O=je(e.dataType)===\"f32\"?`var threadMax = ${k}(-3.402823e+38f);`:`var threadMax = ${k}(-65504.0h);`,R=j=>`\n      var<workgroup> rowMaxShared : ${k};\n      var<workgroup> rowSumShared : ${k};\n      var<workgroup> threadShared : array<${k}, ${a}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${k} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${k}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${j.registerUniform(\"packedCols\",\"i32\").declareVariables(P,T)}\n      ${j.mainStart()}\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${a};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${O}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${k}(${A(\"threadShared[0]\",l)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${k}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${k}(${wt(\"threadShared[0]\",l)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;return{name:\"Softmax\",shaderCache:{hint:`${l}`,inputDependencies:[\"type\"]},getRunData:()=>({outputs:[{dims:t,dataType:e.dataType}],dispatchGroup:{x:y},programUniforms:[{type:\"uint32\",data:S}]}),getShaderSource:R}},$d=(e,r)=>{Eg(e.inputs),e.compute(Og(e.inputs[0],r))},Cd=e=>he({axis:e.axis})});var kg,Pg,Rg,Bg,Mg,xd,_d,Id=ae(()=>{\"use strict\";ke();Le();Pe();kg=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\")},Pg=(e,r)=>{let t=[],u=r.numOutputs;return e[1].dims[0]>0&&(e[1].getBigInt64Array().forEach(a=>t.push(Number(a))),u=t.length),he({numOutputs:u,axis:r.axis,splitSizes:t})},Rg=e=>`\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${e}u;\n}`,Bg=e=>{let r=e.length,t=[];for(let u=0;u<r;++u){let a=e[u].setByIndices(\"indices\",\"input[global_idx]\");r===1?t.push(a):u===0?t.push(`if (outputNumber == ${u}u) { ${a} }`):u===r-1?t.push(`else { ${a} }`):t.push(`else if (outputNumber == ${u}) { ${a} }`)}return`\n      fn writeBufferData(outputNumber: u32, indices: ${e[0].type.indices}, global_idx: u32) {\n        ${t.join(`\n`)}\n      }`},Mg=(e,r)=>{let t=e[0].dims,u=Z.size(t),a=e[0].dataType,p=t.length,m=r.axis,y=m<0?t.length+m:m,l=new Array(r.numOutputs),S=te(\"input\",a,t),A=new Array(r.numOutputs),P=[],T=[],k=0;for(let j=0;j<r.numOutputs;j++){k+=r.splitSizes[j],A[j]=k;let M=t.slice();M[r.axis]=r.splitSizes[j],T.push(M),l[j]=se(`output${j}`,a,T[j]),P.push({dims:T[j],dataType:e[0].dataType})}let O=p<2?\"indices\":`indices[${y}]`,R=j=>`\n  ${j.declareVariables(S,...l)}\n  const sizeInConcatAxis = array<u32, ${A.length}>(${A.map(M=>`${M}u`).join(\",\")});\n  ${Rg(A.length)}\n  ${Bg(l)}\n\n  ${j.mainStart()}\n    ${j.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n\n    var indices = ${S.offsetToIndices(\"global_idx\")};\n    let outputNumber = calculateOutputIndex(${O});\n    if (outputNumber != 0) {\n        ${O} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;return{name:\"Split\",shaderCache:{hint:r.cacheKey},getShaderSource:R,getRunData:()=>({outputs:P,dispatchGroup:{x:Math.ceil(u/64)}})}},xd=(e,r)=>{kg(e.inputs);let t=e.inputs.length===1?r:Pg(e.inputs,r);e.compute(Mg(e.inputs,t),{inputs:[0]})},_d=e=>{let r=e.axis,t=e.splitSizes,u=e.numOutputs<0?t.length:e.numOutputs;if(u!==t.length)throw new Error(\"numOutputs and splitSizes lengh must be equal\");return he({axis:r,numOutputs:u,splitSizes:t})}});var Ad,Dg,jg,zg,Td,Ed=ae(()=>{\"use strict\";Ze();ke();Pe();Ad=e=>Array.from(e.getBigInt64Array(),Number),Dg=e=>{if(!e||e.length!==2)throw new Error(\"Tile requires 2 inputs.\");if(e[0].dataType!==1&&e[0].dataType!==6&&e[0].dataType!==12)throw new Error(\"Tile only support float, int32, and uint32 data types\");if(e[1].dataType!==7)throw new Error(\"Tile `repeats` input should be of int64 data type\");if(e[1].dims.length!==1)throw new Error(\"Tile `repeats` input should be 1-D\");if(Ad(e[1]).length!==e[0].dims.length)throw new Error(\"Tile `repeats` input should have same number of elements as rank of input data tensor\")},jg=(e,r)=>{let t=[];for(let u=0;u<e.length;++u)t.push(e[u]*r[u]);return t},zg=e=>{let r=e[0].dims,t=Ad(e[1]),u=jg(r,t),a=Z.size(u),p=e[0].dataType,m=te(\"input\",p,r),y=se(\"output\",p,u),l=S=>`\n      const inputShape = ${m.indices(...r)};\n      ${S.declareVariables(m,y)}\n      ${S.mainStart()}\n      ${S.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n      let outputIndices = ${y.offsetToIndices(\"global_idx\")};\n      var inputIndices: ${m.type.indices};\n      for (var i = 0; i < ${r.length}; i++) {\n        let inputDimValue = ${y.indicesGet(\"outputIndices\",\"i\")}  % ${m.indicesGet(\"inputShape\",\"i\")};\n\n        ${m.indicesSet(\"inputIndices\",\"i\",\"inputDimValue\")}\n      }\n      ${y.setByOffset(\"global_idx\",m.getByIndices(\"inputIndices\"))}\n    }`;return{name:\"Tile\",shaderCache:{hint:`${t}`},getRunData:()=>({outputs:[{dims:u,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)}}),getShaderSource:l}},Td=e=>{Dg(e.inputs),e.compute(zg(e.inputs),{inputs:[0]})}});var Vg,Wg,Od,kd=ae(()=>{\"use strict\";Ze();ke();Pe();Vg=(e,r,t,u,a)=>{let p=Z.size(t),m=Math.ceil(p/4),y=se(\"outputData\",a,t,4),l=te(\"aData\",r[1].dataType,r[1].dims,4),S=te(\"bData\",r[2].dataType,r[2].dims,4),A=te(\"cData\",r[0].dataType,r[0].dims,4),P,T=(k,O,R)=>`select(${O}, ${k}, ${R})`;if(!u)P=y.setByOffset(\"global_idx\",T(l.getByOffset(\"global_idx\"),S.getByOffset(\"global_idx\"),A.getByOffset(\"global_idx\")));else{let k=(O,R,j=\"\")=>{let M=`aData[indexA${R}][componentA${R}]`,z=`bData[indexB${R}][componentB${R}]`,q=`bool(cData[indexC${R}] & ${4278190080>>>(3-R)*8}u)`;return`\n            let outputIndices${R} = ${y.offsetToIndices(`global_idx * 4u + ${R}u`)};\n            let offsetA${R} = ${l.broadcastedIndicesToOffset(`outputIndices${R}`,y)};\n            let offsetB${R} = ${S.broadcastedIndicesToOffset(`outputIndices${R}`,y)};\n            let offsetC${R} = ${A.broadcastedIndicesToOffset(`outputIndices${R}`,y)};\n            let indexA${R} = offsetA${R} / 4u;\n            let indexB${R} = offsetB${R} / 4u;\n            let indexC${R} = offsetC${R} / 4u;\n            let componentA${R} = offsetA${R} % 4u;\n            let componentB${R} = offsetB${R} % 4u;\n            ${O}[${R}] = ${j}(${T(M,z,q)});\n          `};a===9?P=`\n            var data = vec4<u32>(0);\n            ${k(\"data\",0,\"u32\")}\n            ${k(\"data\",1,\"u32\")}\n            ${k(\"data\",2,\"u32\")}\n            ${k(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:P=`\n            ${k(\"outputData[global_idx]\",0)}\n            ${k(\"outputData[global_idx]\",1)}\n            ${k(\"outputData[global_idx]\",2)}\n            ${k(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.declareVariables(A,l,S,y)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(m)}\n        ${P}\n      }`},Wg=e=>{let r=e[1].dims,t=e[2].dims,u=e[0].dims,a=e[1].dataType,p=!(Z.areEqual(r,t)&&Z.areEqual(t,u)),m=r,y=Z.size(r);if(p){let l=Tt.calcShape(Tt.calcShape(r,t,!1),u,!1);if(!l)throw new Error(\"Can't perform where op on the given tensors\");m=l,y=Z.size(m)}return{name:\"Where\",getShaderSource:l=>Vg(l,e,m,p,a),getRunData:()=>({outputs:[{dims:m,dataType:a}],dispatchGroup:{x:Math.ceil(y/64/4)}})}},Od=e=>{e.compute(Wg(e.inputs))}});var Pd,Rd=ae(()=>{\"use strict\";Us();Wi();su();lu();Nu();Ju();rl();qi();hl();wl();Sl();Il();El();Pl();Ml();zl();Wl();Gl();ql();ud();dd();ti();pd();gd();wd();Sd();Id();Ed();xr();Hi();kd();Pd=new Map([[\"Abs\",[du]],[\"Acos\",[cu]],[\"Acosh\",[fu]],[\"Add\",[Hu]],[\"ArgMax\",[Ws,Vi]],[\"ArgMin\",[Vs,Vi]],[\"Asin\",[pu]],[\"Asinh\",[mu]],[\"Atan\",[hu]],[\"Atanh\",[gu]],[\"Attention\",[Hs,Ns]],[\"AveragePool\",[Jl,Ql]],[\"BatchNormalization\",[au]],[\"BiasAdd\",[uu]],[\"BiasSplitGelu\",[Uu]],[\"Cast\",[bu,yu]],[\"Ceil\",[wu]],[\"Clip\",[vu]],[\"Concat\",[el,tl]],[\"Conv\",[Yi,Ki]],[\"ConvTranspose\",[ml,pl]],[\"Cos\",[$u]],[\"Cosh\",[Cu]],[\"Div\",[Gu]],[\"Einsum\",[bl,vl]],[\"Elu\",[Su,ui]],[\"Equal\",[Lu]],[\"Erf\",[xu]],[\"Exp\",[_u]],[\"Expand\",[Cl]],[\"Floor\",[Iu]],[\"FusedConv\",[Yi,Ki]],[\"Gather\",[_l,xl]],[\"GatherElements\",[Tl,Al]],[\"Gelu\",[Au]],[\"Gemm\",[Ol,kl]],[\"GlobalAveragePool\",[rd,td]],[\"GlobalMaxPool\",[sd,ad]],[\"Greater\",[Yu]],[\"GreaterOrEqual\",[Xu]],[\"InstanceNormalization\",[Bl,Rl]],[\"LayerNormalization\",[jl,Dl]],[\"LeakyRelu\",[Tu,ui]],[\"Less\",[Zu]],[\"LessOrEqual\",[Qu]],[\"Log\",[Wu]],[\"MatMul\",[Vl]],[\"MaxPool\",[id,od]],[\"Mul\",[Fu]],[\"MultiHeadAttention\",[Hl,Nl]],[\"Neg\",[Ou]],[\"Not\",[Eu]],[\"Pad\",[Ll,Fl]],[\"Pow\",[qu]],[\"Range\",[ld]],[\"Reciprocal\",[ku]],[\"ReduceMin\",[Rs,Ct]],[\"ReduceMean\",[Ts,Ct]],[\"ReduceMax\",[Ps,Ct]],[\"ReduceSum\",[Ms,Ct]],[\"ReduceProd\",[Bs,Ct]],[\"ReduceL1\",[Es,Ct]],[\"ReduceL2\",[Os,Ct]],[\"ReduceLogSum\",[js,Ct]],[\"ReduceLogSumExp\",[ks,Ct]],[\"ReduceSumSquare\",[Ds,Ct]],[\"Relu\",[Pu]],[\"Resize\",[cd,fd]],[\"Sigmoid\",[Ru]],[\"Sin\",[Bu]],[\"Sinh\",[Mu]],[\"Slice\",[bd,vd]],[\"SkipLayerNormalization\",[md,hd]],[\"Split\",[xd,_d]],[\"Sqrt\",[Du]],[\"Softmax\",[$d,Cd]],[\"Sub\",[Ku]],[\"Tan\",[ju]],[\"Tanh\",[zu]],[\"ThresholdedRelu\",[Vu,ui]],[\"Tile\",[Td]],[\"Transpose\",[hs,gs]],[\"Where\",[Od]]])});var bi,Bd=ae(()=>{\"use strict\";Ze();zt();Pe();bi=class{constructor(r){this.backend=r;this.repo=new Map,this.attributesBound=!1}getArtifact(r){return this.repo.get(r)}setArtifact(r,t){this.repo.set(r,t)}run(r,t,u,a,p,m,y){let l=this.backend.device,S=this.backend.getComputePassEncoder();S.setPipeline(r.computePipeline);let A=[];for(let T of a)A.push({binding:A.length,resource:{buffer:T.buffer}});for(let T of p)A.push({binding:A.length,resource:{buffer:T.buffer}});y&&A.push({binding:A.length,resource:y});let P=l.createBindGroup({layout:r.computePipeline.getBindGroupLayout(0),entries:A,label:r.programInfo.name});if(S.setBindGroup(0,P),S.dispatchWorkgroups(...m),this.backend.pendingDispatchNumber++,this.backend.isQueryEnabled()){typeof this.backend.queryData>\"u\"&&(this.backend.queryData=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.COPY_SRC|GPUBufferUsage.QUERY_RESOLVE));let T=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST);this.backend.endComputePass(),this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet,0,2,this.backend.queryData.buffer,0),this.backend.getCommandEncoder().copyBufferToBuffer(this.backend.queryData.buffer,0,T.buffer,0,this.backend.querySetCount*8),this.backend.flush();let k=this.backend.currentKernelId,O=this.backend.kernels.get(k),R=`[${O[0]}] ${O[1]}`;T.buffer.mapAsync(GPUMapMode.READ).then(()=>{let j=new BigUint64Array(T.buffer.getMappedRange()),M=j[0],z=j[1];T.buffer.unmap(),typeof this.backend.queryTimeBase>\"u\"&&(this.backend.queryTimeBase=M);let q=Number(M-this.backend.queryTimeBase),G=Number(z-this.backend.queryTimeBase);if(!Number.isSafeInteger(q)||!Number.isSafeInteger(G))throw new RangeError(\"incorrect timestamp range\");this.backend.gpuDataManager.release(T.id);let Y=\"\";t.forEach((X,J)=>{Y+=`input[${J}]: [${X.dims}] | ${mn(X.dataType)}, `});let _=\"\";u.forEach((X,J)=>{_+=`output[${J}]: [${X.dims}] | ${mn(X.dataType)}, `}),console.log(`[profiling] kernel \"${k}|${R}|${r.programInfo.name}\" ${Y}${_}execution time: ${G-q} ns`)})}this.backend.pendingDispatchNumber>=16&&this.backend.flush()}dispose(){}build(r,t){let u=this.backend.device,a=[];u.features.has(\"shader-f16\")&&a.push(\"enable f16;\");let p=ps(t),m=r.getShaderSource(p),y=`${a.join(`\n`)}\n${p.additionalImplementations}\n${m}`,l=u.createShaderModule({code:y,label:r.name});Ge(\"verbose\",()=>`[WebGPU] ${r.name} shader code: ${y}`);let S=u.createComputePipeline({compute:{module:l,entryPoint:\"main\"},layout:\"auto\",label:r.name});return{programInfo:r,computePipeline:S}}normalizeDispatchGroupSize(r){let t=typeof r==\"number\"?r:r.x,u=typeof r==\"number\"?1:r.y||1,a=typeof r==\"number\"?1:r.z||1,p=this.backend.device.limits.maxComputeWorkgroupsPerDimension;if(t<=p&&u<=p&&a<=p)return[t,u,a];let m=t*u*a,y=Math.ceil(Math.sqrt(m));if(y>p){if(y=Math.ceil(Math.cbrt(m)),y>p)throw new Error(\"Total dispatch size exceeds WebGPU maximum.\");return[y,y,y]}else return[y,y,1]}}});var Ug,Ng,vi,Md=ae(()=>{\"use strict\";zt();as();ds();Rd();Bd();Ug=(e,r)=>{if(r.length!==e.length)throw new Error(`inputDependencies length ${r.length} is not equal to inputTensors length ${e.length}.`);let t=[];for(let u=0;u<e.length;++u){let a=e[u].dataType;switch(r[u]){case\"none\":{t.push(\"\");break}case\"type\":{t.push(`${a}`);break}case\"rank\":{let p=e[u].dims.length;t.push(`${a};${p}`);break}case\"dims\":{let p=e[u].dims.join(\",\");t.push(`${a};${p}`);break}default:throw new Error(`unsupported input dependency: ${r[u]}`)}}return t.join(\"|\")},Ng=(e,r,t)=>{let u=e.name;return e.shaderCache?.hint&&(u+=\"[\"+e.shaderCache.hint+\"]\"),u+=\":\"+t+`:${Ug(r,e.shaderCache?.inputDependencies??new Array(r.length).fill(\"dims\"))}`,u},vi=class{constructor(){this.currentKernelId=null;this.commandEncoder=null;this.computePassEncoder=null;this.pendingDispatchNumber=0;this.querySetCount=2;this.sessionExternalDataMapping=new Map}get currentKernelCustomData(){if(this.currentKernelId===null)throw new Error(\"currentKernelCustomData(): currentKernelId is null. (should not happen)\");let r=this.kernelCustomData.get(this.currentKernelId);return r||(r={},this.kernelCustomData.set(this.currentKernelId,r)),r}async initialize(r){if(!navigator.gpu)throw new Error(\"WebGpuBackend: WebGPU is not available.\");let t=await navigator.gpu.requestAdapter();if(!t)throw new Error(\"WebGpuBackend: Failed to get GPU adapter.\");this.env=r;let u=[],a={requiredLimits:{maxComputeWorkgroupStorageSize:t.limits.maxComputeWorkgroupStorageSize,maxComputeWorkgroupsPerDimension:t.limits.maxComputeWorkgroupsPerDimension,maxStorageBufferBindingSize:t.limits.maxStorageBufferBindingSize,maxBufferSize:t.limits.maxBufferSize,maxComputeInvocationsPerWorkgroup:t.limits.maxComputeInvocationsPerWorkgroup,maxComputeWorkgroupSizeX:t.limits.maxComputeWorkgroupSizeX,maxComputeWorkgroupSizeY:t.limits.maxComputeWorkgroupSizeY,maxComputeWorkgroupSizeZ:t.limits.maxComputeWorkgroupSizeZ},requiredFeatures:u};t.features.has(\"timestamp-query\")&&u.push(\"timestamp-query\"),t.features.has(\"shader-f16\")&&u.push(\"shader-f16\"),this.device=await t.requestDevice(a),this.gpuDataManager=ls(this),this.programManager=new bi(this),this.kernels=new Map,this.kernelPersistentData=new Map,this.kernelCustomData=new Map,is(r.logLevel,!!r.debug),this.device.onuncapturederror=p=>{p.error instanceof GPUValidationError&&console.error(`An uncaught WebGPU validation error was raised: ${p.error.message}`)},Object.defineProperty(this.env.webgpu,\"device\",{value:this.device})}dispose(){typeof this.querySet<\"u\"&&this.querySet.destroy(),this.gpuDataManager.dispose()}getCommandEncoder(){return this.commandEncoder||(this.commandEncoder=this.device.createCommandEncoder()),this.commandEncoder}getComputePassEncoder(){if(!this.computePassEncoder){let r={};this.isQueryEnabled()&&(typeof this.querySet>\"u\"&&(this.querySet=this.device.createQuerySet({type:\"timestamp\",count:this.querySetCount})),r.timestampWrites={querySet:this.querySet,beginningOfPassWriteIndex:0,endOfPassWriteIndex:1}),this.computePassEncoder=this.getCommandEncoder().beginComputePass(r)}return this.computePassEncoder}endComputePass(){this.computePassEncoder&&(this.computePassEncoder.end(),this.computePassEncoder=null)}flush(){this.commandEncoder&&(this.endComputePass(),this.device.queue.submit([this.getCommandEncoder().finish()]),this.gpuDataManager.refreshPendingBuffers(),this.commandEncoder=null,this.pendingDispatchNumber=0)}isQueryEnabled(){return!!(this.device.features.has(\"timestamp-query\")&&this.env.webgpu.profilingMode===\"default\")}run(r,t,u,a,p){let m=[];for(let z=0;z<t.length;++z){let q=this.gpuDataManager.get(t[z].data);if(!q)throw new Error(`no GPU data for input: ${t[z].data}`);m[z]=q}let{outputs:y,dispatchGroup:l,programUniforms:S}=r.getRunData(t),A=u.length===0?y.map((z,q)=>q):u;if(A.length!==y.length)throw new Error(`Output size ${A.length} must be equal to ${y.length}.`);let P=[],T=[];for(let z=0;z<y.length;++z){if(!Number.isInteger(A[z])||A[z]<-3||A[z]>=y.length)throw new Error(`Invalid output index: ${A[z]}`);if(A[z]===-3)continue;let q=A[z]===-1,G=A[z]===-2,Y=q||G?p(y[z].dataType,y[z].dims):a(A[z],y[z].dataType,y[z].dims),_=this.gpuDataManager.get(Y.data);if(!_)throw new Error(`no GPU data for output: ${Y.data}`);if(q&&this.temporaryData.push(_),G){let X=this.kernelPersistentData.get(this.currentKernelId);X||(X=[],this.kernelPersistentData.set(this.currentKernelId,X)),X.push(_)}P.push(Y),T.push(_)}let k;if(S){let z=0,q=[];S.forEach(X=>{let J=typeof X.data==\"number\"?[X.data]:X.data;if(J.length===0)return;let re=J.length<=2?J.length*4:16;z=Math.ceil(z/re)*re,q.push(z),z+=J.length>4?Math.ceil(J.length/4)*16:J.length*4});let G=16;z=Math.ceil(z/G)*G;let Y=new ArrayBuffer(z);S.forEach((X,J)=>{let re=q[J],fe=typeof X.data==\"number\"?[X.data]:X.data;X.type===\"int32\"?new Int32Array(Y,re,fe.length).set(fe):X.type===\"uint32\"?new Uint32Array(Y,re,fe.length).set(fe):new Float32Array(Y,re,fe.length).set(fe)});let _=this.gpuDataManager.create(z,GPUBufferUsage.COPY_DST|GPUBufferUsage.UNIFORM);this.device.queue.writeBuffer(_.buffer,0,Y,0,z),this.gpuDataManager.release(_.id),k={offset:0,size:z,buffer:_.buffer}}let O=this.programManager.normalizeDispatchGroupSize(l),R=O[1]===1&&O[2]===1,j=Ng(r,t,R),M=this.programManager.getArtifact(j);return M||(M=this.programManager.build(r,O),this.programManager.setArtifact(j,M),Ge(\"info\",()=>`[artifact] key: ${j}, programName: ${r.name}`)),Ge(\"info\",()=>`[ProgramManager] run \"${r.name}\" (key=${j}) with ${O[0]}x${O[1]}x${O[2]}`),this.programManager.run(M,t,P,m,T,O,k),P}upload(r,t){this.gpuDataManager.upload(r,t)}memcpy(r,t){this.gpuDataManager.memcpy(r,t)}async download(r,t){await this.gpuDataManager.download(r,t)}alloc(r){return this.gpuDataManager.create(r).id}free(r){return this.gpuDataManager.release(r)}createKernel(r,t,u,a){let p=Pd.get(r);if(!p)throw new Error(`kernel not implemented: ${r}`);this.kernels.set(t,[r,a,p[0],[p[1],u]])}releaseKernel(r){let t=this.kernelPersistentData.get(r);if(t){for(let u of t)this.gpuDataManager.release(u.id);this.kernelPersistentData.delete(r)}this.kernelCustomData.delete(r),this.kernels.delete(r)}computeKernel(r,t,u){let a=this.kernels.get(r);if(!a)throw new Error(`kernel not created: ${r}`);let[p,m,y,l]=a;if(this.currentKernelId!==null)throw new Error(`kernel \"[${p}] ${m}\" is not allowed to be called recursively`);this.currentKernelId=r,l[0]&&(l[1]=l[0](l[1]),l[0]=void 0),Ge(\"info\",()=>`[WebGPU] Start to run kernel \"[${p}] ${m}\"...`);let S=this.env.debug;this.temporaryData=[];try{return S&&this.device.pushErrorScope(\"validation\"),y(t,l[1]),0}catch(A){return u.push(Promise.resolve(`[WebGPU] Kernel \"[${p}] ${m}\" failed. ${A}`)),1}finally{S&&u.push(this.device.popErrorScope().then(A=>A?`GPU validation error for kernel \"[${p}] ${m}\": ${A.message}`:null));for(let A of this.temporaryData)this.gpuDataManager.release(A.id);this.temporaryData=[],this.currentKernelId=null}}registerBuffer(r,t,u,a){let p=this.sessionExternalDataMapping.get(r);p||(p=new Map,this.sessionExternalDataMapping.set(r,p));let m=p.get(t),y=this.gpuDataManager.registerExternalBuffer(u,a,m?.[1]);return p.set(t,[y,u]),y}unregisterBuffers(r){let t=this.sessionExternalDataMapping.get(r);t&&(t.forEach(u=>this.gpuDataManager.unregisterExternalBuffer(u[1])),this.sessionExternalDataMapping.delete(r))}getBuffer(r){let t=this.gpuDataManager.get(r);if(!t)throw new Error(`no GPU data for buffer: ${r}`);return t.buffer}createDownloader(r,t,u){return async()=>{let a=await Pi(this,r,t);return os(a.buffer,u)}}}});var Dd={};qn(Dd,{init:()=>Hg});var wn,to,Hg,jd=ae(()=>{\"use strict\";Ze();Md();zt();ke();wn=class e{constructor(r,t,u,a){this.module=r;this.dataType=t;this.data=u;this.dims=a}getFloat32Array(){if(this.dataType!==1)throw new Error(\"Invalid data type\");let r=Z.size(this.dims);return r===0?new Float32Array:new Float32Array(this.module.HEAP8.buffer,this.data,r)}getBigInt64Array(){if(this.dataType!==7)throw new Error(\"Invalid data type\");let r=Z.size(this.dims);return r===0?new BigInt64Array:new BigInt64Array(this.module.HEAP8.buffer,this.data,r)}getInt32Array(){if(this.dataType!==6)throw new Error(\"Invalid data type\");let r=Z.size(this.dims);return r===0?new Int32Array:new Int32Array(this.module.HEAP8.buffer,this.data,r)}reshape(r){if(Z.size(r)!==Z.size(this.dims))throw new Error(\"Invalid new shape\");return new e(this.module,this.dataType,this.data,r)}},to=class{constructor(r,t,u){this.module=r;this.backend=t;this.customDataOffset=0;this.customDataSize=0;let a=r.HEAPU32,p=u>>2;this.opKernelContext=a[p++];let m=a[p++];this.outputCount=a[p++],this.customDataOffset=a[p++],this.customDataSize=a[p++];let y=[];for(let l=0;l<m;l++){let S=a[p++],A=a[p++],P=a[p++],T=[];for(let k=0;k<P;k++)T.push(a[p++]);y.push(new wn(r,S,A,T))}this.inputs=y}get kernelCustomData(){return this.backend.currentKernelCustomData}get customDataBuffer(){return this.module.HEAPU8.subarray(this.customDataOffset,this.customDataOffset+this.customDataSize)}compute(r,t){let u=t?.inputs?.map(y=>typeof y==\"number\"?this.inputs[y]:y)??this.inputs,a=t?.outputs??[],p=(y,l,S)=>new wn(this.module,l,this.output(y,S),S),m=(y,l)=>{let S=hn(y);if(!S)throw new Error(`Unsupported data type: ${y}`);let A=S*Z.size(l);return new wn(this.module,y,this.backend.gpuDataManager.create(A).id,l)};return this.backend.run(r,u,a,p,m)}output(r,t){let u=this.module.stackSave();try{let a=this.module.stackAlloc((1+t.length)*4),p=a>>2;this.module.HEAPU32[p++]=t.length;for(let m=0;m<t.length;m++)this.module.HEAPU32[p++]=t[m];return this.module._JsepOutput(this.opKernelContext,r,a)}catch(a){throw new Error(`Failed to generate kernel's output[${r}] with dims [${t}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${a}`)}finally{this.module.stackRestore(u)}}},Hg=async(e,r)=>{let t=e.jsepInit;if(t&&navigator.gpu){if(!r.wasm.simd)throw new Error(\"Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP\");let u=new vi;await u.initialize(r),t(u,a=>u.alloc(a),a=>u.free(a),(a,p,m,y=!1)=>{if(y)Ge(\"verbose\",()=>`[WebGPU] jsepCopyGpuToGpu: src=${a}, dst=${p}, size=${m}`),u.memcpy(a,p);else{Ge(\"verbose\",()=>`[WebGPU] jsepCopyCpuToGpu: dataOffset=${a}, gpuDataId=${p}, size=${m}`);let l=e.HEAPU8.subarray(a,a+m);u.upload(p,l)}},async(a,p,m)=>{Ge(\"verbose\",()=>`[WebGPU] jsepCopyGpuToCpu: gpuDataId=${a}, dataOffset=${p}, size=${m}`),await u.download(a,()=>e.HEAPU8.subarray(p,p+m))},(a,p,m)=>u.createKernel(a,p,m,r.debug||r.webgpu.profilingMode===\"default\"?e.UTF8ToString(e._JsepGetNodeName(p)):`${p}`),a=>u.releaseKernel(a),(a,p,m,y)=>{Ge(\"verbose\",()=>`[WebGPU] jsepRun: sessionHandle=${m}, kernel=${a}, contextDataOffset=${p}`);let l=new to(e,u,p);return u.computeKernel(a,l,y)})}}});var Xa;Xa=Ua();var im=Ka(),Ai,Ti=!1,Kn=!1,Za=!1,om=()=>{try{return typeof SharedArrayBuffer>\"u\"?!1:(typeof MessageChannel<\"u\"&&new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch{return!1}},am=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch{return!1}},sm=(e,r)=>e?r?\"ort-wasm-simd-threaded.wasm\":\"ort-wasm-simd.wasm\":r?\"ort-wasm-threaded.wasm\":\"ort-wasm.wasm\",Qa=async e=>{if(Ti)return Promise.resolve();if(Kn)throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");if(Za)throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");Kn=!0;let r=e.initTimeout,t=e.numThreads,u=e.simd,a=t>1&&om(),p=u&&am(),m=e.wasmPaths,y=typeof m==\"string\"?m:void 0,l=sm(p,a),S=typeof m==\"object\"?m[l]:void 0,A=!1,P=[];if(r>0&&P.push(new Promise(T=>{setTimeout(()=>{A=!0,T()},r)})),P.push(new Promise((T,k)=>{let O=a?im:Xa,R={locateFile:(j,M)=>{if(a&&j.endsWith(\".worker.js\")&&typeof Blob<\"u\")return URL.createObjectURL(new Blob([Ya()],{type:\"text/javascript\"}));if(j.endsWith(\".wasm\")){if(S)return S;let z=y??M;return l===\"ort-wasm-simd.wasm\"?z+\"ort-wasm-simd.jsep.wasm\":l===\"ort-wasm-simd-threaded.wasm\"?z+\"ort-wasm-simd-threaded.jsep.wasm\":z+l}return M+j}};if(a)if(typeof Blob>\"u\")R.mainScriptUrlOrBlob=(void 0)(__dirname,\"ort-wasm-threaded.js\");else{let j=`var ortWasmThreaded=${O.toString()};`;R.mainScriptUrlOrBlob=new Blob([j],{type:\"text/javascript\"})}O(R).then(j=>{Kn=!1,Ti=!0,Ai=j,T()},j=>{Kn=!1,Za=!0,k(j)})})),await Promise.race(P),A)throw new Error(`WebAssembly backend initializing failed due to timeout: ${r}ms`)},qe=()=>{if(Ti&&Ai)return Ai;throw new Error(\"WebAssembly is not initialized yet.\")};var Ye=(e,r)=>{let t=qe(),u=t.lengthBytesUTF8(e)+1,a=t._malloc(u);return t.stringToUTF8(e,a,u),r.push(a),a},pn=(e,r,t,u)=>{if(typeof e==\"object\"&&e!==null){if(t.has(e))throw new Error(\"Circular reference in options\");t.add(e)}Object.entries(e).forEach(([a,p])=>{let m=r?r+a:a;if(typeof p==\"object\")pn(p,m+\".\",t,u);else if(typeof p==\"string\"||typeof p==\"number\")u(m,p.toString());else if(typeof p==\"boolean\")u(m,p?\"1\":\"0\");else throw new Error(`Can't handle extra config type: ${typeof p}`)})},We=e=>{let r=qe(),t=r.stackSave();try{let u=r.stackAlloc(8);r._OrtGetLastError(u,u+4);let a=r.HEAP32[u/4],p=r.HEAPU32[u/4+1],m=p?r.UTF8ToString(p):\"\";throw new Error(`${e} ERROR_CODE: ${a}, ERROR_MESSAGE: ${m}`)}finally{r.stackRestore(t)}};var Ja=e=>{let r=qe(),t=0,u=[],a=e||{};try{if(e?.logSeverityLevel===void 0)a.logSeverityLevel=2;else if(typeof e.logSeverityLevel!=\"number\"||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${e.logSeverityLevel}`);if(e?.logVerbosityLevel===void 0)a.logVerbosityLevel=0;else if(typeof e.logVerbosityLevel!=\"number\"||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);e?.terminate===void 0&&(a.terminate=!1);let p=0;return e?.tag!==void 0&&(p=Ye(e.tag,u)),t=r._OrtCreateRunOptions(a.logSeverityLevel,a.logVerbosityLevel,!!a.terminate,p),t===0&&We(\"Can't create run options.\"),e?.extra!==void 0&&pn(e.extra,\"\",new WeakSet,(m,y)=>{let l=Ye(m,u),S=Ye(y,u);r._OrtAddRunConfigEntry(t,l,S)!==0&&We(`Can't set a run config entry: ${m} - ${y}.`)}),[t,u]}catch(p){throw t!==0&&r._OrtReleaseRunOptions(t),u.forEach(m=>r._free(m)),p}};var um=e=>{switch(e){case\"disabled\":return 0;case\"basic\":return 1;case\"extended\":return 2;case\"all\":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},lm=e=>{switch(e){case\"sequential\":return 0;case\"parallel\":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},dm=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});let r=e.extra.session;r.use_ort_model_bytes_directly||(r.use_ort_model_bytes_directly=\"1\"),e.executionProviders&&e.executionProviders.some(t=>(typeof t==\"string\"?t:t.name)===\"webgpu\")&&(e.enableMemPattern=!1)},cm=(e,r,t)=>{for(let u of r){let a=typeof u==\"string\"?u:u.name;switch(a){case\"xnnpack\":a=\"XNNPACK\";break;case\"webnn\":if(a=\"WEBNN\",typeof u!=\"string\"){let m=u;if(m?.deviceType){let y=Ye(\"deviceType\",t),l=Ye(m.deviceType,t);qe()._OrtAddSessionConfigEntry(e,y,l)!==0&&We(`Can't set a session config entry: 'deviceType' - ${m.deviceType}.`)}if(m?.numThreads){let y=m.numThreads;(typeof y!=\"number\"||!Number.isInteger(y)||y<0)&&(y=0);let l=Ye(\"numThreads\",t),S=Ye(y.toString(),t);qe()._OrtAddSessionConfigEntry(e,l,S)!==0&&We(`Can't set a session config entry: 'numThreads' - ${m.numThreads}.`)}if(m?.powerPreference){let y=Ye(\"powerPreference\",t),l=Ye(m.powerPreference,t);qe()._OrtAddSessionConfigEntry(e,y,l)!==0&&We(`Can't set a session config entry: 'powerPreference' - ${m.powerPreference}.`)}}break;case\"webgpu\":if(a=\"JS\",typeof u!=\"string\"){let m=u;if(m?.preferredLayout){if(m.preferredLayout!==\"NCHW\"&&m.preferredLayout!==\"NHWC\")throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${m.preferredLayout}`);let y=Ye(\"preferredLayout\",t),l=Ye(m.preferredLayout,t);qe()._OrtAddSessionConfigEntry(e,y,l)!==0&&We(`Can't set a session config entry: 'preferredLayout' - ${m.preferredLayout}.`)}}break;case\"wasm\":case\"cpu\":continue;default:throw new Error(`not supported execution provider: ${a}`)}let p=Ye(a,t);qe()._OrtAppendExecutionProvider(e,p)!==0&&We(`Can't append execution provider: ${a}.`)}},es=e=>{let r=qe(),t=0,u=[],a=e||{};dm(a);try{let p=um(a.graphOptimizationLevel??\"all\"),m=lm(a.executionMode??\"sequential\"),y=typeof a.logId==\"string\"?Ye(a.logId,u):0,l=a.logSeverityLevel??2;if(!Number.isInteger(l)||l<0||l>4)throw new Error(`log serverity level is not valid: ${l}`);let S=a.logVerbosityLevel??0;if(!Number.isInteger(S)||S<0||S>4)throw new Error(`log verbosity level is not valid: ${S}`);let A=typeof a.optimizedModelFilePath==\"string\"?Ye(a.optimizedModelFilePath,u):0;if(t=r._OrtCreateSessionOptions(p,!!a.enableCpuMemArena,!!a.enableMemPattern,m,!!a.enableProfiling,0,y,l,S,A),t===0&&We(\"Can't create session options.\"),a.executionProviders&&cm(t,a.executionProviders,u),a.freeDimensionOverrides)for(let[P,T]of Object.entries(a.freeDimensionOverrides)){if(typeof P!=\"string\")throw new Error(`free dimension override name must be a string: ${P}`);if(typeof T!=\"number\"||!Number.isInteger(T)||T<0)throw new Error(`free dimension override value must be a non-negative integer: ${T}`);let k=Ye(P,u);r._OrtAddFreeDimensionOverride(t,k,T)!==0&&We(`Can't set a free dimension override: ${P} - ${T}.`)}return a.extra!==void 0&&pn(a.extra,\"\",new WeakSet,(P,T)=>{let k=Ye(P,u),O=Ye(T,u);r._OrtAddSessionConfigEntry(t,k,O)!==0&&We(`Can't set a session config entry: ${P} - ${T}.`)}),[t,u]}catch(p){throw t!==0&&r._OrtReleaseSessionOptions(t),u.forEach(m=>r._free(m)),p}};Ze();var Vd=!1,Gg=e=>{let r=qe(),t=r.stackSave();try{let u=r.stackAlloc(8);return r._OrtGetInputOutputCount(e,u,u+4)!==0&&We(\"Can't get session input/output count.\"),[r.HEAP32[u/4],r.HEAP32[u/4+1]]}finally{r.stackRestore(t)}},Lg=(e,r)=>{qe()._OrtInit(e,r)!==0&&We(\"Can't initialize onnxruntime.\")},Wd=async e=>{Lg(e.wasm.numThreads,gn(e.logLevel));{let r=(jd(),Sr(Dd)).init;await r(qe(),e)}Vd=!0},$n=new Map,Ud=()=>Vd,ro=e=>{let r=qe(),t=r._malloc(e.byteLength);if(t===0)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return r.HEAPU8.set(e,t),[t,e.byteLength]},no=(e,r)=>{let t=qe(),u=0,a=0,p=0,m=[],y=[],l=[];try{[a,m]=es(r),u=t._OrtCreateSession(e[0],e[1],a),u===0&&We(\"Can't create a session.\");let[S,A]=Gg(u),P=[],T=[],k=[];for(let R=0;R<S;R++){let j=t._OrtGetInputName(u,R);j===0&&We(\"Can't get an input name.\"),y.push(j),P.push(t.UTF8ToString(j))}for(let R=0;R<A;R++){let j=t._OrtGetOutputName(u,R);j===0&&We(\"Can't get an output name.\"),l.push(j);let M=t.UTF8ToString(j);T.push(M);{let z=typeof r?.preferredOutputLocation==\"string\"?r.preferredOutputLocation:r?.preferredOutputLocation?.[M]??\"cpu\";if(z!==\"cpu\"&&z!==\"cpu-pinned\"&&z!==\"gpu-buffer\")throw new Error(`Not supported preferred output location: ${z}.`);k.push(z)}}let O=null;return k.some(R=>R===\"gpu-buffer\")&&(p=t._OrtCreateBinding(u),p===0&&We(\"Can't create IO binding.\"),O={handle:p,outputPreferredLocations:k,outputPreferredLocationsEncoded:k.map(R=>Oi(R))}),$n.set(u,[u,y,l,O]),[u,P,T]}catch(S){throw y.forEach(A=>t._OrtFree(A)),l.forEach(A=>t._OrtFree(A)),p!==0&&t._OrtReleaseBinding(p),u!==0&&t._OrtReleaseSession(u),S}finally{t._free(e[0]),a!==0&&t._OrtReleaseSessionOptions(a),m.forEach(S=>t._free(S))}},Nd=(e,r)=>{let t=ro(e);return no(t,r)},Hd=e=>{let r=qe(),t=$n.get(e);if(!t)throw new Error(`cannot release session. invalid session id: ${e}`);let[u,a,p,m]=t;m&&r._OrtReleaseBinding(m.handle),r.jsepUnregisterBuffers?.(e),a.forEach(y=>r._OrtFree(y)),p.forEach(y=>r._OrtFree(y)),r._OrtReleaseSession(u),$n.delete(e)},zd=(e,r,t,u,a)=>{if(!e){r.push(0);return}let p=qe(),m=e[0],y=e[1],l=e[3],S,A;if(m===\"string\"&&l===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");if(l===\"gpu-buffer\"){let k=e[2].gpuBuffer,O=hn(Ei(m));A=y.reduce((R,j)=>R*j,1)*O,S=p.jsepRegisterBuffer(u,a,k,A)}else{let k=e[2];if(Array.isArray(k)){A=4*k.length,S=p._malloc(A),t.push(S);let O=S/4;for(let R=0;R<k.length;R++){if(typeof k[R]!=\"string\")throw new TypeError(`tensor data at index ${R} is not a string`);p.HEAPU32[O++]=Ye(k[R],t)}}else A=k.byteLength,S=p._malloc(A),t.push(S),p.HEAPU8.set(new Uint8Array(k.buffer,k.byteOffset,A),S)}let P=p.stackSave(),T=p.stackAlloc(4*y.length);try{let k=T/4;y.forEach(R=>p.HEAP32[k++]=R);let O=p._OrtCreateTensor(Ei(m),S,A,T,y.length,Oi(l));O===0&&We(`Can't create tensor for input/output. session=${u}, index=${a}.`),r.push(O)}finally{p.stackRestore(P)}},Gd=async(e,r,t,u,a,p)=>{let m=qe(),y=$n.get(e);if(!y)throw new Error(`cannot run inference. invalid session id: ${e}`);let[l,S,A,P]=y,T=r.length,k=u.length,O=0,R=[],j=[],M=[],z=[],q=m.stackSave(),G=m.stackAlloc(T*4),Y=m.stackAlloc(T*4),_=m.stackAlloc(k*4),X=m.stackAlloc(k*4);try{[O,R]=Ja(p);for(let me=0;me<T;me++)zd(t[me],j,z,e,r[me]);for(let me=0;me<k;me++)zd(a[me],M,z,e,T+u[me]);let J=G/4,re=Y/4,fe=_/4,L=X/4;for(let me=0;me<T;me++)m.HEAPU32[J++]=j[me],m.HEAPU32[re++]=S[r[me]];for(let me=0;me<k;me++)m.HEAPU32[fe++]=M[me],m.HEAPU32[L++]=A[u[me]];if(P){let{handle:me,outputPreferredLocations:Re,outputPreferredLocationsEncoded:ue}=P;if(S.length!==T)throw new Error(`input count from feeds (${T}) is expected to be always equal to model's input count (${S.length}).`);for(let Be=0;Be<T;Be++){let Me=r[Be];await m._OrtBindInput(me,S[Me],j[Be])!==0&&We(`Can't bind input[${Be}] for session=${e}.`)}for(let Be=0;Be<k;Be++){let Me=u[Be];a[Be]?.[3]?m._OrtBindOutput(me,A[Me],M[Be],0)!==0&&We(`Can't bind pre-allocated output[${Be}] for session=${e}.`):m._OrtBindOutput(me,A[Me],0,ue[Me])!==0&&We(`Can't bind output[${Be}] to ${Re[Be]} for session=${e}.`)}}let oe;P?oe=await m._OrtRunWithBinding(l,P.handle,k,_,O):oe=await m._OrtRun(l,Y,G,T,X,k,_,O),oe!==0&&We(\"failed to call OrtRun().\");let Se=[];for(let me=0;me<k;me++){let Re=m.HEAPU32[_/4+me];if(Re===M[me]){Se.push(a[me]);continue}let ue=m.stackSave(),Be=m.stackAlloc(4*4),Me=!1,De,Ae=0;try{m._OrtGetTensorData(Re,Be,Be+4,Be+8,Be+12)!==0&&We(`Can't access output tensor data on index ${me}.`);let rt=Be/4,nt=m.HEAPU32[rt++];Ae=m.HEAPU32[rt++];let ne=m.HEAPU32[rt++],we=m.HEAPU32[rt++],Ie=[];for(let Fe=0;Fe<we;Fe++)Ie.push(m.HEAPU32[ne/4+Fe]);m._OrtFree(ne);let tt=Ie.reduce((Fe,Qe)=>Fe*Qe,1);De=mn(nt);let st=P?.outputPreferredLocations[u[me]];if(De===\"string\"){if(st===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");let Fe=[],Qe=Ae/4;for(let at=0;at<tt;at++){let xt=m.HEAPU32[Qe++],dt=at===tt-1?void 0:m.HEAPU32[Qe]-xt;Fe.push(m.UTF8ToString(xt,dt))}Se.push([De,Ie,Fe,\"cpu\"])}else if(st===\"gpu-buffer\"&&tt>0){let Fe=m.jsepGetBuffer(Ae),Qe=hn(nt);if(Qe===void 0||!ts(De))throw new Error(`Unsupported data type: ${De}`);Me=!0,Se.push([De,Ie,{gpuBuffer:Fe,download:m.jsepCreateDownloader(Fe,tt*Qe,De),dispose:()=>{m._OrtReleaseTensor(Re)}},\"gpu-buffer\"])}else{let Fe=Yn(De),Qe=new Fe(tt);new Uint8Array(Qe.buffer,Qe.byteOffset,Qe.byteLength).set(m.HEAPU8.subarray(Ae,Ae+Qe.byteLength)),Se.push([De,Ie,Qe,\"cpu\"])}}finally{m.stackRestore(ue),De===\"string\"&&Ae&&m._free(Ae),Me||m._OrtReleaseTensor(Re)}}return P&&m._OrtClearBoundOutputs(P.handle),Se}finally{m.stackRestore(q),j.forEach(J=>m._OrtReleaseTensor(J)),M.forEach(J=>m._OrtReleaseTensor(J)),z.forEach(J=>m._free(J)),O!==0&&m._OrtReleaseRunOptions(O),R.forEach(J=>m._free(J))}},Ld=e=>{let r=qe(),t=$n.get(e);if(!t)throw new Error(\"invalid session id\");let u=t[0],a=r._OrtEndProfiling(u);a===0&&We(\"Can't get an profile file name.\"),r._OrtFree(a)},Fd=e=>{let r=[];for(let t of e){let u=t[2];!Array.isArray(u)&&\"buffer\"in u&&r.push(u.buffer)}return r};self.onmessage=e=>{switch(e.data.type){case\"init-wasm\":try{Qa(e.data.in).then(()=>postMessage({type:\"init-wasm\"}),r=>postMessage({type:\"init-wasm\",err:r}))}catch(r){postMessage({type:\"init-wasm\",err:r})}break;case\"init-ort\":try{Wd(e.data.in).then(()=>postMessage({type:\"init-ort\"}),r=>postMessage({type:\"init-ort\",err:r}))}catch(r){postMessage({type:\"init-ort\",err:r})}break;case\"create_allocate\":try{let{model:r}=e.data.in,t=ro(r);postMessage({type:\"create_allocate\",out:t})}catch(r){postMessage({type:\"create_allocate\",err:r})}break;case\"create_finalize\":try{let{modeldata:r,options:t}=e.data.in,u=no(r,t);postMessage({type:\"create_finalize\",out:u})}catch(r){postMessage({type:\"create_finalize\",err:r})}break;case\"create\":try{let{model:r,options:t}=e.data.in,u=Nd(r,t);postMessage({type:\"create\",out:u})}catch(r){postMessage({type:\"create\",err:r})}break;case\"release\":try{Hd(e.data.in),postMessage({type:\"release\"})}catch(r){postMessage({type:\"release\",err:r})}break;case\"run\":try{let{sessionId:r,inputIndices:t,inputs:u,outputIndices:a,options:p}=e.data.in;Gd(r,t,u,a,new Array(a.length).fill(null),p).then(m=>{m.some(y=>y[3]!==\"cpu\")?postMessage({type:\"run\",err:\"Proxy does not support non-cpu tensor location.\"}):postMessage({type:\"run\",out:m},Fd(m))},m=>{postMessage({type:\"run\",err:m})})}catch(r){postMessage({type:\"run\",err:r})}break;case\"end-profiling\":try{let r=e.data.in;Ld(r),postMessage({type:\"end-profiling\"})}catch(r){postMessage({type:\"end-profiling\",err:r})}break;case\"is-ort-env-initialized\":try{let r=Ud();postMessage({type:\"is-ort-env-initialized\",out:r})}catch(r){postMessage({type:\"is-ort-env-initialized\",err:r})}break;default:}};})();\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, env, InferenceSession} from 'onnxruntime-common';\n\nimport {OrtWasmMessage, SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport * as core from './wasm-core-impl';\nimport {initializeWebAssembly} from './wasm-factory';\n\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\nlet proxyWorker: Worker|undefined;\nlet initializing = false;\nlet initialized = false;\nlet aborted = false;\n\n// resolve; reject\ntype PromiseCallbacks<T = void> = [(result: T) => void, (reason: unknown) => void];\n\nlet initWasmCallbacks: PromiseCallbacks;\nlet initOrtCallbacks: PromiseCallbacks;\nconst createSessionAllocateCallbacks: Array<PromiseCallbacks<SerializableModeldata>> = [];\nconst createSessionFinalizeCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst createSessionCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst releaseSessionCallbacks: Array<PromiseCallbacks<void>> = [];\nconst runCallbacks: Array<PromiseCallbacks<SerializableTensorMetadata[]>> = [];\nconst endProfilingCallbacks: Array<PromiseCallbacks<void>> = [];\nconst isOrtEnvInitializedCallbacks: Array<PromiseCallbacks<boolean>> = [];\n\nconst ensureWorker = (): void => {\n  if (initializing || !initialized || aborted || !proxyWorker) {\n    throw new Error('worker not ready');\n  }\n};\n\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n  switch (ev.data.type) {\n    case 'init-wasm':\n      initializing = false;\n      if (ev.data.err) {\n        aborted = true;\n        initWasmCallbacks[1](ev.data.err);\n      } else {\n        initialized = true;\n        initWasmCallbacks[0]();\n      }\n      break;\n    case 'init-ort':\n      if (ev.data.err) {\n        initOrtCallbacks[1](ev.data.err);\n      } else {\n        initOrtCallbacks[0]();\n      }\n      break;\n    case 'create_allocate':\n      if (ev.data.err) {\n        createSessionAllocateCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionAllocateCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create_finalize':\n      if (ev.data.err) {\n        createSessionFinalizeCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionFinalizeCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create':\n      if (ev.data.err) {\n        createSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'release':\n      if (ev.data.err) {\n        releaseSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        releaseSessionCallbacks.shift()![0]();\n      }\n      break;\n    case 'run':\n      if (ev.data.err) {\n        runCallbacks.shift()![1](ev.data.err);\n      } else {\n        runCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'end-profiling':\n      if (ev.data.err) {\n        endProfilingCallbacks.shift()![1](ev.data.err);\n      } else {\n        endProfilingCallbacks.shift()![0]();\n      }\n      break;\n    case 'is-ort-env-initialized':\n      if (ev.data.err) {\n        isOrtEnvInitializedCallbacks.shift()![1](ev.data.err);\n      } else {\n        isOrtEnvInitializedCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    default:\n  }\n};\n\nconst scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src : undefined;\n\nexport const initializeWebAssemblyInstance = async(): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    if (initialized) {\n      return;\n    }\n    if (initializing) {\n      throw new Error('multiple calls to \\'initWasm()\\' detected.');\n    }\n    if (aborted) {\n      throw new Error('previous call to \\'initWasm()\\' failed.');\n    }\n\n    initializing = true;\n\n    // overwrite wasm filepaths\n    if (env.wasm.wasmPaths === undefined) {\n      if (scriptSrc && scriptSrc.indexOf('blob:') !== 0) {\n        env.wasm.wasmPaths = scriptSrc.substr(0, +(scriptSrc).lastIndexOf('/') + 1);\n      }\n    }\n\n    return new Promise<void>((resolve, reject) => {\n      proxyWorker?.terminate();\n\n      const workerUrl = URL.createObjectURL(new Blob(\n          [\n            // This require() function is handled by esbuild plugin to load file content as string.\n            // eslint-disable-next-line @typescript-eslint/no-require-imports\n            require('./proxy-worker/main')\n          ],\n          {type: 'text/javascript'}));\n      proxyWorker = new Worker(workerUrl, {name: 'ort-wasm-proxy-worker'});\n      proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\n      proxyWorker.onmessage = onProxyWorkerMessage;\n      URL.revokeObjectURL(workerUrl);\n      initWasmCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-wasm', in : env.wasm};\n      proxyWorker.postMessage(message);\n    });\n\n  } else {\n    return initializeWebAssembly(env.wasm);\n  }\n};\n\nexport const initializeRuntime = async(env: Env): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      initOrtCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-ort', in : env};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    await core.initRuntime(env);\n  }\n};\n\nexport const createSessionAllocate = async(model: Uint8Array): Promise<SerializableModeldata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<SerializableModeldata>((resolve, reject) => {\n      createSessionAllocateCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create_allocate', in : {model}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSessionAllocate(model);\n  }\n};\n\nexport const createSessionFinalize = async(modeldata: SerializableModeldata, options?: InferenceSession.SessionOptions):\n    Promise<SerializableSessionMetadata> => {\n      if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n        ensureWorker();\n        return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n          createSessionFinalizeCallbacks.push([resolve, reject]);\n          const message: OrtWasmMessage = {type: 'create_finalize', in : {modeldata, options}};\n          proxyWorker!.postMessage(message);\n        });\n      } else {\n        return core.createSessionFinalize(modeldata, options);\n      }\n    };\n\nexport const createSession =\n    async(model: Uint8Array, options?: InferenceSession.SessionOptions): Promise<SerializableSessionMetadata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check unsupported options\n    if (options?.preferredOutputLocation) {\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n      createSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create', in : {model, options}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSession(model, options);\n  }\n};\n\nexport const releaseSession = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      releaseSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'release', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.releaseSession(sessionId);\n  }\n};\n\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputs: TensorMetadata[], outputIndices: number[],\n    outputs: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check inputs location\n    if (inputs.some(t => t[3] !== 'cpu')) {\n      throw new Error('input tensor on GPU is not supported for proxy.');\n    }\n    // check outputs location\n    if (outputs.some(t => t)) {\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\n      runCallbacks.push([resolve, reject]);\n      const serializableInputs = inputs as SerializableTensorMetadata[];  // every input is on CPU.\n      const message: OrtWasmMessage =\n          {type: 'run', in : {sessionId, inputIndices, inputs: serializableInputs, outputIndices, options}};\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\n    });\n  } else {\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\n  }\n};\n\nexport const endProfiling = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      endProfilingCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'end-profiling', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.endProfiling(sessionId);\n  }\n};\n\nexport const isOrtEnvInitialized = async(): Promise<boolean> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<boolean>((resolve, reject) => {\n      isOrtEnvInitializedCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'is-ort-env-initialized'};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    return core.isOrtEnvInitialized();\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {readFile} from 'node:fs/promises';\nimport {env, InferenceSession, InferenceSessionHandler, SessionHandler, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, TensorMetadata} from './proxy-messages';\nimport {createSession, createSessionAllocate, createSessionFinalize, endProfiling, initializeRuntime, isOrtEnvInitialized, releaseSession, run} from './proxy-wrapper';\nimport {isGpuBufferSupportedType} from './wasm-common';\n\nlet runtimeInitializationPromise: Promise<void>|undefined;\n\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\n  switch (tensor.location) {\n    case 'cpu':\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\n    case 'gpu-buffer':\n      return [tensor.type, tensor.dims, {gpuBuffer: tensor.gpuBuffer}, 'gpu-buffer'];\n    default:\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\n  }\n};\n\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\n  switch (tensor[3]) {\n    case 'cpu':\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\n    case 'gpu-buffer': {\n      const dataType = tensor[0];\n      if (!isGpuBufferSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\n      }\n      const {gpuBuffer, download, dispose} = tensor[2];\n      return Tensor.fromGpuBuffer(gpuBuffer, {dataType, dims: tensor[1], download, dispose});\n    }\n    default:\n      throw new Error(`invalid data location: ${tensor[3]}`);\n  }\n};\n\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\n  private sessionId: number;\n\n  inputNames: string[];\n  outputNames: string[];\n\n  async createSessionAllocate(path: string): Promise<SerializableModeldata> {\n    // fetch model from url and move to wasm heap. The arraybufffer that held the http\n    // response is freed once we return\n    const response = await fetch(path);\n    if (response.status !== 200) {\n      throw new Error(`failed to load model: ${path}`);\n    }\n    const arrayBuffer = await response.arrayBuffer();\n    return createSessionAllocate(new Uint8Array(arrayBuffer));\n  }\n\n  async loadModel(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\n    if (!(await isOrtEnvInitialized())) {\n      if (!runtimeInitializationPromise) {\n        runtimeInitializationPromise = initializeRuntime(env);\n      }\n      await runtimeInitializationPromise;\n      runtimeInitializationPromise = undefined;\n    }\n\n    if (typeof pathOrBuffer === 'string') {\n      if (typeof process !== 'undefined' && process.versions && process.versions.node) {\n        // node\n        const model = await readFile(pathOrBuffer);\n        [this.sessionId, this.inputNames, this.outputNames] = await createSession(model, options);\n      } else {\n        // browser\n        // fetch model and move to wasm heap.\n        const modelData: SerializableModeldata = await this.createSessionAllocate(pathOrBuffer);\n        // create the session\n        [this.sessionId, this.inputNames, this.outputNames] = await createSessionFinalize(modelData, options);\n      }\n    } else {\n      [this.sessionId, this.inputNames, this.outputNames] = await createSession(pathOrBuffer, options);\n    }\n  }\n\n  async dispose(): Promise<void> {\n    return releaseSession(this.sessionId);\n  }\n\n  async run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType, options: InferenceSession.RunOptions):\n      Promise<SessionHandler.ReturnType> {\n    const inputArray: Tensor[] = [];\n    const inputIndices: number[] = [];\n    Object.entries(feeds).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.inputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid input '${name}'`);\n      }\n      inputArray.push(tensor);\n      inputIndices.push(index);\n    });\n\n    const outputArray: Array<Tensor|null> = [];\n    const outputIndices: number[] = [];\n    Object.entries(fetches).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.outputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid output '${name}'`);\n      }\n      outputArray.push(tensor);\n      outputIndices.push(index);\n    });\n\n    const inputs =\n        inputArray.map((t, i) => encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`));\n    const outputs = outputArray.map(\n        (t, i) => t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null);\n\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\n\n    const resultMap: SessionHandler.ReturnType = {};\n    for (let i = 0; i < results.length; i++) {\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\n    }\n    return resultMap;\n  }\n\n  startProfiling(): void {\n    // TODO: implement profiling\n  }\n\n  endProfiling(): void {\n    void endProfiling(this.sessionId);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {cpus} from 'node:os';\nimport {Backend, env, InferenceSession, InferenceSessionHandler} from 'onnxruntime-common';\n\nimport {initializeWebAssemblyInstance} from './wasm/proxy-wrapper';\nimport {OnnxruntimeWebAssemblySessionHandler} from './wasm/session-handler-inference';\n\n/**\n * This function initializes all flags for WebAssembly.\n *\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\n * being created, to override default value.\n */\nexport const initializeFlags = (): void => {\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\n    env.wasm.initTimeout = 0;\n  }\n\n  if (typeof env.wasm.simd !== 'boolean') {\n    env.wasm.simd = true;\n  }\n\n  if (typeof env.wasm.proxy !== 'boolean') {\n    env.wasm.proxy = false;\n  }\n\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\n    const numCpuLogicalCores = typeof navigator === 'undefined' ? cpus().length : navigator.hardwareConcurrency;\n    env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\n  }\n};\n\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\n  async init(): Promise<void> {\n    // populate wasm flags\n    initializeFlags();\n\n    // init wasm\n    await initializeWebAssemblyInstance();\n  }\n  createInferenceSessionHandler(path: string, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  createInferenceSessionHandler(buffer: Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  async createInferenceSessionHandler(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler> {\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\n    await handler.loadModel(pathOrBuffer, options);\n    return Promise.resolve(handler);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OnnxruntimeWebAssemblyBackend} from './backend-wasm';\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\n// So we import code inside the if-clause to allow bundler remove the code safely.\n\nexport * from 'onnxruntime-common';\nimport * as ort from 'onnxruntime-common';\nexport default ort;\n\nimport {registerBackend, env} from 'onnxruntime-common';\nimport {version} from './version';\n\nif (!BUILD_DEFS.DISABLE_WEBGL) {\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\n  registerBackend('webgl', onnxjsBackend, -10);\n}\n\nif (!BUILD_DEFS.DISABLE_WASM) {\n  const wasmBackend = BUILD_DEFS.DISABLE_TRAINING ? require('./backend-wasm-inference').wasmBackend :\n                                                    require('./backend-wasm-training').wasmBackend;\n  if (!BUILD_DEFS.DISABLE_WEBGPU && typeof navigator !== 'undefined' && navigator.gpu) {\n    registerBackend('webgpu', wasmBackend, 5);\n  }\n  registerBackend('cpu', wasmBackend, 10);\n  registerBackend('wasm', wasmBackend, 10);\n  if (BUILD_DEFS.DISABLE_TRAINING) {\n    registerBackend('xnnpack', wasmBackend, 9);\n    registerBackend('webnn', wasmBackend, 9);\n  }\n}\n\nObject.defineProperty(env.versions, 'web', {value: version, enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n"],
  "mappings": ";;;;;ygBAAA,IAcMA,GACAC,GAYOC,GA0CAC,GArEbC,GAAAC,GAAA,kBAcML,GAAqC,IAAI,IACzCC,GAAqC,CAAA,EAY9BC,GAAkB,CAACI,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBT,GAAS,IAAIM,CAAI,EACxC,GAAIG,IAAmB,OACrBT,GAAS,IAAIM,EAAM,CAAC,QAAAC,EAAS,SAAAC,CAAQ,CAAC,MACjC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIT,GAAyB,QAAQK,CAAI,EAC3CI,IAAM,IACRT,GAAyB,OAAOS,EAAG,CAAC,EAGtC,QAASA,EAAI,EAAGA,EAAIT,GAAyB,OAAQS,IACnD,GAAIV,GAAS,IAAIC,GAAyBS,CAAC,CAAC,EAAG,UAAYF,EAAU,CACnEP,GAAyB,OAAOS,EAAG,EAAGJ,CAAI,EAC1C,OAGJL,GAAyB,KAAKK,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAUaH,GAAiB,MAAMQ,GAAqD,CACvF,IAAMC,EAAeD,EAAa,SAAW,EAAIV,GAA2BU,EACtEE,EAAS,CAAA,EACf,QAAWC,KAAeF,EAAc,CACtC,IAAMG,EAAcf,GAAS,IAAIc,CAAW,EAC5C,GAAIC,EAAa,CACf,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,SAGF,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAI,GAEpD,MAAMA,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACLD,GACHH,EAAO,KAAK,CAAC,KAAMC,EAAa,IAAKG,CAAC,CAAC,EAEzCF,EAAY,QAAU,WAEtB,OAAOA,EAAY,cAKzB,MAAM,IAAI,MAAM,oCAAoCF,EAAO,IAAII,GAAK,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,CAC1G,ICrGA,IAAAC,GAAAC,GAAA,kBA4EAC,OC5EA,IAMaC,GANbC,GAAAC,GAAA,kBAMaF,GAAU,WCNvB,IAQIG,GAESC,GAVbC,GAAAC,GAAA,kBAIAC,KAIIJ,GAAwC,UAE/BC,GAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAC,OAAQI,EAAO,EAE1B,IAAI,SAASC,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDN,GAAgBM,EAClB,EACA,IAAI,UAAQ,CACV,OAAON,EACT,GAIF,OAAO,eAAeC,GAAK,WAAY,CAAC,WAAY,EAAI,CAAC,IC/BzD,IAmKaM,GAnKbC,GAAAC,GAAA,kBAGAC,KAgKaH,GAAWA,KCnKxB,IASaI,GA0FAC,GAnGbC,GAAAC,GAAA,kBASaH,GAAkB,CAACI,EAAgBC,IAA4C,CAC1F,IAAMC,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQF,EAAO,KAAK,CAAC,EAC5BE,EAAO,OAASF,EAAO,KAAK,CAAC,EAC7B,IAAMG,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAJ,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,IAEtBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,GAGxB,IAAMM,EAAcL,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/DM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASK,EAAI,EAAGA,EAAIV,EAAQU,IAC1B,QAASC,EAAI,EAAGA,EAAIZ,EAAOY,IAAK,CAC9B,IAAMC,GAAMjB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMlB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,GAAMnB,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EY,EAAIN,IAAmB,GACzB,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE1EL,EAAgB,UAAY,QAAUc,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxEjB,EAAgB,SAASa,EAAGD,EAAG,EAAG,CAAC,EAGvC,OAAOb,EAAO,UAAS,MAEvB,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaL,GAAoB,CAACG,EAAgBC,IAAiD,CACjG,IAAME,EAAkB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EACpEkB,EACJ,GAAIlB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAiB,EACArB,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBsB,EAAWtB,EAAO,KAAK,CAAC,IAExBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBsB,EAAWtB,EAAO,KAAK,CAAC,GAE1B,IAAMM,EAAcL,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhGM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIH,IAAY,SACVA,EAAQ,SAAW,QAAcqB,IAAa,GAAKrB,EAAQ,SAAW,QACrEqB,IAAa,GAAMrB,EAAQ,SAAW,OAASA,EAAQ,SAAW,OACrE,MAAM,IAAI,MAAM,+CAAgD,EAKpE,IAAMsB,EAAO,EACTC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACzEhB,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BW,EAAQlB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QAASU,EAAI,EAAGA,EAAIV,EAASD,EACxBoB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMR,IAC/FM,EAAM,KAAKG,CAAa,GAAMxB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKI,CAAa,GAAMzB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKK,CAAa,GAAM1B,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKM,CAAa,EAAIb,IAAmB,GAC3C,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAI5E,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOa,CACT,IC/LA,IAiBaO,GAkFAC,GA8IAC,GAWAC,GASAC,GArQbC,GAAAC,GAAA,kBAIAC,KAaaP,GAAiB,CAACQ,EAAqCC,IAA0C,CAC5G,GAAID,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIC,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAC,OAAAC,EAAQ,MAAAC,CAAK,EAAIF,EAElBG,EAAOH,EAAQ,MAAQ,CAAC,KAAM,IAAK,KAAM,CAAC,EAC5CI,EACAC,EAEA,OAAQF,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAQA,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMG,EAAcN,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DO,EACFP,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACzGQ,EAASP,EAASC,EAClBO,EAAcF,IAAiB,OAAS,IAAI,aAAaC,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGE,EAAO,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACnFC,EAAiB,EAAGC,EAAiBR,EAAQS,EAAiBT,EAAS,EAAGU,EAAiB,GAG3FZ,IAAgB,QAClBI,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdP,IAAiB,OACnBW,EAAiBV,EAAS,EACjBD,IAAiB,OAC1BQ,EAAiB,EACjBE,EAAiBT,EACjBQ,EAAiBR,EAAS,GACjBD,IAAiB,QAC1BU,EAAiB,EACjBD,EAAiBR,EACjBO,EAAiBP,EAAS,GAG5B,QAASW,EAAI,EAAGA,EAAIX,EACfW,IAAKR,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAC9FD,EAAYM,GAAgB,GAAKhB,EAAOY,CAAa,EAAIN,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYO,GAAgB,GAAKjB,EAAOa,CAAa,EAAIP,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYQ,GAAgB,GAAKlB,EAAOc,CAAa,EAAIR,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9Ec,IAAmB,IAAMJ,IAAkB,KAC7CL,EAAYS,GAAgB,GAAKnB,EAAOe,CAAa,EAAIT,EAAS,CAAC,GAAKD,EAAS,CAAC,GAOtF,OAFqBG,IAAiB,OAAS,IAAIa,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,EACxD,IAAIkB,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,CAEzG,EAKaV,GAAkB,MAC3B6B,EACArB,IACyC,CAE3C,IAAMsB,EAAiB,OAAQ,iBAAsB,KAAeD,aAAiB,iBAC/EE,EAAiB,OAAQ,UAAe,KAAeF,aAAiB,UACxEG,EAAgB,OAAQ,YAAiB,KAAeH,aAAiB,YACzEI,EAAW,OAAOJ,GAAU,SAE9BK,EACAC,EAA+C3B,GAAW,CAAA,EAG9D,GAAIsB,EAAgB,CAElB,IAAMM,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAI5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MAMlB,GALIrB,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADA2B,EAAwB3B,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7E2B,EAAsB,aAAe,OAEvCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,OAE9ByB,EAAsB,aAAe,OACrCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAGhC2B,EAAgB,UAAUR,EAAO,EAAG,CAAC,EACrCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCsB,EAAgB,CACzB,IAAItB,EACAC,EAiBJ,GAfIF,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,eAEhBC,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,OAGZrB,IAAY,SACd2B,EAAwB3B,GAE1B2B,EAAsB,OAAS,OAC/BA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAE1BF,IAAY,OAAW,CACzB,IAAM8B,EAAa,SAAS,cAAc,QAAQ,EAElDA,EAAW,MAAQ5B,EACnB4B,EAAW,OAAS7B,EAEpB,IAAM4B,EAAkBC,EAAW,WAAW,IAAI,EAElD,GAAID,GAAmB,KACrBA,EAAgB,aAAaR,EAAO,EAAG,CAAC,EACxCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CyB,EAAOL,EAAM,aAENG,EAAe,CAExB,GAAIxB,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAM4B,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAM5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MACpB,OAAAQ,EAAgB,UAAUR,EAAO,EAAG,EAAGnB,EAAOD,CAAM,EACpDyB,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,KACzD0B,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EACvBX,GAAemC,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAMJ,EAAS,SAAS,cAAc,QAAQ,EACxCK,EAAUL,EAAO,WAAW,IAAI,EACtC,GAAI,CAACP,GAAS,CAACY,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAMb,EACfa,EAAS,OAAS,IAAK,CACrBN,EAAO,MAAQM,EAAS,MACxBN,EAAO,OAASM,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGN,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMO,EAAMF,EAAQ,aAAa,EAAG,EAAGL,EAAO,MAAOA,EAAO,MAAM,EAElED,EAAsB,OAASC,EAAO,OACtCD,EAAsB,MAAQC,EAAO,MACrCG,EAAQxC,GAAe4C,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOnC,GAAemC,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKalC,GAAoB,CAC7B2C,EAAsCpC,IAAgD,CACxF,GAAM,CAAC,MAAAE,EAAO,OAAAD,EAAQ,SAAAoC,EAAU,QAAAC,CAAO,EAAItC,EAErCuC,EAAO,CAAC,EAAGtC,EAAQC,EAAO,CAAC,EACjC,OAAO,IAAIkB,GAAO,CAAC,SAAU,UAAW,KAAM,UAAW,QAAAgB,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC5F,EAKa5C,GAAsB,CAC/B8C,EAA0CxC,IAAkD,CAC9F,GAAM,CAAC,SAAAyC,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAItC,EAC5C,OAAO,IAAIoB,GAAO,CAAC,SAAU,aAAc,KAAMqB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC7G,EAKa3C,GAAyB,CAClC+C,EAAS3C,EAAwCwC,IACjD,IAAInB,GAAO,CAAC,SAAU,aAAc,KAAAsB,EAAM,KAAM3C,EAAQ,KAAMwC,GAAQ,CAACxC,EAAO,MAAM,CAAC,CAAC,ICvQ1F,IAWa4C,GAcAC,GAcTC,GACSC,GAxCbC,GAAAC,GAAA,kBAWaL,GAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,UAAW,WAAW,EACvB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACvB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAkB,GACTC,GAAc,IAAK,CAC9B,GAAI,CAACD,GAAiB,CACpBA,GAAkB,GAClB,IAAMI,EAA2B,OAAO,cAAkB,KAAe,OAAO,cAAc,MAAS,WACjGC,EACF,OAAO,eAAmB,KAAe,OAAO,eAAe,MAAS,WAExED,IACFN,GAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DM,IACFP,GAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAGxE,ICxDA,IAWaO,GAkBAC,GA7BbC,GAAAC,GAAA,kBAIAC,KAOaJ,GAAiBK,GAAoC,CAChE,IAAIC,EAAO,EACX,QAASC,EAAI,EAAGA,EAAIF,EAAK,OAAQE,IAAK,CACpC,IAAMC,EAAMH,EAAKE,CAAC,EAClB,GAAI,OAAOC,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQD,CAAC,8BAA8BC,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQD,CAAC,0CAA0CC,CAAG,EAAE,EAE/EF,GAAQE,EAEV,OAAOF,CACT,EAKaL,GAAgB,CAACQ,EAAgBJ,IAAmC,CAC/E,OAAQI,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIC,GAAOD,EAAO,KAAMA,EAAO,KAAMJ,CAAI,EAClD,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,KAAMD,EAAO,KACb,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,UACH,OAAO,IAAIK,GAAO,CAChB,SAAU,UACV,QAASD,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,UAAWD,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCI,EAAO,QAAQ,mBAAmB,EAE1F,ICzDA,IAwBaE,GAxBbC,GAAAC,GAAA,kBAGAC,KAEAC,KAEAC,KACAC,KAgBaN,GAAP,KAAa,CAyCjB,YACIO,EAEAC,EAA8EC,EAAwB,CAExGC,GAAW,EAEX,IAAIC,EACAC,EAEJ,GAAI,OAAOL,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBI,EAAOJ,EAAK,KACZK,EAAOL,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMM,EAAgCC,GAAsC,IAAIH,CAAI,EACpF,GAAI,CAACE,EACH,MAAM,IAAI,UAAU,qBAAqBF,CAAI,uCAAuC,EAEtF,GAAI,EAAEJ,EAAK,gBAAgBM,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUN,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAII,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBJ,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GAAKI,IAAS,WAAaA,IAAS,WAAaA,IAAS,SAAWA,IAAS,SAAWA,IAAS,UAC7FA,IAAS,OACZ,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBJ,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIQ,EACAC,EAEJ,GAAI,OAAOT,GAAS,SAMlB,GAFAI,EAAOJ,EACPS,EAAYP,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAiD,EAIvEO,EAAOP,MACF,CAEL,IAAMS,EAAwBH,GAAsC,IAAIP,CAAI,EAC5E,GAAIU,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BV,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAID,IAAS,UAIX,MAAM,IAAI,UACN,+FAA+F,EAC1FA,IAAS,UAAYA,IAAS,QAYvCQ,EAAQE,EAA8B,KAAKT,EAAM,MAAM,EAIvDO,EAAQE,EAA8B,KAAKT,CAAI,UAExCA,aAAgBS,EACzBF,EAAOP,MAEP,OAAM,IAAI,UAAU,KAAKG,CAAI,kCAAkCM,CAAqB,EAAE,UAO1FD,EAAYR,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMW,EAAmB,OAAOX,EAAK,CAAC,EACtC,GAAIW,IAAqB,SACvBP,EAAO,SACPI,EAAOR,UACEW,IAAqB,UAC9BP,EAAO,OAIPI,EAAO,WAAW,KAAKR,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCW,CAAgB,GAAG,MAE3E,CAEL,IAAMC,EACFC,GAAsC,IAAIb,EAAK,WAA8C,EACjG,GAAIY,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCZ,EAAK,WAAW,GAAG,EAE9EI,EAAOQ,EACPJ,EAAOR,EAKX,GAAIS,IAAc,OAEhBA,EAAY,CAACD,EAAK,MAAM,UACf,CAAC,MAAM,QAAQC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAyC,EAE/DJ,EAAOI,EAEP,KAAK,QAAUD,EACf,KAAK,aAAe,MAItB,IAAMM,EAAOC,GAAcV,CAAI,EAE/B,GAAI,KAAK,SAAWS,IAAS,KAAK,QAAQ,OACxC,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAG9F,KAAK,KAAOV,EACZ,KAAK,KAAOC,EACZ,KAAK,KAAOS,CACd,CAIA,aAAa,UACTE,EACAC,EACoB,CACtB,OAAOC,GAAgBF,EAAOC,CAAO,CACvC,CAEA,OAAO,YACHE,EAA4BF,EAAoC,CAClE,OAAOG,GAAkBD,EAASF,CAAO,CAC3C,CAEA,OAAO,cACHI,EAAgCJ,EAAsC,CACxE,OAAOK,GAAoBD,EAAWJ,CAAO,CAC/C,CAEA,OAAO,iBACHb,EAASmB,EAAwClB,EAAwB,CAC3E,OAAOmB,GAAuBpB,EAAMmB,EAAQlB,CAAI,CAClD,CAKA,UAAUY,EAAgC,CACxC,OAAOQ,GAAgB,KAAMR,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOS,GAAkB,KAAMT,CAAO,CACxC,CAgDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACN,gJAC2E,EAEjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAKA,MAAM,QAAQU,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aAAc,CACjB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMnB,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXmB,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXnB,UAGP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQH,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOuB,GAAc,KAAMvB,CAAI,CACjC,KClaF,IAwUawB,GAxUbC,GAAAC,GAAA,kBAIAC,KAoUaH,GAASA,KCxUtB,IAeaI,GAfbC,GAAAC,GAAA,kBAGAC,KAIAC,KAQaJ,GAAP,MAAOK,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkBC,EAA+BC,EAAiB,CAC1E,IAAMC,EAA4C,CAAA,EAC9CC,EAAsB,CAAA,EAE1B,GAAI,OAAOJ,GAAU,UAAYA,IAAU,MAAQA,aAAiBK,IAAU,MAAM,QAAQL,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIM,EAAiB,GAErB,GAAI,OAAOL,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBI,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQJ,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DK,EAAiB,GAEjB,QAAWC,KAAQN,EAAM,CACvB,GAAI,OAAOM,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEJ,EAAQI,CAAI,EAAI,KAGlB,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIM,EAAY,GACVC,EAAW,OAAO,oBAAoBR,CAAI,EAChD,QAAWM,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKT,EAA4DM,CAAI,GACvEG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBH,EAAQI,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAON,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDE,EAAUH,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWM,KAAQ,KAAK,WACtB,GAAI,OAAOP,EAAMO,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBJ,EAAQI,CAAI,EAAI,KAMpB,IAAMI,EAAU,MAAM,KAAK,QAAQ,IAAIX,EAAOG,EAASC,CAAO,EACxDQ,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAOA,aAAa,OACTG,EAAyCd,EAA8BC,EACvEc,EAAqB,CAEvB,IAAIC,EACAb,EAA0B,CAAA,EAE9B,GAAI,OAAOW,GAAS,UAElB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7Cc,aAAgB,YAEzB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAGpDc,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAAoB,CACnF,IAAMG,EAASH,EACXI,EAAa,EACbC,EAAaL,EAAK,WACtB,GAAI,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,EAAa,GAAKA,GAAcD,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADAE,EAAaL,EAAK,WAAaI,EAC3B,OAAOjB,GAAS,SAAU,CAE5B,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,GAAc,GAAKD,EAAaC,EAAaF,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAaC,CAAU,IAAI,EAE7F,GAAI,OAAOH,GAAS,UAAYA,IAAS,KACvCZ,EAAUY,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7C,OAAOd,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAkC,UAE/C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,EAEtDgB,EAAuB,IAAI,WAAWC,EAAQC,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAyD,EAK/E,IAAMC,GADMjB,EAAQ,oBAAsB,CAAA,GACjB,IAAIkB,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAE9DvB,EAAU,MADA,MAAMwB,GAAeF,CAAY,GACnB,8BAA8BJ,EAAsBb,CAAO,EACzF,OAAO,IAAIN,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,KCrNF,IAqcayB,GArcbC,GAAAC,GAAA,kBAGAC,KAkcaH,GAA4CA,KCrczD,IAAAI,GAAAC,GAAA,oBCAA,IAgBMC,GAGOC,GAnBbC,GAAAC,GAAA,kBAGAC,KAIAC,KASML,GAA0B,gHAGnBC,GAAP,MAAOK,CAAe,CAC1B,YAAoBC,EAA+B,CACjD,KAAK,QAAUA,CACjB,CAGA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,CAEA,aAAa,OAAOC,EAA+CC,EAA+B,CAEhG,IAAMC,EAA+BF,EAAgB,WAAa,GAC5DG,EAAoCH,EAAgB,gBAAkB,GACtEI,EAA0BH,GAAkB,CAAA,EAI5CI,GADMD,EAAQ,oBAAsB,CAAA,GACjB,IAAIE,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAC9DC,EAAU,MAAMC,GAAeH,CAAY,EACjD,GAAIE,EAAQ,6BAA8B,CACxC,IAAMR,EAAU,MAAMQ,EAAQ,6BAC1BP,EAAgB,gBAAiBA,EAAgB,WAAYE,EAAWC,EAAgBC,CAAO,EACnG,OAAO,IAAIN,EAAgBC,CAAO,MAElC,OAAM,IAAI,MAAMP,EAAe,CAEnC,CAWA,wBAAwBiB,EAAkBC,EAA+BC,EAAiB,CAExF,IAAMC,EAA4C,CAAA,EAC9CR,EAAsB,CAAA,EAE1B,GAAI,OAAOK,GAAU,UAAYA,IAAU,MAAQA,aAAiBI,IAAU,MAAM,QAAQJ,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIK,EAAiB,GAErB,GAAI,OAAOJ,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBG,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQH,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DI,EAAiB,GAEjB,QAAWC,KAAQL,EAAM,CACvB,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEH,EAAQG,CAAI,EAAI,KAGlB,GAAI,OAAOJ,GAAS,UAAYA,IAAS,KACvCP,EAAUO,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIK,EAAY,GACVC,EAAW,OAAO,oBAAoBP,CAAI,EAChD,QAAWK,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKR,EAAmDK,CAAI,GAC9DG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBF,EAAQG,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCP,EAAUO,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDP,EAAUM,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWK,KAAQ,KAAK,WACtB,GAAI,OAAON,EAAMM,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBH,EAAQG,CAAI,EAAI,KAIpB,MAAO,CAACH,EAASR,CAAO,CAC1B,CASA,uCAAuCe,EAAkC,CACvE,IAAMC,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAIA,MAAM,aAAaX,EAAkBC,EAA+BC,EAAiB,CACnF,GAAM,CAACC,EAASR,CAAO,EAAI,KAAK,wBAAwBK,EAAOC,EAAMC,CAAI,EACnEQ,EAAU,MAAM,KAAK,QAAQ,aAAaV,EAAOG,EAASR,CAAO,EACvE,OAAO,KAAK,uCAAuCe,CAAO,CAC5D,CAEA,MAAM,kBAAkBI,EAAgB,GAAI,CAC1C,OAAO,KAAK,QAAQ,kBAAkBA,CAAa,CACrD,CAEA,MAAM,qBAAqBC,EAAmBD,EAAgB,GAAI,CAChE,IAAME,EAAa,MAAM,KAAK,kBAAkBF,CAAa,EAG7D,GAAIC,EAAM,SAAW,EAAIC,EACvB,MAAM,IAAI,MACN,qJAC0D,EAEhE,OAAO,KAAK,QAAQ,qBAAqBD,EAAOD,CAAa,CAC/D,CAEA,MAAM,wBAAwBA,EAAgB,GAAI,CAChD,OAAO,KAAK,QAAQ,wBAAwBA,CAAa,CAC3D,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,KCxMF,IAkJaG,GAlJbC,GAAAC,GAAA,kBAKAC,KA6IaH,GAA0CA,KClJvD,IAAAI,GAAA,GAAAC,GAAAD,GAAA,sBAAAE,GAAA,WAAAC,GAAA,oBAAAC,GAAA,QAAAC,GAAA,oBAAAC,KAAA,IAAAC,GAAAC,GAAA,kBAmBAC,KACAC,KACAC,KACAC,KACAC,KACAC,OCxBA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,cAAAE,KAAA,IAAaA,GAAbC,GAAAC,GAAA,KAAaF,GAAW,SCAxB,IAAAG,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,GAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAW,IAAM,CACnB,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,IAAIC,EAAED,EAAUE,EAAGC,EAAGF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAGE,CAAC,CAAC,EAC5DJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,EAAEN,EAAE,CAACO,EAAEC,EAAEC,IAAI,IAAIC,IAAI,CAAC,IAAMC,EAAEC,GAAEC,EAAEL,IAAI,EAAEE,EAAEH,EAAE,GAAGG,CAAC,EAAE,IAAMI,EAAEN,IAAI,EAAE,OAAAK,IAAIC,IAAIP,EAAEO,EAAEL,EAAEI,CAAC,EAAEL,EAAEC,EAAE,MAAaG,IAAGD,EAAEI,GAAG,EAAEL,CAAC,EAAET,EAAEM,GAAG,SAASC,IAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,EAAEb,EAAE,GAAG,CAAC,GAAGY,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,EAAE,MAAMH,EAAE,GAAGC,CAAC,EAAE,GAAGZ,EAAE,KAAKa,EAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,EAAEF,EAAE,OAAO,GAAG,EAAEE,EAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,CAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,GAAGA,CAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,CAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,EAAEC,EAAEC,IAAIX,EAAE,eAAeQ,EAAEC,EAAEC,EAAEC,CAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,EAAEC,IAAIV,EAAE,iBAAiBQ,EAAEC,EAAEC,CAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAG,iBAAiBC,EAAG,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAe,OAAO,eAAnB,WAAiCC,EAAa,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE,GAAGC,EAAGC,EAAGC,EACrP,GAAGJ,EAAG,CAAC,IAAIK,EAAG,cAAcC,EAAG,cAAgBL,EAAEF,EAAGO,EAAG,QAAQL,CAAC,EAAE,IAAI,UAAU,IAAIC,EAAG,CAACxB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAS2B,EAAG,aAAa3B,EAAEC,EAAE,OAAO,MAAM,GAAGyB,EAAG1B,IAAIA,EAAEwB,EAAGxB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAGyB,EAAG,CAACzB,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAE2B,EAAG,SAAS3B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACR,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAG,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAG,CAACnB,EAAEC,IAAI,CAAC,cAAQ,SAC1fD,EAAQC,CAAE,EAAEJ,EAAE,QAAQ,IAAI,4BAA4B,MAASuB,GAAIC,KAAGA,EAAGE,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAK5B,IAAa4B,EAAE5B,GAAgB4B,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGC,EAAGxB,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAKK,EAAG1B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GAC5fwB,EAAG,CAACzB,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,GAAE,IAAI0B,EAAGhC,EAAE,OAAO,QAAQ,IAAI,KAAK,OAAO,EAAEiC,EAAGjC,EAAE,UAAU,QAAQ,MAAM,KAAK,OAAO,EAAE,OAAO,OAAOA,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAGrB,EAAE,aAAaA,EAAE,OAAOsB,EAAGtB,EAAE,MAAM,IAAIkC,EAAGlC,EAAE,aAAakC,EAAGlC,EAAE,YAAY,IAAImC,EAAcnC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BoC,GAAE,iCAAiC,EAC7e,IAAIC,EAAGC,EAAEC,EAAE,GAAGC,EAAGC,GAAEC,GAAEC,EAAEC,GAAEC,GAAGC,GAAG,SAASC,IAAI,CAAC,IAAI5C,EAAEkC,EAAG,OAAOrC,EAAE,MAAMyC,GAAE,IAAI,UAAUtC,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAO2C,EAAE,IAAI,WAAWxC,CAAC,EAAEH,EAAE,OAAO0C,GAAE,IAAI,WAAWvC,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQ4C,GAAE,IAAI,YAAYzC,CAAC,EAAEH,EAAE,QAAQ6C,GAAG,IAAI,aAAa1C,CAAC,EAAEH,EAAE,QAAQ8C,GAAG,IAAI,aAAa3C,CAAC,CAAC,CAAC,IAAI6C,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAE,SAASC,IAAI,CAAC,IAAIhD,EAAEH,EAAE,OAAO,MAAM,EAAEgD,GAAG,QAAQ7C,CAAC,CAAC,CAAC,IAAIiD,GAAE,EAAEC,GAAG,KAAKC,GAAG,KACvY,SAASlB,GAAEjC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAI8B,EAAG9B,CAAC,EAAEoC,EAAE,GAAGC,EAAG,EAAErC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAGC,CAAC,EAAQA,CAAE,CAAC,SAASoD,GAAGpD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIqD,GAA2B,GAAxBA,GAAG,qBAAwB,CAACD,GAAGC,EAAE,EAAE,CAAC,IAAIC,GAAGD,GAAGA,GAAGxD,EAAE,WAAWA,EAAE,WAAWyD,GAAG/B,CAAC,EAAEA,EAAE+B,EAAE,CAAC,SAASC,GAAGvD,EAAE,CAAC,GAAGA,GAAGqD,IAAItB,EAAG,OAAO,IAAI,WAAWA,CAAE,EAAE,GAAGL,EAAG,OAAOA,EAAG1B,CAAC,EAAE,KAAK,iDAAkD,CAChd,SAASwD,GAAGxD,EAAE,CAAC,GAAG,CAAC+B,IAAKX,GAAIC,GAAI,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIsD,GAAGvD,CAAC,CAAC,EAAE,GAAGyB,EAAG,OAAO,IAAI,QAAQ,CAACxB,EAAEC,IAAI,CAACuB,EAAGzB,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIqD,GAAGvD,CAAC,CAAC,CAAC,CAAC,SAASyD,GAAGzD,EAAEC,EAAEC,EAAE,CAAC,OAAOsD,GAAGxD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC2B,EAAG,0CAA0C3B,CAAC,EAAE8B,GAAE9B,CAAC,CAAC,CAAC,CAAC,CAC/e,SAASuD,GAAG1D,EAAEC,EAAE,CAAC,IAAIC,EAAEmD,GAAG,OAAOtB,GAAgB,OAAO,YAAY,sBAA/B,YAAqDqB,GAAGlD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAgB,OAAO,OAAnB,WAAyBmC,GAAGvD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA0B,EAAG,kCAAkC1B,CAAC,EAAE0B,EAAG,2CAA2C,EAAS2B,GAAGvD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAClX,IAAI0D,GAAGC,GAAG,CAAC,QAAQ5D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EACrf,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,OAAOG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,QAAQF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YACjfG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,kBAAkBG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aACnfG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YACrfG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBACrfG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,IAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,CAAC,EAC3f,SAAS,IAAI,CAAC,CAAC+B,GAAE7B,IAAI,CAAC,EAAE,cAAcC,EAAE,MAAM,KAAK8B,EAAE,SAAS7B,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,EAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,EAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,GAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAK+B,EAAE,SAAS9B,IAC/f,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,EAAE,MAAM,KAAK6B,EAAE,SAAS5B,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,IAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,CAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,GAAE7B,IAAI,CAAC,EAAE,cAAcC,EAAE,MAAM,KAAK8B,EAAE,SAAS7B,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,EAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,EAAE,OAAO,OAAO,QAAQN,EACtf,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,GAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAK+B,EAAE,SAAS9B,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,EAAE,MAAM,KAAK6B,EAAE,SAAS5B,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,IAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,EAAE,OACnf,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,QAAQ,CAACE,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,IAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,EAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,QAAQ,CAACE,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EACnfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,IAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,EAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,QAAQ,CAACE,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,IAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,EAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,QAAQ,CAACE,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAClfG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,QAAQJ,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAChfG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKsC,EAAE,SAASrC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,EAAE,sBAAsBsD,GAAErD,CAAC,EAAE,KAAKqD,GAAEpD,CAAC,EAAE,YAAYoD,GAAEnD,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAClf,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBAAqBG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EACzfC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,QAAQC,EAAE,SAASC,EAAE,QAAQ,CAAC,CAACE,EAAE,aAAa,CAAC,CAACD,EAAE,OAAOE,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACL,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,QAAQC,EAAE,SAASC,EAAE,QAAQ,CAAC,CAACE,EAAE,aAAa,CAAC,CAACD,EAAE,OAAOE,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACL,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACX,EAAE,GAAG,YAAYG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,EAAE,eAAeC,EAAE,MAAM,KAAKkC,EAAE,SAAS,OAAOjC,CAAC,IAAI,EAAE,OAAOA,CAAC,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,uBAAuB,CAAC,CAACE,CAAC,CAAC,CAAC,EAAE,QAAQR,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EACrf,QAAQ,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,CAAC,CAAC,CAAC,EAAE,QAAQL,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACf,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,CAAC,EAAE,WAAW,IAAI,CAAC,CAAC+B,GAAE7B,IAAI,CAAC,EAAE,WAAWoD,GAAEnD,CAAC,EAAE,kBAAkBC,EACjgB,MAAM,KAAK+B,GAAG,SAAS9B,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,IAAI,CAACjE,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,EAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKiC,EAAE,SAAShC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAEC,CAAC,EAAE,WAAW,IAAI,CAAC,CAAC4B,GAAE1B,IAAI,CAAC,EAAE,WAAWiD,GAAE/C,CAAC,EAAE,kBAAkBC,EAAE,MAAM,KAAK2B,GAAG,SAASoB,IAAI,EAAEA,EAAE/C,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQf,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,QAAQG,GAAGH,EAAE,GAAGG,CAAC,EAAE,QAAQA,GAAGH,EAAE,GAAGG,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,QAAQ,CAACF,EAAEC,EACnfC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EAAE,SAAS6D,GAAG/D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,IAAIgE,GAAGhE,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EAAEoE,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAE,EAChL,SAASC,GAAGpE,EAAE,CAAC,KAAK,GAAGA,EAAE,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACwC,GAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,UAAU,CAAC,OAAOwC,GAAE,KAAK,GAAG,GAAG,IAAI,CAAC,CAAC,EAAE,KAAK,GAAG,SAASxC,EAAE,CAACwC,GAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACqC,GAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAErC,EAAE,EAAE,CAAC,EAAE,KAAK,GAAG,UAAU,CAAC,OAAUqC,GAAE,KAAK,GAAG,IAAI,IAAI,CAAC,GAAtB,CAAuB,EAAE,KAAK,GAAG,SAASrC,EAAE,CAACqC,GAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAErC,EAAE,EAAE,CAAC,EAAE,KAAK,GAAG,UAAU,CAAC,OAAUqC,GAAE,KAAK,GAAG,IAAI,IAAI,CAAC,GAAtB,CAAuB,EAAE,KAAK,GAAG,SAASrC,EAAEC,EAAE,CAAC,KAAK,GAAG,CAAC,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,SAASD,EAAE,CAACwC,GAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,UAAU,CAAC,OAAOwC,GAAE,KAAK,GACtf,IAAI,IAAI,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAAC,GAAG4B,GAAG,KAAK,GAAG,CAAC,EAAE,OAAO5B,GAAE,KAAK,IAAI,IAAI,CAAC,EAAE,IAAIxC,EAAE,KAAK,GAAG,EAAE,OAAWA,IAAJ,EAAMA,EAAE,KAAK,EAAE,CAAC,CAChH,IAAIqE,GAAGtE,GAAG,CAAC,IAAIC,EAAEkE,GAAE,GAAG,CAAClE,EAAE,OAAOsE,GAAG,CAAC,EAAE,EAAE,IAAIrE,EAAE,IAAIkE,GAAGnE,CAAC,EAAEC,EAAE,GAAGD,CAAC,EAAE,IAAIE,EAAED,EAAE,GAAG,EAAE,GAAG,CAACC,EAAE,OAAOoE,GAAG,CAAC,EAAEtE,EAAE,QAAQG,KAAKJ,EAAE,CAAC,IAAIK,EAAEL,EAAEI,CAAC,EAAE,GAAOC,IAAJ,GAAOA,IAAIF,EAAE,MAAM,GAAGqE,GAAGnE,EAAEF,EAAED,EAAE,GAAG,EAAE,EAAE,OAAOqE,GAAGlE,CAAC,EAAEJ,CAAC,CAAC,OAAAsE,GAAGpE,CAAC,EAASF,CAAC,EAAEwE,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAAC1E,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQyE,GAAG,OAAOA,GAAG,OAAOzE,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EACpf,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GAAG,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EAAE0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAG0E,GAAGnC,GAAEvC,EAAEC,CAAC,EAAE,GAAG0E,GAAG3E,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAE2E,GAAG,CAAC5E,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,EAAEP,EAAE,WAAW,EAAEK,CAAC,EACpgBC,EAAE,QAAQA,EAAE,OAAO,IAAIC,EAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEyE,GAAG7E,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAW8E,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAGhF,GAAG,CAAC,IAAIC,EAAE0E,GAAG3E,CAAC,EAAE,EAAEE,EAAE+E,GAAGhF,CAAC,EAAE,OAAAC,GAAG0E,GAAG5E,EAAEuC,GAAErC,EAAED,CAAC,EAASC,CAAC,EAAEgF,GAAG,CAAC,EACrfC,GAAG,CAACnF,EAAEC,IAAI,CAACiF,GAAG,OAAO,EAAE,IAAIhF,EAAE,IAAID,IAAI,EAAEC,EAAEqC,GAAEvC,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAEiF,GAAG,KAAUhF,GAAL,IAAOsC,EAAEvC,IAAI,CAAC,EAAE0C,GAAG1C,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAOiF,EAAE,EAAEE,GAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAItF,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IAAI,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAI,gBAAgB,EAAEjB,EAAE,IAAIA,KAAKmF,GAAYA,GAAGnF,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAEmF,GAAGnF,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEqF,GAAGpF,CAAC,CAAC,OAAOoF,EAAE,EAAEA,GAAGC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GACpf,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAG1F,EAAE,CAAC,IAAIC,EAAE,MAAM0E,GAAG3E,CAAC,EAAE,CAAC,EAAE,OAAA4E,GAAG5E,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CAC9H,SAAS0F,GAAG3F,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,EAAE+C,EAAE,CAAC,IAAIhD,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,GAAGD,EAAEgD,EAAE,CAAC,EAAEhD,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,EAAE,CAAC,OAAOX,EAAEU,EAAEC,EAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,EAAE,CAAC,SAAS+C,EAAE8B,GAAE,CAAC,MAAO,GAAEA,GAAE,GAAG,EAAEA,GAAE,EAAE,CAAC,CAAC,IAAIC,EAAE,OAAKA,EAAE/B,EAAEhD,EAAE,YAAY,EAAEC,EAAE,YAAY,CAAC,KAAxC,IAAiD8E,EAAE/B,EAAEhD,EAAE,SAAS,EAAEC,EAAE,SAAS,CAAC,KAAlC,IAAuC8E,EAAE/B,EAAEhD,EAAE,QAAQ,EAAEC,EAAE,QAAQ,CAAC,GAAU8E,CAAC,CAAC,SAAStF,EAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EACzf,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,EAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,GAAG,CAAC,IAAI+C,EAAEhD,EAAE,SAAS,EAAE+E,GAAGhB,GAAG/D,EAAE,YAAY,CAAC,EAAE0E,GAAGC,IAAI3B,CAAC,EAAE,GAAG/C,EAAE8E,EAAE/E,EAAE,QAAQ,EAAEC,GAAG8E,EAAE/E,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAGgD,EAAEhD,EAAE,SAASgD,EAAE,CAAC,GAAGhD,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,CAAC,EAAE,KAAK,CAAC,CAAC,OAAA+C,EAAE,IAAI,KAAKhD,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,EAAER,EAAE,IAAI,KAAKO,EAAE,YAAY,EACpf,EAAE,CAAC,CAAC,EAAEgD,EAAEvD,EAAEuD,CAAC,EAAS,GAAGxD,EAAES,EAAED,CAAC,EAAE,GAAGR,EAAEwD,EAAEhD,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,EAAE+B,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGqC,EAAErC,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,EAAEoD,GAAEpD,CAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,EAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WAAW,MAAM,KACnf,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,KAAKD,EAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,EAAE,GAAG,EAAED,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,2DAA2D,MAAM,GAAG,EAAEC,EAAE,wFAAwF,MAAM,GAAG,EAAEH,EAAE,CAAC,KAAKK,GAAGH,EAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,EAAEG,EAAE,EAAE,EAAE,KAAKA,GAAGF,EAAEE,EAAE,EAAE,EAAE,UAAU,EACngB,CAAC,EAAE,KAAKA,GAAGF,EAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,EAAE,EAAE+C,EAAE,EAAEA,GAAGhD,EAAE,GAAG,EAAEC,IAAI8D,GAAG/D,EAAE,GAAG,IAAI,EAAE0E,GAAGC,IAAI3B,GAAG,EAAE,CAAC,OAAOzD,EAAES,EAAE,GAAGC,EAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GAAG,CAAC,IAAIC,EAAE,KAAK,OAAOD,EAAE,GACxf,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,IAAOA,EAAMA,GAAJ,KAAQ+C,GAAGhD,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAKgD,GAAH,GAASA,GAAH,GAAMe,GAAG/D,EAAE,EAAE,IAAIC,EAAE,QAAQ,CAACA,EAAE,GAAG,IAAI+C,GAAGhD,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAMgD,GAAH,GAASA,GAAH,GAAMe,GAAG/D,EAAE,GAAG,IAAI,CAAC,IAAIC,GAAG,CAAC,OAAOV,EAAEU,EAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,EAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,EAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,KAAKD,EAAEP,EAAE,SAASQ,CAAC,IAAIR,EACpfA,EAAE,QAAQ,IAAI,OAAOQ,EAAE,GAAG,EAAED,EAAEC,CAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,EAAEgF,GAAGxF,CAAC,EAAKQ,EAAE,OAAOT,EAAS,GAAEqC,GAAE,IAAI5B,EAAEV,IAAI,CAAC,EAASU,EAAE,OAAO,EAAC,CAAC,SAASoF,GAAG9F,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACgC,GAAEhC,CAAC,CAAC,CAAC,CAAC,SAAS8F,GAAG/F,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAAC4F,GAAG,KAAK7F,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQgC,IAAI4D,GAAG,IAAI,IAAI7F,GAAG8B,GAAE,EAAEpB,IAAOoF,KAAJ,GAAWD,GAAG,SAAP,IAAgBC,GAAE,EAAEH,GAAGI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAE9F,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAIgG,GAAE,EAAEpF,GAAE,KAAKsF,GAAG,EAAEH,GAAG,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC3e,SAASxF,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACsG,GAAG,CAAC,QAAQvG,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASwG,IAAI,CAAC,IAAIzG,EAAEiF,GAAG,KAAK,EAAEhF,EAAED,EAAE,GAAGyC,GAAEzC,GAAG,IAAI,CAAC,EAAEC,EAAEwC,GAAEzC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE+F,GAAG,CAAC,EAAE,IAAI9F,EAAEkG,GAAGnG,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAEoG,KAAKF,GAAGnG,CAAC,EAAEC,EAAEmG,GAAGnG,CAAC,EAAED,GAAGuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEE,EAASF,CAAC,CAC7N,SAAS0G,GAAG1G,EAAE,CAAC,GAAG,CAACoC,EAAE,CAAC,GAAO6D,KAAJ,EAAM,CAAC,IAAIhG,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACiC,IAAI+D,GAAGhG,EAAEF,EAAE,GAAGC,GAAG,CAAC+F,GAAE,EAAEH,GAAG,IAAIa,GAAG9F,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,KAAK+B,EAAEkE,GAAG7D,EAAE3B,GAAE,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,OAAON,EAAE,CAACH,EAAEG,EAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAEiG,GAAGjG,IAAIiG,GAAG,MAAMpG,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAIgG,GAAE,EAAEpF,GAAE4F,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAG,IAAIc,GAAG/F,EAAC,CAAC,EAAE,MAAUoF,KAAJ,GAAOA,GAAE,EAAEH,GAAGe,EAAE,EAAEC,GAAGjG,EAAC,EAAEA,GAAE,KAAK2F,GAAG,QAAQrG,GAAG,CAAC,GAAG,CAACiC,EAAE,GAAG,CAAC,GAAGjC,EAAE,EAAE,CAAC6B,EAAc,GAAG,CAACK,EAAGA,EAClflC,EAAEkC,EAAOL,IAAkBnC,EAAE,QAAOA,EAAE,OAAOM,CAAC,EAAEiC,EAAE,IAAGjB,EAAGhB,EAAE,IAAI4D,GAAG5D,CAAC,CAAC,CAAC,OAAOC,EAAE,CAACA,aAAa2D,IAAc3D,GAAV,UAAae,EAAG,EAAEf,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa2D,IAAc3D,GAAV,UAAae,EAAG,EAAEf,CAAC,CAAC,CAAC,CAAC,GAAG6B,GAAE,kBAAkBgE,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAAC,SAASY,GAAG/G,EAAE,CAAC,OAAO0G,GAAGzG,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CACtP,IAAI+G,GAAG,CAAC,GAAG,SAAShH,EAAEC,EAAEC,EAAE,CAAC,OAAO6G,GAAG,SAAS,CAAC,MAAMlH,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAE,CAAC,OAAAA,EAAE,IAAIoE,GAAGpE,IAAI,CAAC,EAAEA,EAAE,GAAG,IAAIA,EAAE,GAAG,EAAE,EAAEkE,MAAMlE,EAAE,GAAG,EAAE,EAAEiE,GAAG,KAAKjE,CAAC,EAAEiH,GAAGjH,EAAE,EAAE,EAASA,EAAE,GAAG,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,CAAC,EAAE,IAAIA,EAAEiE,GAAG,IAAI,EAAEiD,GAAGlH,EAAE,EAAE,EAAEmE,GAAE,CAAC,EAAE,EAAE,UAAU,CAAC,OAAOG,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE,SAAStE,EAAE,CAAC,OAAOsE,GAAG,CAACtE,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAE,CAAC,OAAOqE,GAAG,CAACtE,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAOoE,GAAG,CAACtE,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,IAAIF,EAAEiE,GAAG,IAAI,EAAEjE,GAAGiC,GAAE,uBAAuB,EAAE,IAAIhC,EAAED,EAAE,GAAG,MAAAA,EAAE,GAAG,IAAIiE,GAAG,KAAKjE,CAAC,EAAEA,EAAE,GAAG,EAAE,EAAEA,EAAE,GAAG,EAAE,EAAEkE,MAAMC,GAAElE,EAAQkE,EAAE,EAAE,EAAE,SAASnE,EAC5fC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIoE,GAAGpE,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEiE,GAAEnE,EAAEkE,KAAWC,EAAE,EAAE,EAAE,UAAU,CAAC,OAAOD,EAAE,EAAE,EAAE,SAASlE,EAAE,CAAC,MAAAmE,KAAIA,GAAEnE,IAAI,GAASmE,EAAE,EAAE,GAAG,UAAU,CAAC,MAAO,EAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,MAAO,EAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,IAAI,GAAG,GAAG,SAASnE,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAC/fwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGF,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,CAAC,EAAE,GAAG,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EACtf,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAG2E,GAAG7E,EAAE,YAAY,CAAC,EAAE8E,GAAGC,IAAI/E,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGD,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,CAAC,EAAE,GAAG,SAASD,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAAEG,EAAG,IAAI,KAAKH,EAAE,YAAY,EACvgB,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAAG,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGqC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,GAAG6E,GAAG5E,EAAE,YAAY,CAAC,EAAE6E,GAAGC,IAAI9E,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEuC,EAAExC,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAAE,IAAWsE,IAAIZ,GACnf3D,EAAE,GAAG,CAAC,KAAK,IAAI2D,EAAE,EAAE,EAAEA,GAAG,CAAC,KAAK,MAAMA,GAAG,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAG,EAAE,CAAC,CAACA,KAAK,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE3D,IAAI,CAAC,EAAE,GAAG,UAAU,CAAC,MAAM,GAAG,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,SAASA,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEK,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACN,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,EAAED,EAAE,kBAAkB,EAAEmC,GAAEzC,IAAI,GAAG,IAAI,CAAC,EAAE,GAAG,KAAK,IAAII,EAAEG,CAAC,EAAEiC,EAAEvC,IAAI,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,GAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAEgF,GAAGhF,CAAC,EAAEC,EAAE+E,GAAG/E,CAAC,EAAEM,EAAEH,GAAGqC,GAAEvC,GAAG,IAAI,CAAC,EAAEF,EAAEyC,GAAEvC,EAAE,GAAG,IAAI,CAAC,EACpfD,IAAIwC,GAAEvC,GAAG,IAAI,CAAC,EAAED,EAAEwC,GAAEvC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,GAAG,IAAI,CAACiC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASjC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEkF,GAAGlF,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,GAAG,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEkF,GAAGlF,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,GAAG,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,IAAI,EAAE,GAAG,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAD,KAAK,EAASsC,GAAE,WAAWvC,IAAI,IAAI,EAAEC,IAAI,EAAEA,GAAGC,IAAI,KAAK,CAAC,CAAC,EAAE,GAAG,SAASF,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEsC,GAAE,OAAO,GAAG,WAAWvC,EAAE,MAAM,GAAG,QAAQE,EAAE,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KAChfD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAE+B,EAAG,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,EAAG,KAAK9B,CAAC,EAAEwC,GAAG,EAAE,IAAIvC,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,GAAG,SAASL,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAAmF,GAAG,EAAE,QAAQ,SAASlF,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAsB,IAApBE,EAAEqC,GAAEzC,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEiC,GAAElC,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEiC,GAAElC,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,EAAE,GAAG,SAASH,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAEmF,GAAG,EAAE5C,GAAEzC,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEqC,GAAExC,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,EACrf,GAAG,IAAI,GAAG,GAAG,UAAU,CAAC,MAAO,GAAE,EAAE,GAAG,UAAU,CAAC,MAAO,GAAE,EAAE,GAAG,SAASH,EAAEC,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEmC,GAAExC,GAAG,IAAI,CAAC,EAAEM,EAAEkC,GAAExC,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,EAAEC,IAAI,CAAC,IAAIC,EAAE8B,GAAEjC,EAAEE,IAAI,CAAC,EAAEE,EAAE6E,GAAGvF,CAAC,EAAMS,IAAJ,GAAYA,IAAL,KAAaT,IAAJ,EAAM6B,EAAGC,GAAI4C,GAAGhE,EAAE,CAAC,CAAC,EAAEA,EAAE,OAAO,GAAGA,EAAE,KAAKD,CAAC,CAAC,CAACL,GAAGG,CAAC,CAAC,OAAAkC,GAAEtC,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,EAAE,GAAG+G,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAClf,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GACpf,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAE,SAASrR,EAAE,CAAC,OAAOA,IAAI,CAAC,EAAE,GAAG2F,GAAG,EAAE,SAAS3F,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOwF,GAAG3F,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GAClU,UAAU,CAAC,SAASH,EAAEE,EAAE,CAAuH,GAAtHA,EAAEA,EAAE,QAAQA,EAAE6F,GAAG7F,CAAC,EAAEiC,EAAEjC,EAAEoR,GAAGpR,CAAC,EAAEgC,EAAGC,EAAE,GAAGS,GAAG,EAAEE,GAAG,QAAQX,EAAE,EAAE,EAAEc,KAAIpD,EAAE,wBAAwBA,EAAE,uBAAuBoD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAI,CAAC,IAAIhD,EAAEgD,GAAGA,GAAG,KAAKhD,EAAE,CAAC,CAAC,OAAOD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE+G,EAAE,EAA4D,GAA1D/D,KAAIpD,EAAE,wBAAwBA,EAAE,uBAAuBoD,EAAC,EAAKpD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAAC4B,EAAG,sDAAsD5B,CAAC,EAAEH,EAAGG,CAAC,CAAC,CAAC,OAAAwD,GAAGzD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,QAAQ,CAAC,CAAC,EAAE,MAAMH,CAAE,EAAQ,CAAC,CAAC,GAAG,EACneF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASsC,EAAE,IAAInC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,CAAC,EAAEJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKZ,EAAE,yBAAyBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BsC,EAAE,IAAInC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAC5bL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EACpeR,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAChfN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKV,EAAE,QAAQsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EACnZ,IAAIiF,GAAGpF,EAAE,QAAQG,IAAIiF,GAAGpF,EAAE,QAAQsC,EAAE,IAAInC,CAAC,EAAE8G,GAAGjH,EAAE,MAAMG,IAAI8G,GAAGjH,EAAE,MAAMsC,EAAE,IAAInC,CAAC,EAAE,EAAE,CAACA,EAAEC,KAAK,EAAEkC,EAAE,IAAInC,EAAEC,CAAC,EAAEsE,GAAGvE,IAAIuE,GAAGpC,EAAE,IAAInC,CAAC,EAAEuR,EAAE,KAAKA,EAAEpP,EAAE,IAAI,EAAEqP,EAAExR,IAAIwR,EAAErP,EAAE,IAAInC,CAAC,EAAEyR,GAAGzR,IAAIyR,GAAGtP,EAAE,IAAInC,CAAC,EAAEkH,GAAGlH,IAAIkH,GAAG/E,EAAE,IAAInC,CAAC,EAAEiH,GAAGjH,IAAIiH,GAAG9E,EAAE,IAAInC,CAAC,EAAEwE,GAAG,CAACxE,EAAEC,EAAEC,KAAKsE,GAAGrC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEmE,GAAGrE,IAAIqE,GAAGlC,EAAE,IAAInC,CAAC,EAAE0R,GAAW7R,EAAE,WAAW,CAACG,EAAEC,KAAKyR,GAAW7R,EAAE,WAAWsC,EAAE,IAAInC,EAAEC,CAAC,EAAE0R,GAAY9R,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKyR,GAAY9R,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAE0R,GAAG/R,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,KAAKyR,GAAG/R,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAE0R,GAAYhS,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAK2R,GACpfhS,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAE4R,GAAGjS,EAAE,WAAW,CAACG,EAAEC,KAAK6R,GAAGjS,EAAE,WAAWsC,EAAE,IAAInC,EAAEC,CAAC,EAAE8R,GAAGlS,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKyR,GAAGlS,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE0R,GAAUnS,EAAE,UAAUG,IAAIgS,GAAUnS,EAAE,UAAUsC,EAAE,IAAInC,CAAC,EAAEiS,GAAGpS,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4R,GAAGpS,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6R,GAAGrS,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAK8R,GAAGrS,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE+R,GAAGtS,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+R,GAAGtS,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgS,GAAGvS,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,KAAKiS,GAAGvS,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkS,GAAGxS,EAAE,UAC/eG,IAAIqS,GAAGxS,EAAE,UAAUsC,EAAE,IAAInC,CAAC,EAAEsS,GAAGzS,EAAE,UAAUG,IAAIsS,GAAGzS,EAAE,UAAUsC,EAAE,IAAInC,CAAC,EAAEuS,GAAG1S,EAAE,YAAY,CAACG,EAAEC,EAAEC,EAAEC,KAAKoS,GAAG1S,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEqS,GAAG3S,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKkS,GAAG3S,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEmS,GAAG5S,EAAE,YAAY,CAACG,EAAEC,EAAEC,EAAEC,KAAKsS,GAAG5S,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEuS,GAAG7S,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKqS,GAAG7S,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEsS,GAAG9S,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKuS,GAAG9S,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEwS,GAAG/S,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKqS,GAAG/S,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EACrfsS,GAAGhT,EAAE,WAAW,CAACG,EAAEC,KAAK4S,GAAGhT,EAAE,WAAWsC,EAAE,IAAInC,EAAEC,CAAC,EAAE6S,GAAGjT,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAK4S,GAAGjT,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAE6S,GAAGlT,EAAE,WAAW,CAACG,EAAEC,KAAK8S,GAAGlT,EAAE,WAAWsC,EAAE,IAAInC,EAAEC,CAAC,EAAE+S,GAAGnT,EAAE,WAAW,CAACG,EAAEC,KAAK+S,GAAGnT,EAAE,WAAWsC,EAAE,IAAInC,EAAEC,CAAC,EAAEgT,GAAGpT,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAK+S,GAAGpT,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEgT,GAAGrT,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKgT,GAAGrT,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEiT,GAAGtT,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK2S,GAAGtT,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE4S,GAAGvT,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKgT,GAAGvT,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEiT,GAAGxT,EAAE,gBACze,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+S,GAAGxT,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgT,GAAGzT,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKiT,GAAGzT,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkT,GAAG1T,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKgT,GAAG1T,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEiT,GAAG3T,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+S,GAAG3T,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgT,GAAG5T,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKiT,GAAG5T,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkT,GAAG7T,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+S,GAAG7T,EAAE,oBAAoBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EACpfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgT,GAAG9T,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+S,GAAG9T,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgT,GAAG/T,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKuT,GAAG/T,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEwT,GAAGhU,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKsT,GAAGhU,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEuT,GAAGjU,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKuT,GAAGjU,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEwT,GAAGlU,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKsT,GAAGlU,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEuT,GAAGnU,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,KAAK6T,GAClfnU,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAE8T,GAAGpU,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKwT,GAAGpU,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEyT,GAAGrU,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKuT,GAAGrU,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEwT,GAAGtU,EAAE,uBAAuB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,KAAKqT,GAAGtU,EAAE,uBAAuBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,EAAEsT,GAAGvU,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,KAAKqT,GAAGvU,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,EAAEsT,GAAGxU,EAAE,qBACze,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKyT,GAAGxU,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE0T,GAAGzU,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKgU,GAAGzU,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEiU,GAAG1U,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4T,GAAG1U,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6T,GAAG3U,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKkU,GAAG3U,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEmU,GAAG5U,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+T,GAAG5U,EAAE,oBAAoBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgU,GAAG7U,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EACpfC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+T,GAAG7U,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgU,GAAG9U,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKmU,GAAG9U,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEoU,GAAG/U,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,KAAKyU,GAAG/U,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAE0U,GAAGhV,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKyU,GAAGhV,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE0U,GAAGjV,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKmU,GAAGjV,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEoU,GAAGlV,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,MAAKX,GAAGlV,EAAE,yBACrfsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,EAAEC,GAAG9V,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKqV,GAAG9V,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEsV,GAAG/V,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKgV,GAAG/V,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEiV,GAAGhW,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKwV,GAAGhW,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEyV,GAAGjW,EAAE,uBAAuB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,KAAK+U,GAAGjW,EAAE,uBAAuBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,EAAEgV,GAAGlW,EAAE,WAAW,CAACG,EAAEC,EAAEC,KAAK6V,GAAGlW,EAAE,WAAWsC,EAAE,IAAInC,EACrfC,EAAEC,CAAC,EAAE8V,GAAGnW,EAAE,YAAY,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4V,GAAGnW,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6V,GAAGpW,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKuV,GAAGpW,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEwV,GAAGrW,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAK8V,GAAGrW,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE+V,EAAGtW,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4V,EAAGtW,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6V,EAAGvW,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKgW,EAAGvW,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEiW,EAAGxW,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+V,EAAGxW,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgW,EAAGzW,EAAE,uBACpe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,KAAKwV,EAAGzW,EAAE,uBAAuBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,EAAEyV,EAAG1W,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK2V,EAAG1W,EAAE,oBAAoBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE4V,EAAG3W,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,KAAK2Q,EAAG3W,EAAE,0BAA0BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,CAAC,EAAE4Q,GAAG5W,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK6V,GAAG5W,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE8V,GAAG7W,EAAE,WAAW,CAACG,EAAEC,EAAEC,KAAKwW,GAAG7W,EAAE,WACjfsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEyW,GAAG9W,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,MAAK0B,GAAG9W,EAAE,6BAA6BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,EAAC,EAAE2B,GAAG/W,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKiW,GAAG/W,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkW,GAAGhX,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKoW,GAAGhX,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEqW,GAAGjX,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKoW,GAAGjX,EAAE,oBAAoBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEqW,GAAGlX,EAAE,eAAe,CAACG,EAAEC,EACpfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKuW,GAAGlX,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEwW,EAAGnX,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK0W,EAAGnX,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE2W,GAAGpX,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK2W,GAAGpX,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE4W,GAAGrX,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4W,GAAGrX,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6W,GAAGtX,EAAE,2BAA2B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,MAAK8B,GAAGtX,EAAE,2BAA2BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,EAAE+B,GAAGvX,EAAE,0BAC3d,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,KAAKuR,GAAGvX,EAAE,0BAA0BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,CAAC,EAAEwR,GAAGxX,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,KAAKuT,GAAGxX,EAAE,yBAAyBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,EAAEwT,GAAGzX,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,KAAKuW,GAAGzX,EAAE,wBAAwBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,EAAEwW,GAAG1X,EAAE,8BAA8B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,MAAK6B,GAAG1X,EAAE,8BAC5dsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,EAAE8B,GAAG3X,EAAE,4BAA4B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,MAAKkC,GAAG3X,EAAE,4BAA4BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,EAAEmC,GAAG5X,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,MAAKqC,GAAG5X,EAAE,0BAA0BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,EAAEsC,GAAG7X,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,MAAKiC,GACrf7X,EAAE,6BAA6BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,EAAEkC,GAAG9X,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKgX,GAAG9X,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEiX,GAAG/X,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKiX,GAAG/X,EAAE,oBAAoBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkX,GAAGhY,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,MAAK2C,GAAGhY,EAAE,wBAAwBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,EAAC,EAAE4C,GAAGjY,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EACpfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,KAAK+W,GAAGjY,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,EAAEgX,GAAGlY,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKmX,GAAGlY,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEoX,GAAGnY,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4X,GAAGnY,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6X,GAAGpY,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK0X,GAAGpY,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE2X,GAAGrY,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK2X,GAAGrY,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE4X,GAAGtY,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKwX,GAAGtY,EAAE,oBACpesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEyX,GAAGvY,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,KAAKqX,GAAGvY,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,EAAEsX,GAAGxY,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+X,GAAGxY,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgY,GAAGzY,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,KAAKwX,GAAGzY,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,EAAEyX,GAAG1Y,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+X,GAAG1Y,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgY,GAAG3Y,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+X,GAAG3Y,EAAE,iBAClfsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgY,GAAG5Y,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKqY,GAAG5Y,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEsY,GAAG7Y,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK8X,GAAG7Y,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE+X,GAAG9Y,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKiY,GAAG9Y,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkY,GAAG/Y,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,KAAK8X,GAAG/Y,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,EAAE+X,GAAGhZ,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKmY,GAAGhZ,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EACnfC,EAAEC,EAAEC,CAAC,EAAEoY,GAAGjZ,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKmY,GAAGjZ,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEoY,GAAGlZ,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKyY,GAAGlZ,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE0Y,GAAGnZ,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKqY,GAAGnZ,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEsY,GAAGpZ,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKyY,GAAGpZ,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE0Y,GAAGrZ,EAAE,uBAAuB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,KAAKoV,GAAGrZ,EAAE,uBAAuBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EACnfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,EAAEqV,GAAGtZ,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,KAAKqV,GAAGtZ,EAAE,wBAAwBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,EAAEsV,GAAGvZ,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKkZ,GAAGvZ,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEmZ,GAAGxZ,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,KAAKkZ,GAAGxZ,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEmZ,GAAGzZ,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK6Y,GAAGzZ,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE8Y,GAAG1Z,EAAE,mCAAmC,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,MAAK+D,GAAG1Z,EAAE,mCAChesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,EAAEgE,GAAG3Z,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKiZ,GAAG3Z,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkZ,GAAG5Z,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,KAAK2Y,GAAG5Z,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,EAAE4Y,GAAG7Z,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,KAAK4V,GAAG7Z,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,EAAE6V,GAAG9Z,EAAE,8BAA8B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,MAAKyE,GAAG9Z,EAAE,8BAChesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,EAAC,EAAE0E,GAAG/Z,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAK0Z,GAAG/Z,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAE2Z,GAAGha,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKiZ,GAAGha,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkZ,GAAGja,EAAE,uBAAuB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,KAAKiU,GAAGja,EAAE,uBAAuBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,CAAC,EAAEkU,GAAGla,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK0Z,GAAGla,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE2Z,GAAGna,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKsZ,GAAGna,EAAE,iBACtesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEuZ,GAAGpa,EAAE,4BAA4B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,MAAKiF,GAAGpa,EAAE,4BAA4BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,EAAC,EAAEkF,GAAGra,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,KAAKqU,GAAGra,EAAE,0BAA0BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,CAAC,EAAEsU,GAAGta,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,MAAKkF,GAAGta,EAAE,6BAA6BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,EAAC,EAAEmF,GAAGva,EAAE,yBACve,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,KAAKsW,GAAGva,EAAE,yBAAyBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,EAAEuW,GAAGxa,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,KAAKuZ,GAAGxa,EAAE,oBAAoBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,EAAEwZ,GAAGza,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4Z,GAAGza,EAAE,oBAAoBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6Z,GAAG1a,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,MAAKsF,GAAG1a,EAAE,6BAA6BsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,EAAC,EAAEuF,GAAG3a,EAAE,cAC3e,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKoa,GAAG3a,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEqa,GAAG5a,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKka,GAAG5a,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEma,GAAG7a,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKma,GAAG7a,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEoa,GAAG9a,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKma,GAAG9a,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEoa,GAAG/a,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKoa,GAAG/a,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEqa,GAAGhb,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKwa,GAAGhb,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEya,GAAGjb,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EACnfC,EAAEC,EAAEC,EAAEC,KAAKoa,GAAGjb,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEqa,GAAGlb,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKsa,GAAGlb,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEua,GAAGnb,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4a,GAAGnb,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6a,GAAGpb,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4a,GAAGpb,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6a,GAAGrb,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK4a,GAAGrb,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE6a,GAAGtb,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKua,GAAGtb,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEwa,GAAGvb,EAAE,iBACnf,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK2a,GAAGvb,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE4a,GAAGxb,EAAE,oBAAoB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,KAAKua,GAAGxb,EAAE,oBAAoBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,EAAEwa,GAAGzb,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+a,GAAGzb,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgb,GAAG1b,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,KAAKyX,GAAG1b,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,EAAE0X,GAAG3b,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKib,GAAG3b,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkb,GAAG5b,EAAE,gBAC9e,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKgb,GAAG5b,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEib,GAAG7b,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKsb,GAAG7b,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEub,GAAG9b,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKib,GAAG9b,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEkb,GAAG/b,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAK0b,GAAG/b,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAE2b,GAAGhc,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,KAAK0b,GAAGhc,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAE2b,GAAGjc,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,KAAK2b,GAAGjc,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAE4b,GAAGlc,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK0b,GAAGlc,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE2b,GAClfnc,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK2b,GAAGnc,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE4b,GAAGpc,EAAE,gBAAgB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK0b,GAAGpc,EAAE,gBAAgBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE2b,GAAGrc,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,KAAKob,GAAGrc,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,EAAEqb,GAAGtc,EAAE,cAAc,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAK+b,GAAGtc,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEgc,GAAGvc,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKkc,GAAGvc,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEmc,GAAGxc,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,KAAKsb,GAAGxc,EAAE,wBAAwBsC,EAAE,IAAInC,EACpfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,EAAEub,GAAGzc,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKkc,GAAGzc,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEmc,GAAG1c,EAAE,aAAa,CAACG,EAAEC,EAAEC,EAAEC,KAAKoc,GAAG1c,EAAE,aAAasC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEyG,GAAG5G,IAAI4G,GAAGzE,EAAE,IAAInC,CAAC,EAAEkG,GAAG,KAAKA,GAAG/D,EAAE,IAAI,EAAEwE,GAAG3G,IAAI2G,GAAGxE,EAAE,IAAInC,CAAC,EAAE6G,GAAG,KAAKA,GAAG1E,EAAE,IAAI,EAAEtC,EAAE,eAAe,QAAQA,EAAE,cAAc,QAAQ,SAASmI,GAAGhI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAAC,OAAOK,GAAG5R,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyH,GAAG9H,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC,OAAOM,GAAY7R,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC9d,SAASuL,GAAG3L,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAACI,GAAY3R,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuH,GAAG3H,EAAEC,EAAE,CAAC,IAAIC,EAAEqR,EAAE,EAAE,GAAG,CAAC,OAAOO,GAAG9R,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALqR,EAAEtR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASoL,GAAGvL,EAAEC,EAAE,CAAC,IAAIC,EAAEqR,EAAE,EAAE,GAAG,CAACG,GAAW1R,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALqR,EAAEtR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASkL,GAAGrL,EAAE,CAAC,IAAIC,EAAEsR,EAAE,EAAE,GAAG,CAACS,GAAUhS,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALsR,EAAEvR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASmI,GAAGrI,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC,OAAOQ,GAAG/R,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACzc,SAAS4H,GAAGpI,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAAC,OAAOU,GAAGjS,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS2H,GAAGlI,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC,OAAOY,GAAGnS,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS4L,GAAGlM,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAACa,GAAGpS,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgM,GAAGrM,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAACoB,GAAG3S,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASoH,GAAG1H,EAAE,CAAC,IAAIC,EAAEsR,EAAE,EAAE,GAAG,CAAC,OAAOe,GAAGtS,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALsR,EAAEvR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAChd,SAASqM,GAAGvM,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAACmB,GAAG1S,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS+H,GAAGtI,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAAC,OAAOqB,GAAG5S,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS6G,GAAGtH,EAAEC,EAAE,CAAC,IAAIC,EAAEqR,EAAE,EAAE,GAAG,CAAC,OAAOsB,GAAG7S,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALqR,EAAEtR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgH,GAAGnH,EAAEC,EAAE,CAAC,IAAIC,EAAEqR,EAAE,EAAE,GAAG,CAAC,OAAOyB,GAAGhT,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALqR,EAAEtR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASoI,GAAGvI,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE8Q,EAAE,EAAE,GAAG,CAAC,OAAO4B,GAAGnT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL8Q,EAAE/Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC/e,SAASiM,GAAG3M,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC8B,GAAGrT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASwM,GAAGhN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAACgC,GAAGvT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS+H,GAAGxI,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAAC,OAAOiC,GAAGxT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASsM,GAAGjN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE8Q,EAAE,EAAE,GAAG,CAACkC,GAAGzT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL8Q,EAAE/Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC9a,SAASwM,GAAGlN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAACwC,GAAG/T,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASiL,GAAG5L,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAACyC,GAAGhU,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASqI,GAAG1I,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAAC,OAAO2C,GAAGlU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS2M,GAAGzN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAE,CAAC,IAAIC,EAAEwQ,EAAE,EAAE,GAAG,CAAC4C,GAAGnU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,CAAC,OAAOgD,EAAE,CAAM,GAAL0N,EAAEzQ,CAAC,EAAK+C,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACtc,SAAS4H,GAAG1L,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC+C,GAAGtU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyL,GAAGjM,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAACiD,GAAGxU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgM,GAAGxM,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAACkD,GAAGzU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuL,GAAGnM,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAACsD,GAAG7U,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACvZ,SAASmH,GAAGzH,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC,OAAO4K,GAAGnc,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS+M,GAAGrN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAE,CAAC,IAAIC,EAAEwQ,EAAE,EAAE,GAAG,CAAC+E,EAAGtW,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,CAAC,OAAOgD,EAAE,CAAM,GAAL0N,EAAEzQ,CAAC,EAAK+C,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASwH,GAAGtL,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC6E,EAAGpW,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgM,GAAGtM,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC8E,EAAGrW,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACla,SAASsL,GAAG9L,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC2E,GAAGlW,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASmM,GAAGzM,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAAC4E,EAAGnW,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASkI,GAAG3I,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAE,CAAC,IAAID,GAAE2L,EAAE,EAAE,GAAG,CAAC,OAAOiF,EAAGxW,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,CAAC,CAAC,OAAOmP,GAAE,CAAM,GAALxD,EAAE5L,EAAC,EAAKoP,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASxH,GAAGxN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAACkF,GAAGzW,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACld,SAAS6H,GAAG5I,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAE,CAAC,IAAIC,GAAE3D,EAAE,EAAE,GAAG,CAAC,OAAOoF,GAAG3W,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAAL3D,EAAE0D,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS7H,GAAGtN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAACuF,GAAG9W,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASiM,GAAG7M,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAE,CAAC,IAAID,GAAE2L,EAAE,EAAE,GAAG,CAAC6F,GAAGpX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,CAAC,CAAC,OAAOmP,GAAE,CAAM,GAALxD,EAAE5L,EAAC,EAAKoP,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC9Z,SAASpI,GAAG5M,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE,CAAC,IAAI+B,EAAE0L,EAAE,EAAE,GAAG,CAAC8F,GAAGrX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,CAAC,OAAO8B,GAAE,CAAM,GAAL4L,EAAE3L,CAAC,EAAKD,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASkH,GAAG9M,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE,CAAC,IAAI+C,EAAEyN,EAAE,EAAE,GAAG,CAAC+F,GAAGtX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,CAAC,OAAO8E,EAAE,CAAM,GAAL2L,EAAE1N,CAAC,EAAK+B,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASwB,GAAGrH,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC,OAAOyF,EAAGhX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuL,GAAG/L,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAACyG,GAAGhY,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACld,SAAS8M,GAAGpN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAACyH,GAAGhZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS4M,GAAG1N,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE,CAAC,IAAI+C,EAAEyN,EAAE,EAAE,GAAG,CAAC8K,GAAGrc,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,CAAC,OAAO8E,EAAE,CAAM,GAAL2L,EAAE1N,CAAC,EAAK+B,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS4F,GAAGzL,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC6H,GAAGpZ,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS2M,GAAG/M,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAAC+H,GAAGtZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC/b,SAAS4M,GAAGvN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAACuD,GAAG9U,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASiN,GAAG/N,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAE,CAAC,IAAIC,GAAE5D,EAAE,EAAE,GAAG,CAACoI,GAAG3Z,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAAL5D,EAAE2D,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASvN,GAAG7H,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC,OAAOqI,GAAG5Z,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASsM,GAAG1M,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAACsI,GAAG7Z,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC1e,SAAS6M,GAAG5N,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAE,CAAC,IAAID,GAAE2L,EAAE,EAAE,GAAG,CAAC2I,GAAGla,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,CAAC,CAAC,OAAOmP,GAAE,CAAM,GAALxD,EAAE5L,EAAC,EAAKoP,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASlH,GAAG9N,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAE,CAAC,IAAIC,GAAE3D,EAAE,EAAE,GAAG,CAAC4I,GAAGna,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAAL3D,EAAE0D,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAStH,GAAG7N,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAE,CAAC,IAAIC,GAAE1D,EAAE,EAAE,GAAG,CAAC0I,GAAGja,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,EAAC,CAAC,OAAOE,GAAE,CAAM,GAAL1D,EAAEyD,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACvb,SAASzM,GAAGzI,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAAC,OAAO+I,GAAGta,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASiI,GAAG7I,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAE,CAAC,IAAIC,GAAE3D,EAAE,EAAE,GAAG,CAAC,OAAOgJ,GAAGva,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAAL3D,EAAE0D,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS/I,GAAGpM,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAACiJ,GAAGxa,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS6M,GAAGnN,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAACmD,GAAG1U,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC7e,SAAS+K,GAAG7L,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAAC8H,GAAGrZ,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS4H,GAAGjI,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAAC,OAAO0J,GAAGjb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASqH,GAAG5H,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC,OAAOqK,GAAG5b,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS2H,GAAG/H,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAAC,OAAOsK,GAAG7b,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASmL,GAAGxL,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAACuK,GAAG9b,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAChd,SAASmH,GAAGxH,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAAC,OAAOgL,GAAGvc,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS8H,GAAGnI,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAAC,OAAOwI,GAAG/Z,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASoN,GAAG3N,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE,CAAC,IAAI+B,EAAE0L,EAAE,EAAE,GAAG,CAAC6I,GAAGpa,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,CAAC,OAAO8B,GAAE,CAAM,GAAL4L,EAAE3L,CAAC,EAAKD,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS2B,GAAGvH,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC,OAAOuB,GAAG9S,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACxa,SAASgH,GAAGpH,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC,OAAO2B,GAAGlT,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuJ,GAAG3J,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC,OAAOW,GAAGlS,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS6J,GAAGnK,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAAC,OAAOgB,GAAGvS,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyP,GAAG9P,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAACkB,GAAGzS,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyK,GAAG9K,EAAEC,EAAE,CAAC,IAAIC,EAAEqR,EAAE,EAAE,GAAG,CAAC,OAAOwB,GAAG/S,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALqR,EAAEtR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC3c,SAASmP,GAAGtP,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC6B,GAAGpT,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS6P,GAAGnQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAAC+B,GAAGtT,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyO,GAAGhP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAAC0K,GAAGjc,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASiP,GAAG1P,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC2F,GAAGlX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACvY,SAAS6I,GAAGrJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAAC,OAAOmC,GAAG1T,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyP,GAAGvQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAACoC,GAAG3T,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyO,GAAGxP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAACsC,GAAG7T,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS4N,GAAGrO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAACuC,GAAG9T,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC1c,SAASsK,GAAG/K,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC,OAAO0B,GAAGjT,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS4I,GAAGhJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAAC,OAAO0C,GAAGjU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASkP,GAAG7P,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE,CAAC,IAAI+C,EAAEyN,EAAE,EAAE,GAAG,CAAC6C,GAAGpU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,CAAC,OAAO8E,EAAE,CAAM,GAAL2L,EAAE1N,CAAC,EAAK+B,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASsJ,GAAGnP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAAC8C,GAAGrU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACjd,SAASwO,GAAGvP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAACqC,GAAG5T,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS8O,GAAGrP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAACgD,GAAGvU,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgQ,GAAG9Q,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE8Q,EAAE,EAAE,GAAG,CAACoD,GAAG3U,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL8Q,EAAE/Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASsK,GAAGhL,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEmR,EAAE,EAAE,GAAG,CAAC,OAAOqD,GAAG5U,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALmR,EAAEpR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACla,SAASsQ,GAAG3Q,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAE,CAAC,IAAI8G,GAAEjL,EAAE,EAAE,GAAG,CAACwD,GAAG/U,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,CAAC,OAAO+G,GAAE,CAAM,GAALjL,EAAEgL,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS1N,GAAG/O,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAACoE,GAAG3V,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgQ,GAAGxQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAACqE,GAAG5V,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC3Z,SAAS6I,GAAG5J,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAAC,OAAOsE,GAAG7V,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS0J,GAAGjK,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE,CAAC,IAAI+C,EAAEyN,EAAE,EAAE,GAAG,CAAC,OAAOuE,GAAG9V,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,CAAC,OAAO8E,EAAE,CAAM,GAAL2L,EAAE1N,CAAC,EAAK+B,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS+K,GAAG5Q,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAACwE,GAAG/V,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS8K,GAAGlL,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC,OAAOyE,GAAGhW,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACxa,SAAS0J,GAAGhK,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAAC,OAAO0E,GAAGjW,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASoN,GAAGhO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAACgF,EAAGvW,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS0J,GAAGzK,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC,OAAOmF,GAAG1W,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASkQ,GAAGtQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAACqF,GAAG5W,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACzc,SAAS4I,GAAG1J,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAAC,OAAOsF,GAAG7W,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuJ,GAAGlK,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE8Q,EAAE,EAAE,GAAG,CAAC,OAAOwF,GAAG/W,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL8Q,EAAE/Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgO,GAAG1O,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC0F,GAAGjX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC7U,SAAS2Q,GAAGnR,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAE,CAAC,IAAIC,GAAE/D,EAAE,EAAE,GAAG,CAAC4F,GAAGnX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAAL/D,EAAE8D,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASlE,GAAGrR,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAE,CAAC,IAAI8G,GAAEjL,EAAE,EAAE,GAAG,CAACgG,GAAGvX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,CAAC,OAAO+G,GAAE,CAAM,GAALjL,EAAEgL,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACnW,SAASvL,GAAGlR,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAE,CAAC,IAAIC,GAAEhE,EAAE,EAAE,GAAG,CAACiG,GAAGxX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAALhE,EAAE+D,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASvE,GAAGjR,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAE,CAAC,IAAIC,GAAE9D,EAAE,EAAE,GAAG,CAACkG,GAAGzX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAAL9D,EAAE6D,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC/U,SAASlE,GAAGpR,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAE,CAAC,IAAIC,GAAEnE,EAAE,EAAE,GAAG,CAACmG,GAAG1X,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,CAAC,OAAO+G,GAAE,CAAM,GAALhL,EAAEkE,EAAC,EAAK8G,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASpM,GAAGpQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAACoG,GAAG3X,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASmP,GAAGjQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAACqG,GAAG5X,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACva,SAAS4P,GAAG1Q,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAE,CAAC,IAAIC,GAAE5D,EAAE,EAAE,GAAG,CAACsG,GAAG7X,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAAL5D,EAAE2D,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASpE,GAAGhR,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE,CAAC,IAAI+C,EAAEyN,EAAE,EAAE,GAAG,CAACuG,GAAG9X,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,CAAC,OAAO8E,EAAE,CAAM,GAAL2L,EAAE1N,CAAC,EAAK+B,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASkL,GAAG/Q,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAACwG,GAAG/X,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC3Z,SAAS8J,GAAG7K,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEoR,EAAE,EAAE,GAAG,CAAC,OAAO6K,GAAGpc,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALoR,EAAErR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgJ,GAAGpJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAAC,OAAO0G,GAAGjY,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS4P,GAAGrQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAAC2G,GAAGlY,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyO,GAAGlP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAAC4G,GAAGnY,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACza,SAAS2N,GAAGzO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE,CAAC,IAAI+C,EAAEyN,EAAE,EAAE,GAAG,CAAC6G,GAAGpY,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,CAAC,CAAC,OAAO8E,EAAE,CAAM,GAAL2L,EAAE1N,CAAC,EAAK+B,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS2D,GAAGxJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC,OAAO8G,GAAGrY,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS8N,GAAGtO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAE,CAAC,IAAIC,EAAEwQ,EAAE,EAAE,GAAG,CAAC+G,GAAGtY,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,CAAC,OAAOgD,EAAE,CAAM,GAAL0N,EAAEzQ,CAAC,EAAK+C,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS8K,GAAG5O,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE8Q,EAAE,EAAE,GAAG,CAACgH,GAAGvY,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL8Q,EAAE/Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC1d,SAASkP,GAAG5P,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAACiH,GAAGxY,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS+J,GAAG1K,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC,OAAOkH,GAAGzY,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS6K,GAAGnL,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAAC,OAAOoH,GAAG3Y,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASwK,GAAGpL,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAAC,OAAOmH,GAAG1Y,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAChd,SAAS0P,GAAGzQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAE,CAAC,IAAIC,EAAEwQ,EAAE,EAAE,GAAG,CAACqH,GAAG5Y,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,CAAC,OAAOgD,EAAE,CAAM,GAAL0N,EAAEzQ,CAAC,EAAK+C,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS0K,GAAGxO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAACsH,GAAG7Y,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuN,GAAGnO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE2Q,EAAE,EAAE,GAAG,CAACuH,GAAG9Y,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAAL0Q,EAAE5Q,CAAC,EAAKE,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASkP,GAAGhQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAACwH,GAAG/Y,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC/c,SAASuJ,GAAG/J,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE8Q,EAAE,EAAE,GAAG,CAAC,OAAO0H,GAAGjZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL8Q,EAAE/Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS0N,GAAGpO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE,CAAC,IAAI+B,EAAE0L,EAAE,EAAE,GAAG,CAAC2H,GAAGlZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,CAAC,OAAO8B,GAAE,CAAM,GAAL4L,EAAE3L,CAAC,EAAKD,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASqI,GAAGjO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE,CAAC,IAAI+B,EAAE0L,EAAE,EAAE,GAAG,CAAC4H,GAAGnZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,CAAC,OAAO8B,GAAE,CAAM,GAAL4L,EAAE3L,CAAC,EAAKD,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAClY,SAAS2I,GAAGvO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAE,CAAC,IAAIC,GAAElE,EAAE,EAAE,GAAG,CAACgI,GAAGvZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAED,GAAEoP,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,EAAC,CAAC,OAAOE,GAAE,CAAM,GAALlE,EAAEiE,EAAC,EAAKC,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS/F,GAAG3P,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAACiI,GAAGxZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASqI,GAAG9I,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAE,CAAC,IAAIC,EAAEwQ,EAAE,EAAE,GAAG,CAAC,OAAOkI,GAAGzZ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,CAAC,OAAOgD,EAAE,CAAM,GAAL0N,EAAEzQ,CAAC,EAAK+C,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACla,SAASkI,GAAGhM,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE,CAAC,IAAI+B,EAAE0L,EAAE,EAAE,GAAG,CAACmI,GAAG1Z,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,CAAC,OAAO8B,GAAE,CAAM,GAAL4L,EAAE3L,CAAC,EAAKD,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASsK,GAAGlQ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,EAAE,CAAC,IAAID,GAAE2L,EAAE,EAAE,GAAG,CAACuI,GAAG9Z,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE+B,CAAC,CAAC,OAAOmP,GAAE,CAAM,GAALxD,EAAE5L,EAAC,EAAKoP,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASnG,GAAG7O,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAACyI,GAAGha,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACvY,SAASsN,GAAGlO,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAE,CAAC,IAAIC,EAAEwQ,EAAE,EAAE,GAAG,CAAC8I,GAAGra,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,CAAC,OAAOgD,EAAE,CAAM,GAAL0N,EAAEzQ,CAAC,EAAK+C,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASwG,GAAGtK,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAAC,OAAOkJ,GAAGza,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASwK,GAAGjL,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC,OAAO+K,GAAGtc,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASqO,GAAG3O,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAACmJ,GAAG1a,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACzb,SAAS8J,GAAGvK,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE8Q,EAAE,EAAE,GAAG,CAAC,OAAOoJ,GAAG3a,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL8Q,EAAE/Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASiK,GAAG3K,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE8Q,EAAE,EAAE,GAAG,CAAC,OAAOqJ,GAAG5a,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL8Q,EAAE/Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASoO,GAAG9O,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAACsJ,GAAG7a,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS6O,GAAGpP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAACuJ,GAAG9a,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACzb,SAAS0I,GAAGtJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAAC,OAAOwJ,GAAG/a,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASoP,GAAG/P,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAACyJ,GAAGhb,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuJ,GAAG7J,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC,OAAO2J,GAAGlb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuI,GAAG/I,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIE,EAAEyQ,EAAE,EAAE,GAAG,CAAC,OAAO4J,GAAGnb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOG,EAAE,CAAM,GAALyQ,EAAE1Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAChc,SAAS0I,GAAGzJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAAC,OAAO6J,GAAGpb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASuI,GAAGlJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAE,CAAC,IAAIC,EAAEwQ,EAAE,EAAE,GAAG,CAAC,OAAO8J,GAAGrb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,CAAC,OAAOgD,EAAE,CAAM,GAAL0N,EAAEzQ,CAAC,EAAK+C,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgG,GAAG9J,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAAC,OAAO+J,GAAGtb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC5W,SAASwI,GAAGjJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,EAAE,CAAC,IAAI+B,EAAE0L,EAAE,EAAE,GAAG,CAAC,OAAOgK,GAAGvb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAEC,EAAE+C,CAAC,CAAC,OAAO8B,GAAE,CAAM,GAAL4L,EAAE3L,CAAC,EAAKD,KAAIA,GAAE,EAAE,MAAMA,GAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyE,GAAGrK,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE+Q,EAAE,EAAE,GAAG,CAAC,OAAOiK,GAAGxb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL+Q,EAAEhR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS+J,GAAGxK,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE6Q,EAAE,EAAE,GAAG,CAAC,OAAOkK,GAAGzb,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL6Q,EAAE9Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASyJ,GAAGpK,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEkR,EAAE,EAAE,GAAG,CAAC,OAAOmK,GAAG1b,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALkR,EAAEnR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CACvd,SAAS2O,GAAGjP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAE4Q,EAAE,EAAE,GAAG,CAACoK,GAAG3b,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAAL4Q,EAAE7Q,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS6O,GAAGzP,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,EAAE,CAAC,IAAIC,EAAEwQ,EAAE,EAAE,GAAG,CAAC2K,GAAGlc,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEE,CAAC,CAAC,OAAOgD,EAAE,CAAM,GAAL0N,EAAEzQ,CAAC,EAAK+C,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS+M,GAAG7Q,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAACwK,GAAG/b,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASgJ,GAAGvJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEiR,EAAE,EAAE,GAAG,CAAC,OAAOyK,GAAGhc,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALiR,EAAElR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAC1b,SAASqK,GAAG5K,EAAE,CAAC,IAAIC,EAAEsR,EAAE,EAAE,GAAG,CAAC,OAAOc,GAAGrS,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALsR,EAAEvR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAASiJ,GAAGnJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAIC,EAAEgR,EAAE,EAAE,GAAG,CAAC,OAAOiB,GAAGxS,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,OAAOE,EAAE,CAAM,GAALgR,EAAEjR,CAAC,EAAKC,IAAIA,EAAE,EAAE,MAAMA,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,SAAS8Q,GAAGtR,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,WAAW4R,GAAG5R,EAAE,UAAU0R,EAAE1R,EAAE,aAAa2R,EAAE3R,EAAE,aAAagE,GAAEhE,EAAE,aAAa,CAACG,EAAEC,EAAEC,IAAI0E,GAAG5E,EAAEuC,GAAEtC,EAAEC,CAAC,EAC1eL,EAAE,gBAAgB8E,GAAG,IAAI+X,GAAGvZ,GAAG,SAASwZ,GAAI,CAACD,IAAIE,GAAG,EAAEF,KAAKvZ,GAAGwZ,EAAG,EACjE,SAASC,IAAI,CAAC,SAAS5c,GAAG,CAAC,GAAG,CAAC0c,KAAKA,GAAG,GAAG7c,EAAE,UAAU,GAAG,CAACuC,GAAG,CAAiE,GAAhE4B,GAAGlB,EAAE,EAAEhD,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAKA,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAEkD,GAAG,QAAQ9C,CAAC,CAAC,CAAC+D,GAAGjB,EAAE,CAAC,CAAC,CAAC,GAAG,EAAE,EAAEE,IAAG,CAAC,GAAGpD,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQmD,GAAG,EAAEgB,GAAGnB,EAAE,EAAE,EAAEI,KAAIpD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EAAE,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAC5e,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAA+c,GAAG,EAGvGhd,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAO,IC7J1B,IAAAmd,GAAAC,GAAA,QCAA,IAAAC,GAAAC,GAAA,QCAA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,GAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAmB,IAAM,CAC3B,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,SAASC,GAAG,CAAC,OAAAC,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASD,EAAC,CAAC,SAASE,GAAG,CAAC,OAAAH,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASE,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAL,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASI,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAP,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASM,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAT,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASQ,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAX,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASU,EAAE,CAAC,IAAIC,EAAEf,EAAUgB,EAAG,EAAED,EAAE,MAAM,IAAI,QAAQ,CAACE,EAAEC,IAAI,CAACF,EAAGC,EAAE,EAAEC,CAAC,CAAC,EACrVH,EAAE,SAAS,CAACE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,KAAI,CAACT,EAAE,GAAGE,EAAEF,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,GAAER,EAAE,GAAGS,GAAEN,EAAE,CAACO,GAAEC,GAAEC,KAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,KAAI,EAAEE,GAAEH,GAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,KAAI,EAAE,OAAAK,IAAIC,KAAIP,GAAEO,GAAEL,GAAEI,CAAC,EAAEL,GAAEC,GAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,IAAG,SAASC,KAAI,CAAC,GAAG,CAAC,GAAGX,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMY,GAAEZ,EAAE,GAAG,CAAC,GAAGW,GAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,GAAE,GAAGC,EAAC,EAAE,GAAGX,EAAE,KAAKY,GAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,GAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQb,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQI,EAAED,EAAEH,EAAE,QAAQ,IAAIA,EAAE,QAAQU,IAAGV,EAAE,QAAQU,EAAC,CAAC,EAAEV,EAAE,mBAAmBI,EAAED,EAAEH,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBU,IAAGV,EAAE,mBAAmBU,EAAC,CAAC,EAAEV,EAAE,cAAcG,EAAEH,EAAE,cAAc,IAAIA,EAAE,cAAcU,IAAGV,EAAE,cAAcU,EAAC,EAAEV,EAAE,mBAAmB,CAACU,GAAEC,GAAEC,GAAEC,KAAIX,EAAE,eAAeQ,GAAEC,GAAEC,GAAEC,EAAC,EAAEb,EAAE,sBAAsBU,IAAG,CAACR,EAAE,kBAAkBQ,EAAC,CAAC,EAAEV,EAAE,cAAcU,IAAGR,EAAE,UAAUQ,EAAC,EAAEV,EAAE,qBAAqB,CAACU,GAAEC,GAAEC,KAAIV,EAAE,iBAAiBQ,GAAEC,GAAEC,EAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEnB,CAAC,EAAEoB,EAAG,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAY,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAEzB,EAAE,wBAAwB,GAAG0B,EAAE,GAAG,SAASC,EAAGzB,EAAE,CAAC,OAAOF,EAAE,WAAWA,EAAE,WAAWE,EAAEwB,CAAC,EAAEA,EAAExB,CAAC,CAAC,IAAI0B,EAAGC,EAAEC,EAC7U,GAAGN,EAAE,CAAC,IAAIO,EAAG,cAAcC,EAAG,cAAgBN,EAAEH,EAAES,EAAG,QAAQN,CAAC,EAAE,IAAI,UAAU,IAAIE,EAAG,CAACzB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE6B,EAAG,UAAU7B,CAAC,EAAS4B,EAAG,aAAa5B,EAAEC,EAAE,OAAO,MAAM,GAAG0B,EAAG3B,IAAIA,EAAEyB,EAAGzB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAG0B,EAAE,CAAC1B,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE6B,EAAG,UAAU7B,CAAC,EAAE4B,EAAG,SAAS5B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,KAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,GAAE,OAAOA,EAAC,CAAC,CAAC,CAAC,EAAE,CAACR,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASoB,EAAG,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAAClB,EAAEC,IAAI,CAAC,cAAQ,SACtfD,EAAQC,CAAE,EAAEJ,EAAE,QAAQ,IAAI,6BAA6B,IAAIE,EAAE,GAAG,CAACA,EAAE,IAAyB,OAAOC,EAAE,CAAC,MAAM,QAAQ,MAAM,yGAAyG,EAAEA,CAAE,CAAC,OAAO,OAAOD,EAAE,MAAM,MAASoB,GAAIC,KAAEA,EAAEG,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAM,OAAO1C,EAAe,KAAeA,IAAc0C,EAAE1C,GAAgB0C,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGF,IAAII,EAAG1B,GAAG,CAAC,IAAIC,EAC9hB,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIO,EAAG5B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GAAG0B,EAAE,CAAC3B,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,IAAGmB,GAAgB,OAAO,YAApB,MAAkC,OAAO,YAAY,KAAsB,aACrd,IAAIS,GAAG,QAAQ,IAAI,KAAK,OAAO,EAAEC,GAAG,QAAQ,MAAM,KAAK,OAAO,EAAEV,IAAIS,GAAG,IAAI/B,IAAI6B,EAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,EAAEgC,GAAG,IAAIhC,IAAI6B,EAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,GAAG,IAAIiC,EAAGnC,EAAE,OAAOiC,GAAGG,GAAEpC,EAAE,UAAUkC,GAAG,OAAO,OAAOlC,EAAEmB,CAAE,EAAEA,EAAG,KAAKnB,EAAE,cAAcoB,EAAGpB,EAAE,aAAaA,EAAE,OAAOqB,EAAErB,EAAE,MAAM,IAAIqC,GAAErC,EAAE,aAAaqC,GAAErC,EAAE,YAAY,IAAIsC,GAActC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BuC,GAAE,iCAAiC,EAAE,IAAIpD,GAAEqD,GAAEC,GAAGC,GAAE,GAAGC,GAAEvD,GAAEG,GAAGE,GAAGE,GAAGE,GAAGE,GAChc,SAASV,IAAG,CAAC,IAAIa,EAAEf,GAAE,OAAOa,EAAE,MAAMZ,GAAE,IAAI,UAAUc,CAAC,EAAEF,EAAE,OAAO,IAAI,WAAWE,CAAC,EAAEF,EAAE,OAAOP,GAAG,IAAI,WAAWS,CAAC,EAAEF,EAAE,OAAOT,GAAG,IAAI,WAAWW,CAAC,EAAEF,EAAE,QAAQ,IAAI,YAAYE,CAAC,EAAEF,EAAE,QAAQL,GAAG,IAAI,YAAYO,CAAC,EAAEF,EAAE,QAAQH,GAAG,IAAI,aAAaK,CAAC,EAAEF,EAAE,QAAQD,GAAG,IAAI,aAAaG,CAAC,CAAC,CAAC,IAAI0C,GAAG5C,EAAE,gBAAgB,SACtS,GAD+S,SAAS4C,IAAIL,GAAE,wDAAwDK,GAAG,wBAAwB,EAC9YnB,EAAEtC,GAAEa,EAAE,mBAAmBA,EAAE,WAAWb,GAAEa,EAAE,mBAAmBb,GAAE,IAAI,YAAY,OAAO,CAAC,QAAQyD,GAAG,MAAM,QAAQ,MAAM,OAAO,EAAE,CAAC,EAAE,EAAEzD,GAAE,kBAAkB,mBAAmB,MAAMiD,GAAE,6NAA6N,EAAEZ,GAAGY,GAAE,2GAA2G,EACrgB,MAAM,YAAY,EAAE/C,GAAE,EAAEuD,GAAGzD,GAAE,OAAO,WAAW,IAAI0D,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAE,SAASC,IAAI,CAAC,OAAOX,IAAe,EAAEU,EAAE,CAAC,IAAIE,GAAE,EAAEC,GAAG,KAAKC,GAAE,KAAK,SAASC,IAAI,CAACH,KAAIlD,EAAE,wBAAwBA,EAAE,uBAAuBkD,EAAC,CAAC,CAAC,SAASI,IAAI,CAA2D,GAA1DJ,KAAIlD,EAAE,wBAAwBA,EAAE,uBAAuBkD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIlD,EAAEkD,GAAEA,GAAE,KAAKlD,EAAE,CAAC,CAAC,CAClW,SAASqC,GAAErC,EAAE,CAAC,MAAGF,EAAE,SAAQA,EAAE,QAAQE,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAIkC,GAAElC,CAAC,EAAEwC,GAAE,GAAGC,GAAE,EAAEzC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAE,EAAEA,CAAC,EAAQA,CAAE,CAAC,SAASqD,GAAGrD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIsD,GAAEA,GAAE,8BAA8BD,GAAGC,EAAC,IAAIA,GAAE7B,EAAG6B,EAAC,GAAG,SAASC,GAAGvD,EAAE,CAAC,GAAGA,GAAGsD,IAAGnB,GAAE,OAAO,IAAI,WAAWA,EAAC,EAAE,GAAGP,EAAG,OAAOA,EAAG5B,CAAC,EAAE,KAAK,iDAAkD,CACpa,SAASwD,GAAGxD,EAAE,CAAC,GAAG,CAACmC,KAAIf,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIsD,GAAGvD,CAAC,CAAC,EAAE,GAAG2B,EAAE,OAAO,IAAI,QAAQ,CAAC1B,EAAEC,IAAI,CAACyB,EAAE3B,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIqD,GAAGvD,CAAC,CAAC,CAAC,CAAC,SAASyD,GAAGzD,EAAEC,EAAEC,EAAE,CAAC,OAAOsD,GAAGxD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC+B,GAAE,0CAA0C/B,CAAC,EAAEkC,GAAElC,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASuD,GAAG1D,EAAEC,EAAE,CAAC,IAAIC,EAAEoD,GAAE,OAAOnB,IAAe,OAAO,YAAY,sBAA/B,YAAqDkB,GAAGnD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAe,OAAO,OAAnB,WAAyBmC,GAAGvD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA8B,GAAE,kCAAkC9B,CAAC,EAAE8B,GAAE,2CAA2C,EAASuB,GAAGvD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC7W,IAAI0D,GAAEC,GAAG,CAAC,OAAO5D,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,QAAQE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,aAAaE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,UAAUE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OACxfE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,QAAQE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,QAAQE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,QAAQE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOE,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACH,EAAE,GAAG,MAAME,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACH,EAAE,GAAG,YAAYE,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACH,EAAE,GAAG,kBAC1fE,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACH,EAAE,GAAG,OAAOE,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,MAAME,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,QAAQE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,UAAUE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,iBAAiBE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,cAAcE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,aAAaE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IACpgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,YAAYE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,YAAYE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,aAAaE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,YAAYE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IACjgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,WAAWE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,WAAWE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,eAAeE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,kBAAkBE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IACvgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,kBAAkBE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACF,EAAE,GAAG,QAAQE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYE,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKX,EAAE,EAAE,SAASY,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAACjB,EAAE,GAAG,gBAAgBE,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAACvB,EAAE,EAAEyB,KAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KACxf,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASwB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAAChB,EAAE,GAAG,gBAAgBE,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKX,EAAE,EAAE,SAASY,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKf,EAAE,EAAE,SAASgB,KAAI,EAAEA,GAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACtB,EAAE,EAAEwB,KAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAKnB,EAAE,EAAE,SAASoB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KACrgB,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAACjB,EAAE,GAAG,gBAAgBE,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAACvB,EAAE,EAAEyB,KAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASwB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAAChB,EAAE,GAAG,gBAAgBE,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKX,EAAE,EAAE,SAASY,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EACnf,MAAMC,EAAE,YAAY,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKf,EAAE,EAAE,SAASgB,KAAI,EAAEA,GAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACtB,EAAE,EAAEwB,KAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAKnB,EAAE,EAAE,SAASoB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,IAAI,CAACH,EAAE,GAAG,oBAAoBE,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAAChE,EAAE,GAAG,cAAcE,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EACpgB,cAAcC,EAAE,UAAU,CAACC,EAAEC,EAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACH,EAAE,GAAG,oBAAoBE,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAAChE,EAAE,GAAG,cAAcE,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,EAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACH,EAAE,GAAG,gBAAgBE,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAAChE,EAAE,GAAG,UAAUE,EAAE,CAAC,OAAO8D,GACnf,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,EAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACH,EAAE,GAAG,gBAAgBE,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAAChE,EAAE,GAAG,UAAUE,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,EAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,OAAOE,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACF,EAAE,GAAG,SACvfE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,SAASE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,SAASE,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACH,EAAE,GAAG,UAAUE,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACH,EAAE,GAAG,SAASE,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,QAAQE,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACF,EAAE,GAAG,SAASE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACH,EAAE,GAAG,SAASE,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACH,EAAE,GAAG,iBAAiBE,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAChgB,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,KAAI,CAACZ,EAAE,GAAG,SAASE,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,GAAE,mBAAmBC,GAAE,sBAAsBsD,GAAErD,EAAC,EAAE,KAAKqD,GAAEpD,EAAC,EAAE,YAAYoD,GAAEnD,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACR,EAAE,GAAG,QAAQE,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKX,EAAE,EAAE,SAASY,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKf,EAAE,EAAE,SAASgB,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACJ,EAAE,GAAG,qBACtfE,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACJ,EAAE,GAAG,wBAAwBE,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACJ,EAAE,GAAG,wBAAwBE,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACF,EAAE,GAAG,QAAQE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACH,EAAE,GAAG,SAASE,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,MAAME,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,qBAAqBE,EAAE,CAAC,QAAQC,EAAE,SAASC,EAAE,QAAQ,CAAC,CAACE,EAAE,aAAa,CAAC,CAACD,EAAE,OAAOE,EACzf,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACL,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,qBAAqBE,EAAE,CAAC,QAAQC,EAAE,SAASC,EAAE,QAAQ,CAAC,CAACE,EAAE,aAAa,CAAC,CAACD,EAAE,OAAOE,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACL,EAAEC,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASE,EAAE,CAAC,UAAU,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,KAAI,CAACV,EAAE,GAAG,YAAYE,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,EAAE,eAAeC,GAAE,MAAM,KAAKhB,EAAE,EAAE,SAAS,OAAOiB,EAAC,IAAI,EAAE,OAAOA,EAAC,EAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,uBAAuB,CAAC,CAACE,EAAC,CAAC,CAAC,EAAE,OAAOR,GAAG,CAACF,EAAE,GAAG,OAAOE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,qBACxfE,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACF,EAAE,GAAG,UAAUE,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACF,EAAE,GAAG,gBAAgBE,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACH,EAAE,GAAG,yBAAyBE,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,KAAI,CAACd,EAAE,GAAG,OAAOE,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKf,EAAE,EAAE,SAASgB,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAC,EAAE,WAAW,IAAI,CAAC,CAACvB,EAAE,EAAEyB,KAAI,CAAC,EAAE,WAAWoD,GAAEnD,EAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAKjB,EAAG,EAAE,SAASkB,KAAI,EAAEA,GAAED,KAClf,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAAChE,EAAE,GAAG,OAAOE,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,EAAC,EAAE,KAAKC,GAAE,MAAM,KAAKjB,EAAE,EAAE,SAASkB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,GAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC1B,EAAE,EAAE4B,KAAI,CAAC,EAAE,WAAWiD,GAAE/C,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAKrB,EAAG,EAAE,SAASoE,KAAI,EAAEA,GAAE/C,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOf,GAAG,CAACF,EAAE,GAAGE,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIH,EAAE,GAAGE,EAAEC,EAAEH,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOE,GAAGF,EAAE,GAAGE,CAAC,EAAE,OAAOA,GAAGF,EAAE,GAAGE,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACJ,EAAE,GAAGE,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACJ,EAAE,GAAGE,EAAEC,EAAEC,CAAC,CAAC,CAAC,EACle,SAAS6D,GAAG/D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,SAASgE,GAAGhE,EAAE,CAACA,EAAE,UAAU,EAAEA,EAAE,UAAU,IAAI,CAAC,CAAC,CAAC,SAASiE,GAAGjE,EAAE,EAAEA,EAAEkE,GAAE,GAAGlE,CAAC,IAAIqC,GAAE,EAAE6B,GAAE,GAAGlE,CAAC,CAAC,CAAC,SAASmE,GAAGnE,EAAE,CAAC,IAAIC,EAAEiE,GAAE,GAAG,EAAE,GAAG,CAACjE,EAAE,MAAO,GAAEiE,GAAE,GAAG,KAAKjE,CAAC,EAAEiE,GAAE,GAAGlE,EAAE,EAAE,EAAEC,EAAEA,EAAE,GAAGD,EAAE,GAAG,IAAIE,EAAE,CAAC,IAAI,MAAM,cAAcF,EAAE,GAAG,IAAIA,EAAE,GAAG,YAAYA,EAAE,EAAE,EAAE,OAAAsB,GAAGrB,EAAE,MAAM,EAAEA,EAAE,YAAYC,EAAEF,EAAE,EAAE,EAAS,CAAC,CACvX,IAAIoE,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACrE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQoE,GAAG,OAAOA,GAAG,OAAOpE,EAAE,kBAAkB,kBAAkBA,EAAE,MAAMC,EAAEC,CAAC,EAAEF,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,GAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,IAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,IAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GACpf,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EAAE0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAGqE,GAAGjF,EAAE,EAAEY,EAAEC,CAAC,EAAE,GAAG,SAASqE,GAAGtE,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,GAAE,EAAE,EAAEvE,CAAC,EAAEyC,GAAEzC,EAAM+C,GAAG,IAAGmB,GAAE,GAAG,EAAKpE,EAAE,QAAOA,EAAE,OAAOE,CAAC,EAAEwC,GAAE,IAAGrB,EAAEnB,EAAE,IAAI+D,GAAG/D,CAAC,CAAC,CAAC,CACjM,IAAIwE,GAAGxE,GAAG,CAAK,GAAJyC,GAAEzC,EAAKuB,EAAE,MAAMkD,GAAGzE,CAAC,EAAE,SAASsE,GAAGtE,CAAC,CAAC,EAAEkE,GAAE,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAAC3C,EAAE2C,GAAE,GAAG,EAAEA,GAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAACvB,GAAG,QAAQ,IAAI,CAACQ,GAAG,EAAEe,GAAE,GAAG,IAAId,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,UAAU,CAACc,GAAE,sBAAsBA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAG9B,GAAc,EAAE,EAAE,GAAG,SAASpC,EAAE,CAACyC,GAAEzC,CAAC,EAAE,GAAG,CAAC,kBAAkB,EAAE,GAAG,UAAU,CAAC,QAAQA,KAAKkE,GAAE,GAAGF,GAAGhE,CAAC,EAAE,IAAIA,KAAKkE,GAAE,GAAGF,GAAGhE,CAAC,EAAEkE,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,CAAC,EAAE,GAAG,SAASlE,EAAE,CAAC,IAAIC,EAAED,EAAE,GAAG,OAAOkE,GAAE,GAAGjE,CAAC,EAAEiE,GAAE,GAAG,KAAKlE,CAAC,EAAEkE,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQlE,CAAC,EAAE,CAAC,EAAEA,EAAE,GAAG,EAAE0E,GAAGzE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,EACtf,GAAG,UAAU,CAACiE,GAAE,GAAG,QAAQlE,GAAGA,EAAE,CAAC,CAAC,EAAE,GAAGA,GAAG,IAAI,QAAQC,GAAG,CAACD,EAAE,UAAUK,GAAG,CAACA,EAAEA,EAAE,KAAK,IAAIC,GAAED,EAAE,IAAI,GAAGA,EAAE,cAAcA,EAAE,cAAcsE,GAAG,EAAE,CAAC,IAAIpE,GAAE2D,GAAE,GAAG7D,EAAE,EAAE,EAAEE,GAAEA,GAAE,YAAYF,EAAEA,EAAE,YAAY,EAAE6B,GAAE,0CAA0C5B,GAAE,uBAAuBD,EAAE,aAAa,qCAAqC,CAAC,MAA0BC,KAAjB,eAAmBsE,GAAG,EAA0BtE,KAAhB,cAAkB6D,GAAG9D,CAAC,EAA4BC,KAAlB,gBAAoB2D,GAAG5D,EAAE,MAAM,EAAyBC,KAAf,cAAiBD,EAAEA,EAAE,OAAOC,GAAE4D,GAAE,GAAG7D,CAAC,EAAE,OAAO6D,GAAE,GAAG7D,CAAC,EAAE2D,GAAG1D,EAAC,EAAEoE,GAAGrE,CAAC,EAAE6D,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQ5D,EAAC,EAClgB,CAAC,EAAEA,GAAE,GAAG,GAA2BA,KAAjB,eAAmB4D,GAAE,GAAG7D,EAAE,MAAM,EAAE,YAAY,CAAC,IAAI,QAAQ,CAAC,EAAqBC,KAAX,UAAaN,EAAE,OAAO,GAAGC,EAAED,CAAC,GAAoBM,KAAV,QAAY,MAAM,UAAUD,EAAE,SAAS,KAAKA,EAAE,IAAI,EAA2BA,EAAE,SAAnB,eAA0BL,EAAE,YAAYK,CAAC,EAA0BC,KAAhB,cAAkBR,EAAEO,EAAE,OAAO,EAAE,GAAGA,EAAE,IAAI,EAAOC,IAAG4B,GAAE,kCAAkC5B,EAAC,CAAC,EAAEN,EAAE,QAAQK,GAAG,CAAC,MAAA6B,GAAE,yBAAyB7B,EAAE,SAAS,IAAIA,EAAE,OAAO,KAAKA,EAAE,OAAO,EAAQA,CAAE,EAAEiB,IAAItB,EAAE,GAAG,UAAU,SAASK,EAAE,CAACL,EAAE,UAAU,CAAC,KAAKK,CAAC,CAAC,CAAC,CAAC,EAAEL,EAAE,GAAG,QAAQ,SAASK,EAAE,CAACL,EAAE,QAAQK,CAAC,CAAC,CAAC,GAC/f,IAAIH,EAAE,CAAC,EAAEC,EAAE,CAAC,SAAS,UAAU,QAAQ,UAAU,EAAEC,EAAE,IAAIA,KAAKD,EAAEL,EAAE,eAAeM,CAAC,GAAGF,EAAE,KAAKE,CAAC,EAAEJ,EAAE,YAAY,CAAC,IAAI,OAAO,SAASE,EAAE,UAAUJ,EAAE,qBAAqBhB,EAAW,WAAWG,GAAE,WAAWsD,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,SAASvC,EAAE,CAACA,EAAE,CAAC,EAAE,GAAG,UAAU,CAAC,IAAIA,EAAEyB,EAAG,kCAAkC,EAAEzB,EAAE,IAAI,OAAOA,CAAC,EAAEkE,GAAE,GAAG,KAAKlE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,OAAGkE,GAAE,GAAG,QAAR,IAAiBA,GAAE,GAAG,EAAEA,GAAE,GAAGA,GAAE,GAAG,CAAC,CAAC,GAAUA,GAAE,GAAG,IAAI,CAAC,CAAC,EAAEpE,EAAE,QAAQoE,GAAE,IAAIW,GAAG7E,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEF,CAAC,CAAC,EACzbA,EAAE,oBAAoB,UAAU,CAAC,IAAIE,EAAE2E,GAAG,EAAE1E,EAAEX,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAEV,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAE8E,GAAG7E,EAAEA,EAAED,CAAC,EAAE+E,GAAG9E,CAAC,CAAC,EAAE,SAASwE,GAAGzE,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,GAAE,EAAE,EAAEvE,CAAC,EAAEwE,GAAGxE,CAAC,CAAC,CAACF,EAAE,iBAAiB,SAASE,EAAEC,EAAE,CAACD,EAAEgF,GAAG,MAAM,KAAK,CAAChF,EAAEC,CAAC,CAAC,EAAE8C,GAAG,EAAEmB,GAAE,GAAGlE,CAAC,EAAEiF,GAAGjF,CAAC,CAAC,EAAE,SAASkF,GAAGlF,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACT,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAES,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACT,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAES,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACV,EAAE,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI2F,GAAG,EAAEC,GAAG,EAC/b,SAASC,GAAGrF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAEgD,GAAE,EAAE,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAEmF,GAAGtF,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASmF,GAAGtF,EAAEC,EAAEC,EAAEC,EAAE,CAA6B,GAA5BH,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAkB,OAAO,kBAApB,IAAsC,OAAO+B,GAAE,qFAAqF,EAAE,EAAE,IAAI9B,EAAE,CAAC,EAAE,OAAGmB,GAAOnB,EAAE,SAAN,EAAoBiF,GAAGrF,EAAEC,EAAEC,EAAEC,CAAC,GAAEH,EAAE,CAAC,GAAGE,EAAE,GAAGF,EAAE,GAAGG,EAAE,GAAGC,CAAC,EAASmB,GAAGvB,EAAE,GAAG,cAAc,YAAYA,EAAEI,CAAC,EAAE,GAAG+D,GAAGnE,CAAC,EAAC,CAAC,SAASuF,GAAGvF,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAEgD,GAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAASsF,GAAGxF,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,GAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CACrc,IAAIwF,GAAGzF,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEyF,GAAG,CAAC1F,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,GAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,IAAG,OAAOA,GAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,GAAE,QAAQA,GAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,GAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,EAAC,KAAK,CAAC,GAAG,MAAMA,GAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,IAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,GAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,IAAG,EAAE,KAAK,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,IACpf,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,IAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,IAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEuF,GAAG,CAAC3F,EAAEC,EAAEC,IAAIwF,GAAG1F,EAAEZ,EAAE,EAAEa,EAAEC,CAAC,EAAE,SAAS0F,GAAG5F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,GAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG7F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,GAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG9F,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAEgD,GAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAAS6F,GAAG/F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,GAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGhG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGjG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGlG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASgG,GAAGnG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAC9d,SAASiG,EAAGpG,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,CAAC,CAAC,CAAC,SAASqG,GAAGrG,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAASqG,EAAGtG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIqG,EAAGvG,GAAG,CAAC,GAAG,CAACwC,GAAE,GAAG,CAAC,GAAGxC,EAAE,EAAE,CAAC+C,GAAG,EAAE,GAAG,CAACxB,EAAE0D,GAAGxC,EAAC,EAAE+B,GAAG/B,EAAC,CAAC,OAAOxC,EAAE,CAACA,aAAa8D,IAAc9D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa8D,IAAc9D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,EAAE,SAASuG,GAAGxG,EAAE,CAACA,KAAK,EAAe,OAAO,QAAQ,IAA5B,aAAiC,QAAQ,GAAGV,EAAE,EAAEU,GAAG,EAAEA,CAAC,EAAE,MAAM,KAAK4E,EAAE,EAAE5E,GAAG,IAAI,QAAQ,MAAMV,EAAE,EAAEU,GAAG,EAAE,CAAC,EAAE,CAACF,EAAE,kCAAkC0G,GAAG,SAAS5B,IAAI,CAAC,IAAI5E,EAAE2E,GAAG,EAAE3E,IAAIwG,GAAGxG,CAAC,EAAEuG,EAAG,IAAIE,GAAG,CAAC,EAAE,CAAC3G,EAAE,aAAa8E,GACpf,IAAI8B,GAAE1G,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAW2G,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAE,SAASC,GAAG7G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAE,CAAC,OAAOgB,EAAEgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,GAAG,CAAC,SAASuG,GAAG9G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAE,CAAC,GAAGiB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,CAAC,CAAC,IAAIyG,GAAG/G,GAAG,CAAC,IAAIC,EAAEwF,GAAGzF,CAAC,EAAE,EAAEE,EAAE8G,GAAG/G,CAAC,EAAE,OAAAC,GAAGyF,GAAG3F,EAAEE,EAAED,CAAC,EAASC,CAAC,EAAE+G,GAAG,CAAC,EAAEC,GAAG,CAAClH,EAAEC,IAAI,CAACgH,GAAG,OAAO,EAAE,IAAI/G,EAAE,IAAID,IAAI,EAAEC,EAAEd,EAAE,EAAEY,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAEgH,GAAG,KAAU/G,GAAL,IAAOZ,EAAE,EAAEW,IAAI,CAAC,EAAEL,EAAG,EAAEK,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAOgH,EAAE,EAAEE,GAAGnH,GAAG,CAAC,IAAIC,EAAEmH,GAAG,EAAE,OAAApH,EAAEA,EAAE,EAAE+E,GAAG9E,CAAC,EAASD,CAAC,EACve,SAASuE,GAAEvE,EAAEC,EAAE,CAAC,IAAIC,EAAE,UAAU,OAAO,EAAEC,EAAE,UAAU,OAAOgH,GAAG,IAAI,CAAC,QAAQ/G,EAAEiH,GAAG,EAAEnH,CAAC,EAAEG,EAAED,GAAG,EAAEE,GAAE,EAAEA,GAAEJ,EAAEI,KAAI,CAAC,IAAIC,GAAEJ,EAAE,EAAEG,EAAC,EAAEV,EAAG,EAAES,EAAEC,KAAI,CAAC,EAAEC,EAAC,CAAC,OAAO+G,GAAGtH,EAAEE,EAAEE,EAAEH,CAAC,CAAC,CAAC,CAAC,CAC3J,IAAIsH,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAI1H,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IAAI,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAI,gBAAgB,EAAEjB,EAAE,IAAIA,KAAKuH,GAAYA,GAAGvH,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAEuH,GAAGvH,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEyH,GAAGxH,CAAC,CAAC,OAAOwH,EAAE,EAAEA,GACtW,SAASC,GAAG3H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAAuH,GAAG,EAAE,QAAQ,SAAStH,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAwB,IAAtBE,EAAEZ,EAAE,EAAEQ,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAErB,EAAE,EAAEoB,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAErB,EAAE,EAAEoB,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,CAAC,SAASyH,GAAG5H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAEuH,GAAG,EAAEjI,EAAE,EAAEQ,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEZ,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,CAAC,SAAS0H,GAAG7H,EAAE,CAAC,OAAOuB,EAAEgD,GAAE,GAAG,EAAEvE,CAAC,EAAE,EAAE,CAAC,SAAS8H,GAAG9H,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAEgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAC/c,SAAS4H,GAAG/H,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmB,EAAEgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAAC,IAAI4H,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,SAASC,GAAGjI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,GAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAEF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,GAAEd,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEM,GAAEf,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,GAAE,EAAEA,GAAED,GAAEC,KAAI,CAAC,IAAIC,GAAErB,EAAE,EAAEkB,GAAEE,KAAI,CAAC,EAAEE,GAAEsH,GAAGhI,CAAC,EAAMS,KAAJ,GAAYA,KAAL,KAAaT,IAAJ,EAAMiC,EAAGC,IAAGmC,GAAG3D,GAAE,CAAC,CAAC,EAAEA,GAAE,OAAO,GAAGA,GAAE,KAAKD,EAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAf,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,CAAC,IAAI8H,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGpI,EAAE,CAAC,IAAIC,EAAE,MAAMwF,GAAGzF,CAAC,EAAE,CAAC,EAAE,OAAA0F,GAAG1F,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACjf,IAAIoI,GAAG,CAACrI,EAAEC,IAAI,CAACjB,EAAE,EAAE,IAAIgB,EAAEC,IAAI,CAAC,CAAC,EAC/B,SAASqI,GAAGtI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE+C,GAAE,CAAC,IAAIhD,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAEgD,GAAE,CAAC,EAAEhD,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,GAAEQ,EAAEC,GAAE,CAAC,SAAS+C,GAAEyE,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE1E,GAAEhD,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDyH,GAAE1E,GAAEhD,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCyH,GAAE1E,GAAEhD,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUyH,EAAC,CAAC,SAASjI,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,GAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI+C,GAAEhD,EAAE,SAAS,EAAE0H,IAAG9B,GAAE5F,EAAE,YAAY,CAAC,EAAEoH,GAAGC,IAAIrE,EAAC,EAAE,GAAG/C,GAAEyH,GAAE1H,EAAE,QAAQ,EAAEC,IAAGyH,GAAE1H,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAGgD,GAAEhD,EAAE,SAASgD,GAAE,CAAC,GAAGhD,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA+C,GAAE,IAAI,KAAKhD,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAEgD,GAAEvD,GAAEuD,EAAC,EAAS,GAAGxD,GAAES,GAAED,CAAC,EAAE,GAAGR,GAAEwD,GAAEhD,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,GAAEnB,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGb,EAAE,EAAEa,GAAG,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGb,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,GAAEoD,GAAEpD,EAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,GAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WACxf,MAAM,KAAK,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,MAAKD,GAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,GAAEC,EAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,GAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GACzfF,GAAEE,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,GAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,GAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE+C,GAAE,EAAEA,IAAGhD,EAAE,GAAG,EAAEC,KAAI2F,GAAE5F,EAAE,GAAG,IAAI,EAAEoH,GAAGC,IAAIrE,IAAG,EAAE,CAAC,OAAOzD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GACnf,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ+C,IAAGhD,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAKgD,IAAH,GAASA,IAAH,GAAM4C,GAAE5F,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI+C,IAAGhD,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAMgD,IAAH,GAASA,IAAH,GAAM4C,GAAE5F,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,MAAKD,GAAEP,EAAE,SAASQ,EAAC,IACrgBR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,GAAEC,EAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,GAAE0H,GAAGlI,CAAC,EAAKQ,GAAE,OAAOT,EAAS,GAAEoI,GAAG3H,GAAEV,CAAC,EAASU,GAAE,OAAO,EAAC,CAAC,SAAS+H,GAAGzI,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACoC,GAAEpC,CAAC,CAAC,CAAC,CAAC,SAASyI,GAAG1I,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACuI,GAAG,KAAKxI,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQoC,KAAImG,GAAG,IAAI,IAAIxI,GAAGkC,GAAE,EAAExB,IAAO+H,KAAJ,GAAWD,GAAG,SAAP,IAAgBC,GAAE,EAAE9F,IAAI,EAAE2F,GAAGI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAEzI,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI2I,GAAE,EAAE/H,GAAE,KAAKiI,GAAG,EAAEH,GAAG,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC7e,SAASnI,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACiJ,GAAG,CAAC,QAAQlJ,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASmJ,IAAI,CAAC,IAAIpJ,EAAEgH,GAAG,KAAK,EAAE/G,EAAED,EAAE,GAAGR,EAAE,EAAEQ,GAAG,IAAI,CAAC,EAAEC,EAAET,EAAE,EAAEQ,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE0I,GAAG,CAAC,EAAE,IAAIzI,EAAE6I,GAAG9I,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE+I,KAAKF,GAAG9I,CAAC,EAAEC,EAAE8I,GAAG9I,CAAC,EAAED,GAAGA,EAAEC,EAAEZ,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEC,EAASD,CAAC,CAAC,SAASqJ,IAAI,CAAC,IAAIrJ,EAAEV,EAAE,EAAEuB,GAAE,GAAG,IAAI,CAAC,EAAE,OAAAb,EAAEsC,GAAE0G,GAAGhJ,CAAC,CAAC,EAAE,EAAE8C,GAAU9C,EAAE,CAAC,CACtS,SAASsJ,GAAGtJ,EAAE,CAAC,GAAG,CAACwC,GAAE,CAAC,GAAOoG,KAAJ,EAAM,CAAC,IAAI3I,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACqC,KAAIsG,GAAG3I,EAAEF,EAAE,GAAGC,GAAG,CAAC0I,GAAE,EAAEH,GAAG,IAAIc,GAAG1I,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,EAAEiJ,GAAG,CAAC,OAAO9I,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,GAAE4I,GAAG5I,KAAI4I,GAAG,MAAM/I,EAAEG,GAAE,OAAOA,GAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI2I,GAAE,EAAE/H,GAAEuI,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAG,IAAIe,GAAG3I,EAAC,CAAC,EAAE,MAAU+H,KAAJ,GAAOA,GAAE,EAAEH,GAAGgB,EAAE,EAAEC,GAAG7I,EAAC,EAAEA,GAAE,KAAKsI,GAAG,QAAQhJ,GAAGoG,EAAGpG,CAAC,CAAC,GAAGkC,GAAE,kBAAkBuG,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAC/d,SAASa,GAAG3J,EAAE,CAAC,OAAOsJ,GAAGrJ,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CAACiE,GAAE,GAAG,EAChD,IAAI0F,GAAG,CAAC,KAAKtF,GAAGG,GAAGY,GAAGE,GAAGC,GAAGI,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,EAAGC,GAAGC,EAAGO,GAAGC,GAAGa,GAAGC,GAAGC,GAAGC,GAAGC,GAAGE,EAAE,EAAE4B,GAAG,CAAC,EAAE,SAAS7J,EAAEC,EAAEC,EAAE,CAAC,OAAOyJ,GAAG,SAAS,CAAC,MAAM7J,EAAE,GAAGE,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIkF,GAAGlF,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEiF,GAAGnF,EAAEoF,KAAWD,EAAG,EAAE,EAAE,SAASnF,EAAE,CAAC8J,GAAG9J,IAAI,EAAE,CAACqB,EAAE,EAAE,CAACD,EAAG,OAAO,EAAE,EAAE8C,GAAE,GAAG,CAAC,EAAE,EAAE,SAASlE,EAAE,CAACA,KAAK,EAAEuB,EAAE,YAAY,CAAC,IAAI,gBAAgB,OAAOvB,CAAC,CAAC,EAAEiE,GAAGjE,CAAC,CAAC,EAAE,EAAEsF,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEI,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,EAAG,EAAEC,GAAG,EAAEC,EAAG,EAAE,IAAI,GAAG,EAAE,SAAStG,EAAEC,EAAE,CAACD,KAAK,EAAEA,GAAGC,IAAI,EAAE,WAAW,IAAI2E,GAAG,CAAC,EAAErD,EAAE,YAAY,CAAC,aAAavB,EAC5f,IAAI,cAAc,CAAC,GAAGA,EAAEkE,GAAE,GAAGlE,CAAC,IAAIA,EAAE,YAAY,CAAC,IAAI,cAAc,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,EAAE,EAAE,EAAEwG,GAAG,EAAE,SAASxG,EAAE,CAACsB,GAAG4C,GAAE,GAAGlE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEV,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEV,EAAE,EAAEY,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEV,EAAE,EAAEY,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEA,GAAGA,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAC3f,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,EAAEV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEV,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEV,EAAE,EAAEY,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEV,EAAE,EAAEY,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEC,GAAGyG,GAAE1G,EAAE,YAAY,CAAC,EAAE2G,GAAGC,IAAI5G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEV,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAED,EAAEX,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EACrf,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEA,GAAGC,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,EAAEX,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKX,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKV,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEV,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEV,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEV,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEV,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEZ,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAAEG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,GAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEZ,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,IAAGH,GAClf,EAAED,IAAII,IAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,GAAEF,GAAGD,EAAE,GAAGb,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEC,GAAGwG,GAAEzG,EAAE,YAAY,CAAC,EAAE0G,GAAGC,IAAI3G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEX,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEE,EAAEZ,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEX,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEX,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEX,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEX,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEX,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAAE,IAAW8J,IAAIpG,GAAE3D,EAAE,GAAG,CAAC,KAAK,IAAI2D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE3D,IAAI,CAAC,EAAE,EAAE6G,GAAG,EAAEC,GACpf,EAAE,SAAS9G,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEM,GAAE,CAAC,OAAOA,GAAEA,GAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,GAAE,CAAC,EAAE,KAAK,CAACT,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,GAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,GAAE,kBAAkB,EAAEE,GAAE,KAAK,IAAIJ,EAAEG,EAAC,EAAEf,EAAE,EAAEQ,GAAG,IAAI,CAAC,EAAE,GAAGQ,GAAElB,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,EAAC,EAAEN,EAAE+G,GAAG/G,CAAC,EAAEC,EAAE8G,GAAG9G,CAAC,EAAEM,GAAEH,GAAGZ,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEF,EAAER,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAED,IAAIT,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAED,EAAET,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACqC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASrC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEiH,GAAGjH,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EACtfC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEiH,GAAGjH,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,MAAA6C,IAAI,EAAO,QAAS,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,WAAW,YAAY,IAAI,EAAE,EAAE,UAAU,CAAC,OAAOxB,EAAE,cAAc,KAAK,EAAE,OAAO,UAAU,mBAAmB,EAAE,EAAE,SAAStB,EAAEC,EAAEC,EAAEC,EAAE,CAAmC,IAAlC+D,GAAE,GAAGjE,IAAI,EAAEsH,GAAG,OAAOrH,EAAED,EAAEE,IAAI,GAAG,EAAMA,EAAE,EAAEA,EAAED,EAAEC,IAAIoH,GAAGpH,CAAC,EAAEP,EAAG,EAAEK,EAAEE,IAAI,CAAC,EAAE,OAAO,EAAEH,EAAE4D,GAAG,CAAC5D,EAAE,CAAC,EAAE4J,GAAG5J,CAAC,GAAG,MAAM,KAAKuH,EAAE,CAAC,EAAE,EAAE,SAASvH,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEb,EAAE,EAAE,OAAO,GAAGY,GAAGC,GAAG,WAAWD,EAAE,MAAM,GAAG,QAAQE,EACxf,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KAAKD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAElB,GAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,GAAE,KAAKmB,CAAC,EAAEjB,GAAE,EAAE,IAAIkB,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAEsH,GAAG,EAAEC,GAAG,EAAEpD,GAAG,EAAEqD,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEE,GAAG,EAAEhJ,IAAGa,EAAE,WAAW,EAAEwI,GAAG,EAAE,SAAStI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmI,GAAGtI,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GACrW,UAAU,CAAC,SAASH,EAAEE,EAAEC,EAAE,CAAC,OAAAD,EAAEA,EAAE,QAAQA,EAAEwI,GAAGxI,CAAC,EAAEoC,GAAEpC,EAAE8J,GAAG9J,CAAC,EAAEgE,GAAE,GAAG,KAAK5B,GAAE,EAAE,EAAEM,GAAG,QAAQN,GAAE,CAAC,EAAEC,GAAGpC,EAAEiD,GAAG,EAASlD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE4J,EAAE,EAAO,GAAL1G,GAAG,EAAKrD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBG,EAAED,CAAC,CAAC,OAAOE,EAAE,CAACgC,GAAE,sDAAsDhC,CAAC,EAAE,EAAEA,CAAC,CAAC,CAAC,OAAAwD,GAAGzD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,SAASA,EAAE,MAAM,CAAC,CAAC,EAAE,MAAM,CAAC,EAAQ,CAAC,CAAC,GAAG,EAAEJ,EAAE,SAAS,CAACE,EAAEC,KAAKH,EAAE,SAASwC,GAAE,GAAGtC,EAAEC,CAAC,EAAEH,EAAE,iBAAiB,CAACE,EAAEC,KAAKH,EAAE,iBAAiBwC,GAAE,GAAGtC,EAAEC,CAAC,EAC7ZH,EAAE,yBAAyB,CAACE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,MAAKX,EAAE,yBAAyBwC,GAAE,GAAGtC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,EAAC,EAAEX,EAAE,4BAA4B,CAACE,EAAEC,KAAKH,EAAE,4BAA4BwC,GAAE,IAAItC,EAAEC,CAAC,EAAEH,EAAE,6BAA6B,CAACE,EAAEC,EAAEC,KAAKJ,EAAE,6BAA6BwC,GAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEJ,EAAE,0BAA0B,CAACE,EAAEC,EAAEC,KAAKJ,EAAE,0BAA0BwC,GAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEJ,EAAE,0BAA0BE,IAAIF,EAAE,0BAA0BwC,GAAE,IAAItC,CAAC,EAAEF,EAAE,kBAAkB,CAACE,EAAEC,EAAEC,KAAKJ,EAAE,kBAAkBwC,GAAE,IAAItC,EAAEC,EAAEC,CAAC,EAC7dJ,EAAE,mBAAmBE,IAAIF,EAAE,mBAAmBwC,GAAE,IAAItC,CAAC,EAAEF,EAAE,wBAAwB,CAACE,EAAEC,EAAEC,KAAKJ,EAAE,wBAAwBwC,GAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACE,EAAEC,KAAKH,EAAE,iBAAiBwC,GAAE,IAAItC,EAAEC,CAAC,EAAEH,EAAE,kBAAkB,CAACE,EAAEC,KAAKH,EAAE,kBAAkBwC,GAAE,IAAItC,EAAEC,CAAC,EAAEH,EAAE,SAASE,IAAIF,EAAE,SAASwC,GAAE,IAAItC,CAAC,EAAEF,EAAE,iBAAiB,CAACE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,iBAAiBwC,GAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,kBAAkB,CAACE,EAAEC,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,kBAAkBwC,GAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,kBAAkBE,IAAIF,EAAE,kBAAkBwC,GAAE,IAAItC,CAAC,EAC5dF,EAAE,qBAAqB,CAACE,EAAEC,EAAEC,EAAEC,KAAKL,EAAE,qBAAqBwC,GAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsB,CAACE,EAAEC,EAAEC,KAAKJ,EAAE,sBAAsBwC,GAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEJ,EAAE,sBAAsBE,IAAIF,EAAE,sBAAsBwC,GAAE,IAAItC,CAAC,EAAEF,EAAE,kBAAkBE,IAAIF,EAAE,kBAAkBwC,GAAE,IAAItC,CAAC,EAAEF,EAAE,cAAc,CAACE,EAAEC,EAAEC,KAAKJ,EAAE,cAAcwC,GAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEJ,EAAE,eAAe,CAACE,EAAEC,EAAEC,EAAEC,KAAKL,EAAE,eAAewC,GAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBE,IAAIF,EAAE,sBAAsBwC,GAAE,IAAItC,CAAC,EAAEF,EAAE,mBAAmBE,IAAIF,EAAE,mBAAmBwC,GAAE,IAAItC,CAAC,EACxeF,EAAE,mBAAmB,CAACE,EAAEC,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,mBAAmBwC,GAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,QAAQ,CAACE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,MAAKT,EAAE,QAAQwC,GAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAC,EAAET,EAAE,iBAAiBE,IAAIF,EAAE,iBAAiBwC,GAAE,IAAItC,CAAC,EAAEF,EAAE,YAAY,CAACE,EAAEC,EAAEC,KAAKJ,EAAE,YAAYwC,GAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiBE,IAAIF,EAAE,iBAAiBwC,GAAE,IAAItC,CAAC,EAAE,IAAI2E,GAAG7E,EAAE,cAAc,KAAK6E,GAAG7E,EAAE,cAAcwC,GAAE,IAAI,EAAE0E,GAAGlH,EAAE,QAAQE,IAAIgH,GAAGlH,EAAE,QAAQwC,GAAE,IAAItC,CAAC,EAAE0J,GAAG5J,EAAE,MAAME,IAAI0J,GAAG5J,EAAE,MAAMwC,GAAE,IAAItC,CAAC,EAAEF,EAAE,sBAAsB,KAAKA,EAAE,sBAAsBwC,GAAE,IAAI,EAC7d,IAAIwH,GAAGhK,EAAE,yBAAyB,CAACE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKyJ,GAAGhK,EAAE,yBAAyBwC,GAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,4BAA4B,KAAKA,EAAE,4BAA4BwC,GAAE,IAAI,EAC1K,IAAIgF,GAAG,CAACtH,EAAEC,EAAEC,EAAEC,KAAKmH,GAAGhF,GAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEuE,GAAG1E,IAAI0E,GAAGpC,GAAE,IAAItC,CAAC,EAAEiF,GAAGnF,EAAE,yBAAyBE,IAAIiF,GAAGnF,EAAE,yBAAyBwC,GAAE,IAAItC,CAAC,EAAEyG,GAAG3G,EAAE,2BAA2B,KAAK2G,GAAG3G,EAAE,2BAA2BwC,GAAE,IAAI,EAAEyH,GAAG/J,IAAI+J,GAAGzH,GAAE,IAAItC,CAAC,EAAE8E,GAAG,CAAC9E,EAAEC,KAAK6E,GAAGxC,GAAE,IAAItC,EAAEC,CAAC,EAAEmH,GAAG,KAAKA,GAAG9E,GAAE,IAAI,EAAEyC,GAAG/E,IAAI+E,GAAGzC,GAAE,IAAItC,CAAC,EAAEqH,GAAGrH,IAAIqH,GAAG/E,GAAE,IAAItC,CAAC,EAAEgF,GAAGlF,EAAE,WAAW,CAACE,EAAEC,KAAK+E,GAAGlF,EAAE,WAAWwC,GAAE,IAAItC,EAAEC,CAAC,EAAEuJ,GAAGxJ,IAAIwJ,GAAGlH,GAAE,IAAItC,CAAC,EAAE6I,GAAG,KAAKA,GAAGvG,GAAE,IAAI,EAAEiH,GAAGvJ,IAAIuJ,GAAGjH,GAAE,IAAItC,CAAC,EAAEyJ,GAAG,KAAKA,GAAGnH,GAAE,IAAI,EAAExC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAC1d,SAASkK,GAAGhK,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,aAAaC,EAAED,EAAE,YAAY,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACF,EAAE,iBAAiBiD,GAAGjD,EAAE,WAAWb,GAAEa,EAAE,WAAWuH,GAAGvH,EAAE,UAAUsH,GAAGtH,EAAE,aAAaiF,GAAGjF,EAAE,aAAa+D,GAAE/D,EAAE,aAAa6F,GAAG7F,EAAE,gBAAgB2F,GAAG3F,EAAE,WAAWiE,GAAGjE,EAAE,QAAQoE,GAAE,IAAI+F,GAAG/G,GAAE,SAASgH,GAAI,CAACD,IAAIE,GAAG,EAAEF,KAAK/G,GAAEgH,EAAG,EAC/b,SAASC,IAAI,CAAC,SAASnK,GAAG,CAAC,GAAG,CAACiK,KAAKA,GAAG,GAAGnK,EAAE,UAAU,GAAG,CAAC0C,MAAIjB,GAAGsD,GAAGjC,EAAE,EAAE7C,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAK,CAACyB,GAAE,CAAC,GAAGzB,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAIG,EAAEH,EAAE,QAAQ,MAAM,EAAE+C,GAAG,QAAQ5C,CAAC,CAAC,CAAC4E,GAAGhC,EAAE,CAAC,CAAE,CAAC,GAAG,EAAE,EAAEG,IAAG,GAAGzB,EAAExB,EAAGD,CAAC,EAAEyB,GAAGsD,GAAGjC,EAAE,EAAE,YAAY9C,CAAC,MAAM,CAAC,GAAGA,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQ6C,GAAG,QAAQ7C,EAAE,OAAO,MAAM,CAAC,EAAE+E,GAAGlC,EAAE,EAAE,EAAEK,KAAIlD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EACpiB,CAAC,EAAEE,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAAC,GAAGF,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAqK,GAAG,EAGzHpL,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAe,IC9FlC,IAAAuL,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,0/ECAA,IAUIC,GASEC,GAMFC,GACAC,GACAC,GACAC,GAEEC,GAwBAC,GAyBAC,GAWOC,GA8GAC,GAxMbC,GAAAC,GAAA,kBAeEZ,GACmE,KAG/DC,GAE2B,KAK7BE,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAC5C,GAAI,CAEF,OAAI,OAAO,kBAAsB,IACxB,IAKL,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SAAS,IAAI,WAAW,CACzC,EAAG,GAAI,IAAK,IAAK,EAAG,EAAI,EAAI,EAAG,EAAG,EAAG,EAAI,GAAI,EAAK,EAAI,EAAG,EAAG,EAAI,EAAG,EACnE,EAAG,EAAI,EAAK,EAAK,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAI,IAAK,GAAI,EAAG,EAAG,GAAI,EAClE,CAAC,CAAC,EACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SAAS,IAAI,WAAW,CACzC,EAAK,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAK,GAAK,EAAG,GAAI,EACvF,IAAK,GAAI,IAAK,GAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAI,IAAK,IAAK,EAAG,GAAI,EACzF,CAAC,CAAC,CACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,CAACK,EAAkBC,IACrCD,EAIKC,EAAa,8BAAgC,qBAE7CA,EAAa,yBAA2B,gBAItCL,GAAwB,MAAMM,GAA+C,CACxF,GAAIZ,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAyD,EAE3E,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAsD,EAGxED,GAAe,GAGf,IAAMY,EAAUD,EAAM,YAChBE,EAAaF,EAAM,WACnBG,EAAOH,EAAM,KAEbD,EAAaG,EAAa,GAAKX,GAAuB,EACtDO,EAAUK,GAAQX,GAAgB,EAElCY,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAeb,GAAgBK,EAASC,CAAU,EAClDQ,EAAmB,OAAOH,GAAc,SAAWA,EAAUE,CAAY,EAAI,OAE/EE,EAAY,GAEVC,EAA8B,CAAC,EA6ErC,GA1EIR,EAAU,GACZQ,EAAM,KAAK,IAAI,QAASC,GAAY,CAClC,WAAW,IAAM,CACfF,EAAY,GACZE,EAAQ,CACV,EAAGT,CAAO,CACZ,CAAC,CAAC,EAIJQ,EAAM,KAAK,IAAI,QAAQ,CAACC,EAASC,IAAW,CAC1C,IAAMC,EAAUb,EAAab,GAAyBD,GAChD4B,EAAiC,CACrC,WAAY,CAACC,EAAkBC,IAA4B,CACzD,GAAuChB,GAAce,EAAS,SAAS,YAAY,GAC/E,OAAO,KAAS,IAClB,OAAO,IAAI,gBAAgB,IAAI,KAC3B,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAGhC,GAAIA,EAAS,SAAS,OAAO,EAAG,CAC9B,GAAIP,EACF,OAAOA,EAGT,IAAMS,EAASX,GAAsBU,EAGnC,OAAIT,IAAiB,qBACZU,EAAS,0BACPV,IAAiB,8BACnBU,EAAS,mCAIbA,EAASV,CAClB,CAEA,OAAOS,EAAkBD,CAC3B,CACF,EAEA,GAAuCf,EACrC,GAAI,OAAO,KAAS,IAClBc,EAAO,oBAA2B,SAAK,UAAW,sBAAsB,MACnE,CACL,IAAMI,EAAmB,uBAAuBL,EAAQ,SAAS,CAAC,IAClEC,EAAO,oBAAsB,IAAI,KAAK,CAACI,CAAgB,EAAG,CAAC,KAAM,iBAAiB,CAAC,CACrF,CAGFL,EAAQC,CAAM,EAAE,KAEZK,GAAU,CACR7B,GAAe,GACfD,GAAc,GACdD,GAAO+B,EACPR,EAAQ,CACV,EAECS,GAAS,CACR9B,GAAe,GACfC,GAAU,GACVqB,EAAOQ,CAAI,CACb,CAAC,CACP,CAAC,CAAC,EAEF,MAAM,QAAQ,KAAKV,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DP,CAAO,IAAI,CAE1F,EAEaN,GAAc,IAAqB,CAC9C,GAAIP,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,IC9MA,IAKaiC,GAeAC,GA6BAC,GAjDbC,GAAAC,GAAA,kBAGAC,KAEaL,GAAkB,CAACM,EAAcC,IAA6B,CACzE,IAAMC,EAAOC,GAAY,EAEnBC,EAAaF,EAAK,gBAAgBF,CAAI,EAAI,EAC1CK,EAAaH,EAAK,QAAQE,CAAU,EAC1C,OAAAF,EAAK,aAAaF,EAAMK,EAAYD,CAAU,EAC9CH,EAAO,KAAKI,CAAU,EAEfA,CACT,EAMaV,GACT,CAACW,EAAkCC,EAAgBC,EAClDC,IAAuC,CACtC,GAAI,OAAOH,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAIE,EAAK,IAAIF,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/CE,EAAK,IAAIF,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACI,EAAKC,CAAK,IAAM,CAChD,IAAMC,EAAQL,EAAUA,EAASG,EAAMA,EACvC,GAAI,OAAOC,GAAU,SACnBhB,GAAoBgB,EAAkCC,EAAO,IAAKJ,EAAMC,CAAO,UACtE,OAAOE,GAAU,UAAY,OAAOA,GAAU,SACvDF,EAAQG,EAAMD,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1BF,EAAQG,EAAOD,EAAS,IAAM,GAAG,MAEjC,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMSf,GAAkBiB,GAA0B,CACvD,IAAMX,EAAOC,GAAY,EAEnBW,EAAQZ,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMa,EAAeb,EAAK,WAAW,CAAC,EACtCA,EAAK,iBAAiBa,EAAcA,EAAe,CAAC,EACpD,IAAMC,EAAYd,EAAK,OAAOa,EAAe,CAAC,EACxCE,EAAsBf,EAAK,QAAQa,EAAe,EAAI,CAAC,EACvDG,EAAeD,EAAsBf,EAAK,aAAae,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGJ,CAAO,gBAAgBG,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAhB,EAAK,aAAaY,CAAK,CACzB,CACF,IC/DA,IAQaK,GARbC,GAAAC,GAAA,kBAKAC,KACAC,KAEaJ,GAAiBK,GAA6D,CACzF,IAAMC,EAAOC,GAAY,EACrBC,EAAmB,EACjBC,EAAmB,CAAC,EAEpBC,EAA0CL,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCK,EAAW,iBAAmB,UAE5B,OAAOL,EAAQ,kBAAqB,UAAY,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1FA,EAAQ,iBAAmB,GAAKA,EAAQ,iBAAmB,EAC7D,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,gBAAgB,EAAE,EAGjF,GAAIA,GAAS,oBAAsB,OACjCK,EAAW,kBAAoB,UACtB,OAAOL,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBK,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAIN,GAAS,MAAQ,SACnBM,EAAgBC,GAAgBP,EAAQ,IAAKI,CAAM,GAGrDD,EAAmBF,EAAK,qBACpBI,EAAW,iBAAmBA,EAAW,kBAAoB,CAAC,CAACA,EAAW,UAAYC,CAAa,EACnGH,IAAqB,GACvBK,GAAe,2BAA4B,EAGzCR,GAAS,QAAU,QACrBS,GAAoBT,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACU,EAAKC,IAAU,CAC7F,IAAMC,EAAgBL,GAAgBG,EAAKN,CAAM,EAC3CS,EAAkBN,GAAgBI,EAAOP,CAAM,EAEjDH,EAAK,sBAAsBE,EAAkBS,EAAeC,CAAe,IAAM,GACnFL,GAAe,iCAAiCE,CAAG,MAAMC,CAAK,GAAG,CAErE,CAAC,EAGI,CAACR,EAAkBC,CAAM,CAClC,OAASU,EAAG,CACV,MAAIX,IAAqB,GACvBF,EAAK,sBAAsBE,CAAgB,EAE7CC,EAAO,QAAQW,GAASd,EAAK,MAAMc,CAAK,CAAC,EACnCD,CACR,CACF,IChEA,IAQME,GAeAC,GAWAC,GAoBAC,GA+EOC,GArIbC,GAAAC,GAAA,kBAKAC,KACAC,KAEMR,GAA4BS,GAAmD,CACnF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMR,GAAoBS,GAAmD,CAC3E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMR,GAAwBS,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMC,EAAUD,EAAQ,MAAM,QACzBC,EAAQ,+BAEXA,EAAQ,6BAA+B,KAIrCD,EAAQ,oBACRA,EAAQ,mBAAmB,KAAKE,IAAO,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAC5FF,EAAQ,iBAAmB,GAE/B,EAEMR,GACF,CAACW,EAA8BC,EAC9BC,IAA2B,CAC1B,QAAWH,KAAME,EAAoB,CACnC,IAAIE,EAAS,OAAOJ,GAAO,SAAWA,EAAKA,EAAG,KAG9C,OAAQI,EAAQ,CACd,IAAK,UACHA,EAAS,UACT,MACF,IAAK,QAEH,GADAA,EAAS,QACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMK,EAAeL,EACrB,GAAIK,GAAc,WAAY,CAC5B,IAAMC,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBF,EAAa,WAAYF,CAAM,EACnEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,WAAY,CAC5B,IAAIM,EAAaN,EAAa,YAE1B,OAAOM,GAAc,UAAY,CAAC,OAAO,UAAUA,CAAU,GAAKA,EAAa,KACjFA,EAAa,GAEf,IAAML,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBI,EAAW,SAAS,EAAGR,CAAM,EACjEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,gBAAiB,CACjC,IAAMC,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBF,EAAa,gBAAiBF,CAAM,EACxEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDL,EAAa,eAAe,GAAG,CAEhG,CACF,CACA,MACF,IAAK,SAEH,GADAD,EAAS,KACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMY,EAAgBZ,EACtB,GAAIY,GAAe,gBAAiB,CAClC,GAAIA,EAAc,kBAAoB,QAAUA,EAAc,kBAAoB,OAChF,MAAM,IAAI,MAAM,oDAAoDA,EAAc,eAAe,EAAE,EAErG,IAAMN,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBK,EAAc,gBAAiBT,CAAM,EACzEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDE,EAAc,eAAe,GAAG,CAEjG,CACF,CACA,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqCR,CAAM,EAAE,CACjE,CAEA,IAAMS,EAAmBN,GAAgBH,EAAQD,CAAM,EACnDM,GAAY,EAAE,4BAA4BR,EAAsBY,CAAgB,IAAM,GACxFH,GAAe,oCAAoCN,CAAM,GAAG,CAEhE,CACF,EAESb,GAAqBO,GAAkE,CAClG,IAAMgB,EAAOL,GAAY,EACrBR,EAAuB,EACrBE,EAAmB,CAAC,EAEpBY,EAAkDjB,GAAW,CAAC,EACpET,GAAqB0B,CAAc,EAEnC,GAAI,CACF,IAAMnB,EAAyBT,GAAyB4B,EAAe,wBAA0B,KAAK,EAChGlB,EAAgBT,GAAiB2B,EAAe,eAAiB,YAAY,EAC7EC,EACF,OAAOD,EAAe,OAAU,SAAWR,GAAgBQ,EAAe,MAAOZ,CAAM,EAAI,EAEzFc,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,qCAAqCA,CAAgB,EAAE,EAGzE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EAA+B,OAAOJ,EAAe,wBAA2B,SAClFR,GAAgBQ,EAAe,uBAAwBZ,CAAM,EAC7D,EAcJ,GAZAF,EAAuBa,EAAK,yBACxBlB,EAAwB,CAAC,CAACmB,EAAe,kBAAmB,CAAC,CAACA,EAAe,iBAAkBlB,EAC/F,CAAC,CAACkB,EAAe,gBAAiB,EAAGC,EAAiBC,EAAkBC,EACxEC,CAA4B,EAC5BlB,IAAyB,GAC3BS,GAAe,+BAAgC,EAG7CK,EAAe,oBACjBzB,GAAsBW,EAAsBc,EAAe,mBAAoBZ,CAAM,EAGnFY,EAAe,uBACjB,OAAW,CAACK,EAAMC,CAAK,IAAK,OAAO,QAAQN,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAOC,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAMC,EAAaf,GAAgBa,EAAMjB,CAAM,EAC3CW,EAAK,6BAA6Bb,EAAsBqB,EAAYD,CAAK,IAAM,GACjFX,GAAe,wCAAwCU,CAAI,MAAMC,CAAK,GAAG,CAE7E,CAGF,OAAIN,EAAe,QAAU,QAC3BQ,GAAoBR,EAAe,MAAO,GAAI,IAAI,QAAoC,CAACS,EAAKH,IAAU,CACpG,IAAMf,EAAgBC,GAAgBiB,EAAKrB,CAAM,EAC3CK,EAAkBD,GAAgBc,EAAOlB,CAAM,EAEjDW,EAAK,0BAA0Bb,EAAsBK,EAAeE,CAAe,IAAM,GAC3FE,GAAe,qCAAqCc,CAAG,MAAMH,CAAK,GAAG,CAEzE,CAAC,EAGI,CAACpB,EAAsBE,CAAM,CACtC,OAASsB,EAAG,CACV,MAAIxB,IAAyB,GAC3Ba,EAAK,0BAA0Bb,CAAoB,EAErDE,EAAO,QAAQuB,GAASZ,EAAK,MAAMY,CAAK,CAAC,EACnCD,CACR,CACF,IC/MA,IAiCaE,GAqCAC,GAsCAC,GAMAC,GAoCAC,GAoBAC,GAMAC,GAhLbC,GAAAC,GAAA,kBAiCaR,GAA8BS,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKaR,GAA8BS,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaR,GAAwBS,GACpB,CAAC,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,OAAW,MAAS,EAAEA,CAAQ,EAKxGR,GAAqCM,GAEoD,CAChG,OAAQA,EAAM,CACZ,IAAK,UACH,OAAO,YACT,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKSL,GAAwBQ,GAAkE,CACrG,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaP,GAA4BI,GAAyDA,IAAS,WACvGA,IAAS,SAAWA,IAAS,SAAWA,IAAS,QAAUA,IAAS,WAAaA,IAAS,SAKjFH,GAA4BO,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,IC/LA,IAYMC,GAEAC,GAKFC,GACAC,GAESC,GAQAC,GAWAC,GAzCbC,GAAAC,GAAA,kBAKAC,KAOMT,GAAiB,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAEzCC,GAAQ,CAACS,EAAeC,IAA0B,CAEtD,QAAQ,IAAI,IAAIX,GAAeU,CAAK,CAAC,IAAI,IAAI,KAAK,EAAE,YAAY,CAAC,IAAIC,CAAO,EAAE,CAChF,EAKaP,GAAkB,CAACQ,EAA2BC,IAA0B,CACnFX,GAAiBU,EACjBT,GAAQU,CACV,EAKaR,GAAM,CAACS,EAAoBC,IAAuB,CAC7D,IAAMC,EAAeC,GAAqBH,CAAQ,EAC5CI,EAAcD,GAAqBf,EAAc,EACnDc,GAAgBE,GAClBjB,GAAMe,EAAc,OAAOD,GAAQ,WAAaA,EAAI,EAAIA,CAAG,CAE/D,EAKaT,GAAwB,IAAIa,IAAiC,CACpEhB,IACFE,GAAI,GAAGc,CAAI,CAEf,IC7CA,IAOaC,GAPbC,GAAAC,GAAA,kBAKAC,KAEaH,GAAa,CAACI,EAAyBC,IAE5C,IAAKC,GAAkCD,CAAI,GAAGD,CAAU,ICThE,IAAAG,GAAAC,GAAA,oBCAA,IA2EMC,GAEFC,GACEC,GAYOC,GAkCPC,GAoOOC,GAhWbC,GAAAC,GAAA,kBAIAC,KAEAC,KAqEMT,GAA4BU,GAAiB,KAAK,KAAKA,EAAO,EAAE,EAAI,GAEtET,GAAO,EACLC,GAAqB,IAAMD,KAYpBE,GACT,MAAMQ,EAAwBC,EAAsBC,EAAsBC,IAC/C,CACrB,IAAMC,EAAaf,GAAyBa,CAAY,EAClDG,EAAgBL,EAAQ,OAAO,aAEjC,CAAC,KAAMI,EAAY,MAAO,eAAe,SAAW,eAAe,QAAQ,CAAC,EAChF,GAAI,CACF,IAAME,EAAiBN,EAAQ,kBAAkB,EACjDA,EAAQ,eAAe,EACvBM,EAAe,mBACXL,EAA+B,EAAuBI,EACtD,EAA4BD,CAChC,EACAJ,EAAQ,MAAM,EAEd,MAAMK,EAAc,SAAS,WAAW,IAAI,EAE5C,IAAME,EAAcF,EAAc,eAAe,EACjD,GAAIF,EAAiB,CAEnB,IAAMK,EAAeL,EAAgB,EACrC,OAAAK,EAAa,IAAI,IAAI,WAAWD,EAAa,EAAGL,CAAY,CAAC,EACtDM,CACT,KAGE,QAAO,IAAI,WAAWD,EAAY,MAAM,EAAGL,CAAY,CAAC,CAE5D,QAAE,CACAG,EAAc,QAAQ,CACxB,CACF,EAEFZ,GAAN,KAAmD,CAiBjD,YAAoBO,EAAwB,CAAxB,aAAAA,EAClB,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,IAC9B,KAAK,2BAA6B,CAAC,EACnC,KAAK,eAAiB,CAAC,EACvB,KAAK,gBAAkB,IAAI,GAC7B,CAEA,OAAOS,EAAeC,EAAwB,CAC5C,IAAMC,EAAiBD,EAAK,OACtBE,EAAYF,EAAK,WACjBG,EAAYH,EAAK,WACjBX,EAAOV,GAAyBwB,CAAS,EAGzCC,EAAe,KAAK,aAAa,IAAIL,CAAE,EAC7C,GAAI,CAACK,EACH,MAAM,IAAI,MAAM,uCAAuC,EAEzD,GAAIA,EAAa,eAAiBD,EAChC,MAAM,IAAI,MAAM,yCAAyCC,EAAa,YAAY,eAAeD,CAAS,EAAE,EAI9G,IAAME,EAAwB,KAAK,QAAQ,OAAO,aAE9C,CAAC,iBAAkB,GAAM,KAAAhB,EAAM,MAAO,eAAe,UAAY,eAAe,QAAQ,CAAC,EAGvFQ,EAAcQ,EAAsB,eAAe,EACzD,IAAI,WAAWR,CAAW,EAAE,IAAI,IAAI,WAAWI,EAAgBC,EAAWC,CAAS,CAAC,EACpFE,EAAsB,MAAM,EAI5B,IAAMT,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBAAmBS,EAAuB,EAAGD,EAAa,QAAQ,OAAQ,EAAGf,CAAI,EAEhGiB,GAAU,UAAW,IAAM,qCAAqCP,CAAE,GAAG,EAErE,KAAK,2BAA2B,KAAKM,CAAqB,CAC5D,CAEA,OAAOE,EAAqBC,EAAgC,CAE1D,IAAMC,EAAqB,KAAK,aAAa,IAAIF,CAAQ,EACzD,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAMC,EAA0B,KAAK,aAAa,IAAIF,CAAa,EACnE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAID,EAAmB,eAAiBC,EAAwB,aAC9D,MAAM,IAAI,MAAM,mDAAmD,EAErE,IAAMrB,EAAOV,GAAyB8B,EAAmB,YAAY,EAG/Db,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBACXa,EAAmB,QAAQ,OAAQ,EAAGC,EAAwB,QAAQ,OAAQ,EAAGrB,CAAI,CAC3F,CAEA,uBAAuBsB,EAAmBnB,EAAsBoB,EAAoC,CAClG,IAAIb,EACJ,GAAIa,EAAgB,CAElB,GADAb,EAAK,KAAK,gBAAgB,IAAIa,CAAc,EACxCb,IAAO,OACT,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIY,IAAWC,EACb,OAAAN,GACI,UACA,IAAM,uDAAuDd,CAAY,WACrEO,CAAE,6BAA6B,EAChCA,EAET,KAAK,gBAAgB,OAAOa,CAAc,CAC5C,MACEb,EAAKlB,GAAmB,EAG1B,YAAK,aAAa,IAAIkB,EAAI,CAAC,QAAS,CAAC,GAAAA,EAAI,OAA2B,OAAAY,CAAM,EAAG,aAAAnB,CAAY,CAAC,EAC1F,KAAK,gBAAgB,IAAImB,EAAQZ,CAAE,EACnCO,GACI,UACA,IAAM,uDAAuDd,CAAY,WAAWO,CAAE,eAAe,EAClGA,CACT,CAEA,yBAAyBY,EAAyB,CAChD,IAAMZ,EAAK,KAAK,gBAAgB,IAAIY,CAAM,EACtCZ,IAAO,SACT,KAAK,aAAa,OAAOA,CAAE,EAC3B,KAAK,gBAAgB,OAAOY,CAAM,EAClCL,GAAU,UAAW,IAAM,4DAA4DP,CAAE,EAAE,EAE/F,CAGA,OAAOV,EAAcwB,EAAQ,eAAe,QAAU,eAAe,SAAW,eAAe,SAAmB,CAChH,IAAMnB,EAAaf,GAAyBU,CAAI,EAE5CE,EAGEuB,GAAaD,EAAQ,eAAe,WAAa,eAAe,QAEhEE,GAAaF,EAAQ,eAAe,WAAa,eAAe,QACtE,GAAIC,GAAaC,EAAW,CAC1B,IAAMC,EAAcF,EAAY,KAAK,YAAc,KAAK,mBACpDG,EAAUD,EAAY,IAAItB,CAAU,EACnCuB,IACHA,EAAU,CAAC,EACXD,EAAY,IAAItB,EAAYuB,CAAO,GAEjCA,EAAQ,OAAS,EACnB1B,EAAY0B,EAAQ,IAAI,EAGxB1B,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,CAE1E,MAEEtB,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,EAGxE,IAAMK,EAAU,CAAC,GAAIrC,GAAmB,EAAG,OAA2B,OAAQU,CAAS,EACvF,YAAK,aAAa,IAAI2B,EAAQ,GAAI,CAAC,QAAAA,EAAS,aAAc7B,CAAI,CAAC,EAE/DiB,GAAU,UAAW,IAAM,uCAAuCjB,CAAI,WAAW6B,EAAQ,EAAE,EAAE,EACtFA,CACT,CAEA,IAAInB,EAAkC,CACpC,OAAO,KAAK,aAAa,IAAIA,CAAE,GAAG,OACpC,CAEA,QAAQA,EAAuB,CAC7B,IAAMoB,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,+BAA+B,EAGjD,OAAAb,GAAU,UAAW,IAAM,sCAAsCP,CAAE,gBAAgBoB,EAAW,QAAQ,EAAE,EAAE,EAE1G,KAAK,aAAa,OAAOpB,CAAE,EAC3B,KAAK,eAAe,KAAKoB,EAAW,QAAQ,MAAM,EAG3CA,EAAW,YACpB,CAEA,MAAM,SAASpB,EAAeN,EAAkD,CAC9E,IAAM0B,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,qBAAqB,EAGvC,MAAMrC,GAAgB,KAAK,QAASqC,EAAW,QAAQ,OAAQA,EAAW,aAAc1B,CAAe,CACzG,CAEA,uBAA8B,CAC5B,QAAWkB,KAAU,KAAK,2BAExBA,EAAO,QAAQ,EAEjB,KAAK,2BAA6B,CAAC,EACnC,QAAWA,KAAU,KAAK,gBAEnBA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAE7D,KAAK,YAAY,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,GAEpCA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAEpE,KAAK,mBAAmB,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,EAErDA,EAAO,QAAQ,EAGnB,KAAK,eAAiB,CAAC,CACzB,CAEA,SAAU,CACR,KAAK,YAAY,QAASM,GAAY,CACpCA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EACD,KAAK,mBAAmB,QAASM,GAAY,CAC3CA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EAED,KAAK,aAAa,QAASS,GAAY,CACrCA,EAAQ,QAAQ,OAAO,QAAQ,CACjC,CAAC,EAED,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,GAChC,CACF,EAEapC,GAAuB,IAAIqC,IACpC,IAAItC,GAAmB,GAAGsC,CAAI,ICjWlC,IAGMC,GAsBOC,GAzBbC,GAAAC,GAAA,kBAGMH,GAAN,KAAgC,CAC9B,YAAYI,EAAoC,CAC9C,OAAO,OAAO,KAAMA,CAAS,CAC/B,CAGA,IAAW,UAAmB,CAC5B,OAAK,KAAK,MACR,KAAK,IACD,OAAO,oBAAoB,IAAI,EAAE,KAAK,EAAE,IAAIC,GAAQ,GAAI,KAAiCA,CAAI,CAAC,EAAE,EAAE,KAAK,GAAG,GAEzG,KAAK,GACd,CACF,EASaJ,GAAkEG,GAC3E,IAAIJ,GAA0BI,CAAS,IC1B3C,IAKaE,GAaAC,GAoEAC,EAiHAC,GA0MAC,GAkDAC,GACAC,GApcbC,GAAAC,GAAA,kBAKaR,GAAN,KAAiB,CAOtB,OAAO,gBAAgBS,EAAqBC,EAAiD,CAC3F,OAAQD,EAAE,CAAC,IAAMC,EAAE,CAAC,EAAK,OAAY,CAACD,EAAE,CAAC,EAAGC,EAAE,CAAC,CAAC,CAClD,CACF,EAGaT,GAAN,KAAoB,CAQzB,OAAO,UAAUU,EAA0BC,EAA0BC,EAAW,GAAoC,CAClH,IAAMC,EAAQH,EAAM,OACdI,EAAQH,EAAM,OACpB,GAAIE,IAAU,EACZ,OAAOF,EAET,GAAIG,IAAU,EACZ,OAAOJ,EAET,IAAMK,EAAQ,KAAK,IAAIL,EAAM,OAAQC,EAAM,MAAM,EAC3CK,EAAQ,IAAI,MAAcD,CAAK,EAGrC,GAAIH,EAAU,CACZ,GAAIC,EAAQ,GAAKC,EAAQ,EACvB,OAEF,IAAMG,EACFlB,GAAW,gBAAgB,CAACW,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,EAAG,CAACF,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,CAAC,EACzG,GAAIG,IAAiB,OACnB,OAEF,CAACD,EAAMD,EAAQ,CAAC,EAAGC,EAAMD,EAAQ,CAAC,CAAC,EAAIE,CACzC,CAEA,QAASC,EAAIN,EAAW,EAAI,EAAGM,GAAKH,EAAOG,IAAK,CAC9C,IAAMC,EAAON,EAAQK,EAAI,EAAI,EAAIR,EAAMG,EAAQK,CAAC,EAC1CE,EAAON,EAAQI,EAAI,EAAI,EAAIP,EAAMG,EAAQI,CAAC,EAEhD,GAAIC,IAASC,GAAQD,EAAO,GAAKC,EAAO,EACtC,OAEFJ,EAAMD,EAAQG,CAAC,EAAI,KAAK,IAAIC,EAAMC,CAAI,CACxC,CAEA,OAAOJ,CACT,CAOA,OAAO,iBAAiBK,EAA0BC,EAAwC,CAExF,IAAMC,EAAYF,EAAM,OAClBG,EAAYF,EAAW,OAC7B,GAAIC,EAAYC,EACd,MAAO,GAET,QAASN,EAAI,EAAGA,GAAKK,EAAWL,IAC9B,GAAIG,EAAME,EAAYL,CAAC,IAAM,GAAKG,EAAME,EAAYL,CAAC,IAAMI,EAAWE,EAAYN,CAAC,EACjF,MAAO,GAGX,MAAO,EACT,CACF,EAGajB,EAAN,MAAMwB,CAAU,CAIrB,OAAO,KAAKC,EAAiC,CAC3C,OAAOD,EAAU,0BAA0BC,EAAM,EAAGA,EAAK,MAAM,CACjE,CAKA,OAAO,kBAAkBA,EAAyBC,EAAsB,CACtE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,wCAAwCD,EAAK,MAAM,cAAc,EAE/G,OAAOD,EAAU,0BAA0BC,EAAMC,EAAMD,EAAK,MAAM,CACpE,CAKA,OAAO,gBAAgBA,EAAyBC,EAAsB,CACpE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,sCAAsCD,EAAK,MAAM,cAAc,EAE7G,OAAOD,EAAU,0BAA0BC,EAAM,EAAGC,CAAI,CAC1D,CAKA,OAAO,0BAA0BD,EAAyBE,EAAeC,EAAqB,CAC5F,IAAIC,EAAO,EACX,QAASZ,EAAIU,EAAOV,EAAIW,EAAKX,IAAK,CAGhC,GAAIQ,EAAKR,CAAC,EAAI,EACZ,MAAM,IAAI,MAEN,+GAA+G,EAErHY,GAAQJ,EAAKR,CAAC,CAChB,CACA,OAAOY,CACT,CAEA,OAAO,eAAeJ,EAA4C,CAChE,IAAMK,EAAOL,EAAK,OAClB,GAAIK,IAAS,EACX,MAAO,CAAC,EACH,GAAIA,IAAS,EAClB,MAAO,CAAC,CAAC,EAEX,IAAMC,EAAU,IAAI,MAAMD,CAAI,EAC9BC,EAAQD,EAAO,CAAC,EAAI,EACpBC,EAAQD,EAAO,CAAC,EAAIL,EAAKK,EAAO,CAAC,EACjC,QAASb,EAAIa,EAAO,EAAGb,GAAK,EAAG,EAAEA,EAC/Bc,EAAQd,CAAC,EAAIc,EAAQd,EAAI,CAAC,EAAIQ,EAAKR,EAAI,CAAC,EAE1C,OAAOc,CACT,CAKA,OAAO,cAAcL,EAAcM,EAA4B,CAC7D,GAAIN,EAAO,CAACM,GAAcN,GAAQM,EAChC,MAAM,IAAI,MAAM,sCAAsC,EAExD,OAAON,EAAO,EAAIA,EAAOM,EAAaN,CACxC,CAEA,OAAO,cAAcO,EAAyBD,EAA+B,CAC3E,OAAOC,EAAK,IAAIC,GAAK,KAAK,cAAcA,EAAGF,GAAcC,EAAK,MAAM,CAAC,CACvE,CAQA,OAAO,gBAAgB1B,EAAsB4B,EAA6C,CACxF,OAAIA,EACKA,EAAK,IAAKC,GAAM7B,EAAE6B,CAAC,CAAC,EAEpB7B,EAAE,MAAM,EAAE,QAAQ,CAE7B,CAOA,OAAO,SAASkB,EAAyBY,EAA2C,CAClF,IAAMP,EAAOL,EAAK,OAClB,OAAOA,EAAK,IAAI,CAACW,EAAGnB,IAAMmB,EAAIC,EAAIpB,CAAC,EAAIoB,EAAIpB,EAAIa,CAAI,CAAC,CACtD,CAOA,OAAO,SAASQ,EAA2BC,EAAoC,CAC7E,OAAID,EAAO,SAAWC,EAAO,OACpB,GAEFD,EAAO,MAAM,CAACF,EAAGnB,IAAMmB,IAAMG,EAAOtB,CAAC,CAAC,CAC/C,CACF,EAEahB,GAAN,MAAMuC,CAAa,CAUxB,OAAO,qBACHC,EAA2BC,EAA8BC,EAAuBZ,EAChFa,EAAqBC,EAAsB,CAC7C,GAAI,CAACJ,GAAoBE,EAAY,SAAWD,EAAU,OAAS,EACjE,MAAM,IAAI,MAAM,oFAAoF,EAGtG,GAAID,EAEF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IACxCA,GAAOH,EAAY,OACrBA,EAAY,KAAKD,EAAUI,EAAM,CAAC,CAAC,EAEnCH,EAAYG,CAAG,EAAIJ,EAAUI,EAAM,CAAC,EAM1C,QAASA,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMf,EAAQ,QAChB,GAAIA,EAAQe,CAAG,EAAI,EACjB,MAAM,IAAI,MAAM,8CAA8C,OAGhEf,EAAQ,KAAK,CAAC,EAKlB,QAASe,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMF,EAAU,QAClB,GAAIA,EAAUE,CAAG,EAAI,EACnB,MAAM,IAAI,MAAM,gDAAgD,OAGlEF,EAAU,KAAK,CAAC,EAKpB,QAASE,EAAM,EAAGA,EAAMH,EAAY,OAAS,EAAGG,IAC9C,GAAIA,EAAMD,EAAK,QACb,GAAIA,EAAKC,CAAG,EAAI,EACd,MAAM,IAAI,MAAM,0CAA0C,OAG5DD,EAAK,KAAK,CAAC,EAKf,QAASC,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAAO,CACjD,GAAIH,EAAYG,CAAG,GAAK,EACtB,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAID,EAAKC,CAAG,GAAKH,EAAYG,CAAG,GAAKD,EAAKC,EAAMH,EAAY,MAAM,GAAKA,EAAYG,CAAG,EACpF,MAAM,IAAI,MAAM,oCAAoC,CAExD,CACF,CAGA,OAAO,yBACHJ,EAA8BX,EAA4Ba,EAC1DD,EAAgCE,EAAgBE,EAAwBC,EAAwB,CAClG,GAAKA,EAIL,IAAIH,EAAK,SAAW,GAAKH,EAAU,OAAS,GAC1C,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIX,EAAQ,SAAYW,EAAU,OAAS,EACzC,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIC,EAAY,SAAYD,EAAU,OAAS,EAC7C,MAAM,IAAI,MAAM,iEAAiE,EAGnF,QAASI,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CN,EAAa,wBACTE,EAAUI,GAAOC,EAAgB,EAAI,EAAE,EAAGhB,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAChGA,EAAMJ,EAAU,OAAS,EAAGM,CAAO,EAE3C,CAaA,OAAO,uBACHP,EAA2BC,EAA8BX,EAAmBa,EAC5ED,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,EACtB,MAAM,IAAI,MAAM,4CAA4C,EAI9D,IAAMO,EAAa,CAACP,EAAU,CAAC,EAAGA,EAAU,CAAC,CAAC,EAE9C,OAAAF,EAAa,mBACTC,EAAkBC,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACpFC,CACT,CAYA,OAAO,uBACHP,EAA8BQ,EAA+BnB,EAAmBa,EAChFD,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,GAAKQ,EAAW,QAAU,EAChD,MAAM,IAAI,MAAM,yDAAyD,EAI3E,IAAMD,EAAa,CAACP,EAAU,CAAC,EAAGQ,EAAW,CAAC,CAAC,EAE/C,OAAAV,EAAa,mBAAmB,GAAOE,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACrGC,CACT,CAKA,OAAe,mBACXR,EAA2BC,EAA8BO,EAAsBlB,EAC/Ea,EAA8BD,EAAgCE,EAAgBG,EAAkB,CAClG,GAAIP,EACF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAK,CAAC,MAGnB,SAASH,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAKT,EAAa,wBACzBE,EAAUI,EAAM,CAAC,EAAGf,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAAKA,EAAMJ,EAAU,OAAS,EACxGM,CAAO,CAAC,CAGlB,CAIA,OAAe,wBACXG,EAAgBC,EAAgBC,EAAkBC,EAAgBT,EAAgBU,EAClFC,EAAsBR,EAA0B,CAClD,IAAMS,EAAUJ,GAAYC,EAAS,GAAK,EAC1C,GAAIN,GAAWA,IAAY,SACzB,OAAQA,EAAS,CACf,IAAK,QACH,OAAAH,EAAKU,CAAY,EAAI,EACrBV,EAAKW,CAAY,EAAI,EACd,KAAK,OAAQL,EAASM,GAAWL,EAAU,CAAC,EACrD,IAAK,aACL,IAAK,aACH,GAAIC,IAAa,EACf,MAAM,IAAI,MAAM,qDAAqD,EAChE,CAEL,IAAMK,IADoBP,EAASC,EAAS,GAAKA,EACX,GAAKA,EAASE,EAASH,EAC7D,OAAAN,EAAKU,CAAY,EACgB,KAAK,MAAjCP,IAAY,cAA4BU,EAAY,GAAK,EAAgBA,EAAY,CAA3B,EAC/Db,EAAKW,CAAY,EAAIE,EAAYb,EAAKU,CAAY,EAC3C,KAAK,OAAQJ,EAASO,EAAYJ,GAAUF,EAAU,CAAC,CAChE,CACF,QACE,MAAM,IAAI,MAAM,0BAA0B,CAC9C,KAEA,QAAO,KAAK,OAAQD,EAASN,EAAKU,CAAY,EAAIV,EAAKW,CAAY,EAAIC,GAAWL,EAAU,CAAC,CAEjG,CACF,EAEalD,GAAN,KAAe,CAIpB,OAAO,qBACHyD,EAA8BC,EAAoBC,EAA+BC,EACjFC,EAAkD,CACpD,GAAIJ,EAAU,SAAW,GAAKE,EAAW,SAAW,EAClD,MAAM,IAAI,MAAM,4BAA4B,EAG9C,IAAIG,EACAC,EACAC,EAEAN,GACFI,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,IAEfK,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,GAGjB,IAAIQ,EAAO,GAUX,GARIL,GACFI,EAAIL,EAAW,CAAC,EAChBM,EAAO,IAEPD,EAAIL,EAAW,CAAC,EAChBM,EAAO,GAGLN,EAAWM,CAAI,IAAMF,EACvB,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAID,GAAK,GAAKE,GAAK,GAAKD,GAAK,EAC3B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIF,GAAa,CAAChE,GAAc,iBAAiBgE,EAAW,CAACC,EAAGE,CAAC,CAAC,EAChE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,MAAO,CAACF,EAAGE,EAAGD,CAAC,CACjB,CACF,EAGa9D,GAAW,sBACXC,GAAW,uBCpcxB,IAiBagE,GAsMPC,GAoCOC,GAUAC,GAOAC,GAiBAC,GAcAC,GAgBAC,GAkBAC,GAsBPC,GAwSOC,GAaAC,GAaAC,GAgFPC,GAqHOC,GAYAC,GAeAC,GAr4BbC,GAAAC,GAAA,kBAGAC,KACAC,KAaapB,GAAiB,GAsMxBC,GAAoB,CAACoB,EAAcC,IAAiD,CACxF,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,OAAQD,EAAM,CACZ,QACE,OAAOC,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,QACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,QACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,OACE,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mBAAmB,EAErC,MAAO,CAAC,MAAO,YAAY,EAE7B,QACE,MAAM,IAAI,MAAM,sBAAsBD,CAAI,EAAE,CAChD,CACF,EAEanB,GAA8B,CAACmB,EAAgBC,EAAsB,IAAM,CACtF,IAAMC,EAAatB,GAAkBoB,EAAMC,CAAU,EACrD,OAAO,OAAOC,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAOapB,GAA8BqB,GACvCA,EAAK,SAAW,EAAI,CAAC,EAAI,CAAC,CAAC,KAAM,SAAU,KAAMA,CAAI,EAAG,CAAC,KAAM,SAAU,KAAMC,EAAU,eAAeD,CAAI,CAAC,CAAC,EAMrGpB,GAAoBsB,GAE3BA,EAAO,IAAM,EACR,EACEA,EAAO,IAAM,EACf,EAGF,EASIrB,GAAa,CAACsB,EAAW,MAAOL,EAAqBM,EAAQ,MACpE,CAACN,GAAcA,IAAe,EACzB,GAAGK,CAAQ,IAAIC,CAAK,IAGtB,MAAMN,CAAU,IAAIK,CAAQ,KAAKC,CAAK,IASlCtB,GAAY,CAACqB,EAAkBL,EAAoBM,IAC1DD,IAAa,MACRC,EAELN,IAAe,EACV,OAAOM,CAAK,IAGd,MAAMN,CAAU,KAAKM,CAAK,IAQtBrB,GAAY,CAACsB,EAAcP,IAClCA,IAAe,EACV,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAC1CP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,MAClBP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAGlCA,EASIrB,GAAe,CAACqB,EAAcC,EAAsBC,IAC3DF,EAAK,WAAW,WAAW,GAAKE,EAAS,EACvC,OAAQD,GAAW,SACd,GAAGD,CAAI,KAAKC,CAAK,WAAWA,CAAK,SAEjC,GAAGD,CAAI,IAAI,KAAK,MAAMC,EAAQ,CAAC,CAAC,KAAKA,EAAQ,CAAC,IAGhDC,EAAS,EAAI,GAAGF,CAAI,IAAIC,CAAK,IAAMD,EAcxCpB,GACF,CAACoB,EAAcG,EAAoBC,EAAuCC,EACzEZ,IAAuC,CACtC,IAAMa,EAAa,OAAOF,GAAgB,SACpCG,EAAOD,EAAaF,EAAcA,EAAY,OAC9CI,EAAe,CAAC,GAAG,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAC,EACzCE,EAAcF,EAAO,EAAI,MAAQA,GAAQ,EAAI,MAAMA,CAAI,QAAU,cAAcA,CAAI,IACnFb,EAAatB,GAAkB+B,EAAYV,CAAU,EACrDiB,EAAY,OAAOhB,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACtEiB,EAAc,OAAOjB,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACxEF,EAAO,CAAC,QAASiB,EAAa,MAAOC,EAAW,QAASC,EAAa,OAAQR,CAAU,EAExFS,EAAgBC,IAA+B,OAAOA,IAAQ,SAAWA,GAAM,GAAGA,EAAG,IAErFC,EAAqB,CACzB,gBAAiB,GACjB,gBAAiB,GACjB,2BAA4B,GAC5B,IAAK,GACL,aAAc,GACd,IAAK,GACL,aAAc,EAChB,EAEMC,EAAgBT,EAAa,YAAc,GAC3CU,EAAQ,GAAGD,CAAa,GAAGf,CAAI,SAC/BiB,EAAU,GAAGF,CAAa,GAAGf,CAAI,WAEnCkB,EAAa,GACjB,QAASC,GAAI,EAAGA,GAAIZ,EAAO,EAAGY,KAC5BD,GAAc;AAAA,aACTC,EAAC,gBAAgBxC,GAAasC,EAASE,GAAGZ,CAAI,CAAC;AAAA,cAC9CY,EAAC,gBAAgBxC,GAAasC,EAASE,GAAGZ,CAAI,CAAC;AAAA,cAC/CY,EAAC,UAAUA,EAAC;AAAA,oBACNA,EAAC;AAAA,MAGfD,GAAc,WAAWX,EAAO,CAAC,eAEjC,IAAMa,EAAgCb,EAAO,EAAI,GAAK;AAAA,WACjDP,CAAI,oBAAoBR,EAAK,OAAO;AAAA,mBAC5BA,EAAK,OAAO;AAAA;AAAA,MAEzB0B,CAAU;AAAA;AAAA,KAIJG,EAAmBC,KACvBR,EAAmB,gBAAkB,GAC9BP,EAAO,EAAIe,GAAY,OAAOtB,CAAI,IAAIsB,EAAS,KAGlDC,EAAoB,CAAC,EAC3B,GAAIhB,GAAQ,EACV,QAASY,GAAIZ,EAAO,EAAGY,IAAK,EAAGA,KAC7BI,EAAQ,KAAK,GAAG5C,GAAasC,EAASE,GAAGZ,CAAI,CAAC,eAAeY,EAAC,IAAI,EAItE,IAAMK,EAAgCjB,EAAO,EAAI,GAAK;AAAA,WACjDP,CAAI,aAAaR,EAAK,OAAO;AAAA,aAC3B+B,EAAQ,KAAK,GAAG,CAAC;AAAA,KAGlBE,EAAmBC,KACvBZ,EAAmB,gBAAkB,GAC9BP,EAAO,EAAImB,GAAa,OAAO1B,CAAI,IAAI0B,EAAU,KAGpDC,EAAU,IAAIC,KAChBrB,IAAS,EAAI,KAAO,GAAGf,EAAK,OAAO,IAAIoC,GAAK,IAAIhB,CAAY,EAAE,KAAK,GAAG,CAAC,IAErEiB,GAAa,CAACH,GAAoBI,KAClCvB,EAAO,EACF,GAAGmB,EAAU,GAEb,GAAG/C,GAAa+C,GAAYI,GAAKvB,CAAI,CAAC,GAI3CwB,GAAa,CAACL,GAAoBI,GAAoB/B,KACtDQ,EAAO,EACF,GAAGmB,EAAU,IAAI3B,EAAK,IAEtB,GAAGpB,GAAa+C,GAAYI,GAAKvB,CAAI,CAAC,IAAIR,EAAK,IAIpDiC,EAAoE,CAAC,EACrEC,GAA6B,CAACP,GAAoBQ,KAA0B,CAChFpB,EAAmB,2BAA6B,GAChD,IAAMqB,GAAU,GAAGD,GAAO,IAAI,uBAAuBlC,CAAI,SACzD,GAAImC,MAAWH,EACb,MAAO,GAAGG,EAAO,IAAIT,EAAU,IAEjC,IAAMH,GAAU,CAAC,EACjB,QAASJ,GAAIZ,EAAO,EAAGY,IAAK,EAAGA,KAAK,CAClC,IAAMW,GAAMI,GAAO,WAAW,gBAAiBf,GAAIe,GAAO,KAAO3B,CAAI,EACrEgB,GAAQ,KAAK,GAAGM,GAAWZ,EAASE,EAAC,CAAC,OAAOW,EAAG,MAAMD,GAAWb,EAAOG,EAAC,CAAC,GAAG,CAC/E,CACA,OAAAa,EAAyCG,EAAO,EAC5C,MAAMA,EAAO,mBAAmBD,GAAO,KAAK,OAAO;AAAA,sBACzCX,GAAQ,OAAS,EAAIA,GAAQ,KAAK,GAAG,EAAI,IAAI;AAAA,cAGpD,GAAGY,EAAO,IAAIT,EAAU,GACjC,EAEMU,GAAc,CAACC,GAAuBtC,MAAmB,IAAM,CACnE,GAAIP,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAIqC,EAAM,KAAKtC,EAAK,IAC7B,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAIqC,EAAM,mBAAmBtC,EAAK,8BAA8BA,EAAK,UAC9E,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAIqC,EAAM,mBAAmBtC,EAAK,UAC3C,GAAIP,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,GAAGQ,CAAI,IAAIqC,EAAM,8DAA8DtC,EAAK,MAE3F,MAAM,IAAI,MAAM,6CAA6CP,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG8C,GAAeD,KAA2B,IAAM,CACpD,GAAI7C,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAIqC,EAAM,IACnB,GAAI7C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAIqC,EAAM,OACvB,GAAI7C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAIqC,EAAM,OACvB,GAAI7C,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,mBAAmBQ,CAAI,IAAIqC,EAAM,oBAAoBrC,CAAI,IAAIqC,EAAM,sBAAsBrC,CAAI,IAChGqC,EAAM,wBAAwBrC,CAAI,IAAIqC,EAAM,oBAEhD,MAAM,IAAI,MAAM,6CAA6C7C,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG+C,GAA6BhC,EAAO,EAAI,GAAK;AAAA,WAC9CP,CAAI,sBAAsBR,EAAK,OAAO,QAAQkB,CAAS;AAAA,aACrD4B,GAAY,OAAOtC,CAAI,WAAW,CAAC;AAAA,KAGpCwC,GAAoBjC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,GAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,GAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJnB,CAAI,IAAIyC,EAAc,QAAQ/B,CAAS;AAAA,iBACjCV,CAAI,aAAa2B,EAAQe,EAAU,CAAC;AAAA,IAE/C,GAAG,EAEGC,GAAM,IAAIhB,KAA0C,CACxD,GAAIA,GAAQ,SAAWpB,EACrB,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAGlD,IAAMqC,GAAoBjB,GAAQ,IAAIf,CAAY,EAAE,KAAK,GAAG,EAE5D,OAAIL,IAAS,EACJ+B,GAAY,IAAI,EACd/B,IAAS,EACX+B,GAAYM,GAAkB,CAAC,CAAC,GAEvC9B,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOd,CAAI,IAAI4C,EAAiB,IAE3C,EAEMC,GAAgBnB,IAChBnB,EAAO,EACF+B,GAAYZ,EAAU,GAE7BZ,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOd,CAAI,aAAa0B,EAAU,KAIvCoB,GAA6BvC,EAAO,EAAI,GAAK;AAAA,WAC9CP,CAAI,sBAAsBR,EAAK,OAAO,YAAYkB,CAAS;AAAA,MAChE0B,GAAY,OAAOpC,CAAI,YAAa,OAAO,CAAC;AAAA,KAGtC+C,GAAoBxC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,GAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,GAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJnB,CAAI,IAAIyC,EAAc,YAAY/B,CAAS;AAAA,UAC5CV,CAAI,aAAa2B,EAAQe,EAAU,CAAC;AAAA,IAExC,GAAG,EAiEH,MAAO,CACL,KA/BW,IAAM,CACjB,IAAMM,GAAQ,CAAC,EACf,OAAK1C,IACH0C,GAAM,KAAK,SAAShC,CAAK,MAAMxB,EAAK,OAAO,IAAIY,EAAY,KAAK,GAAG,CAAC,IAAI,EACxE4C,GAAM,KAAK,SAAS/B,CAAO,MAAMzB,EAAK,OAAO,IAAII,EAAU,eAAeQ,CAAW,EAAE,KAAK,GAAG,CAAC,IAAI,GAElGU,EAAmB,iBACrBkC,GAAM,KAAK5B,CAA6B,EAEtCN,EAAmB,iBACrBkC,GAAM,KAAKxB,CAA6B,EAEtCV,EAAmB,4BACrB,OAAO,OAAOkB,CAAwC,EAAE,QAAQiB,IAAQD,GAAM,KAAKC,EAAI,CAAC,EAEtFnC,EAAmB,KACrBkC,GAAM,KAAKD,EAAiB,EAE1BjC,EAAmB,cACrBkC,GAAM,KAAKF,EAA0B,EAEnChC,EAAmB,KACrBkC,GAAM,KAAKR,EAAiB,EAE1B1B,EAAmB,cACrBkC,GAAM,KAAKT,EAA0B,EAEhCS,GAAM,KAAK;AAAA,CAAI,CACxB,EAIE,KAAAxD,EACA,gBAAA6B,EACA,gBAAAI,EACA,2BAAAQ,GACA,QAAAN,EACA,WAAAE,GACA,WAAAE,GACA,IAxEU,IAAImB,KAAkD,CAChE,GAAIA,GAAgB,SAAW3C,EAAO,EACpC,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,IAAMR,GAAQmD,GAAgB3C,CAAI,EAClC,GAAI,OAAOR,IAAU,SACnB,MAAM,IAAI,MAAM,sBAAsB,EAGxC,IAAM6C,GAAoBM,GAAgB,MAAM,EAAG3C,CAAI,EAAE,IAAIK,CAAY,EAAE,KAAK,GAAG,EAEnF,OAAIL,IAAS,EACJ6B,GAAY,KAAMrC,EAAK,EACrBQ,IAAS,EACX6B,GAAYQ,GAAkB,CAAC,EAAG7C,EAAK,GAE9Ce,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOd,CAAI,IAAI4C,EAAiB,KAAK7C,EAAK,IAErD,EAoDE,YAAAqC,GACA,aAnDmB,CAACV,GAAoB3B,KACpCQ,EAAO,EACF6B,GAAYV,GAAY3B,EAAK,GAEpCe,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOd,CAAI,aAAa0B,EAAU,KAAK3B,EAAK,MA8CrD,IAAA4C,GACA,YAAAL,GACA,aAAAO,GAEA,MAAAxC,EACA,KAAAL,EACA,QAAAiB,EACA,MAAAD,EACA,KAAAT,CACF,CACF,EAWS1B,GACT,CAACmB,EAAcR,EAAcY,EAAuCX,EAAsB,IACtFb,GAAoBoB,EAAMR,EAAMY,EAAa,QAASX,CAAU,EAW3DX,GACT,CAACkB,EAAcR,EAAcY,EAAuCX,EAAsB,IACtFb,GAAoBoB,EAAMR,EAAMY,EAAa,SAAUX,CAAU,EAW5DV,GACT,CAACiB,EAAcR,EAAcY,EAAuCX,EAAsB,IACtFb,GAAoBoB,EAAMR,EAAMY,EAAa,WAAYX,CAAU,EA8ErET,GAAN,KAA+C,CAC7C,YAAoBmE,EAAmD,CAAnD,6BAAAA,EAmFpB,KAAQ,kBAAqC,CAAC,EAC9C,KAAQ,UAA6B,CAAC,EACtC,KAAQ,SAA8B,CAAC,EAoBvC,KAAQ,cAAgB,CAzGgD,CAExE,sCAAsCtD,EAA6B,CAGjE,MAAO,qBADY,OAAOA,GAAS,SAAW,GAAGA,CAAI,IAAMA,CACrB,eACxC,CAEA,UAAUuD,EAAiDjF,GAAgB,CACzE,IAAMkF,EAAiB,OAAOD,GAAkB,SAAWA,EAAgBA,EAAc,CAAC,EACpFE,EAAiB,OAAOF,GAAkB,SAAW,EAAIA,EAAc,CAAC,EACxEG,EAAiB,OAAOH,GAAkB,SAAW,EAAIA,EAAc,CAAC,EAExEI,EAAuB,KAAK,wBAAwB,CAAC,IAAM,GAAK,KAAK,wBAAwB,CAAC,IAAM,EACpGC,EAAYD,EAAuB;AAAA,wDAEA;AAAA;AAAA,yDAGnCE,EAAsBF,EACxB,gCACA;AAAA,mEAEIH,EAAiBC,EAAiBC,CAAc,mBAExD,MAAO,4BAA4BF,CAAc,KAAKC,CAAc,KAAKC,CAAc;AAAA,YAC/EE,CAAS;AAAA,MACfC,CAAmB;AAAA,GAEvB,CAEQ,uBAAuBC,EAA+B,CACxDA,EAAS,OAAS,IAChBA,EAAS,MAAM,WAAW,WAAW,GACvC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,MAAM,QAAQ,YAAa,EAAE,EAAG,KAAM,MAAO,OAAQA,EAAS,IAAI,CAAC,EAEpGA,EAAS,QAAQ,WAAW,WAAW,GACzC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,QAAQ,QAAQ,YAAa,EAAE,EAAG,KAAM,MAAO,OAAQA,EAAS,IAAI,CAAC,EAG9G,CAEQ,gBAAgBA,EAAyBC,EAA8B,CAC7E,GAAID,EAAS,QAAU,WACrB,MAAM,IAAI,MAAM,+FAA+F,EAEjH,KAAK,UAAU,KAAKA,CAAQ,EAC5B,KAAK,uBAAuBA,CAAQ,EAEpC,IAAME,EAASF,EAAS,QAAU,QAAU,OAAS,aAC/ChD,EAAcgD,EAAS,KAAK,QAClC,MAAO,sBAAsBC,CAAY,kBAAkBC,CAAM,KAAKF,EAAS,IAAI,WAAWhD,CAAW,IAC3G,CAEA,oBAAoBmD,EAAoC,CACtD,OAAOA,EAAU,IAAIC,GAAK,KAAK,gBAAgBA,EAAG,KAAK,eAAe,CAAC,EAAE,KAAK;AAAA,CAAI,CACpF,CAEQ,yBAAyBJ,EAA+B,CAC9D,GAAIA,EAAS,QAAU,WACrB,MAAM,IAAI,MACN,sGAAsG,EAG5G,KAAK,kBAAkB,KAAKA,CAAQ,EACpC,KAAK,uBAAuBA,CAAQ,CACtC,CAEA,6BAA6BG,EAA0C,CACrE,OAAAA,EAAU,QAAQC,GAAK,KAAK,yBAAyBA,CAAC,CAAC,EAChD,IACT,CAEA,gBAAgB/D,EAAcR,EAA8BU,EAAS,EAAiB,CACpF,YAAK,SAAS,KAAK,CAAC,KAAAF,EAAM,KAAAR,EAAM,OAAAU,CAAM,CAAC,EAChC,IACT,CAEA,iBAAiB8D,EAAqD,CACpE,YAAK,SAAW,KAAK,SAAS,OAAOA,CAAkB,EAChD,IACT,CAKQ,oBAA6B,CACnC,GAAI,KAAK,SAAS,SAAW,EAC3B,MAAO,GAGT,IAAMC,EAA4B,CAAC,EACnC,OAAW,CAAC,KAAAjE,EAAM,KAAAR,EAAM,OAAAU,CAAM,IAAK,KAAK,SACtC,GAAIA,GAAUA,EAAS,EACrB+D,EAAgB,KAAK,GAAGjE,CAAI,eAAeR,CAAI,MAAM,KAAK,KAAKU,EAAS,CAAC,CAAC,GAAG,MACxE,CACL,IAAMgE,EAAWhE,GAAU,MAAQA,IAAW,EAAIV,EAAO,MAAMU,CAAM,IAAIV,CAAI,IAC7EyE,EAAgB,KAAK,GAAGjE,CAAI,IAAIkE,CAAQ,EAAE,CAC5C,CAGF,MAAO;AAAA,0BACeD,EAAgB,KAAK,IAAI,CAAC;AAAA,2BACzB,KAAK,aAAa,oCAC3C,CAMA,IAAI,2BAAoC,CACtC,OAAO,KAAK,mBAAmB,EAAI,KAAK,UAAU,IAAI9C,GAAKA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,EAC1E,KAAK,kBAAkB,IAAIA,GAAKA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,CACzD,CACF,EAEalC,GAAsBkF,GAA4C,IAAInF,GAAiBmF,CAAa,EAYpGjF,GAAmB,CAACkF,EAA4BC,IAA0C,CACrG,IAAMC,EAASF,EAAQ,OACjBzE,EAAiB,CAAC,EACxB,QAASwB,EAAI,EAAGA,EAAImD,EAAQnD,IAAK,CAC/B,IAAMN,EAAMyD,EAAS,EAAInD,EACnBoD,EAAIH,EAAQvD,CAAG,GAAK,GAChBwD,EAASA,EAAS,OAAS,EAAIlD,CAAC,GAAK,GACvC,GAAKoD,IAAM,GACjB5E,EAAK,QAAQkB,CAAG,CAEpB,CACA,OAAOlB,CACT,EAGaR,GAAwBqF,GAA2B,KCr4BhE,IAcMC,GAMAC,GAGAC,GAGAC,GAWOC,GA+CAC,GAKAC,GAzFbC,GAAAC,GAAA,kBAIAC,KACAC,KAGAC,KAMMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,6BAA6B,CAEjD,EAEMX,GAAkB,CAACY,EAAmBC,IACvCA,GAAQA,EAAK,SAAWD,EAAa,CAAC,GAAI,IAAI,MAAMA,CAAS,EAAE,KAAK,CAAE,EAAE,QAAQ,EAAIC,EAEnFZ,GAAiB,CAACa,EAA+BD,IACnDE,EAAU,gBAAgBD,EAAYd,GAAgBc,EAAW,OAAQD,CAAI,CAAC,EAE5EX,GAAmB,CAACW,EAAgBG,EAAcC,EAAsBC,IAAkC,CAC9G,IAAMC,EAAc,CAAC,EACrBA,EAAY,KAAK,cAAcD,EAAO,KAAK,OAAO,QAAQD,EAAM,KAAK,OAAO;AAAA,aACjEA,EAAM,KAAK,OAAO,GAAG,EAChC,QAASG,EAAI,EAAGA,EAAIJ,EAAM,EAAEI,EAC1BD,EAAY,KAAKF,EAAM,WAAW,IAAKJ,EAAKO,CAAC,EAAG,KAAKA,CAAC,GAAG,CAAC,EAE5D,OAAAD,EAAY,KAAK,YAAY,EACtBA,EAAY,KAAK;AAAA,CAAI,CAC9B,EAEahB,GAA6B,CAACkB,EAAyBC,IAAoC,CACtG,IAAMC,EAAgBF,EAAY,SAC5BT,EAAYS,EAAY,KAAK,OAC7BR,EAAOb,GAAgBY,EAAWU,CAAQ,EAC1CE,EAAoBC,GAAqBb,CAAS,EAClDc,EAAczB,GAAeoB,EAAY,KAAMR,CAAI,EACnDc,EAAiBH,EAAoBE,EAAY,OAASA,EAC1DE,EAAgBJ,EAAoBZ,EAAYS,EAAY,KAC5DH,EAASW,GAAe,SAAUN,EAAeI,CAAc,EAC/DV,EAAQa,GAAc,IAAKP,EAAeK,CAAa,EAEvDG,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBf,EAAOC,CAAM,CAAC;AAAA;AAAA,IAElFhB,GAAiBW,EAAMD,EAAWK,EAAOC,CAAM,CAAC;AAAA;AAAA,IAEhDc,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,oBAE5Dd,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,MAGlDA,EAAO,YAAY,aAAcD,EAAM,aAAa,UAAU,CAAC,CAAC;AAAA,KAEpE,MAAO,CACL,KAAM,YACN,YAAa,CAAC,KAAM,GAAGK,CAAQ,GAAI,kBAAmBE,EAAoB,CAAC,MAAM,EAAI,CAAC,MAAM,CAAC,EAC7F,WAAab,GAAW,CACtB,IAAMsB,EAAalB,EAAU,KAAKW,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUf,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,EAClE,gBAAiBT,EACb,CACE,CAAC,KAAM,SAAU,KAAMS,CAAU,EACjC,GAAGC,GAA2BvB,EAAO,CAAC,EAAE,IAAI,EAC5C,GAAGuB,GAA2BR,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAMO,CAAU,CACnC,CACN,CACF,EACA,gBAAAF,CACF,CACF,EAEa3B,GAAY,CAAC+B,EAAyBC,IAA0C,CAC3FrC,GAAeoC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQhC,GAA2BgC,EAAQ,OAAO,CAAC,EAAGC,EAAW,IAAI,CAAC,CAChF,EAEa/B,GAA4B+B,GACrCC,GAA4B,CAAC,KAAMD,EAAW,IAAgB,CAAC,IC1FnE,IAYME,GAaAC,GAaAC,GAaAC,GAYAC,GAQAC,GAYAC,GAcAC,GASAC,GAaOC,GA0EPC,GAkCOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAvQbC,GAAAC,GAAA,kBAKAC,KAGAC,KACAC,KACAC,KAEM1B,GAAqC,CACzC,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,oCACX,UAAW,6BACX,GAAI,6BACJ,GAAI,oCACJ,OAAQ,uBACV,EAEMC,GAA2C,CAC/C,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,wBACX,UAAW,wBACX,GAAI,wBACJ,GAAI,wBACJ,OAAQ,uBACV,EAEMC,GAA4C,CAChD,IAAK,aACL,IAAK,aACL,KAAM,IACN,IAAK,IACL,KAAM,IACN,UAAW,IACX,UAAW,IACX,GAAI,IACJ,GAAI,IACJ,OAAQ,GACV,EAEMC,GAA8C,CAClD,IAAK,YACL,IAAK,YACL,IAAK,YACL,KAAM,YACN,UAAW,YACX,UAAW,iBACX,GAAI,YACJ,GAAI,kBACJ,OAAQ,gBACV,EAEMC,GAAmB,CAACuB,EAAsBC,IAA2B,CACzE,IAAMC,EAAM,CAAC,EACb,QAASC,EAAIF,EAAOD,EAAcG,EAAIF,EAAM,EAAEE,EAC5CD,EAAI,KAAKC,CAAC,EAEZ,OAAOD,CACT,EAEMxB,GAA4B,CAAC0B,EAA0BC,IAAkD,CAC7G,IAAMC,EAAc,CAAC,EACfL,EAAOG,EAAM,OACnB,QAASG,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,IACxBD,EAAY,KAAKF,EAAMG,CAAG,CAAC,EAG/B,IAAMC,EAAcH,EAAK,IAAIE,GAAOH,EAAMG,CAAG,CAAC,EAC9C,MAAO,CAACD,EAAaE,CAAW,CAClC,EAEM7B,GAAuB,CAACyB,EAAiBC,IAA6B,CAC1E,IAAMJ,EAAOG,EAAM,OAASC,EAAK,OAC3BI,EAAc,CAAC,EACjBC,EAAW,EACf,QAASH,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,GACxBE,EAAY,KAAKL,EAAMM,GAAU,CAAC,EAElCD,EAAY,KAAK,CAAC,EAGtB,OAAOA,CACT,EAEM7B,GAAuB,CAACyB,EAAgBJ,IAA0B,CACtE,QAASE,EAAI,EAAGA,EAAIE,EAAK,OAAQ,EAAEF,EACjC,GAAIE,EAAKA,EAAK,OAASF,EAAI,CAAC,IAAMF,EAAO,EAAIE,EAC3C,MAAO,GAGX,MAAO,EACT,EAEMtB,GAAqB,CAACwB,EAAgBJ,IAA2B,CACrE,IAAMC,EAAM,CAAC,EACb,GAAI,CAACtB,GAAqByB,EAAMJ,CAAI,EAAG,CACrC,QAASE,EAAI,EAAGA,EAAIF,EAAM,EAAEE,EACtBE,EAAK,QAAQF,CAAC,IAAM,IACtBD,EAAI,KAAKC,CAAC,EAGdE,EAAK,QAAQM,GAAQT,EAAI,KAAKS,CAAI,CAAC,CACrC,CACA,OAAOT,CACT,EAEapB,GACT,CAAC8B,EAAcC,EAAqCC,EAA+BC,EAClFC,EAA0BV,EAAuBE,IAAuC,CACvF,IAAMS,EAAaH,EAAO,CAAC,EAAE,KAEvBI,EAAaC,EAAU,KAAKb,CAAW,EACvCc,EAAaD,EAAU,KAAKX,CAAW,EAEvCa,EAAQC,GAAc,KAAMR,EAAO,CAAC,EAAE,SAAUG,CAAU,EAC1DM,EAASC,GAAe,SAAUR,EAAgBV,CAAW,EAE7DmB,EAAgB,GAEhBC,EAAsB;AAAA,+CACaH,EAAO,KAAK,OAAO,KAAKE,CAAa;AAAA,SAgD9E,MAAO,CACL,KAAAb,EACA,YAAAC,EACA,gBAhDuBc,GAA+B;AAAA,UACpDA,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBN,EAAOE,CAAM,CAAC;AAAA,UACjFG,CAAmB;AAAA;AAAA;AAAA;AAAA,WAIlBC,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA,2CAGLA,CAAa;AAAA;AAAA;AAAA,4BAG5BF,EAAO,KAAK,OAAO,IAAIhD,GAAiBwC,CAAU,CAAC;AAAA;AAAA,wDAEvBU,CAAa;AAAA,6BACxCF,EAAO,KAAK,OAAO,IAAIF,EAAM,YAAY,YAAY,CAAC;AAAA,yBAC1DhD,GAAU0C,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,wCAKNU,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAM3BnD,GAAgByC,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAS3CQ,EAAO,YACH,cACA,GACIR,IAAe,OAAS,eAAeQ,EAAO,KAAK,OAAO,wBAClC,GAAG/C,GAAmBuC,CAAU,CAAC,EAAE,EAAE,CAAC;AAAA;AAAA,WASxE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUU,CAAc,CAAC,EACvD,cAAe,CAAC,EAAGE,CAAU,EAC7B,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAME,CAAU,CAAC,CACtD,EACF,CACF,EAEErC,GACF,CAAC6C,EAAyBhB,EAAciB,EACvCd,IAAiG,CAChG,IAAMe,EACFF,EAAQ,OAAO,SAAW,EAAIC,EAAaE,GAAiCH,EAAQ,OAAQC,CAAU,EAEtGG,EAAcF,EAAkB,KAChCE,EAAY,SAAW,GAAK,CAACF,EAAkB,oBACjDE,EAAcJ,EAAQ,OAAO,CAAC,EAAE,KAAK,IAAI,CAACK,EAAM9B,IAAMA,CAAC,GAEzD,IAAM+B,EAAgBf,EAAU,cAAca,EAAaJ,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EAEpFvB,EAAO6B,EACPb,EAAQO,EAAQ,OAAO,CAAC,EACtBO,EAAetD,GAAmBwB,EAAMuB,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EACvEO,EAAa,OAAS,IACxBd,EAAQO,EAAQ,QACZQ,GAA2BR,EAAQ,OAAO,CAAC,EAAGO,CAAY,EAAG,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAChG9B,EAAO5B,GAAiB4B,EAAK,OAAQgB,EAAM,KAAK,MAAM,GAGxD,GAAM,CAACf,EAAaE,CAAW,EAAI9B,GAA0B2C,EAAM,KAAMhB,CAAI,EACzEgC,EAAmB/B,EACnBwB,EAAkB,WACpBO,EAAmB1D,GAAqB2B,EAAa4B,CAAa,GAGpEN,EAAQ,QACJ9C,GACI8B,EAAM,CAAC,KAAMkB,EAAkB,SAAU,kBAAmB,CAAC,MAAM,CAAC,EAAG,CAACT,CAAK,EAAGN,EAChFa,EAAQ,OAAO,CAAC,EAAE,SAAUS,EAAkB7B,CAAW,EAC7D,CAAC,OAAQ,CAACa,CAAK,CAAC,CAAC,CACvB,EAESrC,GAAmB,CAAC4C,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEa5C,GAAiB,CAAC2C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa3C,GAAiB,CAAC0C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa1C,GAAwB,CAACyC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEazC,GAAkB,CAACwC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEaxC,GAAkB,CAACuC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEavC,GAAmB,CAACsC,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEatC,GAAkB,CAACqC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEarC,GAAwB,CAACoC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEapC,GAAqB,CAACmC,EAAyBC,IAAuC,CACjG9C,GAAa6C,EAAS,qBAAsBC,EAAY,QAAQ,CAClE,ICzQA,IAYMS,GAoBAC,GACOC,GA4EAC,GAUPC,GAeAC,GAWAC,GAWAC,GAWAC,GAWAC,GAoBAC,GAqBAC,GAoBAC,GAWAC,GAWAC,GAWAC,GAsBOC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAtXbC,GAAAC,GAAA,kBAKAC,KACAC,KAGAC,KACAC,KAEMhC,GAAkBiC,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,0BAA0B,CAE9C,EAYMhC,GAAkBiC,GAAU,CAAC,GAAI,GAAI,eAAeA,EAAM,YAAY,aAAa,CAAC,IAAK,EAAE,EACpFhC,GACT,CAACiC,EAAcC,EAAqCH,EAA+BI,EAClFC,EAAqBC,EAA0BC,EAAW,GAAOC,EAAoB,KAAuB,CAC3G,IAAMC,EAAwB,CAAC,EACzBC,EAAaV,EAAO,CAAC,EAAE,KAEvBW,EAAOC,EAAU,cAAcP,EAAWL,EAAO,CAAC,EAAE,KAAK,MAAM,EAC/Da,EAAkB,CAACL,GAAqBG,EAAK,SAAW,EAC9DD,EAAW,QAAQ,CAACI,EAAGC,IAAM,CACvBF,GAAmBF,EAAK,QAAQI,CAAC,GAAK,EACpCR,GACFE,EAAY,KAAK,CAAC,EAGpBA,EAAY,KAAKK,CAAC,CAEtB,CAAC,EAED,IAAME,EAAoB,CAAC,EAErBf,EAAQgB,GAAc,KAAMjB,EAAO,CAAC,EAAE,SAAUU,CAAU,EAC1DQ,EAASC,GAAe,SAAUb,EAAgBG,CAAW,EAC7DW,EAAMhB,EAASH,EAAOiB,EAAQP,CAAI,EAClCU,EAAwB,iBAAiBpB,EAAM,gBAAgB,cAAc,CAAC,IAC9EqB,EAAqB,OAAOD,CAAqB,IACjDE,EAAqB,OAAOF,CAAqB,IACjDG,EAAmBJ,EAAI,CAAC,IAAM,GAAM,GAAKG,EAC3CE,GAAcL,EAAI,CAAC,IAAM,GAAME,EAAqBD,GAAyB;AAAA,EAAOD,EAAI,CAAC,EAE7F,QAASM,EAAI,EAAGC,EAAI,EAAGD,EAAI1B,EAAO,CAAC,EAAE,KAAK,OAAQ0B,IAE5Cb,GAAmBF,EAAK,QAAQe,CAAC,GAAK,GACpCnB,GACFoB,IAGFF,EAAY,YAAYC,CAAC,eAAeA,CAAC,MAAM1B,EAAO,CAAC,EAAE,KAAK0B,CAAC,CAAC,MAAMA,CAAC;AAAA,kBAC/DN,EAAI,CAAC,EAAE,SAAS,WAAW,EAAI,oBAAoBM,CAAC,IAAM,EAAE;AAAA,kBAC5DzB,EAAM,WAAW,eAAgByB,EAAG,IAAIA,CAAC,EAAE,CAAC;AAAA,kBAC5CD,CAAS;AAAA,mBAGjBT,EAAQ,KAAK,GAAGf,EAAM,WAAW,eAAgByB,EAAGR,EAAO,WAAW,gBAAiBS,CAAC,CAAC,CAAC,GAAG,EAC7FA,KAIJ,IAAMC,EAAahB,EAAU,KAAKH,CAAW,EAkB7C,MAAO,CACL,KAAAP,EACA,YAAAC,EACA,gBApBuB0B,GAA+B;AAAA,UACpDA,EAAa,iBAAiB5B,EAAOiB,CAAM,CAAC;AAAA;AAAA,UAE5CW,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsCD,CAAU,CAAC;AAAA,8BAC5C3B,EAAM,KAAK,OAAO;AAAA,gCAChBiB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDF,EAAQ,KAAK;AAAA,CAAI,CAAC;AAAA,YAClBI,EAAI,CAAC,CAAC;AAAA,YACNI,CAAe;AAAA,YACfJ,EAAI,CAAC,CAAC;AAAA,YACNK,CAAS;AAAA,YACTL,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,SAAW,EAAIF,EAAO,YAAY,aAAc,OAAO,EAAIE,EAAI,MAAM,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,WAO1F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMX,EAAa,SAAUH,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAES1D,GACT,CAAC8B,EAA+B8B,IAAmD,CACjF,IAAMnB,EAAiB,CAAC,EACxB,OAAIX,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,GACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQ+B,GAAKpB,EAAK,KAAK,OAAOoB,CAAC,CAAC,CAAC,EAEzDC,GACH,CAAC,KAAArB,EAAM,SAAUmB,EAAW,SAAU,kBAAmBA,EAAW,iBAAiB,CAAC,CAC5F,EAEE3D,GACF,CAAC8D,EAAyB/B,EAAc4B,EAA8B1B,IAA6B,CACjG,IAAMJ,EAASiC,EAAQ,OACjBC,EACFlC,EAAO,SAAW,EAAI8B,EAAa5D,GAAiC8B,EAAQ8B,CAAU,EAE1FG,EAAQ,QACJhE,GACIiC,EAAM,CAAC,KAAMgC,EAAkB,QAAQ,EAAG,CAAClC,EAAO,CAAC,CAAC,EACpDkC,EAAkB,mBAAqBA,EAAkB,KAAK,SAAW,EAAIlE,GAAOoC,EACpF8B,EAAkB,KAAMlC,EAAO,CAAC,EAAE,SAAUkC,EAAkB,SAC9DA,EAAkB,iBAAiB,EACvC,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEE9D,GAAoB,CAAC6D,EAAyBH,IAAuC,CACzF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,eAAgBH,EANf,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,qBACL,CAC8D,CAChE,EAEM5B,GAAgB,CAAC4D,EAAyBH,IAAuC,CACrF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,EACL,CAC0D,CAC5D,EAEM3B,GAAgB,CAAC2D,EAAyBH,IAAuC,CACrF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,sBACvC,sBACL,CAC0D,CAC5D,EAEM1B,GAAuB,CAAC0D,EAAyBH,IAAuC,CAC5F/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,qBACL,CACiE,CACnE,EAEMzB,GAAiB,CAACyD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAgB7B9D,GAAiB8D,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAKnC,EAAM,WAAW,eAAgByB,EAAG,CAAC,CAAC,EAIvD,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEMxB,GAAkB,CAACwD,EAAyBH,IAAuC,CACvF/D,GAAekE,EAAQ,MAAM,EAiB7B9D,GAAiB8D,EAAS,aAAcH,EAhBb,CAAC7B,EAAOiB,EAAQP,IAAS,CAClD,IAAI0B,EAAO,EACX,QAASX,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,KAE1C0B,GAAQJ,EAAQ,OAAO,CAAC,EAAE,KAAKP,CAAC,GAIpC,MAAO,CACL,oBACA,GACA,cAAczB,EAAM,YAAY,aAAa,CAAC,KAC9C,eAAeiB,EAAO,KAAK,KAAK,UAAUmB,CAAI,IAChD,CACF,CAC4D,CAC9D,EAEM3D,GAAiB,CAACuD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAgB7B9D,GAAiB8D,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAK,gBAAgBV,CAAC,QAAQ,EAI1C,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEMtB,GAAkB,CAACsD,EAAyBH,IAAuC,CACvF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,aAAcH,EANb,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC4D,CAC9D,EAEMrB,GAAiB,CAACqD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,YAAaH,EANZ,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC2D,CAC7D,EAEMpB,GAAuB,CAACoD,EAAyBH,IAAuC,CAC5F/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,oBACvC,EACL,CACiE,CACnE,EAEMnB,GACF,CAACwD,EAA0B3B,EAAyBH,IAAwC,CAC1F,GAAIG,EAAK,SAAW,EAClB,MAAO,EAAAH,EAGT,IAAIoB,EAAa,EACbW,EAAa,EACjB,QAASC,EAAM,EAAGA,EAAM7B,EAAK,OAAQ6B,IAC/B7B,EAAK,QAAQ6B,CAAG,IAAM,GACxBZ,GAAcU,EAAME,CAAG,EAEvBD,GAAcD,EAAME,CAAG,EAO3B,OAAOD,EAAa,IAAMX,EAAa,IACzC,EAES7C,GAAa,CAACkD,EAAyBH,IAAuC,CACrFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FrD,GAAgBwD,EAASH,CAAU,EAEnCW,GAAiBR,EAASH,CAAU,CAExC,EAEa9C,GAAW,CAACiD,EAAyBH,IAAuC,CACnFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FzD,GAAc4D,EAASH,CAAU,EAEjCY,GAAeT,EAASH,CAAU,CAEtC,EAEa7C,GAAW,CAACgD,EAAyBH,IAAuC,CACnFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FxD,GAAc2D,EAASH,CAAU,EAEjCa,GAAeV,EAASH,CAAU,CAEtC,EAEa5C,GAAkB,CAAC+C,EAAyBH,IAAuC,CAC1FhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FvD,GAAqB0D,EAASH,CAAU,EAExCc,GAAsBX,EAASH,CAAU,CAE7C,EAEa3C,GAAY,CAAC8C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FtD,GAAeyD,EAASH,CAAU,EAElCe,GAAgBZ,EAASH,CAAU,CAEvC,EAEa1C,GAAY,CAAC6C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FpD,GAAeuD,EAASH,CAAU,EAElCgB,GAAgBb,EAASH,CAAU,CAEvC,EAEazC,GAAa,CAAC4C,EAAyBH,IAAuC,CACrFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FnD,GAAgBsD,EAASH,CAAU,EAEnCiB,GAAiBd,EAASH,CAAU,CAExC,EAEaxC,GAAY,CAAC2C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FlD,GAAeqD,EAASH,CAAU,EAElCkB,GAAgBf,EAASH,CAAU,CAEvC,EAEavC,GAAkB,CAAC0C,EAAyBH,IAAuC,CAC1FhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FjD,GAAqBoD,EAASH,CAAU,EAExCmB,GAAsBhB,EAASH,CAAU,CAE7C,EAEatC,GAAe,CAACyC,EAAyBH,IAAuC,CACvFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5F1D,GAAkB6D,EAASH,CAAU,EAErCoB,GAAmBjB,EAASH,CAAU,CAE1C,EAEarC,GAAyBqC,GAClCE,GAA4BF,CAAiE,ICvXjG,IAcMqB,GAeOC,GA0BAC,GA0BAC,GAjFbC,GAAAC,GAAA,kBAOAC,KAEAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,qBAAqB,CAEzC,EAQaR,GAAS,CAACS,EAAyBC,IAA0C,CACxFX,GAAeU,EAAQ,MAAM,EAC7B,IAAME,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIF,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEE,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEAJ,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMP,EAAW,QAAQ,EAAG,CAACD,EAAQ,OAAO,CAAC,CAAC,EAAGE,EAAa,CAACD,EAAW,IAAI,IACzFA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEaT,GAAS,CAACQ,EAAyBC,IAA0C,CACxFX,GAAeU,EAAQ,MAAM,EAC7B,IAAME,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIF,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEE,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEAJ,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMP,EAAW,QAAQ,EAAG,CAACD,EAAQ,OAAO,CAAC,CAAC,EAAGE,EAAa,CAACD,EAAW,IAAI,IACzFA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEaR,GAA4BQ,GACrCQ,GAA4BR,CAAoE,IClFpG,IAmEMS,GAsKOC,GAGAC,GAkFPC,GAwGAC,GAiFOC,GASPC,GAmHOC,GAnnBbC,GAAAC,GAAA,kBAIAC,KACAC,KAEAC,KA4DMZ,GAA0B,CAACa,EAA+BC,IAAoD,CAmClH,IAAMC,EAAQF,EAAO,CAAC,EAChBG,EAAUH,EAAO,CAAC,EAClBI,EAAOJ,EAAO,CAAC,EACfK,EAAYL,EAAO,CAAC,EACpBM,EAAON,EAAO,CAAC,EACfO,EAAuBP,EAAO,CAAC,EAErC,GAAIM,GAAQC,EACV,MAAM,IAAI,MAAM,4DAA4D,EAG9E,GAAIL,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,sCAAsC,EAGxD,IAAMM,EAAYN,EAAM,KAAK,CAAC,EACxBO,EAAiBP,EAAM,KAAK,CAAC,EAC7BQ,EAAkBR,EAAM,KAAK,CAAC,EAEpC,GAAIE,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAID,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIA,EAAQ,KAAK,CAAC,IAAMO,EACtB,MAAM,IAAI,MAAM,uEAAuE,EAGzF,GAAIN,EAAK,KAAK,CAAC,IAAMD,EAAQ,KAAK,CAAC,EACjC,MAAM,IAAI,MAAM,oFAAoF,EAGtG,IAAIQ,EAAcP,EAAK,KAAK,CAAC,EAAI,EAC7BQ,EAAcD,EACdE,EAAcD,EAClB,GAAIX,EAAW,eAAe,OAAS,EAAG,CACxC,GAAIA,EAAW,eAAe,SAAW,EACvC,MAAM,IAAI,MAAM,mDAAmD,EAErE,QAAWa,KAAMb,EAAW,eAC1B,GAAIa,EAAKb,EAAW,WAAa,EAC/B,MAAM,IAAI,MAAM,mDAAmD,EAIvEU,EAAcV,EAAW,eAAe,CAAC,EACzCW,EAAcX,EAAW,eAAe,CAAC,EACzCY,EAAcZ,EAAW,eAAe,CAAC,CAC3C,CAEA,IAAMc,EAAmBN,EAEzB,GAAIE,IAAgBC,EAClB,MAAM,IAAI,MAAM,6DAA6D,EAG/E,GAAIR,EAAK,KAAK,CAAC,IAAMO,EAAcC,EAAcC,EAC/C,MAAM,IAAI,MAAM,+EAA+E,EAGjG,IAAIG,EAAqB,EACzB,GAAIV,EAAM,CACR,GAAIM,IAAgBC,EAClB,MAAM,IAAI,MAAM,oDAAoD,EAEtE,GAAIP,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,qCAAqC,EAEvD,GAAIA,EAAK,KAAK,CAAC,IAAM,EACnB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAK,KAAK,CAAC,IAAME,EACnB,MAAM,IAAI,MAAM,kDAAkD,EAEpE,GAAIF,EAAK,KAAK,CAAC,IAAML,EAAW,SAC9B,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAIK,EAAK,KAAK,CAAC,IAAMM,EAAcX,EAAW,SAC5C,MAAM,IAAI,MAAM,gEAAgE,EAG7EA,EAAW,yBACde,EAAqBV,EAAK,KAAK,CAAC,EAGpC,CAEA,IAAMW,EAAsBF,EAAmBC,EACzCE,EAAoB,GAEpBC,EAAW,EACjB,GAAId,EAGF,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAIC,EACF,MAAM,IAAI,MAAM,uBAAuB,EAEzC,GAAIC,EACF,MAAM,IAAI,MAAM,uCAAuC,EAGzD,MAAO,CACL,UAAAC,EACA,eAAAC,EACA,mBAAAO,EACA,iBAAAD,EACA,oBAAAE,EACA,kBAAAC,EACA,gBAAAR,EACA,WAAYC,EACZ,YAAAE,EACA,SAAU,KAAK,MAAMF,EAAcV,EAAW,QAAQ,EACtD,UAAW,KAAK,MAAMY,EAAcZ,EAAW,QAAQ,EACvD,SAAUA,EAAW,SACrB,iBAAkB,GAClB,uBAAwB,GACxB,gBAAiBA,EAAW,gBAC5B,SAAAkB,EACA,MAAOlB,EAAW,MAClB,oBAAqB,GACrB,aAAc,GACd,UAAW,CACb,CACF,EAEab,GAA4Ba,GACrCmB,GAA4B,CAAC,GAAGnB,CAAU,CAAC,EAElCZ,GAAwB,CAACgC,EAAyBnB,EAAmBoB,EAAWC,IAAc,CACzG,IAAMC,EAAaC,GAAiBF,CAAC,EAC/BG,EAAcC,GAAe,IAAKzB,EAAM,SAAUA,EAAM,KAAMsB,CAAU,EAE1EI,EAAiB,kBACjBJ,IAAe,EACjBI,EAAiB,4CACRJ,IAAe,IACxBI,EAAiB,6FAEnB,IAAMC,EAAWC,GAA4B5B,EAAM,QAAQ,EACvD6B,EAAK,GACHC,EAAQT,EAAIC,EACdQ,EAAQD,EACVA,EAAK,EACIC,EAAQ,EAAI,KACrBD,EAAK,KAAK,KAAKC,EAAQ,CAAC,GAE1B,IAAMC,EAAgB,KAAK,KAAKV,EAAIC,EAAaO,CAAE,EAE7CG,EAAmBC,GAA+B;AAAA,gBAC1CN,CAAQ,UAAUN,CAAC;AAAA,kBACjBA,EAAIC,CAAU;AAAA,qCACKO,CAAE;AAAA,qCACFA,CAAE;AAAA;AAAA,IAEnCI,EAAa,iBAAiBT,CAAW,CAAC;AAAA,6BACjBK,CAAE;AAAA;AAAA;AAAA,sCAGOE,CAAa;AAAA;AAAA;AAAA,4BAGvBG,GAAW,MAAOZ,EAAY,gBAAgB,CAAC;AAAA,+BAC5CS,CAAa;AAAA,8BACdI,GAAUR,EAAUL,EAAY,eAAe,CAAC;AAAA;AAAA,2BAEnDI,CAAc;AAAA;AAAA;AAAA;AAAA,2BAIdG,CAAE;AAAA;AAAA;AAAA;AAAA,sBAIPK,GAAW,MAAOZ,EAAY,GAAG,CAAC;AAAA,+BACzBS,CAAa;AAAA,yBACnBI,GAAUR,EAAUL,EAAY,eAAe,CAAC;AAAA;AAAA,2BAE9Cc,GAAU,YAAad,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,2BAIlCO,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA,iCAKIE,CAAa;AAAA,0BACpBG,GAAWP,EAAUL,EAAY,MAAM,CAAC;AAAA;AAAA;AAAA,iCAGjCS,CAAa;AAAA,yBACrBI,GAAUR,EAAUL,EAAY,eAAe,CAAC;AAAA,0BAC/CE,EAAY,KAAK,KAAK;AAAA;AAAA;AAAA,KAK9CL,EAAQ,QACJ,CACE,KAAM,wBACN,YAAa,CAAC,KAAM,GAAGE,CAAC,EAAE,EAC1B,gBAAAW,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,EACV,cAAe,CAAC,EAAGZ,CAAC,CACtB,EACF,EACA,CAAC,OAAQ,CAACpB,CAAK,EAAG,QAAS,CAAC,CAAC,CAAC,CACpC,EAEMZ,GACF,CAAC+B,EAAyBkB,EAAeC,EAAiBC,EACzDC,EAAiCzC,IAA+B,CAC/D,IAAM0C,EAAa,CACjBD,EAAW,UAAWA,EAAW,SAAUA,EAAW,eACtDA,EAAW,iBAAmBA,EAAW,kBAC3C,EAGME,EAAQ3C,EAAW,QAAU,EAAI,EAAM,KAAK,KAAKyC,EAAW,QAAQ,EAAIzC,EAAW,MAEnF4B,EAAWC,GAA4BS,EAAE,QAAQ,EAEjDf,EAAaC,GAAiBiB,EAAW,QAAQ,EACjDG,EAASC,GAAc,IAAKP,EAAE,SAAUA,EAAE,KAAMf,CAAU,EAC1DuB,EAASD,GAAc,MAAON,EAAI,SAAUA,EAAI,KAAMhB,CAAU,EAChEwB,EAASrB,GAAe,SAAUY,EAAE,SAAUI,CAAU,EAExDM,EAAqBP,EAAW,SAAWlB,EAC3C0B,EAAIR,EAAW,eACfS,EAAIT,EAAW,oBACfU,EAAIH,EAEJI,EAAY,GAEZC,EAAW,CACf,EAAG,KAAK,KAAKZ,EAAW,oBAAsBW,CAAS,EACvD,EAAG,KAAK,KAAKX,EAAW,eAAiBW,CAAS,EAClD,EAAGX,EAAW,UAAYA,EAAW,QACvC,EAEM1C,EAAS,CAACuC,EAAGC,CAAG,EAChBN,EAAmBC,GAA+B;AAAA,mBAC3Ce,CAAC;AAAA,mBACDC,CAAC;AAAA,mBACDC,CAAC;AAAA,iBACHvB,CAAQ,MAAMe,CAAK;AAAA,gBACpBf,CAAQ;AAAA,sBACFwB,CAAS;AAAA;AAAA,gCAECR,EAAO,KAAK,OAAO,KAAKQ,EAAYA,CAAS;AAAA,gCAC7CR,EAAO,KAAK,OAAO,KAAKQ,EAAYA,CAAS;AAAA;AAAA,IAEzElB,EAAa,iBAAiBU,EAAQE,EAAQC,CAAM,CAAC;AAAA;AAAA,6BAE5BK,CAAS,KAAKA,CAAS;AAAA;AAAA;AAAA,wCAGZC,EAAS,EAAIA,EAAS,CAAC;AAAA,6BAClCA,EAAS,CAAC,yBAAyBD,EAAYA,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBASjEX,EAAW,eAAiBO,CAAkB;AAAA,oBAC9CP,EAAW,iBAAmBO,CAAkB;AAAA;AAAA,kBAElDb,GAAWP,EAAUL,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAoBtBc,GAAU,QAASd,CAAU,CAAC;AAAA;AAAA,KAI9C+B,EAAQlC,EAAQ,QAClB,CACE,KAAM,iBACN,YAAa,CAAC,KAAM,KAAK,UAAUqB,CAAU,CAAC,EAC9C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAY,SAAUJ,EAAE,SAAU,aAAgC,CAAC,EACpF,cAAee,CACjB,GACA,gBAAApB,CACF,EACA,CAAC,OAAAlC,EAAQ,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAE9B,OAAAX,GACIgC,EAASkC,EAAOb,EAAW,UAAYA,EAAW,SAAWA,EAAW,eACxEA,EAAW,mBAAmB,EAE3Ba,CACT,EAEEhE,GACF,CAAC8B,EAAyBkC,EAAmBC,EAAeC,IAAgC,CAC1F,IAAMC,EAAc,CAACD,EAAO,UAAWA,EAAO,eAAgBA,EAAO,WAAW,EAE1EE,EAAcb,GAAc,QAASS,EAAM,SAAUA,EAAM,IAAI,EAC/DK,EAAUd,GAAc,IAAKU,EAAE,SAAUA,EAAE,IAAI,EAC/CR,EAASrB,GAAe,SAAU4B,EAAM,SAAUG,CAAW,EAE7D7B,EAAWC,GAA4ByB,EAAM,QAAQ,EAErDF,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKG,EAAO,UAAYJ,CAAS,EACzC,EAAG,KAAK,KAAKI,EAAO,eAAiBJ,CAAS,EAC9C,EAAGI,EAAO,UAAYA,EAAO,QAC/B,EAEMvB,EAAmBC,GAA+B;AAAA,mBAC3CsB,EAAO,cAAc;AAAA,mBACrBA,EAAO,SAAS;AAAA,mBAChBA,EAAO,mBAAmB;AAAA,0BACnBA,EAAO,QAAQ;AAAA,sBACnBJ,CAAS;AAAA;AAAA,gCAECM,EAAY,KAAK,OAAO,KAAKN,EAAYA,CAAS;AAAA,gCAClDM,EAAY,KAAK,OAAO,KAAKN,EAAYA,CAAS;AAAA;AAAA,IAE9ElB,EAAa,iBAAiBwB,EAAaC,EAASZ,CAAM,CAAC;AAAA;AAAA,6BAElCK,CAAS,KAAKA,CAAS;AAAA;AAAA;AAAA,wCAGZC,EAAS,EAAIA,EAAS,CAAC;AAAA,6BAClCA,EAAS,CAAC,yBAAyBD,EAAYA,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBASpExB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qCAgBY4B,EAAO,QAAQ;AAAA,mDACDA,EAAO,QAAQ;AAAA,sCAC5BA,EAAO,QAAQ,gCAAgCA,EAAO,SAAS;AAAA;AAAA,kCAEnEA,EAAO,eAAiBA,EAAO,WAAW,UAAUA,EAAO,WAAW;AAAA,oCACpEA,EAAO,SAAS;AAAA;AAAA;AAAA,KAK9C,OAAOpC,EAAQ,QACX,CACE,KAAM,iBACN,YAAa,CAAC,KAAM,KAAK,UAAUoC,CAAM,CAAC,EAC1C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUH,EAAM,SAAU,aAAgC,CAAC,EACzF,cAAeD,CACjB,GACA,gBAAApB,CACF,EACA,CAAC,OAAQ,CAACqB,EAAOC,CAAC,EAAG,QAAS,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAC3C,EAEShE,GACT,CAAC6B,EAAyBkB,EAAesB,EAAeL,EAAeM,EACtEC,EAA6BC,EAAgCC,EAC7D1D,EAA4CmC,EAAiCzC,IAA+B,CAC3G,IAAMsD,EAAQjE,GAAsB+B,EAASkB,EAAGsB,EAAGtD,EAAsBmC,EAAYzC,CAAU,EAE/FV,GAAwB8B,EAASkC,EAAOC,EAAGd,CAAU,CACvD,EAEEjD,GAAU,CAAC4B,EAAyBqB,IAAoC,CAC5E,IAAMgB,EAAc,CAClBhB,EAAW,UACXA,EAAW,SACXA,EAAW,eACXA,EAAW,QACb,EAEMb,EAAWC,GAA4BT,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAEjE6B,EAAIR,EAAW,eACfU,EAAIV,EAAW,gBACfS,EAAIT,EAAW,SAEfW,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKZ,EAAW,SAAWW,CAAS,EAC5C,EAAG,KAAK,KAAKX,EAAW,eAAiBW,CAAS,EAClD,EAAGX,EAAW,UAAYA,EAAW,QACvC,EAEMR,EAAkB,IAAM;AAAA,mBACbgB,CAAC;AAAA,mBACDE,CAAC;AAAA,mBACDD,CAAC;AAAA,0BACMT,EAAW,QAAQ;AAAA,gBAC7BA,EAAW,WAAaA,EAAW,WAAaA,EAAW,WAAW;AAAA,sBAChEW,CAAS;AAAA;AAAA,oCAEKxB,CAAQ,KAAKwB,EAAYA,CAAS;AAAA,sCAChCxB,CAAQ,KAAKwB,EAAYA,CAAS;AAAA,sCAClCxB,CAAQ,KAAKwB,EAAYA,CAAS;AAAA,sCAClCxB,CAAQ,KAAKwB,EAAYA,CAAS;AAAA;AAAA,0DAEdxB,CAAQ;AAAA,2DACPA,CAAQ;AAAA,yDACVA,CAAQ;AAAA,kEACCA,CAAQ;AAAA,kEACRA,CAAQ;AAAA,kEACRA,CAAQ;AAAA;AAAA,6BAE7CwB,CAAS,KAAKA,CAAS;AAAA;AAAA;AAAA,wCAGZC,EAAS,EAAIA,EAAS,CAAC;AAAA,6BAClCA,EAAS,CAAC,yBAAyBD,EAAYA,CAAS;AAAA;AAAA,wCAE7CX,EAAW,QAAQ;AAAA,wCACnBA,EAAW,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,qCAKtBA,EAAW,QAAQ;AAAA,wBAChCA,EAAW,UAAU;AAAA,wBACrBA,EAAW,UAAU;AAAA;AAAA,mBAE1Bb,CAAQ;AAAA,mBACRA,CAAQ;AAAA,mBACRA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qCAuBUa,EAAW,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAchD1C,EAAS,CAACqB,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,CAAC,EAEvE,OAAOA,EAAQ,QACX,CACE,KAAM,mBACN,YAAa,CAAC,KAAM,KAAK,UAAUqB,CAAU,CAAC,EAC9C,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMgB,EAAa,SAAUrC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,EAC1F,CAAC,KAAMqC,EAAa,SAAUrC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,EAC1F,CAAC,KAAMqC,EAAa,SAAUrC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,CAC5F,EACA,cAAeiC,CACjB,GACA,gBAAApB,CACF,EACA,CAAC,OAAAlC,EAAQ,QAAS,CAAC,GAAI,GAAI,EAAE,CAAC,CAAC,CACrC,EAEaN,GAAY,CAAC2B,EAAyBpB,IAAqC,CACtF,IAAMwD,EAAStE,GAAwBkC,EAAQ,OAAQpB,CAAU,EAE3D,CAACsC,EAAGsB,EAAGL,CAAC,EAAI/D,GAAQ4B,EAASoC,CAAM,EAEzC,OAAOjE,GACH6B,EAASkB,EAAGsB,EAAGL,EAAGnC,EAAQ,OAAO,CAAC,EAAG,OAAW,OAAW,OAAWA,EAAQ,OAAO,CAAC,EAAGoC,EAAQxD,CAAU,CACjH,IC1nBA,IAqBMiE,GAkCAC,GAgFOC,GAGAC,GA1IbC,GAAAC,GAAA,kBAGAC,KAGAC,KACAC,KAGAC,KAWMT,GAAiB,CAACU,EAA+BC,IAA0C,CAC/F,GAAI,CAACD,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,sCAAsC,EAGxD,IAAME,EAAkB,CAACC,EAA2BC,EAA6BC,IAAoB,CACnG,IAAMC,EAAIF,EAAS,OACnB,GAAIE,IAAMH,EAAO,OACf,MAAM,IAAI,MAAM,GAAGE,CAAO,uBAAuBC,CAAC,EAAE,EAEtDF,EAAS,QAAQ,CAACG,EAAGC,IAAM,CACzB,GAAID,IAAMJ,EAAOK,CAAC,EAChB,MAAM,IAAI,MAAM,GAAGH,CAAO,SAASG,CAAC,gBAAgB,CAExD,CAAC,CACH,EAEA,GAAIR,EAAO,CAAC,EAAE,KAAK,OAAS,EAAG,CAC7B,IAAMS,EAAQR,EAAW,SAAW,OAC/BA,EAAW,QAAUD,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,EACvBA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,EAAE,OAAOA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,CAAC,EACxGA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGC,EAAW,QAAU,EAAI,MAAS,EAC9DC,EAAgBF,EAAO,CAAC,EAAE,KAAMS,EAAO,qBAAqB,EAC5DP,EAAgBF,EAAO,CAAC,EAAE,KAAMS,EAAO,iBAAiB,EACxDP,EAAgBF,EAAO,CAAC,EAAE,KAAMS,EAAO,oBAAoB,EAC3DP,EAAgBF,EAAO,CAAC,EAAE,KAAMS,EAAO,mBAAmB,CAC5D,MACEP,EAAgBF,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,qBAAqB,EAC1DE,EAAgBF,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,iBAAiB,EACtDE,EAAgBF,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,oBAAoB,EACzDE,EAAgBF,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,mBAAmB,CAE5D,EAEMT,GACF,CAACS,EAA+BC,IAAiD,CAC/E,GAAM,CAAC,QAAAS,EAAS,QAAAC,EAAS,OAAAC,CAAM,EAAIX,EAC7BY,EAASb,EAAO,CAAC,EAAE,KACnBc,EAAaH,EAAUI,GAAiBF,EAAOA,EAAO,OAAS,CAAC,CAAC,EAAI,EACrEG,EAAcJ,IAAW,QAAUC,EAAO,OAAS,EAAIC,EAAa,EACpEG,EAAaC,EAAU,KAAKL,CAAM,EAAIC,EAEtCK,EAAoBC,GAAqBP,EAAO,MAAM,GAAKF,EAC3DU,EAAcF,EAAoBN,EAAO,OAASA,EAClDS,EAAIC,GAAc,IAAKvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMc,CAAU,EACrEU,EAAQD,GAAc,QAASvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMgB,CAAW,EAC9ES,EAAOF,GAAc,OAAQvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMgB,CAAW,EAC5EU,EAAYH,GAAc,YAAavB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMgB,CAAW,EACtFW,EAAWJ,GAAc,WAAYvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMgB,CAAW,EACpFY,EAAIC,GAAe,IAAK7B,EAAO,CAAC,EAAE,SAAUqB,EAAaP,CAAU,EAGnEgB,EAAc,IAAc,CAChC,IAAIC,EAAU,GACd,GAAIpB,EACFoB,EAAU,iBACNlB,EAAO,SAAW,EAAM,KACpBD,IAAW,OAAS,iBAAiBC,EAAO,OAAS,CAAC,OAAOC,CAAU,GACnD,kBAAkB,YAE1CF,IAAW,OACbmB,EAAU;AAAA,cACRH,EAAE,WAAW,gBAAiB,IAAK,GAAG,CAAC;AAAA,4BACzBA,EAAE,gBAAgB,eAAe,CAAC,QAC7C,CAELG,EAAU,kBAAkBP,EAAM,KAAK,OAAO;AAAA,qDACLX,EAAO,OAAS,CAAC,KAE1D,QAASL,EAAI,EAAGA,EAAIgB,EAAM,KAAMhB,IAC9BuB,GAAW,YAAYvB,CAAC,qBAAqBA,CAAC,KAEhDuB,GAAW,iBAAiBP,EAAM,gBAAgB,UAAU,CAAC,GAC/D,CAEF,OAAOO,CACT,EACMC,EAAgCC,GAAyB;AAAA,oBACjDvB,CAAO;AAAA,IACvBuB,EAAO,gBAAgB,aAAc,KAAK,EAAE,iBAAiBX,EAAGE,EAAOC,EAAMC,EAAWC,EAAUC,CAAC,CAAC;AAAA,IACpGK,EAAO,UAAU,CAAC;AAAA,IAClBA,EAAO,sCAAsC,qBAAqB,CAAC;AAAA,0BAC7CL,EAAE,gBAAgB,gBAAgBd,CAAU,EAAE,CAAC;AAAA,MACnEgB,EAAY,CAAC;AAAA,kBACDN,EAAM,YAAY,SAAS,CAAC;AAAA,iBAC7BC,EAAK,YAAY,SAAS,CAAC;AAAA,sBACtBC,EAAU,YAAY,SAAS,CAAC;AAAA,qBACjCC,EAAS,YAAY,SAAS,CAAC;AAAA,cACtCL,EAAE,YAAY,YAAY,CAAC;AAAA;AAAA,MAEnCM,EAAE,YAAY,aAAc,OAAO,CAAC;AAAA,KAEpC,MAAO,CACL,KAAM,qBACN,YAAa,CACX,KAAM,GAAG3B,EAAW,OAAO,IAAIA,EAAW,MAAM,IAAIU,CAAO,IAAIG,CAAU,GACzE,kBAAmBK,EAAoB,CAAC,OAAQ,OAAQ,OAAQ,OAAQ,MAAM,EAAI,MACpF,EACA,gBAAiBa,EACjB,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMhC,EAAO,CAAC,EAAE,KAAM,SAAUA,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC9D,cAAe,CAAC,EAAG,KAAK,KAAKiB,EAAa,EAAuB,CAAC,EAClE,gBAAiBE,EACb,CACE,CAAC,KAAM,SAAU,KAAMF,CAAU,EACjC,GAAGiB,GAA2BrB,CAAM,CACtC,EACA,CACE,CAAC,KAAM,SAAU,KAAMI,CAAU,CACnC,CACN,EACF,CACF,EAESzB,GAA4BS,GACrCkC,GAA4BlC,CAAoE,EAEvFR,GAAY,CAAC2C,EAAyBnC,IAA8C,CAC/F,GAAM,CAAC,OAAAD,EAAQ,YAAAqC,CAAW,EAAID,EACxBE,EAAoB9C,GAAyB,CAAC,GAAGS,EAAY,YAAAoC,CAAW,CAAC,EAI/E,GAHIE,GAAI,OAAO,sBACbjD,GAAeU,EAAQsC,CAAiB,EAEtCrC,EAAW,aACb,MAAM,IAAI,MAAM,uDAAuD,EAEvEmC,EAAQ,QAAQ7C,GAAoCS,EAAQsC,CAAiB,CAAC,CAElF,ICrJA,IASME,GAkBAC,GAkCOC,GA7DbC,GAAAC,GAAA,kBAIAC,KAGAC,KAEMN,GAAkBO,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,IAAK,IAAK,IAAI,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC9C,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMN,GAA4BM,GAA+C,CAC/E,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAExBE,EAAWF,EAAO,CAAC,EAAE,KAAK,CAAC,EAE3BG,EAAaC,EAAU,KAAKH,CAAW,EAAI,EAE3CI,EAAWL,EAAO,CAAC,EAAE,SACrBM,EAAQC,GAAc,QAASF,EAAUJ,EAAa,CAAC,EACvDO,EAAOD,GAAc,OAAQF,EAAU,CAACH,CAAQ,EAAG,CAAC,EACpDO,EAAWF,GAAc,WAAYF,EAAUJ,EAAa,CAAC,EAC7DS,EAASC,GAAe,SAAUN,EAAUJ,EAAa,CAAC,EAahE,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CACpE,GACA,gBAjBuBS,GAA+B;AAAA,qBACrCV,CAAQ;AAAA,IACzBU,EAAa,iBAAiBN,EAAOE,EAAMC,EAAUC,CAAM,CAAC;AAAA;AAAA,IAE5DE,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA,kBAClDG,EAAM,YAAY,YAAY,CAAC;AAAA,UACvCE,EAAK,YAAY,uBAAuB,CAAC,MAAMC,EAAS,YAAY,YAAY,CAAC;AAAA,MACrFC,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAU7C,CACF,EAEaf,GAAWkB,GAAkC,CACxDpB,GAAeoB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQnB,GAAyBmB,EAAQ,MAAM,CAAC,CAC1D,IChEA,IAeMC,GA4BAC,GAiBOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAGAC,GASAC,GAIAC,GA8BPC,GAMOC,GAaAC,GAIAC,GAIAC,GAQAC,GAGAC,GAeAC,GAcAC,GAMAC,GAIAC,GAIAC,GAOAC,GAMAC,GAIAC,GAIAC,GAIAC,GAKAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAOAC,GA5QbC,GAAAC,GAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMzC,GACF,CAAC0C,EAA4BC,EAAkBC,EAAuBC,EACrEC,EAAmCC,IAA8C,CAChF,IAAMC,EAAU,KAAK,KAAKL,EAAW,CAAC,EAElCM,EAAa,GACb,OAAOH,GAAa,SACtBG,EAAa,GAAGH,CAAQ,MAExBG,EAAaH,EAAS,GAAG,EAG3B,IAAMI,EAAQC,GAAc,YAAaP,EAAe,CAACI,CAAO,EAAG,CAAC,EAC9DI,EAASC,GAAe,aAAcR,EAAgB,CAACG,CAAO,EAAG,CAAC,EAExE,MAAO;AAAA,QACLN,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBQ,EAAOE,CAAM,CAAC;AAAA;AAAA,IAEnFL,GAA4B,EAAE;AAAA;AAAA,IAE9BL,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA;AAAA,cAE/DQ,EAAM,YAAY,YAAY,CAAC;AAAA,MACvCE,EAAO,YAAY,aAAcH,CAAU,CAAC;AAAA,IAE9C,EAEEhD,GACF,CAACiD,EAAmBI,EAAcR,EAAmCC,EACpEQ,EAAmBV,EAAyBK,EAAM,YAA2B,CAC5E,KAAAI,EACA,YAAa,CAAC,KAAMC,EAAU,kBAAmB,CAAC,MAAM,CAAC,EACzD,gBAAiBb,GAAgB1C,GAC7B0C,EAAcc,EAAU,KAAKN,EAAM,IAAI,EAAGA,EAAM,SAAUL,EAAgBC,EAAUC,CAAwB,EAChH,WAAaU,IAAkB,CAC7B,QAAS,CAAC,CAAC,KAAMP,EAAM,KAAM,SAAUL,CAAc,CAAC,EACtD,cACI,CAAC,EAAG,KAAK,KAAKW,EAAU,KAAKC,EAAa,CAAC,EAAE,IAAI,EAAI,GAA0B,CAAgB,CAAC,EACpG,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKD,EAAU,KAAKN,EAAM,IAAI,EAAI,CAAC,CAAC,CAClE,CACF,EACF,GAEShD,GAAOwD,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEavD,GAAQuD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEatD,GAASsD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEarD,GAAQqD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEapD,GAASoD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEanD,GAAQmD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EACalD,GAASkD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAOajD,GAAuBkD,GAChCC,GAA4BD,CAA0B,EAG7CjD,GAAO,CAACgD,EAAyBC,IAAqC,CACjF,IAAIE,EACJ,OAAQF,EAAW,GAAI,CACrB,QACEE,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,QACEA,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,OACEA,EAAO,aACP,MACF,QACE,MAAM,IAAI,WAAW,0EAA0EF,EAAW,EAAE,EAAE,CAClH,CACAD,EAAQ,QACJzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQG,EAAM,OAAWF,EAAW,SAAUA,EAAW,EAAE,CAAC,CAClH,EAOMhD,GAAoCmD,GAAkD,CAC1F,IAAMC,EAAOD,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAIE,GAC9DC,EAAOH,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAII,GACpE,OAAON,GAA4B,CAAC,IAAAG,EAAK,IAAAE,CAAG,CAAC,CAC/C,EAEarD,GAAO,CAAC8C,EAAyBS,IAAyC,CACrF,IAAMR,EAAaD,EAAQ,OAAO,SAAW,EAAIS,EAAiBxD,GAAiC+C,EAAQ,MAAM,EAC3GU,EAAWC,GAA4BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QACJzD,GACIyD,EAAQ,OAAO,CAAC,EAAG,OAAQ,GAAK,SAAS,CAAC,0BAA2B;AAAA,4BACnDU,CAAQ,YAAYA,CAAQ,IAAIT,EAAW,GAAG;AAAA,4BAC9CS,CAAQ,YAAYA,CAAQ,IAAIT,EAAW,GAAG;AAAA,EAEhEA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEa9C,GAAQ6C,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa5C,GAAO4C,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa3C,GAAQ2C,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAMa1C,GAAwB2C,GACjCC,GAA4BD,CAA6B,EAEhD1C,GAAM,CAACyC,EAAyBC,IAAsC,CACjFD,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,YAAYA,CAAC,IAAK;AAAA,gCACvBX,EAAW,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAS1CA,EAAW,QAAQ,CAAC,CAC1B,EAEazC,GAAU,CAACkD,EAAkBG,EAAU,QAAU;AAAA,YAClDA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA;AAAA,iBAEFH,CAAQ,QAAQA,CAAQ;AAAA;AAAA;AAAA;AAAA,GAM5BjD,GAAOuC,GAAkC,CACpD,IAAMU,EAAWC,GAA4BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,YAAYA,CAAC,IAAKpD,GAAQ,QAAQkD,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC9F,EAEahD,GAAOsC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEarC,GAASqC,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapC,GAAQoC,GAAkC,CACrD,IAAMU,EAAWC,GAA4BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,OAAQY,GAAK,SAASA,CAAC,sBAAsBA,CAAC,0BACjEpD,GAAQ,QAAQkD,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC7C,EAEa7C,GAAY,CAACmC,EAAyBC,IAAsC,CACvFD,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,YAAaY,GAAK,8BAA8BA,CAAC,KAAKA,CAAC,KAAKA,CAAC,sBAChF,sCAAsCX,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,CACtF,EAEanC,GAAOkC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa7C,GAAOiC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa5C,GAAcgC,GAAkC,CAC3DA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,aAAcY,GAAK,OAAOA,CAAC,EAAE,CAAC,CAChG,EAEa3C,GAAQ+B,GAAkC,CACrDA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,OAAQY,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,oBAAoB,CAAC,CAC5F,EAEa1C,GAAW8B,GAAkC,CACxDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,UAAWY,GAAK,sBAAsBA,CAAC,KAAK,CAAC,CAC/G,EAEazC,GAAO6B,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa5B,GAAQ4B,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa3B,GAAQ2B,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa1B,GAAO0B,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEazB,GAAQyB,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEaxB,GAAkB,CAACwB,EAAyBC,KACvDD,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,kBAAmBY,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,8BAC5E,wDAAwDX,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,EAC/F,GAGIxB,GAAOuB,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,IC9QA,IAUMc,GAkBAC,GAyCOC,GArEbC,GAAAC,GAAA,kBAIAC,KAGAC,KACAC,KAEMP,GAAkBQ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,KAAM,KAAM,KAAK,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACjD,MAAM,IAAI,MAAM,4CAA4C,EAG9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMP,GAAkCO,GAA+C,CACrF,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAAK,MAAM,EACzCC,EAAY,CAAC,EAAIA,EAAY,CAAC,EAAI,EAElC,IAAMC,EAAQC,GAAc,QAASH,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EACpEI,EAAOD,GAAc,OAAQH,EAAO,CAAC,EAAE,SAAU,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAG,CAAC,EACvEK,EAASC,GAAe,SAAUN,EAAO,CAAC,EAAE,SAAUC,EAAa,CAAC,EAEpEM,EAAaC,EAAU,KAAKP,CAAW,EAAI,EAC3CQ,EAAWC,GAA4BV,EAAO,CAAC,EAAE,QAAQ,EAsB/D,MAAO,CACL,KAAM,gBACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKO,EAAa,EAAuB,CAAC,CACpE,GACA,gBA1BuBI,GAA+B;AAAA;AAAA,yBAEjCX,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,EAAI,CAAC;AAAA;AAAA,IAE9CW,EAAa,iBAAiBT,EAAOE,EAAMC,CAAM,CAAC;AAAA;AAAA,IAElDO,GAAQ,QAAQH,CAAQ,IAAKA,CAAQ,CAAC;AAAA;AAAA,IAEtCE,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCJ,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ9DF,EAAO,YAAY,aAAc,uBAAuB,CAAC;AAAA,IAU7D,CACF,EAEaX,GAAiBmB,GAAkC,CAC9DrB,GAAeqB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpB,GAA+BoB,EAAQ,MAAM,CAAC,CAChE,ICxEA,IAiBMC,GAyGAC,GA6EAC,GAQOC,GAIAC,GAIAC,GAMAC,GAIAC,GAsBAC,GAIAC,GAMAC,GAMAC,GAMAC,GA7QbC,GAAAC,GAAA,kBAGAC,KAEAC,KAGAC,KASMjB,GACF,CAACkB,EAA4BC,EAA0BC,EAA0BC,EAChFC,EAAoBC,EAAsBC,EAAsCC,EAChFC,EAAeC,EAAeC,EAAoBC,EAClDC,IAAsC,CACrC,IAAIC,EACAC,EACA,OAAOP,GAAa,SACtBM,EAAmBC,EAAmB,CAACC,EAAGC,IAAM,GAAGT,CAAQ,KAAKQ,CAAC,MAAMC,CAAC,KAC/D,OAAOT,GAAa,WAC7BM,EAAmBC,EAAmBP,GAEtCM,EAAmBN,EAAS,OAC5BO,EAAmBP,EAAS,QAG9B,IAAMU,EAAoBN,EAAoBV,EAAM,OAASA,EACvDiB,EAAoBP,EAAoBT,EAAM,OAASA,EACvDiB,EAAoBR,EAAoBR,EAAW,OAASA,EAC5DiB,EAASC,GAAe,aAAcX,EAAYS,EAAmB,CAAC,EACtEJ,EAAIO,GAAc,QAASd,EAAOS,EAAmB,CAAC,EACtDD,EAAIM,GAAc,QAASb,EAAOS,EAAmB,CAAC,EAExDK,EACJ,GAAInB,EACF,GAAIC,EAAa,CACf,IAAMmB,EAAgBC,EAAU,KAAKxB,CAAK,IAAM,EAC1CyB,EAAgBD,EAAU,KAAKvB,CAAK,IAAM,EAC1CyB,EAAuB1B,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC3E2B,GAAuB1B,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC7EsB,GAAiBE,EACnBH,EAAaH,EAAO,YAChB,aACAN,EACIU,EAAgB,GAAGT,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,EACvFW,EAAgB,GAAGV,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,CAAC,CAAC,EAEjGO,EAAa;AAAA,kCACSH,EAAO,gBAAgB,iBAAiB,CAAC;AAAA,4BAC/CL,EAAE,2BAA2B,gBAAiBK,CAAM,CAAC;AAAA,4BACrDJ,EAAE,2BAA2B,gBAAiBI,CAAM,CAAC;AAAA,cAEjEA,EAAO,YACH,aACAN,EACIR,GAA+BqB,EAC3BZ,EAAE,YAAY,cAAc,EAC5B,GAAGA,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,cAAc,CAAC,kBACpDT,GAA+BsB,GAC3BZ,EAAE,YAAY,cAAc,EAC5B,GAAGA,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,cAAc,CAAC,iBAAiB,CAAC,CAAC;AAAA,WAGvF,MACEO,EAAaH,EAAO,YAChB,aAAcN,EAAiBC,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAEzF,CACL,GAAI,CAACX,EACH,MAAM,IAAI,MAAM,sFAAsF,EAGxG,IAAMwB,EAAmB,CAACC,EAAgBC,EAAWC,GAAW,KAAO,CACrE,IAAMC,GAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IACpD,MAAO;AAAA,+BACcA,CAAC,MAAMX,EAAO,gBAAgB,qBAAqBW,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMhB,EAAE,2BAA2B,gBAAgBgB,CAAC,GAAIX,CAAM,CAAC;AAAA,yBAChEW,CAAC,MAAMf,EAAE,2BAA2B,gBAAgBe,CAAC,GAAIX,CAAM,CAAC;AAAA,wBACjEW,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,EAAQ,IAAInB,EAAiBoB,GAAaC,CAAW,CAAC;AAAA,WAE9E,EACIxB,IAAe,EACjBa,EAAa;AAAA;AAAA,cAETM,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCN,EAAa;AAAA,cACTM,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACH7B,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBe,EAAGC,EAAGI,CAAM,CAAC;AAAA;AAAA,UAE9ER,GAA4B,EAAE;AAAA;AAAA,UAE9BZ,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,UACvEuB,CAAU;AAAA,QAEhB,EAEExC,GACF,CAACoD,EAAcC,EAAkBrB,EAAeC,EAAeT,EAC9DK,EAAmCyB,EAAyBtB,EAAE,WAA0B,CACvF,IAAMuB,EAAc,CAACb,EAAU,SAASV,EAAE,KAAMC,EAAE,IAAI,EAClDuB,EAAcxB,EAAE,KAChByB,EAAaf,EAAU,KAAKV,EAAE,IAAI,EAElCX,EAAY,GACZE,EAA8B,GAG5BmC,EAAc,CAACH,CAAW,EAChC,GAAIA,EAAa,CACf,IAAMI,EAAkBC,GAAc,UAAU5B,EAAE,KAAMC,EAAE,KAAM,EAAK,EACrE,GAAI,CAAC0B,EACH,MAAM,IAAI,MAAM,8CAA+C,EAEjEH,EAAcG,EACdF,EAAaf,EAAU,KAAKc,CAAW,EACvC,IAAMf,EAAgBC,EAAU,KAAKV,EAAE,IAAI,IAAM,EAC3CW,EAAgBD,EAAU,KAAKT,EAAE,IAAI,IAAM,EAC3CW,EAAuBZ,EAAE,KAAK,OAAS,GAAKA,EAAE,KAAKA,EAAE,KAAK,OAAS,CAAC,EAAI,IAAM,EAC9Ea,EAAuBZ,EAAE,KAAK,OAAS,GAAKA,EAAE,KAAKA,EAAE,KAAK,OAAS,CAAC,EAAI,IAAM,EACpFyB,EAAY,KAAKjB,CAAa,EAC9BiB,EAAY,KAAKf,CAAa,EAC9Be,EAAY,KAAKd,CAAoB,EACrCc,EAAY,KAAKb,CAAoB,EAErC,IAAIgB,EAAkB,EACtB,QAASC,EAAI,EAAGA,EAAIN,EAAY,OAAQM,IAAK,CAC3C,IAAMC,EAAO/B,EAAE,KAAKA,EAAE,KAAK,OAAS8B,CAAC,GAAK,EACpCE,EAAO/B,EAAE,KAAKA,EAAE,KAAK,OAAS6B,CAAC,GAAK,EAC1C,GAAIC,IAASC,EACXH,GAAmBE,MAEnB,MAEJ,CACIF,EAAkB,IAAM,GAC1BtC,EAA8B,GAC9BF,EAAY,KACHoB,GAAiBE,GAAiBC,GAAwBC,KACnExB,EAAY,GAEhB,MAEEA,EAAY,GAEdqC,EAAY,KAAKrC,CAAS,EAC1B,IAAMO,EAAoBqC,GAAqBjC,EAAE,KAAK,MAAM,GAAKiC,GAAqBhC,EAAE,KAAK,MAAM,GAC/FgC,GAAqBT,EAAY,MAAM,EAC3C,MAAO,CACL,KAAAJ,EACA,YAAa,CACX,KAAMC,EAAWK,EAAY,IAAKV,GAAMA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,EAC9D,kBAAmBpB,EAAoB,CAAC,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,CAC3E,EACA,gBAAkBX,GAAiBlB,GAC/BkB,EAAce,EAAE,KAAMC,EAAE,KAAMuB,EAAanC,EAAWkC,EAAahC,EAA6BC,EAChGQ,EAAE,SAAUC,EAAE,SAAUqB,EAAgB1B,EAAmBC,CAAwB,EACvF,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM2B,EAAa,SAAUF,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,GAA0B,CAAsB,CAAC,EAC3F,gBAAiB7B,EACb,CACE,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKc,EAAU,KAAKc,CAAW,EAAI,CAAC,CAAC,EACjE,GAAGU,GAA2BlC,EAAE,IAAI,EACpC,GAAGkC,GAA2BjC,EAAE,IAAI,EACpC,GAAGiC,GAA2BV,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKd,EAAU,KAAKc,CAAW,EAAI,CAAC,CAAC,CACnE,CACN,EACF,CACF,EAEEvD,GACF,CAACkE,EAAyBf,EAAc5B,EAA8BK,EACrEwB,EAAmBC,IAAkC,CACpDa,EAAQ,QAAQnE,GACZoD,EAAMC,GAAY,GAAIc,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAG3C,EAAUK,EACtEyB,CAAc,CAAC,CACrB,EAESpD,GAAOiE,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa9B,GAAOgE,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa7B,GAAS+D,GAAkC,CACtDlE,GACIkE,EAAS,QAAU,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEa5B,GAAO8D,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa3B,GAAO6D,GAAkC,CACpD,IAAMC,EAAO7B,GAAc,QAAS4B,EAAQ,OAAO,CAAC,EAAE,SAAUA,EAAQ,OAAO,CAAC,EAAE,IAAI,EAAE,KAAK,MAE7FlE,GACIkE,EAAS,MAAQ,CAAC,OAAQ,CAACnC,EAAGC,IAAM,cAAcD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,qBAAqBD,CAAC,IAAIC,CAAC,GAAG,EAC7G;AAAA,wBACkBmC,CAAI,SAASA,CAAI,QAAQA,CAAI;AAAA,iBACpCA,CAAI;AAAA,iBACJA,CAAI;AAAA,uBACEA,CAAI;AAAA,iBACVA,CAAI;AAAA;AAAA,+BAEUA,CAAI,6BAA6BA,CAAI,qBAAqBA,CAAI,IAV1EA,IAAS,MAAQ,QAAU,EAW5B;AAAA;AAAA,oCAEkBA,CAAI,eAAeA,CAAI,cAAcA,CAAI;AAAA;AAAA,oBAEzDA,CAAI;AAAA;AAAA,OAEjB,CACP,EAEa7D,GAAO4D,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEazB,GAAW2D,GAAkC,CACxDlE,GACIkE,EAAS,UAAY,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEaxB,GAAQ0D,GAAkC,CACrDlE,GACIkE,EAAS,OAAS,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACnG,QAAwB,CAC9B,EAEavB,GAAkByD,GAAkC,CAC/DlE,GACIkE,EAAS,iBAAmB,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAC3G,OAAW,QAAwB,CACzC,EAEatB,GAAewD,GAAkC,CAC5DlE,GACIkE,EAAS,cAAgB,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EACxG,OAAW,QAAwB,CACzC,ICjRA,IAcMoC,GAqBAC,GAWAC,GAmBAC,GAkGOC,GAKAC,GAxKbC,GAAAC,GAAA,kBAIAC,KACAC,KAGAC,KAMMV,GAAkBW,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAGlC,IAAMC,EAAYD,EAAO,CAAC,EAAE,SACtBE,EAAsBF,EAAO,CAAC,EAAE,KAAK,OAE3C,QAAWG,KAASH,EAAQ,CAE1B,GAAIG,EAAM,WAAaF,EACrB,MAAM,IAAI,MAAM,kCAAkC,EAIpD,GAAIE,EAAM,KAAK,SAAWD,EACxB,MAAM,IAAI,MAAM,0CAA0C,CAE9D,CACF,EAEMZ,GAA0B,CAACc,EAAyBC,IAAwC;AAAA;AAAA,wCAE1DD,CAAe,MAAMC,CAAmB;AAAA,gCAChDD,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,KAGtBb,GAAmB,CAACS,EAAkCM,IAA0B,CACpF,IAAMF,EAAkBJ,EAAO,OAEzBO,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIJ,EAAiB,EAAEI,EAAG,CACxC,IAAMC,EAAgBH,EAAO,YAAY,aAAcN,EAAOQ,CAAC,EAAE,aAAa,SAAS,CAAC,EACpFJ,IAAoB,EACtBG,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,qBAAqBC,CAAC,QAAQC,CAAa,IAAI,EACrDD,IAAMJ,EAAkB,EACjCG,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,0BAA0BC,CAAC,OAAOC,CAAa,IAAI,CAEtE,CACA,OAAOF,EAAU,KAAK;AAAA,CAAI,CAC5B,EAEMf,GAA0B,CAACQ,EAA+BU,IAA8B,CAC5F,IAAMC,EAAaX,EAAO,CAAC,EAAE,KAAK,MAAM,EACxC,GAAIU,GAAQC,EAAW,QAAUD,EAAQ,GAAKC,EAAW,OACvD,MAAM,IAAI,MAAM,8DAA+D,EAEjF,IAAMC,EAAgBF,EAAO,EAAKC,EAAW,OAASD,EAAOA,EAGvDG,EAAcF,EAAW,MAAM,CAAC,EACtC,QAASH,EAAI,EAAGA,EAAIR,EAAO,OAAQQ,IAAK,CACtC,IAAMM,EAAad,EAAOQ,CAAC,EAAE,KAAK,MAAM,EACxC,QAASO,EAAY,EAAGA,EAAYJ,EAAW,OAAQI,IAErD,GAAIA,IAAcH,EAChBC,EAAYD,CAAY,GAAKE,EAAWC,CAAS,UAG1CJ,EAAWI,CAAS,IAAMD,EAAWC,CAAS,EACrD,MAAM,IAAI,MAAM,kCAAkC,CAGxD,CAEA,IAAMC,EAAaC,EAAU,KAAKJ,CAAW,EAEvCK,EAAmB,IAAI,MAAclB,EAAO,MAAM,EAClDmB,EAAY,IAAI,MAAqBnB,EAAO,MAAM,EAClDoB,EAAWpB,EAAO,CAAC,EAAE,SAEvBqB,EAAc,EACZC,EAAwD,CAAC,EACzDC,EAAoB,CAAC,EACrBC,EAA4B,CAAC,EAC7BC,EAAoC,CAAC,CAAC,KAAM,SAAU,KAAMT,CAAU,CAAC,EAC7E,QAASR,EAAI,EAAGA,EAAIR,EAAO,OAAQ,EAAEQ,EACnCa,GAAerB,EAAOQ,CAAC,EAAE,KAAKI,CAAY,EAC1CM,EAAiBV,CAAC,EAAIa,EACtBG,EAA0B,KAAKE,GAAqB1B,EAAOQ,CAAC,EAAE,KAAK,MAAM,CAAC,EAC1Ee,EAAkB,KAAKC,EAA0BhB,CAAC,EAAIR,EAAOQ,CAAC,EAAE,KAAK,OAASR,EAAOQ,CAAC,EAAE,IAAI,EAC5FW,EAAUX,CAAC,EAAImB,GAAc,QAAQnB,CAAC,GAAIY,EAAUG,EAAkBf,CAAC,CAAC,EACxEc,EAAkB,KAAKE,EAA0BhB,CAAC,EAAI,OAAS,MAAM,EACrEiB,EAAgB,KAAK,CAAC,KAAM,SAAU,KAAMP,EAAiBV,CAAC,CAAC,CAAC,EAElE,QAASA,EAAI,EAAGA,EAAIR,EAAO,OAAQ,EAAEQ,EAC/BgB,EAA0BhB,CAAC,GAC7BiB,EAAgB,KAAK,GAAGG,GAA2B5B,EAAOQ,CAAC,EAAE,IAAI,CAAC,EAItE,IAAMqB,EAA6BH,GAAqBb,EAAY,MAAM,EACtEgB,GACFJ,EAAgB,KAAK,GAAGG,GAA2Bf,CAAW,CAAC,EAGjE,IAAMiB,EAAoBD,EAA6BhB,EAAY,OAASA,EACtEP,EAASyB,GAAe,SAAUX,EAAUU,CAAiB,EAE7DE,EAAc1B,EAAO,WAAW,UAAWM,CAAY,EACvDP,EACF,MAAM,KAAK,MAAMa,EAAiB,MAAM,EAAE,KAAK,CAAC,EAAE,IAAIV,GAAK,4BAA4BA,CAAC,EAAE,EAAE,KAAK,GAAG,EAClGyB,EAAmBC,GAA+B;AAAA;AAAA,KAErD,IAAM,CACPA,EAAa,gBAAgB,aAAc,KAAK,EAChD,QAAS1B,EAAI,EAAGA,EAAIR,EAAO,OAAQQ,IACjC0B,EAAa,gBAAgB,mBAAmB1B,CAAC,GAAI,KAAK,EAE5D,OAAO0B,EAAa,iBAAiB,GAAGf,EAAWb,CAAM,CAC3D,GAAG,CAAC;AAAA;AAAA,IAEFhB,GAAwB4B,EAAiB,OAAQb,CAAmB,CAAC;AAAA;AAAA,IAErE6B,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,oBAE3D5B,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2CAEb0B,CAAW;AAAA;AAAA,0CAEZd,EAAiB,MAAM,MAAMb,CAAmB;AAAA,QAClF2B,CAAW;AAAA;AAAA;AAAA,MAGbzC,GAAiB4B,EAAWb,CAAM,CAAC;AAAA,KAGvC,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGI,CAAI,GAAI,kBAAAY,CAAiB,EAChD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKgB,EAAa,EAAuB,CAAC,EAClE,gBAAAS,CACF,GACA,gBAAAQ,CACF,CACF,EAEaxC,GAAS,CAAC0C,EAAyBC,IAAuC,CACrF/C,GAAe8C,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ3C,GAAwB2C,EAAQ,OAAQC,EAAW,IAAI,CAAC,CAC1E,EAEa1C,GAAyB0C,GAClCC,GAA4B,CAAC,KAAMD,EAAW,IAAc,CAAC,ICzKjE,IAYaE,GAsBAC,GAlCbC,GAAAC,GAAA,kBAGAC,KASaJ,GAAuB,CAACK,EAA0CC,IAClB,CACvD,OAAQD,EAAW,WAAY,CAC7B,IAAK,OACH,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,sBAAsBC,CAAS,SAAS,EAC3F,IAAK,UACH,MAAO,CACL,mBAAoB,GACpB,gBAAiB,YAAYA,CAAS,YAAYA,CAAS,wBAC7D,EACF,IAAK,OACH,MAAO,CACL,mBAAoB,mBAAmBA,CAAS,IAAID,EAAW,OAAQ,qBAAqBC,CAAS,IACjGD,EAAW,OAAQ,KACvB,gBAAiB,6CACnB,EAEF,QACE,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,EAAE,CACvD,CACF,EAESJ,GACRI,GAAgF,CAC/E,IAAME,EAAaF,GAAY,YAAwB,GAEvD,GAAIE,IAAe,OAAQ,CACzB,GAAM,CAACC,EAASC,CAAO,EAAIJ,GAAY,mBAAyC,CAACK,GAAUC,EAAQ,EACnG,MAAO,CAAC,WAAAJ,EAAY,QAAAE,EAAS,QAAAD,EAAS,mBAAoB,GAAGD,CAAU,IAAIC,CAAO,IAAIC,CAAO,EAAE,CACjG,CACA,MAAO,CAAC,WAAAF,EAAY,mBAAoBA,CAAU,CACpD,IC3CJ,IAqBaK,GAeAC,GApCbC,GAAAC,GAAA,kBAqBaH,GAAc,CAACI,EAAmBC,IAAqB,CAClE,OAAQD,EAAW,CACjB,IAAK,GACH,OAAOC,EACT,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,QACE,MAAM,IAAI,MAAM,GAAGD,CAAS,8BAA8B,CAC9D,CACF,EAEaH,GAAeK,GAA6B;AAAA,QACjDA,EAAU,iDAAmD,EAAE;UCrCvE,IAqBaC,GArBbC,GAAAC,GAAA,kBAqBaF,GAAiBG,GAAuB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAO3CA,CAAS,YAAYA,CAAS,YAAYA,CAAS;AAAA;IC5B7D,IA6BMC,GAiBAC,GAyBOC,GAuFPC,GAiBAC,GAKOC,GAgKPC,GA8EOC,GAlabC,GAAAC,GAAA,kBAsBAC,KAEAC,KACAC,KAEAC,KAEMb,GAA6B,CAACc,EAAoBC,IAClDD,EACK;AAAA;AAAA;AAAA,wDAG6CC,EAAY,iBAAmB,EAAE;AAAA,UAI9E;AAAA;AAAA;AAAA,gDAGqCA,EAAY,iBAAmB,EAAE;AAAA,UAK3Ed,GAAyB,CAACe,EAAqBC,IAC/CD,EACK;AAAA;AAAA;AAAA;AAAA,UAIDC,IAAqB,EAAI,GAAK,6DAA6D;AAAA;AAAA;AAAA;AAAA;AAAA,YAKzFA,IAAqB,EAAI,GAAK,2CAA2C;AAAA,WAG1E;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMCA,IAAqB,EAAI,GAAK,yCAAyC;AAAA,WAKtEf,GACT,CAACgB,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,KAAe,CACpF,IAAMC,EAAaL,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CO,EAAaN,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CQ,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EACtCP,EAAmBS,EAAaP,EAAc,CAAC,EAC/CS,EAAgBP,EAAYF,EAAc,CAAC,EAEjD,GAAI,GAAIH,GAAcC,IAAqB,GAAKC,EAAc,CAAC,IAAM,GAC7D,CAACF,IAAeC,IAAqB,GAAKA,IAAqB,KACjES,EAAaP,EAAc,CAAC,IAAM,GAAKE,EAAYF,EAAc,CAAC,IAAM,GAAKD,EAAc,CAAC,IAAM,GACtG,MAAM,IAAI,MAAM,iBAAiBF,CAAU,8BACvCC,CAAgB,yBAAyBC,EAAc,CAAC,CAAC;AAAA,oCACjCD,CAAgB;AAAA,eACrCS,CAAU,yCAAyCP,EAAc,CAAC,CAAC,eACtEE,CAAS,0CAA0CF,EAAc,CAAC,CAAC,kBACnED,EAAc,CAAC,CAAC,aAAa,EAEnC,MAAO;AAAA,yCAC4BD,CAAgB,IAAIG,CAAI,MAAMM,EAAaT,CAAgB,MAAMU,CAAU;AAAA,2CACzEP,CAAI,MAAMK,EAAaP,EAAc,CAAC,CAAC,MAAMG,CAAS;AAAA;AAAA,uBAE1EH,EAAc,CAAC,CAAC;AAAA,uBAChBA,EAAc,CAAC,CAAC;AAAA,2BACZD,CAAgB;AAAA,oBACvBI,CAAS;AAAA;AAAA,2BAEFF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAUrEG,EAAS,IAAM,iBAAiB;AAAA,IAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,8CACvCS,CAAU;AAAA;AAAA,mBAErCF,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,yCAAyC;AAAA,iBAClGC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,wBAE9CH,CAAI;AAAA;AAAA;AAAA,8BAGEQ,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAM/B5B,GAA2BgB,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,0CAInBa,CAAa;AAAA;AAAA;AAAA,sFAI7Cb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAU/BE,IAAqB,EAAI,GAAK,4DAA4D;AAAA;AAAA,YAE1FhB,GAAuBe,EAAYC,CAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAU5D,EAEEd,GAAyB,CAACW,EAAoBC,IAC9CD,EACK;AAAA;AAAA;AAAA,yCAG8BC,EAAY,iBAAmB,EAAE;AAAA,cAI/D;AAAA;AAAA;AAAA,iCAGsBA,EAAY,iBAAmB,EAAE;AAAA,cAK5DX,GAA2BY,GAC7BA,EAAa,gDAAkD,gDAItDX,GACT,CAACa,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,GACtEM,EAA4B,KAAkB,CAC7C,IAAML,EAAaN,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CM,EAAaP,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CO,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EAE5C,GAAI,EAAEG,EAAaR,EAAc,CAAC,IAAM,GAAKO,EAAaP,EAAc,CAAC,IAAM,GACzEE,EAAYF,EAAc,CAAC,IAAM,GACrC,MAAM,IAAI,MAAM,cAAcQ,CAAU,yCACpCR,EAAc,CAAC,CAAC,gBAAgBO,CAAU,yCAC1CP,EAAc,CAAC,CAAC,eAAeE,CAAS,yCAAyCF,EAAc,CAAC,CAAC,EAAE,EAEzG,IAAMW,EAAgBH,EAAaR,EAAc,CAAC,EAC5CY,EAAgBL,EAAaP,EAAc,CAAC,EAC5CS,EAAgBP,EAAYF,EAAc,CAAC,EAC3Ca,EAAgBH,EAClB;AAAA;AAAA;AAAA,gDAGsCL,CAAU;AAAA,gDACVC,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,iDAKTE,CAAU,2BAA2BR,EAAc,CAAC,CAAC;AAAA,mDACnDO,CAAU,2BAA2BP,EAAc,CAAC,CAAC;AAAA,YAC5FhB,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,iDAIRM,CAAS,2BAA2BF,EAAc,CAAC,CAAC;AAAA,uDAC9CM,CAAU,2BAA2BN,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,uCAGrEJ,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAO5CK,CAAI;AAAA;AAAA;AAAA,2DAG2BD,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,0BAI7DH,EAAa,oCAAoCG,EAAc,CAAC,CAAC,KACpD,iCAAiCA,EAAc,CAAC,CAAC,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0DAUzBA,EAAc,CAAC,CAAC;AAAA;AAAA,4DAEdA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,MAKlE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CAMkCK,CAAU;AAAA;AAAA,kCAEpBM,CAAa;AAAA,kCACbC,CAAa;AAAA,kCACbH,CAAa;AAAA;AAAA;AAAA;AAAA,sCAITE,CAAa;AAAA,wCACXC,CAAa;AAAA;AAAA;AAAA,QAG7C5B,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,sCAKfa,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAMrBb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOvCK,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpBhB,GAAwBY,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBrC,MAAO;AAAA,yCAC4BI,CAAI,KAAKM,CAAU,MAAMC,CAAU;AAAA,yCACnCP,CAAI,KAAKK,CAAU,MAAMJ,CAAS;AAAA,yBAClDH,EAAc,CAAC,CAAC;AAAA,yBAChBA,EAAc,CAAC,CAAC;AAAA,sBACnBG,CAAS;AAAA;AAAA,2BAEJF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,kBAInEG,EAAS,IAAM,iBAAiB;AAAA,MAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,qBAClEO,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,yCAAyC;AAAA,mBAClGC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,4BAE5CH,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ1BY,CAAa;AAAA;AAAA,CAGf,EAEE1B,GACF,CAAC2B,EAAmBC,EAAkBC,EAAyBC,EAC9DC,EAAuCC,EAAiB,KAAkB,CACzE,GAAM,CAACC,EAAaC,EAAaC,CAAU,EAAIJ,EACzC,CAACK,EAAeC,EAAWC,EAAWC,CAAc,EAAIT,EACxDU,EAAiBC,GAAiBR,EAAaE,CAAU,EACzDO,EAAiBD,GAAiBP,EAAaC,CAAU,EACzDQ,EAAWC,GAA4Bd,EAAU,CAAC,EAAE,KAAK,MAAM,EAC/De,EAAc,IAAM,CACxB,IAAMC,EAAQT,EAAU,KAClBU,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBX,EAAU,KAAK,OAAO,IACpD,QAASY,EAAIH,EAAQ,EAAI,EAAGI,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAV,EAAe,QAAQS,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcF,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBE,CACT,EACMG,EAAc,IAAM,CACxB,IAAMC,EAAQd,EAAU,KAClBS,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBV,EAAU,KAAK,OAAO,IACpD,QAASW,EAAIG,EAAQ,EAAI,EAAGF,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAR,EAAe,QAAQO,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcI,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBJ,CACT,EAwCA,MAvCe;AAAA,kEAC6CZ,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBkB,EAAY,CAAC;AAAA,kBACLR,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kEAKcD,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBwB,EAAY,CAAC;AAAA,kBACLb,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,6DAKSe,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BACnEhB,CAAS;AAAA;AAAA;AAAA;AAAA,UAKzBC,EACI,mBAAmBI,EAAiB,cAAgB,GAAGqB,GAAY1B,EAAWgB,CAAQ,CAAC,aAAa,IAChE,EAAsC;AAAA,UAC9Ed,CAAe;AAAA,UACfU,EAAe,aAAa,oBAAqB,OAAO,CAAC;AAAA;AAAA;AAAA,KAK/D,EAEStC,GACT,CAACqD,EAA+BC,EAAoDC,EACnFC,EACAzB,EAAiB,KAAyD,CACzE,IAAM0B,EAASJ,EAAO,CAAC,EAAE,KACnBK,EAASL,EAAO,CAAC,EAAE,KAEnBM,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAaF,EAAO,MAAM,EAAG,EAAE,EAE/BG,EAAYL,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAID,EAAY,MAAM,EAAG,EAAE,EAC5FO,EAAsBC,GAAqBF,EAAU,MAAM,EAC3DG,EAAmBF,EAAsBD,EAAU,OAASA,EAC5DrD,EAAYyD,GAAiB,YAAaZ,EAAO,CAAC,EAAE,SAAUW,EAAkB,CAAC,EACjFE,EAAYC,EAAU,KAAKN,CAAS,EAEpCO,EAAYX,EAAOA,EAAO,OAAS,CAAC,EACpCY,EAAWZ,EAAOA,EAAO,OAAS,CAAC,EACnCa,EAAYZ,EAAOA,EAAO,OAAS,CAAC,EACpCa,EAASF,EAAW,IAAM,GAAKC,EAAY,IAAM,EAGjDE,EAAoBJ,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDxD,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClD6D,EAAW,CACf,KAAK,KAAKH,EAAY1D,EAAc,CAAC,EAAI4D,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKJ,EAAYxD,EAAc,CAAC,EAAI4D,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKN,EAAYtD,EAAc,CAAC,EAAI4D,EAAkB,CAAC,CAAC,CAC/D,EAEM9B,EAAWC,GAA4BU,EAAO,CAAC,EAAE,QAAQ,EACzDqB,EAAaH,EAAS,EAAI,EAE1BI,EAAa,CAAC,GAAGhB,EAAYS,EAAWC,EAAWK,CAAU,EAC7DE,EAAwBb,GAAqBY,EAAW,MAAM,EAC9DE,GAAeD,EAAwBD,EAAW,OAASA,EAE3DG,GAAa,CAAC,GAAGlB,EAAYS,EAAUC,EAAYI,CAAU,EAC7DK,EAAwBhB,GAAqBe,GAAW,MAAM,EAC9DE,GAAeD,EAAwBD,GAAW,OAASA,GAE3DG,GAAkB,CAACf,EAAWE,EAAWE,EAAYI,CAAU,EAE/DQ,GAAIC,GAAc,IAAK9B,EAAO,CAAC,EAAE,SAAUwB,GAAcH,CAAU,EACnEU,GAAID,GAAc,IAAK9B,EAAO,CAAC,EAAE,SAAU2B,GAAcN,CAAU,EACnEW,GAAS/C,GAAe,SAAUe,EAAO,CAAC,EAAE,SAAU4B,GAAgB,OAAQP,CAAU,EACxFY,GAAiB,CAACJ,GAAGE,EAAC,EACtBG,GACF,CAAC,CAAC,KAAM,QAAS,KAAMnB,CAAS,EAAG,CAAC,KAAM,QAAS,KAAME,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMD,CAAQ,CAAC,EACpGP,GACFyB,GAAgB,KAAK,GAAGC,GAA2B3B,CAAS,CAAC,EAE3De,GACFW,GAAgB,KAAK,GAAGC,GAA2Bb,CAAU,CAAC,EAE5DI,GACFQ,GAAgB,KAAK,GAAGC,GAA2BV,EAAU,CAAC,EAEhE,IAAMW,GAAwD,CAAC,EAC/DA,GAAkB,KAAKb,EAAwB,OAAS,MAAM,EAC9Da,GAAkB,KAAKV,EAAwB,OAAS,MAAM,EAE9D,IAAMpD,GAAU0B,EAAO,OAAS,EAC1B,CAAC,mBAAAqC,GAAoB,gBAAA9D,EAAe,EAAI+D,GAAqBrC,EAAsB+B,GAAO,KAAK,KAAK,EACpGO,GAAmB7F,GACrB2E,EAAY/C,GAASC,GAAiB,CAACpB,EAAW0E,GAAGE,GAAGC,EAAM,EAAG,CAAC1B,EAAYC,EAAYC,CAAS,EACnG9B,CAAc,EAClB,GAAIJ,GAAS,CACX,IAAMkE,GAAiB9D,EAAiB2C,EAAa,EACrDY,GAAe,KAAKH,GAAc,OAAQ9B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQwC,EAAc,CAAC,EACpGN,GAAgB,KAAK,GAAGC,GAA2BnC,EAAO,CAAC,EAAE,IAAI,CAAC,EAElEoC,GAAkB,KAAK,MAAM,CAC/B,CACAF,GAAgB,KAAK,GAAGC,GAA2BP,EAAe,CAAC,EAEnE,IAAMa,GAAmBC,IAA+B;AAAA,IAEpDA,GAAa,gBAAgB,YAAa,KAAK,EAC1C,gBAAgB,YAAa,KAAK,EAClC,gBAAgB,WAAY,KAAK,EACjC,0BAA0BvF,CAAS,EACnC,iBAAiB,GAAG8E,GAAgBD,EAAM,CAAC;AAAA,IACtDK,EAAkB;AAAA,IAClBE,EAAgB;AAAA,IAEVrB,EAAS5E,GAA2B6E,EAAmB5D,EAAe8B,EAAUlC,CAAS,EAChFV,GAAuB0E,EAAmB5D,EAAe8B,EAAUlC,CAAS,CAAC;AAAA,qBAG1F,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM8C,EAAqB,mBAAqB,GAAGkB,CAAiB,GAC7DlB,EAAqB,UAAU,GAC/BA,EAAqB,OAAO,GAC5BA,EAAqB,OAAO,GAC5BiB,CAAM,GACN5C,EAAO,GACPI,CAAc,GACrB,kBAAA0D,EACF,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMlC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGoB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,gBAAAc,EACF,GACA,gBAAAO,EACF,CACF,IC/gBJ,IAgCME,GA6HOC,GA7JbC,GAAAC,GAAA,kBAqBAC,KAGAC,KAEAC,KAEAC,KACAC,KACAC,KAEMT,GACF,CAACU,EAAyBC,EAAoBC,EAAoBC,EAAmBC,EAAU,GAC9FC,EAA4BC,EAAoB,EAAGC,EAAoB,EAAGC,EAAmB,EAC7FC,EAAW,QAAkB,CAC5B,IAAMC,EAAeF,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,uBACT,IAAK,GACH,MAAO,kBAAkBC,CAAQ,8CACnC,IAAK,GACH,MAAO,2BACT,QACE,MAAM,IAAI,MAAM,oBAAoBD,CAAgB,oBAAoB,CAC5E,CACF,EACMG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,oDACT,IAAK,GACH,MAAO,wDACT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBZ,EAAiB;AAAA;AAAA,MAGA;AAAA;AAAA,MAIjCa,EAAkBb,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCc,EAAUd,EAAiB,2BAA6B,2BACxDe,EAASf,EAAiB,2BAA6B,2BACvDgB,EAAMhB,EAAiB,MAAQ,MAC/BiB,EAAMjB,EAAiB,MAAQ,MAC/BkB,EAAe;AAAA;AAAA,qBAENlB,EAAiB,gCAAkC,+BAA+B;AAAA,mBACpFgB,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA,iBAELC,CAAG;AAAA,iBACHA,CAAG;AAAA;AAAA;AAAA,gBAGJA,CAAG;AAAA,oBACCE,GAAYb,EAAmBG,CAAQ,CAAC;AAAA;AAAA;AAAA,8BAG9BK,CAAO,2BAA2BC,CAAM;AAAA,QAC9DH,CAAa;AAAA;AAAA,QAEbF,EAAYJ,CAAiB,CAAC;AAAA;AAAA,qBAI1Bc,EAAUpB,EAAkBC,GAAaE,EAAW;AAAA,wBACxCG,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SACbN,GAAYD,EAAY;AAAA,wBACxCI,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SAEzCY,EAAU,GAAGV,EAAYJ,CAAiB,CAAC,GAE3Ce,EAAUH,GAAYX,EAAkBC,CAAQ,EAChDc,EACFvB,EAAiBmB,GAAYb,EAAmBG,CAAQ,EAAIU,GAAYZ,EAAmBE,CAAQ,EACjGe,EACFxB,EAAiBmB,GAAYZ,EAAmBE,CAAQ,EAAIU,GAAYb,EAAmBG,CAAQ,EACjG,CAAC,mBAAAgB,EAAoB,gBAAAC,EAAe,EAAIC,GAAqBtB,EAAYiB,CAAO,EAuBtF,MAtBiB;AAAA,MACjBG,CAAkB;AAAA,yDACiCF,CAAK;AAAA,QACtDvB,EAAiBoB,EAAUC,CAAO;AAAA;AAAA;AAAA,yDAGeG,CAAK;AAAA,QACtDxB,EAAiBqB,EAAUD,CAAO;AAAA;AAAA;AAAA,gEAGsBE,CAAO;AAAA,0BAC7Cd,CAAgB;AAAA;AAAA;AAAA;AAAA,uBAInBR,EAAiB,gCAAkC,+BAA+B;AAAA,QACjGa,CAAe;AAAA,QACfe,GAAYxB,CAAO,CAAC;AAAA,QACpBsB,EAAe;AAAA;AAAA;AAAA,MAKnB,EAESnC,GACT,CAACsC,EAA+BxB,EAA4ByB,EAAgCC,EAC3FC,EAAmBC,EAAkBC,EAAkBC,IAAoD,CAC1G,IAAMnC,EAAiBK,EAAW,SAAW,OACvC+B,EAAapC,EAAiB6B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEQ,EAAYP,EAAY,CAAC,EACzBQ,EAAWtC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAYvC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAcxC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAE7DW,EAASzC,IAAmBoC,EAAa,IAAM,GAAKA,EAAa,IAAM,IAAMI,EAAc,IAAM,EAGjGE,EAAY1C,EAAiBwC,EAAcF,EAAWC,EACtDI,EAAY3C,EAAiBsC,EAAWC,EAAYC,EACpDI,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClDC,EAAoBd,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDe,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,iCAAiCD,CAAQ,EAAE,EAEtE,IAAMtC,EAAmBiC,EAAUzC,GAAkBoC,EAAa,IAAM,EAAI,EAAI,EAAK,EAE/EY,EAAaJ,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDI,EAAaL,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDK,EAAY,KAAK,IAAIN,EAAc,CAAC,EAAIpC,EAAkBoC,EAAc,CAAC,CAAC,EAE1E3C,EAAY8B,EAAYiB,IAAe,EACvC9C,GAAY8B,EAAYiB,IAAe,EACvC9C,GAAW8B,EAAWiB,IAAc,EAEpCC,EAAeV,EAAS,CAACjC,EAAkB,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EAC3D4C,GAAIC,GAA4BxB,EAAO,CAAC,EAAE,QAAQ,EAGlDyB,GAAab,EAAS,EAAI,EAC1Bc,GACF,CAAC,CAAC,KAAM,QAAS,KAAMxB,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMC,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMC,CAAQ,CAAC,EAClGuB,GACFC,GAAc,IAAK5B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQrB,IAAqB,EAAI,EAAIA,CAAgB,EACzGkD,GAAID,GAAc,IAAK5B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQyB,EAAU,EAC5EK,GAAiB,CAACH,GAAGE,EAAC,EAE5BH,GAAgB,KAAK,GAAGK,GAA2B/B,EAAO,CAAC,EAAE,IAAI,CAAC,EAClE0B,GAAgB,KAAK,GAAGK,GAA2B/B,EAAO,CAAC,EAAE,IAAI,CAAC,EAElE,IAAIgC,GAAmB;AAAA,qDACwBpB,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA,8BAChDX,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA;AAAA,6EAEsBX,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA;AAAA,qCAEjEX,EAAS,MAAQ,EAAE;AAAA,SAElD,GAAIP,EAAS,CACX,IAAM4B,GAAOL,GAAc,OAAQ5B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQyB,EAAU,EACxFK,GAAe,KAAKG,EAAI,EAExBP,GAAgB,KAAK,GAAGK,GAA2B/B,EAAO,CAAC,EAAE,IAAI,CAAC,EAElEgC,IAAoB;AAAA,0DAC8BpB,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA,+BACpDpD,EAAiB,IAAM,GAAG,GAAGyC,EAAS,MAAQ,EAAE;AAAA,UAEzE,CACA,IAAMsB,GAASC,GAAe,SAAUnC,EAAO,CAAC,EAAE,SAAUC,EAAY,OAAQwB,EAAU,EAC1F,OAAAC,GAAgB,KAAK,GAAGK,GAA2B9B,CAAW,CAAC,EACxD,CACL,KAAM,eACN,YAAa,CAAC,KAAMzB,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMyB,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,gBAAAS,EACF,GACA,gBAAkBU,IAA+B;AAAA,UAC/CC,GAAc,yBAAyB,CAAC;AAAA;AAAA;AAAA;AAAA,UAKtCD,GAAa,gBAAgB,YAAa,KAAK,EAC1C,gBAAgB,YAAa,KAAK,EAClC,gBAAgB,WAAY,KAAK,EACjC,iBAAiB,GAAGN,GAAgBI,EAAM,CAAC;AAAA,mDACT1D,EAAW,YAAY,CAAC,CAAC,KAAKA,EAAW,YAAY,CAAC,CAAC;AAAA,4CAC9DA,EAAW,KAAK,CAAC,CAAC,KAAKA,EAAW,KAAK,CAAC,CAAC;AAAA,+CACtCA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC7CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,UAC1FwD,EAAgB;AAAA,UAEdvE,GACIU,EAAgBC,EAAWC,GAAWC,GAAU+B,EAAS7B,EAAY8C,EAAa,CAAC,EAAGA,EAAa,CAAC,EACpGA,EAAa,CAAC,EAAGC,EAAC,CAAC;AAAA,cAEvBX,EACI0B,GAA2BtB,EAAmBD,EAAeQ,GAAG,OAAW,CAACpD,EAAgBkD,CAAS,EACrGkB,GACIvB,EAAmBD,EAAeQ,GAAG,OAAW,CAACpD,EAAgBkD,EAAW,GAAO,OACnFf,CAAyB,CAAC,EACxC,CACF,ICtQJ,IAeakC,GAfbC,GAAAC,GAAA,kBAIAC,KAGAC,KACAC,KACAC,KAMaN,GACT,CAACO,EAA+BC,EAC/BC,IAAqF,CACpF,IAAMC,EAAUH,EAAO,OAAS,EAC1BI,EAAcD,EAAU,8BAAgC,GACxDE,EAASL,EAAO,CAAC,EAAE,KACnBM,EAASN,EAAO,CAAC,EAAE,KACnBO,EAAyBD,EAAO,CAAC,EAAIL,EAAW,MAEhDO,EAAgBP,EAAW,SAAW,OACtCQ,EAAcC,GAChBL,EAAQC,EAAQL,EAAW,UAAWA,EAAW,KAAMA,EAAW,QAASO,CAAa,EACtFG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAASC,GAAe,SAAUd,EAAO,CAAC,EAAE,SAAUS,CAAW,EACjE,CAAC,mBAAAM,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBhB,EAAYY,EAAO,KAAK,KAAK,EAC1FK,EAAIC,GAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUK,CAAM,EACjDe,EAAID,GAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUM,CAAM,EACjDe,EAAY,CAACH,EAAGE,CAAC,EACnBjB,GACFkB,EAAU,KAAKF,GAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,CAAC,EAGvE,IAAMsB,EAAmBC,GAA+B;AAAA,oCAC1BtB,EAAW,QAAQ,CAAC,CAAC,MAAMA,EAAW,QAAQ,CAAC,CAAC;AAAA,iCACnDA,EAAW,KAAK,CAAC,CAAC,MAAMA,EAAW,KAAK,CAAC,CAAC;AAAA;AAAA,IAEvEsB,EAAa,iBAAiB,GAAGF,EAAWR,CAAM,CAAC;AAAA;AAAA,IAEnDE,CAAkB;AAAA;AAAA,IAElBQ,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCZ,CAAU,CAAC;AAAA;AAAA,0BAE1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,8CAEhBL,EAAgB,EAAI,CAAC;AAAA,yDACVA,EAAgB,EAAI,CAAC,oBACpEA,EAAgB,EAAI,CAAC;AAAA,2CACYD,CAAsB;AAAA;AAAA,iBAEhDM,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA,kDACPP,EAAO,CAAC,CAAC;AAAA,uCACpBA,EAAO,CAAC,CAAC;AAAA,8CACFA,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,yCAE9BI,EAAOG,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,8CAIxBF,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA,yCAC9BI,EAAOG,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAK5DA,EAAgBU,EAAE,IAAI,QAAS,UAAW,SAAU,eAAe,EACnDA,EAAE,IAAI,QAAS,gBAAiB,UAAW,QAAQ,CAAC;AAAA,uBACvDE,EAAE,IAAI,iBAAkB,aAAc,UAAW,QAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,MAK3EhB,CAAW;AAAA,MACXY,CAAe;AAAA,MACfH,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,KAEzC,MAAO,CACL,KAAM,cACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CACR,KAAMC,EAA6BA,EAA2BO,CAAW,EAAIA,EAC7E,SAAUT,EAAO,CAAC,EAAE,QACtB,CAAC,EACD,cAAe,CAAC,EAAG,KAAK,KAAKW,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAW,CACF,CACF,IChGJ,IAcaE,GA6BPC,GAEAC,GAmDAC,GAmBOC,GAgBPC,GAsGAC,GA0BOC,GAnQbC,GAAAC,GAAA,kBAIAC,KACAC,KAGAC,KACAC,KACAC,KACAC,KACAC,KAEahB,GACT,CAACiB,EAA+BC,EAAgCC,EAC/DC,EAA+BC,EAA4BC,IAAqC,CAC/F,IAAMC,EAAYN,EAAW,CAAC,EACxBO,EAAoBP,EAAW,MAAMK,EAAgB,EAAI,EAAGA,EAAgB,EAAI,CAAC,EACjFG,EAAcD,EAAkB,OAChCE,EAAcR,EAAY,CAAC,EAE3BS,EADqBT,EAAY,MAAM,CAAC,EACA,IAAI,CAACU,EAAGC,IAAMD,GAAKA,EAAI,IAAMT,EAAUU,CAAC,EAAI,EAAE,EAEtFC,EAD2BN,EAAkB,IAAI,CAACI,EAAGC,IAAMD,EAAIR,EAAWS,CAAC,EAAIT,EAAWS,EAAIJ,CAAW,CAAC,EAEnF,IAAI,CAACG,EAAGC,IAAM,KAAK,OAAOD,EAAID,EAAmBE,CAAC,EAAIR,EAAQQ,CAAC,GAAKR,EAAQQ,CAAC,CAAC,CAAC,EAC5G,OAAAC,EAAY,OAAO,EAAG,EAAGP,CAAS,EAClCO,EAAY,OAAOR,EAAgB,EAAI,EAAG,EAAGI,CAAW,EACjDI,CACT,EAcE7B,GAA2B,CAAC,EAAG,EAAG,EAAG,CAAC,EAEtCC,GAAiB,CAAC6B,EAA+BC,IAAqC,CAG1F,GAAI,CAACD,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAME,EAAcF,EAAO,CAAC,EAAE,KAAKC,EAAW,SAAW,OAASD,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFG,EAAkBH,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIC,EAAW,MACvD,GAAIC,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,GAAIH,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAC/F,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMN,EAAcM,EAAO,CAAC,EAAE,KAAK,OAAS,EAE5C,GAAIC,EAAW,UAAU,SAAWP,EAClC,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAIvD,GAAIO,EAAW,QAAQ,SAAWP,EAChC,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAIrD,GAAIO,EAAW,KAAK,SAAWP,EAAc,EAC3C,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAKtD,GAAIO,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWD,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAEM5B,GAA4B,CAA2B6B,EAAeD,IAAqC,CAC/G,IAAMb,EAAcc,EAAW,YAAY,MAAM,EAEjD,QAASH,EAAI,EAAGA,EAAIE,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEF,EACvCX,EAAYW,EAAI,CAAC,IAAM,IACzBX,EAAYW,EAAI,CAAC,EAAIE,EAAO,CAAC,EAAE,KAAKF,CAAC,GAGzC,IAAMM,EAAOH,EAAW,KAAK,MAAM,EACnCI,GAAa,yBACTL,EAAO,CAAC,EAAE,KAAMC,EAAW,QAASA,EAAW,UAAWd,EAAaiB,EAAMH,EAAW,SAAW,OACnGA,EAAW,OAAO,EAGtB,IAAMK,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EACrD,cAAO,OAAOK,EAAe,CAAC,YAAAnB,EAAa,KAAAiB,EAAM,SAAUH,EAAW,QAAQ,CAAC,EACxEK,CACT,EAEajC,GAAuB4B,GAAwD,CAC1F,IAAMM,EAAuBC,GAAkCP,CAAU,EAEnEQ,EAASR,EAAW,OACpBS,EAAU,CAAC,SAAU,QAAS,aAAc,YAAY,EAAET,EAAW,QAAkB,EACvFb,EAAYa,EAAW,UACvBU,EAAQV,EAAW,MACnBd,EAAcc,EAAW,aACzBG,EAAOH,EAAW,KAClBX,EAAUW,EAAW,QACrBW,EAAYX,EAAW,WAA6B,EAE1D,OAAOY,GACH,CAAC,QAAAH,EAAS,OAAAD,EAAQ,UAAArB,EAAW,MAAAuB,EAAO,YAAAxB,EAAa,KAAAiB,EAAM,QAAAd,EAAS,SAAAsB,EAAU,GAAGL,CAAoB,CAAC,CACxG,EAEMjC,GAAS,CAACwC,EAAyBd,EAA+BC,IAAqC,CAC3G,IAAMc,EAAqB3C,GAA0B6B,EAAYD,CAAM,EAKvE,GAAIC,EAAW,QAAU,EAAG,CAC1Ba,EAAQ,QAAQE,GAA6BhB,EAAQe,CAAkB,CAAC,EACxE,MACF,CAEA,IAAME,EAAiBhB,EAAW,SAAW,OACvCiB,EAAUlB,EAAO,SAAW,EAC5BmB,EAAcnB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACnDG,EAAapB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EAClDI,EAAgBrB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACrDK,EAAetB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BuB,EAAcvB,EAAO,CAAC,EAAE,KAAK,CAAC,EAE9BD,EAAc9B,GAChB+B,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMC,EAAW,UAAWc,EAAmB,KAAMd,EAAW,QAC1FgB,CAAc,EACZO,EAAYzB,EAAYkB,EAAiB,EAAI,CAAC,EAC9CQ,EAAW1B,EAAYkB,EAAiB,EAAI,CAAC,EAC7CtB,EAAcI,EAAYkB,EAAiB,EAAI,CAAC,EAEhDS,EAAWT,GAAkBK,IAAiBH,GAAeI,IAAgBH,GAC/EnB,EAAW,KAAK,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,EACvD,GAAIyB,GACCJ,IAAiB,GAAKC,IAAgB,GAAKtB,EAAW,UAAU,CAAC,IAAM,GAAKA,EAAW,UAAU,CAAC,IAAM,GACxGA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,GACrFA,EAAW,KAAK,CAAC,IAAM,EAAI,CAE9B,IAAM0B,EAAQ5B,EAAY,CAAC,EACvB6B,EAAWC,EAAWC,GACpBC,GAAe,CAAC,EACtB,GAAId,EAAgB,CAClB,IAAMe,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG9B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC+B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAIlE,GAHIA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAE5BN,EAAU,CACZ,IAAMQ,GAAYf,EAAcC,EAAaC,EAC7CO,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAG2B,EAAOO,EAAS,CAAC,EACnDL,EAAYG,EAAiB,QAAQ,CAAC,EAAGE,GAAWvC,CAAW,CAAC,EAChEmC,GAAoB,CAAC,EAAGH,EAAOhC,CAAW,CAC5C,MACEiC,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAOR,EAAcC,EAAYC,CAAa,CAAC,EAC9EQ,EAAYG,EAAiB,QAAQ,CAAC,EAAGX,EAAe1B,CAAW,CAAC,EACpEmC,GAAoB,CAACH,EAAOH,EAAYC,EAAU9B,CAAW,EAE/DoC,GAAa,KAAKH,CAAS,EAC3BG,GAAa,KAAKF,CAAS,CAC7B,MACED,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAON,EAAeF,EAAcC,CAAU,CAAC,EAC9ES,EAAY7B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAGL,EAAa0B,CAAa,CAAC,EAC7DS,GAAoB,CAACH,EAAOhC,EAAa6B,EAAYC,CAAQ,EAC7DM,GAAa,KAAKF,CAAS,EAC3BE,GAAa,KAAKH,CAAS,EAEzBV,GACFa,GAAa,KAAK/B,EAAO,CAAC,CAAC,EAE7Bc,EAAQ,QACJqB,GAAwBJ,GAAchB,EAAoBhB,EAAa+B,GAAmBb,CAAc,EACxG,CAAC,OAAQc,EAAY,CAAC,EAC1B,MACF,CAIA,IAAMK,EAAgE,GAGhEJ,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG9B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC+B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAIhC,IAAMK,EAAa,CAACrC,EAAO,CAAC,EAAGgC,CAAgB,EAC3Cd,GACFmB,EAAW,KAAKrC,EAAO,CAAC,CAAC,EAI3B,IAAMsC,EAAYrB,EAAiBO,EAAYC,EAAW9B,EACpD4C,EAAYtB,EAAiBtB,EAAc6B,EAAYC,EACvDe,EAAWlB,EAAeC,EAAcF,EAC9CP,EAAQ,QACJ2B,GACIJ,EAAYtB,EAAoBhB,EAAauC,EAAWC,EAAWC,EAAUtB,EAC7EkB,CAAyB,EAC7B,CAAC,OAAQC,CAAU,CAAC,CAC1B,EAEM9D,GAAS,CAACuC,EAAyBb,IAAqC,CAE5E,IAAMV,EAAgBU,EAAW,SAAW,OACtCD,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdvB,EAEI,CAACuB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACIA,EAAQ,OAAO,SAAW,GAC5Bd,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAMV,EAAO,CAAC,EAAGH,EAAW,KAAK,CAAC,EAAG,EAAGA,EAAW,KAAK,CAAC,CAAC,EACpDX,EAAU,CAAC,CAAC,EAAE,OAAOW,EAAW,OAAO,EACvCb,EAAY,CAAC,CAAC,EAAE,OAAOa,EAAW,SAAS,EAC3Cd,EAAc,CAAC,CAAC,EAAE,OAAOc,EAAW,WAAW,EAC/Cc,EAAqB3C,GAA0B,CAAC,GAAG6B,EAAY,KAAAG,EAAM,QAAAd,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGa,CAAM,EACnHc,EAAQ,QAAQE,GACZhB,EAAQe,EACRhB,GAAeR,EAAgB,CAACQ,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAAI,CAAC,CAAC,CAAC,CAC3F,EAEavB,GAAO,CAACsC,EAAyBb,IAAqC,CACjF9B,GAAe2C,EAAQ,OAAQb,CAAU,EACrCa,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCvC,GAAOuC,EAASb,CAAU,EAE1B3B,GAAOwC,EAASA,EAAQ,OAAQb,CAAU,CAE9C,IC1QA,IAgCMyC,GA4HOC,GA5JbC,GAAAC,GAAA,kBAqBAC,KAGAC,KAEAC,KAEAC,KACAC,KACAC,KAEMT,GACF,CAACU,EAAyBC,EAAU,GAAOC,EAAqCC,EAAmB,IAAc,CAC/G,IAAMC,EAAOC,GAAYF,EAAkB,KAAK,EAC1CG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,sEACT,IAAK,GACH,MAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAUT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBP,EAAiB;AAAA;AAAA,QAGA;AAAA;AAAA,QAIjCQ,EAAkBR,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCS,EAAUT,EAAiB,iBAAmB,iBAC9CU,EAASV,EAAiB,iBAAmB,iBAC7CW,EAAMX,EAAiB,MAAQ,MAC/BY,EAAMZ,EAAiB,MAAQ,MAE/Ba,EAAe;AAAA,yBACFb,EAAiB,iBAAmB,gBAAgB;AAAA,uBACtDA,EAAiB,gCAAkC,+BAA+B;AAAA,qBACpFW,CAAG;AAAA,qBACHA,CAAG;AAAA;AAAA,mBAELC,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA;AAAA,kCAGYH,CAAO;AAAA,iBACxBL,CAAI;AAAA;AAAA,kCAEaM,CAAM;AAAA,iBACvBN,CAAI;AAAA;AAAA;AAAA;AAAA,kBAIHQ,CAAG;AAAA,QACbL,CAAa;AAAA,0EACqDJ,CAAgB,KAE9EW,EAAUd,EAAiB;AAAA,0BACbG,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SACoB;AAAA,0BACbD,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SAEPW,EAAU;AAAA,0BACIZ,CAAgB;AAAA,yBACjBH,EAAiB,iBAAmB,gBAAgB;AAAA;AAAA;AAAA,YAInEA,EAAiB,sDACA,qDAAqD;AAAA;AAAA;AAAA,UAGtEM,EAAYH,CAAgB,CAAC;AAAA;AAAA,eAExBC,CAAI;AAAA,QAGP,CAAC,mBAAAY,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBhB,EAAYE,CAAI,EAsBnF,MArBiB;AAAA,QACfY,CAAkB;AAAA,uDAC6BZ,CAAI;AAAA,MACrDJ,EAAiBc,EAAUC,CAAO;AAAA;AAAA;AAAA,uDAGeX,CAAI;AAAA,MACrDJ,EAAiBe,EAAUD,CAAO;AAAA;AAAA;AAAA,iEAGyBV,CAAI;AAAA,wBAC7CD,CAAgB;AAAA;AAAA;AAAA,uBAGjBH,EAAiB,gCAAkC,+BAA+B;AAAA,QACjGQ,CAAe;AAAA,QACfW,GAAYlB,CAAO,CAAC;AAAA,QACpBgB,CAAe;AAAA,8EACuDd,CAAgB;AAAA;AAAA,IAI1F,EAESZ,GACT,CAAC6B,EAA+BlB,EAAqCmB,EACpEC,EAAmBC,EAAmBC,EAAkBC,EACxDC,IAAoD,CACnD,IAAM1B,EAAiBE,EAAW,SAAW,OACvCyB,EAAa3B,EAAiBoB,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEQ,EAAYP,EAAY,CAAC,EACzBQ,EAAW7B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAY9B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAc/B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC7DW,EACFhC,EAAiB2B,EAAa,IAAM,GAAKI,EAAc,IAAM,EAAIF,EAAW,IAAM,GAAKE,EAAc,IAAM,EAGzGE,EAAYjC,EAAiB+B,EAAcF,EAAWC,EACtDI,EAAYlC,EAAiB6B,EAAWC,EAAYC,EACpDI,EAA0CH,EAC5C,CAAC,EAAG,EAAG,CAAC,EACR,CAAEC,GAAa,GAAKC,GAAa,EAAK,EAAI,GAAID,EAAY,GAAKC,GAAa,EAAI,EAAI,GAAI,CAAC,EACvFE,EACFJ,EAAS,CAAC,EAAG,EAAG,CAAC,EAAI,CAACC,GAAa,EAAI,EAAI,EAAGA,EAAY,GAAKC,GAAa,EAAI,EAAI,EAAG,CAAC,EACtFG,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,wCAAwCD,CAAQ,EAAE,EAE7E,IAAMlC,EAAmB6B,EAAS,EAAI,EAChCO,EAAY,KAAK,IAAIJ,EAAc,CAAC,EAAIhC,EAAkBgC,EAAc,CAAC,CAAC,EAC1EK,EAAaR,EAAS,EAAI,EAC1BS,EACF,CAAC,CAAC,KAAM,QAAS,KAAMnB,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMC,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMC,CAAQ,CAAC,EAClGkB,EAAIC,GAAc,IAAKvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQoB,CAAU,EAC5EI,GAAID,GAAc,IAAKvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ,CAAC,EACnEyB,GAASC,GAAe,SAAU1B,EAAO,CAAC,EAAE,SAAUC,EAAY,OAAQmB,CAAU,EACpFO,EAAiB,CAACL,EAAGE,EAAC,EAC5BH,EAAgB,KAAK,GAAGO,GAA2B5B,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEqB,EAAgB,KAAK,GAAGO,GAA2B5B,EAAO,CAAC,EAAE,IAAI,CAAC,EAElE,IAAI6B,GAAmB,GACvB,GAAIxB,EAAS,CACX,IAAMyB,GAAOP,GAAc,OAAQvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQoB,CAAU,EACxFO,EAAe,KAAKG,EAAI,EACxBT,EAAgB,KAAK,GAAGO,GAA2B5B,EAAO,CAAC,EAAE,IAAI,CAAC,EAElE6B,IAAoB;AAAA,0DAC8BjB,EAAS,YAAc,KAAK;AAAA,+BACvDhC,EAAiB,IAAM,GAAG,GAAGgC,EAAS,MAAQ,EAAE;AAAA,UAEzE,CAEA,OAAAS,EAAgB,KAAK,GAAGO,GAA2B3B,CAAW,CAAC,EAExD,CACL,KAAM,wBACN,YAAa,CAAC,KAAMnB,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMmB,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,gBAAAI,CACF,GACA,gBAAkBU,IAA+B;AAAA,UAC/CC,GAAc,yBAAyB,CAAC;AAAA,UAEtCD,GAAa,gBAAgB,YAAa,KAAK,EAC1C,gBAAgB,YAAa,KAAK,EAClC,gBAAgB,WAAY,KAAK,EACjC,iBAAiB,GAAGJ,EAAgBF,EAAM,CAAC;AAAA,oDACRzB,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,mDACzBlB,EAAW,YAAYF,EAAiB,EAAI,CAAC,CAAC,KACrFE,EAAW,YAAYF,EAAiB,EAAI,CAAC,CAAC;AAAA;AAAA,gBAG9CE,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYF,EAAiB,EAAI,CAAC,EAAI,IAAME,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gBAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYF,EAAiB,EAAI,CAAC,EAAI,IAAME,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gFAExFA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,8EAEvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,gDACHA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC9CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClEoB,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/ByB,EAAgB;AAAA,UAChB3D,GAA6BU,EAAgByB,EAASvB,EAAYC,CAAgB,CAAC;AAAA,UAEjF6B,EAASqB,GACIjB,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,CAAS,EAClFe,GACIlB,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,EAAW,GAChF,OAAWb,CAAyB,CAAC,EACxD,CACF,IChQJ,IA0BM6B,GAsNOC,GAhPbC,GAAAC,GAAA,kBAmBAC,KAEAC,KAEAC,KAGMN,GACF,CAACO,EAA4BC,EAA+BC,EAC3DC,EAAgCC,EAAkBC,EAA+BC,EAAS,GAC1FC,IAA6B,CAC5B,IAAMC,EAAiBN,EAAW,SAAW,OACvCO,EAASD,EAAiB,EAAI,EAC9BE,EAASF,EAAiB,EAAI,EAC9BG,EAAaH,EAAiB,EAAI,EAClCI,EAAaC,EAAU,KAAKV,CAAW,EACvCW,EAAgBR,EAAS,EAAI,EAC7BS,EAAQb,EAAW,MACnBc,EAASf,EAAO,CAAC,EAAE,KACnBgB,EAAwBD,EAAO,CAAC,EAAID,EACpCG,EAAyBF,EAAO,CAAC,EAEnCG,EAAmB;AAAA,iDACoBb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,0BAC9DD,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,KAEvDH,IACFe,GAAoB;AAAA,sDAC0Bb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,2BAClEC,EAAiB,IAAM,GAAG,GAAGF,EAAS,MAAQ,EAAE;AAAA,QAGrE,IAAMc,EAAad,EAAS,EAAI,EAC1Be,EAAIC,GAAc,IAAKrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACrEG,EAAKD,GAAc,KAAMrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACvEI,EAAiB,CAACD,EAAIF,CAAC,EACzBjB,GACFoB,EAAe,KAAKF,GAAc,OAAQrB,EAAO,CAAC,EAAE,SAAU,CAACE,EAAYQ,CAAU,CAAC,EAAGS,CAAU,CAAC,EAEtG,IAAMK,EAASC,GAAe,SAAUzB,EAAO,CAAC,EAAE,SAAUE,EAAaiB,CAAU,EAC7EO,EAAe;AAAA,2BACAtB,EAAuB,cAAgB,gBAAgB;AAAA,kBAChEA,EAAuB,cAAgB,gBAAgB;AAAA,kBACvDA,EAAuB,cAAgB,gBAAgB,MAAMS,CAAa;AAAA,wBACpET,EAAuB,cAAgB,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM7CE,CAAQ,MAAMO,CAAa;AAAA,8BAC/BA,CAAa;AAAA,8BACbP,CAAQ;AAAA;AAAA;AAAA,uBAGfA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,oCAExCA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOnBA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA,0BACpDA,CAAQ,wBAAwBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAO/CA,CAAQ;AAAA;AAAA;AAAA;AAAA,wCAINA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAUhBc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAMhBgB,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA;AAAA,iDAEjBhB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMdI,CAAU;AAAA;AAAA,gCAErBU,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCASZc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA,oCACjChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mCAUTO,CAAa;AAAA,qCACXV,EAAU,YAAc,KAAK;AAAA,YACtDqB,EAAO,IAAI,QAAS,IAAK,QAAS,KAAM,OAAO,CAAC;AAAA;AAAA,SAGhDG,GAAc;AAAA,gCACMH,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBAC5CA,EAAO,WAAW,gBAAiB,CAAC,CAAC;AAAA,qBACxCA,EAAO,WAAW,gBAAiBd,CAAU,CAAC;AAAA,oBAC/Cc,EAAO,WAAW,gBAAiBhB,CAAM,CAAC;AAAA,oBAC1CgB,EAAO,WAAW,gBAAiBf,CAAM,CAAC;AAAA;AAAA;AAAA;AAAA,+BAI/BQ,CAAsB;AAAA,6CACRA,CAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAQ1CX,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,sCAEvCA,CAAQ,gBAAgBE,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAUzCF,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,wCAEvCA,CAAQ,gBAAgBG,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA,6CAKzBO,CAAqB;AAAA,2CACvBA,CAAqB;AAAA,+BAEtDT,EAAiBe,EAAG,IAAI,QAAS,OAAQ,OAAQ,cAAc,EAC9CA,EAAG,IAAI,QAAS,eAAgB,OAAQ,MAAM,CAAC;AAAA,+BAC3CF,EAAE,IAAI,eAAgB,cAAe,cAAe,aAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM/DjB,EAAU,WAAa,KAAK;AAAA,YAClDqB,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,UAG/C,MAAO;AAAA,IACTzB,EAAa,iBAAiB,GAAGwB,EAAgBC,CAAM,CAAC;AAAA,IACxDN,CAAgB;AAAA,2CACuBhB,EAAY,KAAK,GAAG,CAAC;AAAA,8CAClBF,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,0CAC5BC,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,6CAC5CA,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC,KACjFN,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC;AAAA,4CACZN,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,YAGrFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,YAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,0EACxBA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,0EACvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,MAC3GF,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsCY,CAAU,CAAC;AAAA,IAChEN,EAASqB,EAAeC,EAAW,GACnC,EAESlC,GACT,CAACO,EAA+BC,EAC/B2B,IAAqF,CACpF,IAAMzB,EAAUH,EAAO,OAAS,EAE1BE,EAAcD,EAAW,YACzBU,EAAaC,EAAU,KAAKV,CAAW,EAMvC2B,EAAW,CACf,KAAK,KAAKlB,EAAa,EAAE,EACzB,EACA,CACF,EACAmB,GAAU,UAAW,IAAM,uCAAuCD,CAAQ,EAAE,EAE5E,IAAMvB,EAAWyB,GAA4B/B,EAAO,CAAC,EAAE,QAAQ,EAC/D,MAAO,CACL,KAAM,kBACN,YAAa,CAAC,KAAMC,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,cAAe,CAAC,EAAG4B,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,QAAS,CAAC,CACR,KAAMD,EAA6BA,EAA2B1B,CAAW,EAAIA,EAC7E,SAAUF,EAAO,CAAC,EAAE,QACtB,CAAC,CACH,GACA,gBAAkBD,GAA+BP,GAC7CO,EAAcC,EAAQC,EAAYC,EAAaC,EAAS0B,EAAS,CAAC,IAAM,GAAKA,EAAS,CAAC,IAAM,EAAG,GAChGvB,CAAQ,CACd,CACF,IClRJ,IAaM0B,GAIAC,GAWAC,GAkCAC,GA4COC,GA8BPC,GAqEAC,GAEAC,GAmDAC,GA6COC,GA/SbC,GAAAC,GAAA,kBAIAC,KAGAC,KACAC,KAEAC,KACAC,KAEMhB,GACF,CAACiB,EAAeC,EAAgBC,EAAaC,EAAgBC,EAAkBC,KAC1EL,EAAQ,GAAKC,EAASC,GAAOC,EAAS,GAAKC,EAAW,EAAIC,EAE7DrB,GAAoB,CAACsB,EAAkBC,EAAiBC,EAAgBC,EAAcC,IAAiB,CAC3G,IAAMC,EAAW,KAAK,MAAML,EAAW,CAAC,EACpCC,IAAY,cACdC,EAAKC,CAAI,EAAIE,EACbH,EAAKE,CAAI,EAAIJ,EAAWK,GACfJ,IAAY,eACrBC,EAAKC,CAAI,EAAIH,EAAWK,EACxBH,EAAKE,CAAI,EAAIC,EAEjB,EAEM1B,GACF,CAAC2B,EAA+BC,EAAgCC,EAA8BP,EAC7FQ,EAAeP,EAAgBQ,EAA4BC,EAAwBC,EACnFC,IAA0B,CACzB,IAAMC,EAAcR,EAAW,OAAS,EAClCS,EAAoBF,EAAY,SAAW,EACjD,GAAID,EAAc,SAAW,EAC3B,QAASI,EAAI,EAAGA,EAAIF,EAAa,EAAEE,EACjCJ,EAAc,KAAK,CAAC,EAGxB,IAAMK,EAAYX,EAAW,CAAC,EACxBY,EAAcX,EAAYI,EAAgB,EAAI,CAAC,EAAIF,EACzD,QAASO,EAAI,EAAGG,EAAIb,EAAW,OAASQ,GAAeH,EAAgB,EAAI,GAAIK,EAAIF,EAAa,EAAEE,EAAG,EAAEG,EAAG,CACxG,IAAMC,EAASd,EAAWa,CAAC,EACrBpB,EAAUgB,EAAoBK,EAASV,EAAQM,CAAC,EAAIH,EAAYG,CAAC,EACjEhB,EAAWvB,GAAgB2C,EAAQV,EAAQM,CAAC,EAAGd,EAAKc,CAAC,EAAGT,EAAYY,CAAC,EAAGX,EAAUQ,CAAC,EAAGjB,CAAO,EACnGrB,GAAkBsB,EAAUC,EAASC,EAAMc,EAAGA,EAAIF,CAAW,EACzDC,GACFF,EAAY,KACRH,EAAQM,CAAC,GAAKI,EAAS,GAAKR,EAAcI,CAAC,GAAKT,EAAYY,CAAC,EAAI,GAAKX,EAAUQ,CAAC,EAAI,EAAId,EAAKc,CAAC,EAC/Fd,EAAKc,EAAIF,CAAW,CAAC,CAE7B,CACAD,EAAY,OAAO,EAAG,EAAGI,CAAS,EAClCJ,EAAY,OAAOF,EAAgB,EAAI,EAAG,EAAGO,CAAW,CAC1D,EAQEtC,GACF,CAAoCyC,EAAeC,IAAqC,CACtF,IAAMf,EAAcc,EAAW,YAAY,MAAM,EAEjD,GAAIA,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAClGjB,EAAY,OAAS,EACrB,QAASS,EAAI,EAAGA,EAAIM,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEN,EAC3CT,EAAY,KAAKe,EAAO,CAAC,EAAE,KAAKN,CAAC,CAAC,CAEtC,CACA,IAAMS,EAAiBJ,EAAW,SAAW,OAC7Cd,EAAY,OAAO,EAAG,EAAGe,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC1Cf,EAAY,OAAOkB,EAAiB,EAAI,EAAG,EAAGH,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAE/D,IAAMpB,EAAOmB,EAAW,KAAK,MAAM,EAC7BR,EAAcQ,EAAW,YAAY,MAAM,EAC3CT,EAAgBS,EAAW,cAAc,MAAM,EAC/Cf,EAAagB,EAAO,CAAC,EAAE,KACzBd,EAAYa,EAAW,UAAU,MAAM,EAC3C,GAAIb,EAAU,OAAO,CAACe,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC9C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5Cd,EAAY,IAAI,MAAMM,CAAW,EAAE,KAAK,CAAC,CAC3C,CACA,IAAIJ,EAAUW,EAAW,QAAQ,MAAM,EACvC,GAAIX,EAAQ,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC5C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5CZ,EAAU,IAAI,MAAMI,CAAW,EAAE,KAAK,CAAC,CACzC,CAGAnC,GACI2B,EAAYC,EAAaC,EAAWa,EAAW,QAASA,EAAW,MAAOnB,EAAMQ,EAASe,EACzFb,EAAeC,CAAW,EAG9B,IAAMa,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EAC/CM,EAAWN,EAAW,SAAW,CACrCd,EAAY,KAAK,IAAI,EAAGL,EAAK,KAAK,GAAG,EAAGQ,EAAQ,KAAK,GAAG,EAAGE,EAAc,KAAK,GAAG,EAAGC,EAAY,KAAK,GAAG,EACxGL,EAAU,KAAK,GAAG,CACpB,EAAE,KAAK,GAAG,EACV,cAAO,OAAOkB,EAAe,CAAC,YAAAnB,EAAa,KAAAL,EAAM,cAAAU,EAAe,YAAAC,EAAa,UAAAL,EAAW,QAAAE,EAAS,SAAAiB,CAAQ,CAAC,EACnGD,CACT,EAES7C,GAAgCwC,GAAiE,CAC5G,IAAMO,EAAuBC,GAAkCR,CAAU,EAEnES,EAAST,EAAW,OACpBpB,EACF,CAAC,SAAU,QAAS,aACnB,YAAY,EAAE,OAAOoB,EAAW,QAAW,IAAc,EAAIA,EAAW,OAAiB,EACxFb,EAAYa,EAAW,UACvBZ,EAAQY,EAAW,MACnBd,EAAcc,EAAW,YACzBnB,EAAOmB,EAAW,KAClBX,EAAUW,EAAW,QACrBU,EAAYV,EAAW,SAA2B,EAClDT,EAAgBS,EAAW,cAC3BR,EAAcQ,EAAW,YAC/B,OAAOW,GAA4B,CACjC,QAAA/B,EACA,OAAA6B,EACA,UAAAtB,EACA,MAAAC,EACA,YAAAF,EACA,cAAAK,EACA,YAAAC,EACA,KAAAX,EACA,QAAAQ,EACA,SAAAqB,EACA,GAAGH,CACL,CAAC,CACH,EAEM9C,GAAiB,CAACwC,EAA+BD,IAA8C,CAGnG,GAAI,CAACC,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,2CAA2C,EAG7D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAMW,EAAcX,EAAO,CAAC,EAAE,KAAKD,EAAW,SAAW,OAASC,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFY,EAAkBZ,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,GAAIW,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMC,EAAcb,EAAO,CAAC,EAAE,KAAK,CAAC,EAAID,EAAW,MAGnD,GAAIC,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMa,GAC/E,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMrB,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAG5C,GAFqBD,EAAW,UAAU,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEnDH,EAAW,UAAU,SAAWP,EAClD,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAKvD,GAFmBO,EAAW,QAAQ,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEjDH,EAAW,QAAQ,SAAWP,EAC9C,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAKrD,GADgBO,EAAW,KAAK,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAC9CH,EAAW,KAAK,SAAWP,EAAc,EACtD,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAItD,GAAIO,EAAW,cAAc,SAAWP,GAAeO,EAAW,cAAc,SAAW,EACzF,MAAM,IAAI,MAAM,4BAA4BP,CAAW,GAAG,EAM5D,GADuBO,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GACrDH,EAAW,YAAY,SAAW,GACpDA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5D,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAID,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAGMvC,GAAsB,CAAC,EAAG,EAAG,EAAG,CAAC,EAEjCC,GACF,CAACoD,EAAyBd,EAA+BD,IAA8C,CACrG,IAAMgB,EAAqBzD,GAAmCyC,EAAYC,CAAM,EAC1EG,EAAiBJ,EAAW,SAAW,OACvCiB,EAAUhB,EAAO,SAAW,EAClC,GAAIe,EAAmB,QAAU,EAAG,CAClCD,EAAQ,QAAQG,GAAiCjB,EAAQe,CAAkB,CAAC,EAC5E,MACF,CACA,IAAMxB,EAAcwB,EAAmB,YACjCG,EAAY3B,EAAYY,EAAiB,EAAI,CAAC,EAC9CgB,EAAW5B,EAAYY,EAAiB,EAAI,CAAC,EAC7CP,EAAcL,EAAYY,EAAiB,EAAI,CAAC,EAChDiB,EAAepB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BqB,EAAcrB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC9BsB,EAAgBtB,EAAO,CAAC,EAAE,KAAKG,EAAiB,EAAI,CAAC,EAErDoB,EAAYpB,EAAiBe,EAAYC,EAAWvB,EACpD4B,EAAYrB,EAAiBP,EAAcsB,EAAYC,EACvDM,EAAWL,EAAeC,EAAcC,EAExCI,EAAgE,GAIhEC,EAAoBb,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJc,GAA2B5B,EAAO,CAAC,EAAGvC,EAAmB,EACzD,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAACsC,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACe,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKa,GAIhC,IAAME,EAAsB,CAAC7B,EAAO,CAAC,EAAG2B,CAAgB,EACpDX,IACE,CAACb,GAAkBH,EAAO,CAAC,EAAE,KAAK,SAAW,EAC/C6B,EAAoB,KAAK7B,EAAO,CAAC,EAAE,QAAQ,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAG,CAAC,CAAC,CAAC,EAErE6B,EAAoB,KAAK7B,EAAO,CAAC,CAAC,GAKtCc,EAAQ,QACJgB,GACID,EAAqBd,EAAoBxB,EAAagC,EAAWC,EAAWC,EAAUT,EACtFU,CAAyB,EAC7B,CAAC,OAAQG,CAAmB,CAAC,CACnC,EAEElE,GAAkB,CAACmD,EAAyBf,IAA8C,CAE9F,IAAMV,EAAgBU,EAAW,SAAW,OAEtCC,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdzB,EAEI,CAACyB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACId,EAAO,SAAW,GACpBA,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAI7B,EAAcc,EAAW,aACzBd,EAAY,SAAW,GAAKA,EAAY,CAAC,IAAM,KACjDA,EAAc,CAAC6B,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,GAE1C,IAAI5B,EAAYa,EAAW,WACvBb,EAAU,SAAW,GAAKA,EAAU,CAAC,IAAM,KAC7CA,EAAY,CAAC,CAAC,GAEhB,IAAIE,EAAUW,EAAW,SACrBX,EAAQ,SAAW,GAAKA,EAAQ,CAAC,IAAM,KACzCA,EAAU,CAAC,CAAC,GAEd,IAAIR,EAAOmB,EAAW,KAClBnB,EAAK,SAAW,IAClBA,EAAO,CAAC,EAAG,CAAC,GAEdA,EAAO,CAAC,EAAGA,EAAK,CAAC,EAAG,EAAGA,EAAK,CAAC,CAAC,EAC9BQ,EAAU,CAAC,CAAC,EAAE,OAAOA,CAAO,EAC5BF,EAAY,CAAC,CAAC,EAAE,OAAOA,CAAS,EAChCD,EAAc,CAAC,CAAC,EAAE,OAAOA,CAAW,EACpC,IAAM8B,EACFzD,GAAmC,CAAC,GAAGyC,EAAY,KAAAnB,EAAM,QAAAQ,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGe,CAAM,EACrGc,EAAQ,QAAQG,GACZjB,EAAQe,EACRxB,GAAeF,EAAgB,CAACE,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAC/C,CAACA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,CAAC,CAAC,CACtF,EAEa3B,GAAgB,CAACkD,EAAyBf,IAA8C,CACnGvC,GAAesD,EAAQ,OAAQf,CAAU,EACrCe,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCnD,GAAgBmD,EAASf,CAAU,EAEnCrC,GAAgBoD,EAASA,EAAQ,OAAQf,CAAU,CAEvD,ICtTA,IAsBMgC,GAEAC,GACAC,GACAC,GACAC,GAQAC,GAqBAC,GA4HAC,GAEAC,GAqHOC,GASAC,GApTbC,GAAAC,GAAA,kBAIAC,KACAC,KAGAC,KAcMf,GACF,qBACEC,GAAc,IAAMD,GAAgB,KACpCE,GAAkB,IAAMD,GAAc,IACtCE,GAAa,IAAMF,GAAc,MAAQA,GACzCG,GAAiB,IAAMD,GAAa,IAQpCE,GAAN,KAAiB,CACf,YAAYW,EAAa,GAAI,CAC3B,KAAK,gBAAkB,IAAI,IAC3B,KAAK,WAAaA,CACpB,CAGA,UAAUC,EAAgBC,EAAe,CACvC,IAAIC,EAAQ,KAAK,gBAAgB,IAAIF,CAAM,EACvCE,IAAU,OACZA,EAAQ,CAACD,CAAK,EAEdC,EAAM,KAAKD,CAAK,EAElB,KAAK,gBAAgB,IAAID,EAAQE,CAAK,CACxC,CAIF,EAEMb,GAAN,KAAqB,CACnB,YAAYc,EAA+CC,EAAkB,CAAlB,cAAAA,EACzD,KAAK,YAAc,GACnB,KAAK,aAAe,IAAI,IACxB,KAAK,IAAM,IAAI,MACf,KAAK,WAAa,CAAC,EAGnB,GAAI,CAACC,EAAKC,CAAG,EAAIF,EAAS,SAAS,IAAI,EAAIA,EAAS,MAAM,KAAM,CAAC,EAAI,CAACA,EAAU,EAAE,EAClF,GAAI,CAACC,EAAI,MAAM,OAAOlB,EAAc,CAAC,EACnC,MAAM,IAAI,MAAM,kBAAkB,EAapC,GAXmBkB,EAAI,MAAM,GAAG,EACrB,QAAQ,CAACE,EAAWN,IAAU,CACvC,IAAMO,EAAOL,EAAOF,CAAK,EAAE,KAAK,MAAM,EACtC,GAAI,CAACM,EAAU,MAAM,OAAOtB,EAAe,CAAC,EAC1C,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMwB,EAAa,KAAK,YAAYF,EAAW,GAAMC,EAAMP,CAAK,EAChE,KAAK,IAAI,KAAKQ,CAAU,CAC1B,CAAC,EAGGH,IAAQ,GAEVA,GAAO,CAAC,GAAG,KAAK,aAAa,QAAQ,CAAC,EAC1B,OAAO,CAAC,CAACI,EAAKC,CAAI,IAAOA,EAAK,QAAU,GAAKD,IAAQ,KAAM,EAC3D,IAAI,CAAC,CAACA,CAAG,IAAMA,CAAG,EAClB,KAAK,EAAE,UAEf,CAACJ,EAAI,MAAM,OAAOtB,EAAW,CAAC,EAChC,MAAM,IAAI,MAAM,aAAa,EAKdsB,EAAI,MAAM,OAAOvB,GAAe,GAAG,CAAC,GAC3C,QAASiB,GAAW,CAC9B,GAAIA,IAAW,MACb,KAAK,WAAa,KAAK,WAAW,OAAO,KAAK,YAAY,MACrD,CACL,IAAMW,EAAO,KAAK,aAAa,IAAIX,CAAM,EACzC,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,oBAAoB,EAEtC,KAAK,WAAW,KAAKA,EAAK,QAAQ,CACpC,CACF,CAAC,EACD,KAAK,IAAM,KAAK,YAAYL,EAAK,GAAO,KAAK,UAAU,CACzD,CAGA,UAAUN,EAAgBY,EAAkBb,EAAoB,CAC9D,IAAIY,EAAO,KAAK,aAAa,IAAIX,CAAM,EACvC,GAAIW,IAAS,OAAW,CACtB,GAAIA,EAAK,WAAaC,GAAYD,EAAK,QAAU,EAC/C,MAAM,IAAI,MAAM,oBAAoB,EAEpCA,EAAK,QACLA,EAAK,aAAa,KAAKZ,CAAU,CAErC,MACEY,EAAO,CAAC,MAAO,EAAG,SAAAC,EAAU,aAAc,CAACb,CAAU,CAAC,EAExD,KAAK,aAAa,IAAIC,EAAQW,CAAI,CACpC,CAGA,YAAYE,EAAcC,EAAkBN,EAAyBP,EAAQ,GAAgB,CAC3F,IAAMc,EAAOP,EAAK,OACdQ,EAAW,GACXC,EAAe,CAAC,EAChBC,EAAU,EAEd,GAAI,CAACL,EAAK,MAAM,OAAO5B,EAAe,CAAC,GAAM,CAAC6B,GAAWD,IAAS,GAChE,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMM,EAAeN,EAAK,MAAM,OAAO9B,GAAe,GAAG,CAAC,EACpD0B,EAAa,IAAIrB,GAAWa,CAAK,EAEvC,OAAAkB,GAAc,QAAQ,CAACnB,EAAgBoB,IAAc,CACnD,GAAIpB,IAAW,MAAO,CACpB,GAAIgB,EACF,MAAM,IAAI,MAAM,6CAA6C,EAE/DA,EAAW,GACX,IAAMK,EAAoBN,EAAOI,EAAa,OAAS,EACvD,GAAIE,EAAoB,EACtB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GADAJ,EAAeT,EAAK,MAAMU,EAASA,EAAUG,CAAiB,EAC1D,KAAK,aACP,GAAI,KAAK,aAAa,SAAWJ,EAAa,QAC1C,KAAK,aAAa,SAAS,IAAMA,EAAa,SAAS,EACzD,MAAM,IAAI,MAAM,8BAA8B,UAEvCH,EACT,KAAK,YAAc,GACnB,KAAK,aAAeG,MAEpB,OAAM,IAAI,MAAM,uCAAuC,EAGzD,QAASK,EAAI,EAAGA,EAAIL,EAAa,OAAQK,IAAK,CAC5C,IAAMtB,EAAS,OAAO,aAAa,IAAI,WAAW,CAAC,EAAIsB,CAAC,EACxDb,EAAW,UAAUT,EAAQoB,EAAIE,CAAC,EAClC,KAAK,UAAUtB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAC/C,CACF,MACEQ,EAAW,UAAUT,EAAQoB,GAAK,KAAK,YAAc,KAAK,aAAa,OAAS,EAAI,EAAE,EACtF,KAAK,UAAUpB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAEjD,CAAC,EACMQ,CACT,CAQF,EAEMnB,GAAaiC,GAAyBA,EAAO,OAE7ChC,GACF,CAACiC,EAA+CC,EAAuCC,EACtFC,EAAgCC,IAAgD,CAE/E,IAAMC,EADeJ,EAAY,IAAI,CAACjB,EAAMP,IAAUuB,EAA0BvB,CAAK,EAAIO,EAAK,OAASA,CAAI,EAC5E,IAAI,CAACsB,EAAa7B,IAAU8B,GAAc,QAAQ9B,CAAK,GAAIyB,EAAUI,CAAW,CAAC,EAC1GE,EAAaC,EAAU,KAAKL,CAAW,EACvCM,EAA6BC,GAAqBP,EAAY,MAAM,EACpEQ,EAAoBF,EAA6BN,EAAY,OAASA,EACtES,EAASC,GAAe,SAAUZ,EAAUU,CAAiB,EAC7DG,EACF,CAAC,GAAGZ,EAAe,aAAa,KAAK,CAAC,EAAE,OAAQ3B,GAAW,CAAC2B,EAAe,IAAI,gBAAgB,IAAI3B,CAAM,CAAC,EACxGwC,EAAmBC,GAA+B,CACtD,IAAMC,EAAoB,CAAC,EACrBC,EAAW,kBACXC,EAAU,iBACVC,EAAY,eACZC,EAAgC,CAAC,EACjCC,EAAiC,CAAC,EAClCC,EAAiC,CAAC,EAClCC,EAA4B,CAAC,EAC7BC,EAAyBvB,EAAe,aAAa,OAASA,EAAe,IAAI,gBAAgB,KACvGA,EAAe,aAAa,QAAQ,CAAChB,EAAMX,KAAW,CACpD,GAAI2B,EAAe,IAAI,gBAAgB,IAAI3B,EAAM,EAAG,CAClD,IAAMmD,GAAcxB,EAAe,IAAI,gBAAgB,IAAI3B,EAAM,IAAI,CAAC,EAClEmD,KAAgB,QAClBxB,EAAe,IAAI,QAAQ,CAACd,EAAMO,KAAM,CACtC,GAAIT,EAAK,aAAa,SAASS,EAAC,EAAG,CACjC,IAAMgC,GAAUvC,EAAK,gBAAgB,IAAIb,EAAM,EAC/C,GAAIoD,KAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,GAAQ,QAASnD,IAAU,CACzByC,EAAQ,KAAK,GACTb,EAAUT,EAAC,EAAE,WACT,QAAQA,EAAC,UAAWnB,GAAOoC,EAAO,WAAW,gBAAiBc,EAAW,CAAC,CAAC,EAAE,CACvF,CAAC,CACH,CACF,CAAC,CAEL,MACExB,EAAe,IAAI,QAAQ,CAACd,GAAMO,IAAM,CACtC,GAAIT,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMgC,GAAUvC,GAAK,gBAAgB,IAAIb,EAAM,EAC/C,GAAIoD,KAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,GAAQ,QAASnD,IAAU,CACzB6C,EAAoB,KAAK,GAAGjB,EAAUT,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,GAAO,GAAGD,EAAM,EAAE,CAAC,EAAE,CAC/F,CAAC,EACDiD,EAAgB,KAAK,WAAWpB,EAAUT,CAAC,EAAE,aAAa,QAAQA,CAAC,SAAS,CAAC,GAAG,CAClF,CACF,CAAC,EACD2B,EAAqB,KACjB,WAAW/C,EAAM,cAAcA,EAAM,eAAeV,GAAUU,EAAM,CAAC,KAAKA,EAAM,OAAO,EAC3FgD,EAAqB,KAAK,GAAG,CAEjC,CAAC,EACD,IAAMK,EAAYH,EACd,CACE,GAAGR,EACH,aAAab,EAAU,IAAI,CAACyB,EAAUlC,KAAMkC,EAAS,aAAa,QAAQlC,EAAC,SAAS,CAAC,EAAE,KAAK,KAAK,CAAC,GACpG,EACA,CACE,GAAGsB,EACHE,EACA,GAAGG,EACH,GAAGD,EACHH,EACA,GAAGM,EACHJ,EACA,GAAGG,CACL,EACJ,MAAO;AAAA,cAEHP,EACK,iBAAiBF,EAAgB,IAAKvC,IAAY,CAAC,KAAM,GAAGV,GAAUU,CAAM,CAAC,GAAI,KAAM,KAAK,EAAE,CAAC,EAC/F,gBAAgB,aAAc,KAAK,EACnC,iBAAiB,GAAG6B,EAAWQ,CAAM,CAAC;AAAA;AAAA,cAEzCI,EAAa,UAAU,CAAC;AAAA,cACxBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,kCACrDJ,EAAO,gBAAgB,YAAY,CAAC;AAAA,cACxDR,EAAU,IAAI,CAAC0B,EAAMnC,KAAM,YAAYA,EAAC,YAAYS,EAAUT,EAAC,EAAE,KAAK,OAAO,GAAG,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,cAC5FiC,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,cACpBhB,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,YAE/C,EACA,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAMV,EAAe,SACrB,kBAAmBH,EAA0B,IAAKgC,GAAuBA,EAAqB,OAAS,MAAM,CAC/G,EACA,WAAY,IAAM,CAGhB,IAAMC,EACFlB,EAAgB,OAAQvC,GAAW2B,EAAe,aAAa,IAAI3B,CAAM,CAAC,EACrE,IAAKA,IAAY,CAAC,KAAM,SAAU,KAAM2B,EAAe,aAAa,IAAI3B,CAAM,GAAG,UAAY,CAAC,EAAE,EACzGyD,EAAoB,KAAK,CAAC,KAAM,SAAU,KAAMzB,CAAU,CAAC,EAC3D,IAAM0B,EACFjC,EAAY,OAAO,CAACkC,EAAG1D,IAAUuB,EAA0BvB,CAAK,CAAC,EAC5D,IAAI,CAACO,EAAMmD,IAAM,CAAC,GAAGC,GAA2BpD,CAAI,CAAC,CAAC,EACtD,OAAO,CAACqD,EAAKC,IAAyBD,EAAI,OAAOC,CAAoB,EAAGL,CAAmB,EACpG,OAAIvB,GACFwB,EAAgB,KAAK,GAAGE,GAA2BhC,CAAW,CAAC,EAEzD,CACN,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAAF,CAAQ,CAAC,EACvC,cAAe,CAAC,EAAG,KAAK,KAAKM,EAAa,EAAuB,CAAC,EAClE,gBAAA0B,CACF,CACF,EACA,gBAAAlB,CACF,CACF,EAEShD,GAAS,CAACuE,EAAyBC,IAAuC,CACrF,IAAMrC,EAAiB,IAAItC,GAAe0E,EAAQ,OAAQC,EAAW,QAAQ,EACvExC,EAA4BuC,EAAQ,OAAO,IAAI,CAACE,EAAON,IAAMxB,GAAqB8B,EAAM,KAAK,MAAM,CAAC,EACpGrC,EAAcD,EAAe,WAC7BF,EAAcsC,EAAQ,OAAO,IAAI,CAACE,EAAON,IAAMM,EAAM,IAAI,EAC/DF,EAAQ,QAAQxE,GACZiC,EAA2BC,EAAasC,EAAQ,OAAO,CAAC,EAAE,SAAUpC,EAAgBC,CAAW,CAAC,CACtG,EAEanC,GAAyBuE,GAA0D,CAC9F,IAAM5D,EAAY4D,EAAW,SAAoB,QAAQ,OAAQ,EAAE,EACnE,OAAOE,GAA4B,CAAC,SAAA9D,CAAQ,CAAC,CAC/C,ICvTA,IAUM+D,GAiBAC,GAYAC,GAIAC,GAoEOC,GA/GbC,GAAAC,GAAA,kBAGAC,KAEAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,0BAA0B,EAE5C,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EAEzDG,EAAaD,EAAM,OAASD,EAAW,OAAS,EAAIC,EAAM,OAASD,EAAW,OAC9EG,EAAkBH,EAAW,OAASC,EAAM,OAAS,EAAID,EAAW,OAASC,EAAM,OACvF,KAAOC,EAAaD,EAAM,QAAUE,EAAkBH,EAAW,OAAQ,EAAEE,EAAY,EAAEC,EACvF,GAAIF,EAAMC,CAAU,IAAMF,EAAWG,CAAe,GAAKF,EAAMC,CAAU,IAAM,GAC3EF,EAAWG,CAAe,IAAM,EAClC,MAAM,IAAI,MAAM,oDAAoD,CAG1E,EAEMb,GAAmB,CAACc,EAA2BC,IAAwC,CAC3F,IAAMC,EAAOF,EAAO,OAASC,EAAO,OAC9BJ,EAAkB,CAAC,EACzB,QAASM,EAAI,EAAGA,EAAID,EAAM,EAAEC,EAC1BN,EAAM,KAAKG,EAAOG,CAAC,CAAC,EAEtB,QAASA,EAAI,EAAGA,EAAIF,EAAO,OAAQ,EAAEE,EACnCN,EAAM,KAAKI,EAAOE,CAAC,IAAM,EAAIH,EAAOG,EAAID,CAAI,EAAID,EAAOE,CAAC,CAAC,EAE3D,OAAON,CACT,EAEMV,GAAuB,CAACS,EAA+BC,IACxDD,EAAW,OAASC,EAAM,OAAUX,GAAiBU,EAAYC,CAAK,EAAIX,GAAiBW,EAAOD,CAAU,EAG3GR,GAA2BO,GAA+C,CAC9E,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EACvDS,EAAwBjB,GAAqBS,EAAYC,CAAK,EAC9DQ,EAAWV,EAAO,CAAC,EAAE,SACrBW,EAAaD,IAAa,EAAgB,EAAI,EAC9CE,EAAaC,EAAU,KAAKJ,CAAW,EAAIE,EAE3CG,EAA0BC,GAAqBd,EAAW,MAAM,EAChEe,EAA2BD,GAAqBN,EAAY,MAAM,EAGlEQ,EAAmBC,GAA+B,CACtD,IAAMC,EAAmBL,EAA0Bb,EAAW,OAASA,EACjEmB,EAAoBJ,EAA2BP,EAAY,OAASA,EACpEY,EAAQC,GAAc,QAASZ,EAAUS,EAAkBR,CAAU,EACrEY,EAASC,GAAe,SAAUd,EAAUU,EAAmBT,CAAU,EAC3Ec,EACJ,GAAIf,IAAa,EAAe,CAC9B,IAAMgB,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO;AAAA,6BAChDD,CAAC,MAAML,EAAO,gBAAgB,kBAAkBK,CAAC,GAAG,CAAC;AAAA,sBAC5DA,CAAC,MAAMP,EAAM,2BAA2B,gBAAgBO,CAAC,GAAIL,CAAM,CAAC;AAAA,qBACrEK,CAAC,YAAYA,CAAC;AAAA,yBACVA,CAAC,YAAYA,CAAC;AAAA,YAC3BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIR,EAAM,YAAY,QAAQO,CAAC,EAAE,CAAC,aAAaA,CAAC;AAAA,UAEhFH,EAAa;AAAA,0CACuBd,CAAU;AAAA;AAAA,UAE1Ce,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCH,EAAO,YAAY,aAAc,MAAM,CAAC;AAAA,QAE9C,MACEE,EAAa;AAAA,8BACWF,EAAO,gBAAgB,YAAY,CAAC;AAAA,4BACtCF,EAAM,2BAA2B,gBAAiBE,CAAM,CAAC;AAAA,UAC3EA,EAAO,YAAY,aAAcF,EAAM,YAAY,aAAa,CAAC,CAAC;AAAA,SAGxE,MAAO;AAAA,MACLH,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBG,EAAOE,CAAM,CAAC;AAAA,MAC/EL,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,MACvEO,CAAU,EACd,EAEMK,EAAoC,CAAC,CAAC,KAAM,SAAU,KAAMlB,CAAU,CAAC,EAC7E,OAAIE,GACFgB,EAAgB,KAAK,GAAGC,GAA2B9B,CAAU,CAAC,EAE5De,GACFc,EAAgB,KAAK,GAAGC,GAA2BtB,CAAW,CAAC,EAE1D,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGA,EAAY,MAAM,GAAI,kBAAmB,CAACK,EAA0B,OAAS,MAAM,CAAC,EAC3G,gBAAAG,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMR,EAAa,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKY,EAAa,EAAuB,CAAC,EAClE,gBAAAkB,CACF,EACF,CACF,EAEapC,GAAUsC,GAAkC,CACvD1C,GAAe0C,EAAQ,MAAM,EAC7BA,EAAQ,QAAQvC,GAAwBuC,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxE,IClHA,IAeMC,GAMAC,GAwHOC,GAGAC,GAhJbC,GAAAC,GAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,CAE/C,EAEMT,GAA0B,CAACS,EAA+BC,IAA8C,CAC5G,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAeH,EAAO,CAAC,EAAE,KAEzBI,EAAYF,EAAW,OACvBG,EAAOC,EAAU,cAAcL,EAAW,KAAMG,CAAS,EAEzDG,EAAcL,EAAW,MAAM,CAAC,EACtCK,EAAY,OAAOF,EAAM,EAAG,GAAGF,CAAY,EAE3C,IAAMK,EAAeN,EAAWG,CAAI,EAC9BI,EAAaT,EAAO,CAAC,EAAE,WAAa,EAAgB,EAAI,EACxDU,EAAaJ,EAAU,KAAKC,CAAW,EAAIE,EAE3CE,EAA4BC,GAAqBZ,EAAO,CAAC,EAAE,KAAK,MAAM,EACtEa,EAAmBF,EAA4BX,EAAO,CAAC,EAAE,KAAK,OAASA,EAAO,CAAC,EAAE,KACjFc,EAA8BF,GAAqBZ,EAAO,CAAC,EAAE,KAAK,MAAM,EACxEe,EAAqBD,EAA8Bd,EAAO,CAAC,EAAE,KAAK,OAASA,EAAO,CAAC,EAAE,KACrFgB,EAA6BJ,GAAqBL,EAAY,MAAM,EACpEU,EAAoBD,EAA6BT,EAAY,OAASA,EAEtEW,EACF,CAAC,CAAC,KAAM,SAAU,KAAMR,CAAU,EAAG,CAAC,KAAM,QAAS,KAAMF,CAAY,EAAG,CAAC,KAAM,SAAU,KAAMH,CAAI,CAAC,EACtGM,GACFO,EAAgB,KAAK,GAAGC,GAA2BnB,EAAO,CAAC,EAAE,IAAI,CAAC,EAEhEc,GACFI,EAAgB,KAAK,GAAGC,GAA2BnB,EAAO,CAAC,EAAE,IAAI,CAAC,EAEhEgB,GACFE,EAAgB,KAAK,GAAGC,GAA2BZ,CAAW,CAAC,EAGjE,IAAMa,EAAwD,CAAC,EAC/DA,EAAkB,KAAKT,EAA4B,OAAS,MAAM,EAClES,EAAkB,KAAKN,EAA8B,OAAS,MAAM,EAEpE,IAAMO,EAAmBC,GAA+B,CACtD,IAAMC,EAAOC,GAAc,OAAQxB,EAAO,CAAC,EAAE,SAAUa,EAAkBJ,CAAU,EAC7EgB,EAAUD,GAAc,eAAgBxB,EAAO,CAAC,EAAE,SAAUe,CAAkB,EAC9EW,EAASC,GAAe,SAAU3B,EAAO,CAAC,EAAE,SAAUiB,EAAmBR,CAAU,EAEnFmB,EAAmBC,IAA6B,CACpD,IAAMC,GAAc3B,EAAa,OAC7B4B,EAAU,qBAAqBF,EAAC,OAAOJ,EAAQ,KAAK,OAAO,OAC/D,QAASO,GAAI,EAAGA,GAAIF,GAAaE,KAC/BD,GAAW,GAAGD,GAAc,EAAI,iBAAiBD,EAAC,IAAIG,EAAC,IAAM,iBAAiBH,EAAC,EAAE,MAC7EtB,EAAY,OAAS,EAAI,gBAAgBsB,EAAC,oBAAoBG,EAAC,IAAM,gBAAgBH,EAAC,EAAE,IAE9FE,GAAW;AAAA,mBACEF,EAAC,MAAMJ,EAAQ,aAAa,iBAAiBI,EAAC,EAAE,CAAC;AAAA,mBACjDA,EAAC;AAAA,iBACHA,EAAC,SAASA,EAAC;AAAA;AAAA,2BAEDA,EAAC,MAAMN,EAAK,KAAK,OAAO;AAAA,UAE7C,QAASS,GAAI,EAAGC,GAAI,EAAGD,GAAI5B,EAAW4B,KAChCA,KAAM3B,GACR0B,GAAW,GAAG3B,EAAY,EAAI,cAAcyB,EAAC,IAAIG,EAAC,IAAM,cAAcH,EAAC,EAAE,aAAaA,EAAC,KACvFI,IAAKH,KAELC,GAAW,GAAG3B,EAAY,EAAI,cAAcyB,EAAC,IAAIG,EAAC,IAAM,cAAcH,EAAC,EAAE,MACrEtB,EAAY,OAAS,EAAI,gBAAgBsB,EAAC,IAAII,EAAC,IAAM,gBAAgBJ,EAAC,EAAE,IAC5EI,MAGJ,OAAOF,CACT,EACIG,EACJ,GAAIlC,EAAO,CAAC,EAAE,WAAa,EAAe,CACxC,IAAMmC,GAAmB,CAACC,GAAgBP,EAAWQ,GAAW,KAAO;AAAA,6BAChDR,CAAC,MAAMH,EAAO,gBAAgB,kBAAkBG,CAAC,GAAG,CAAC;AAAA,YACtED,EAAgBC,CAAC,CAAC;AAAA,sBACRA,CAAC,MAAMN,EAAK,gBAAgB,cAAcM,CAAC,EAAE,CAAC;AAAA,qBAC/CA,CAAC,YAAYA,CAAC;AAAA,yBACVA,CAAC,YAAYA,CAAC;AAAA,YAC3BO,EAAM,IAAIP,CAAC,OAAOQ,EAAQ,IAAId,EAAK,YAAY,QAAQM,CAAC,EAAE,CAAC,aAAaA,CAAC;AAAA,UAE/EK,EAAa;AAAA,0CACuBzB,CAAU;AAAA;AAAA,UAE1C0B,GAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,GAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,GAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,GAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCT,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,OAE/C,MACEQ,EAAa;AAAA,4BACSR,EAAO,gBAAgB,YAAY,CAAC;AAAA,QACxDE,EAAgB,EAAE,CAAC;AAAA,oBACPL,EAAK,aAAa,aAAa,CAAC;AAAA,QAC5CG,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,QAG7C,MAAO;AAAA,QAEHJ,EAAa,gBAAgB,aAAc,KAAK,EAC3C,gBAAgB,eAAgB,KAAK,EACrC,gBAAgB,OAAQ,KAAK,EAC7B,iBAAiBC,EAAME,EAASC,CAAM,CAAC;AAAA,QAC5CJ,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,UACzEY,CAAU;AAAA,QAElB,EACA,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMjC,EAAW,SAAU,kBAAAmB,CAAiB,EAC1D,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMb,EAAa,SAAUP,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAG,KAAK,KAAKU,EAAa,EAAuB,CAAC,EAClE,gBAAAQ,CACF,GACA,gBAAAG,CACF,CACF,EAEa7B,GAAyBS,GAClCqC,GAA4B,CAAC,KAAMrC,EAAW,IAAc,CAAC,EAEpDR,GAAS,CAAC8C,EAAyBtC,IAAuC,CACrF,IAAMD,EAASuC,EAAQ,OACvBjD,GAAeU,CAAM,EACrBuC,EAAQ,QAAQhD,GAAwBgD,EAAQ,OAAQtC,CAAU,CAAC,CACrE,ICpJA,IAcMuC,GAeAC,GAqEOC,GAGAC,GArGbC,GAAAC,GAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,EAC1B,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM;AAAA,4DACwC,CAE5D,EAEMR,GACF,CAACQ,EAA+BC,IAAsD,CACpF,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAsBH,EAAO,CAAC,EAAE,SAChCI,EAAYF,EAAW,OACvBG,EAAeC,EAAU,eAAeJ,CAAU,EAClDK,EAAYD,EAAU,KAAKJ,CAAU,EAErCM,EAAeR,EAAO,CAAC,EAAE,KACzBS,EAAkBT,EAAO,CAAC,EAAE,SAC5BU,EAAcJ,EAAU,KAAKE,CAAY,EAEzCG,EAAOL,EAAU,cAAcL,EAAW,KAAMG,CAAS,EACzDQ,EAAeV,EAAWS,CAAI,EAE9BE,EAAcL,EAAa,MAAM,CAAC,EAClCM,EAAaR,EAAU,KAAKO,CAAW,EAEvCE,EAAQC,GAAc,QAASb,EAAqBD,CAAU,EAC9De,EAAUD,GAAc,UAAWP,EAAiB,CAACC,CAAW,CAAC,EACjEQ,EAASC,GAAe,SAAUhB,EAAqBU,CAAW,EAMlEO,EAAmBC,GAA+B;AAAA,wCACtBhB,EAAa,MAAM,KAAKA,EAAa,IAAIiB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,QAChGD,EAAa,iBAAiBN,EAAOE,EAASC,CAAM,CAAC;AAAA,QACrDG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCP,CAAU,CAAC;AAAA;AAAA,4BAE1CI,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,kBAE9CD,EAAQ,YAAY,YAAY,CAAC;AAAA;AAAA,sBAE7BL,CAAY;AAAA;AAAA;AAAA;AAAA;AAAA,4BAKNV,EAAW,MAAM;AAAA,mBAC1BS,CAAI;AAAA;AAAA;AAAA,yBAGEO,EAAO,WAAW,gBAAiB,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAMtBX,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,KAO7C,MAAO,CACL,KAAM,iBACN,YAAa,CAAC,KAAMN,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMY,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAM,CACF,CACF,EAES3B,GAAiCQ,GAC1CsB,GAA4B,CAAC,KAAMtB,EAAW,IAAc,CAAC,EAEpDP,GAAiB,CAAC8B,EAAyBvB,IAA+C,CACrG,IAAMD,EAASwB,EAAQ,OACvBjC,GAAeS,CAAM,EACrBwB,EAAQ,QAAQhC,GAAgCgC,EAAQ,OAAQvB,CAAU,CAAC,CAC7E,ICzGA,IAUMwB,GA0BAC,GAmBAC,GAoEOC,GAKAC,GAhIbC,GAAAC,GAAA,kBAIAC,KACAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,EACjD,MAAM,IAAI,MAAM,0BAA0B,EAG5C,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,UACjCA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SAC3D,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EASMT,GAAU,CAACU,EAAWC,EAAWC,IAAoC,CACzE,GAAIA,EAAK,SAAW,EAClB,MAAO,KAGT,IAAMC,EAAcD,EAAK,SAAW,GAAKF,IAAM,GAAOE,EAAK,SAAW,GAAKA,EAAK,CAAC,IAAMF,EACjFI,EAAaF,EAAKA,EAAK,OAAS,CAAC,IAAMD,EAEzCI,EAAS,KACb,OAAKF,IACHE,GAAU,SAASH,EAAKA,EAAK,OAAS,CAAC,CAAC,KAErCE,IACHC,GAAU,MAGLA,CACT,EAEMd,GAAwB,CAACQ,EAA+BO,IAA4C,CACxG,IAAMC,EAASR,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9BS,EAAST,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9B,CAACU,EAAGC,EAAGC,CAAC,EAAIC,GAAS,qBACvBL,EAAQD,EAAW,OAAQE,EAAQF,EAAW,OAAQP,EAAO,SAAW,EAAIA,EAAO,CAAC,EAAE,KAAO,MAAS,EACpGc,EAAc,CAACJ,EAAGC,CAAC,EACzB,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,qCAAsC,EAExD,IAAMC,EAAaC,EAAU,KAAKF,CAAW,EACzCG,EAAO,GACPV,EAAW,QAAUA,EAAW,OAClCU,EAAO,wCACEV,EAAW,QAAU,CAACA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAUA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAU,CAACA,EAAW,SAC3CU,EAAO,yCAGT,IAAMC,EAAWC,GAA4BnB,EAAO,CAAC,EAAE,QAAQ,EACzDoB,EAAiBb,EAAW,QAAU,EAAI,GAAK,kBAC/Cc,EAAarB,EAAO,SAAW,EAAI,qBAAqBT,GAAQmB,EAAGC,EAAGX,EAAO,CAAC,EAAE,IAAI,CAAC,KAAO,GAC5FsB,EAAkC,CACtC,sDAAsDJ,CAAQ,KAC9D,sDAAsDA,CAAQ,IAChE,EACIlB,EAAO,SAAW,GACpBsB,EAAgC,KAAK,sDAAsDJ,CAAQ,IAAI,EAEzG,IAAMK,EAAmBC,GAA+B;AAAA,mBACvCd,CAAC;AAAA,mBACDC,CAAC;AAAA,mBACDC,CAAC;AAAA,kBACFM,CAAQ,IAAIX,EAAW,KAAK;AAAA,iBAC7BW,CAAQ,IAAIX,EAAW,IAAI;AAAA;AAAA,IAExCe,EAAgC,KAAK;AAAA,CAAI,CAAC;AAAA,uBACvBtB,EAAO,MAAM,6CAA6CkB,CAAQ;AAAA;AAAA,IAErFM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kBAKlDG,CAAQ;AAAA,8BACIN,CAAC;AAAA,QACvBK,CAAI;AAAA;AAAA;AAAA,MAGNG,CAAc;AAAA,MACdC,CAAU;AAAA;AAAA;AAAA,KAId,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAMd,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMO,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKe,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAQ,CACF,CACF,EAEa9B,GAAO,CAACgC,EAAyBlB,IAAqC,CACjFjB,GAAemC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAsBiC,EAAQ,OAAQlB,CAAU,CAAC,CACnE,EAEab,GAAuBa,GAChCmB,GAA4BnB,CAA+D,ICjI/F,IAgBMoB,GAIAC,GA8FAC,GA2GAC,GAgDOC,GAGAC,GAhRbC,GAAAC,GAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMX,GAAW,CACf,KAAM,uBACR,EAEMC,GACF,CAACW,EAA+BC,IAAoD,CAClF,IAAMC,EAASF,EAAO,CAAC,EAAE,KAEnBG,EAAcD,EACdE,EAAO,EACPC,EAAYC,EAAU,gBAAgBJ,EAAQE,CAAI,EAClDG,EAAWD,EAAU,kBAAkBJ,EAAQE,CAAI,EACnDI,EAAIN,EAAO,CAAC,EACZO,EAAIC,GAAc,IAAKV,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EAC3EI,EAAQD,GAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACjEY,EAAOF,GAAc,OAAQV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/Da,EAASC,GAAe,SAAUd,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EACtFQ,EAAY,CAACN,EAAGE,EAAOC,EAAMC,CAAM,EACnCG,EAAWP,EAAE,KAAK,MAClBQ,EAAgB,GAChBC,EAAmBC,GAA+B;AAAA;AAAA,mBAE3CX,CAAC;AAAA,0BACMD,CAAQ;AAAA,yBACTN,EAAW,OAAO;AAAA,gCACXe,CAAQ;AAAA,uCACDA,CAAQ;AAAA,2CACJA,CAAQ,KAAKC,CAAa;AAAA,0BAC3CA,CAAa;AAAA,IACnCE,EAAa,iBAAiB,GAAGJ,CAAS,CAAC;AAAA,IAC3CI,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAOtBD,CAAQ;AAAA;AAAA,4BAECP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAahBO,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOzBP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mDAkBJO,CAAQ;AAAA,qCACtBL,EAAM,YAAY,SAAS,CAAC;AAAA,yBACxCC,EAAK,YAAY,SAAS,CAAC;AAAA;AAAA,oBAEhCH,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA,QAC1CI,EAAO,IAAI,QAAS,UAAW,IAAK,OAAO,CAAC;AAAA;AAAA,KAG9C,MAAO,CACL,GAAGzB,GACH,YAAa,CAAC,KAAMa,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAGK,CAAS,CAC9B,GACA,gBAAAa,CACF,CACF,EAEE5B,GACF,CAAC8B,EAAyBC,EAAmBV,EAAmBC,EAAkBU,EAAWC,EAAWC,EACvGC,IAAoB,CACnB,IAAMC,EAAaC,GAAiBH,CAAC,EAC/BI,EAAclB,GAAc,QAASW,EAAM,SAAUA,EAAM,KAAMK,CAAU,EAC3EG,EAAcnB,GAAc,QAASC,EAAM,SAAUA,EAAM,KAAMe,CAAU,EAC3EI,EAAapB,GAAc,OAAQE,EAAK,SAAUA,EAAK,KAAMc,CAAU,EAEvEK,EAAK,GAGLC,EAAaN,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC5DO,EAAcP,IAAe,EAAI,MAAQ,MAAMA,CAAU,IACzDQ,EAAiB,CAACC,EAAcC,IAAiB,GAAGJ,CAAU,IAAIG,CAAI,KAAKC,CAAI,IAC/EC,EAAcf,EAAIE,EAAIE,EACtBY,EAAS,KAAK,KAAKf,EAAIQ,CAAE,EAEzBQ,EAAuBpB,GAA+B;AAAA,mBAC/CI,CAAC;AAAA,mBACDC,EAAIE,CAAU;AAAA,2BACNH,EAAIC,EAAIE,CAAU;AAAA;AAAA,IAEzCP,EAAa,iBAAiBS,CAAW,CAAC;AAAA,kEACoBI,CAAU;AAAA;AAAA,IAExEb,EAAa,UAAUY,CAAE,CAAC;AAAA,4CACcA,CAAE;AAAA,+CACCA,CAAE;AAAA,8BACnBA,CAAE;AAAA,4BACJO,CAAM;AAAA;AAAA;AAAA;AAAA,iCAIDA,CAAM;AAAA;AAAA;AAAA,gBAGvBE,GAAW,MAAOd,CAAU,CAAC;AAAA,uBACtBc,GAAW,MAAOd,CAAU,CAAC;AAAA;AAAA,sBAE9BO,CAAW;AAAA;AAAA;AAAA;AAAA,2BAINC,EAAe,MAAO,YAAY,CAAC;AAAA,KAGlDO,EAAarB,EAAQ,QACvB,CACE,KAAM,0BACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,WAAAM,EAAY,EAAAJ,EAAG,EAAAC,EAAG,EAAAC,CAAC,CAAC,CAAC,EACzD,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAACF,EAAGE,EAAGO,EAAI,CAAC,EAAG,UAAwB,CAChD,EACA,cAAe,CAAC,EAAGT,EAAIE,EAAIE,CAAU,CACvC,GACA,gBAAiBa,CACnB,EACA,CAAC,OAAQ,CAAClB,CAAK,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EACjCH,EAAmBC,GAA+B;AAAA,mBAC3CI,CAAC;AAAA,mBACDC,EAAIE,CAAU;AAAA,2BACNK,EAAKP,EAAIE,CAAU;AAAA,yBACrBD,CAAO;AAAA;AAAA,2DAE2BO,CAAU;AAAA,2DACVH,EAAY,KAAK,OAAO;AAAA,0DACzBC,EAAW,KAAK,OAAO;AAAA,kEACfE,CAAU;AAAA;AAAA,IAExEb,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCkB,CAAW,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gBAKrDG,GAAW,MAAOd,CAAU,CAAC;AAAA,uBACtBc,GAAW,MAAOd,CAAU,CAAC;AAAA,+BACrBK,CAAE;AAAA,gEAC+BA,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qCAO7BE,CAAW;AAAA,yBACvBA,CAAW;AAAA;AAAA,2BAETC,EAAe,eAAgB,cAAc,CAAC;AAAA,KAGnE,OAAOd,EAAQ,QACX,CACE,KAAM,uCACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,WAAAM,EAAY,EAAAJ,EAAG,EAAAC,EAAG,EAAAC,EAAG,QAAAC,CAAO,CAAC,CAAC,EAClE,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAACH,EAAGE,EAAG,CAAC,EAAG,UAAwB,CAC5C,EACA,cAAe,CAAC,EAAG,KAAK,KAAKa,EAAc,EAAuB,CAAC,CACrE,GACA,gBAAAnB,CACF,EACA,CAAC,OAAQ,CAACuB,EAAY9B,EAAOC,CAAI,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAC3D,EAEErB,GACF,CAAC6B,EAAyBpB,EAA+BC,IAAuC,CAC9F,IAAMC,EAASF,EAAO,CAAC,EAAE,KACnBG,EAAcD,EACdwC,EAAIxC,EAAO,CAAC,EACZM,EAAIN,EAAOA,EAAO,OAAS,CAAC,EAC5ByC,EAAIrC,EAAU,kBAAkBJ,EAAQ,CAAC,EAAIM,EAE7CkB,EAAaC,GAAiBnB,CAAC,EAC/BoC,EAAatC,EAAU,KAAKH,CAAW,EAAIuB,EAC3CE,EAAclB,GAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM0B,CAAU,EACnFmB,EAAe/B,GAAe,SAAUd,EAAO,CAAC,EAAE,SAAUG,EAAauB,CAAU,EAEnFV,EAAW8B,GAA4B9C,EAAO,CAAC,EAAE,QAAQ,EACzD+C,EAAYrB,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC3DsB,EAAgBtB,IAAe,EAAIV,EAAW,MAAMU,CAAU,IAAIV,CAAQ,IAE1EiC,EAAoB3D,GAAY8B,EAASpB,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAG0C,EAAGC,EAAGnC,EAAGP,EAAW,OAAO,EAErGiB,EAAmBC,GAA+B;AAAA,mBAC3CwB,CAAC;AAAA,mBACDnC,EAAIkB,CAAU;AAAA;AAAA,2DAE0BE,EAAY,KAAK,OAAO;AAAA,gEACnBmB,CAAS;AAAA,kEACPF,EAAa,KAAK,OAAO;AAAA;AAAA,IAEvF1B,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kDAMsB6B,CAAa,eAAeA,CAAa;AAAA,KAErF5B,EAAQ,QACJ,CACE,KAAM,wBACN,YAAa,CAAC,KAAM,GAAGnB,EAAW,QAAQ,EAAE,EAC5C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAK4C,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAA1B,CACF,EACA,CAAC,OAAQ,CAAClB,EAAO,CAAC,EAAGiD,CAAiB,CAAC,CAAC,CAC9C,EAESzD,GAA+BS,GACxCiD,GAA4B,CAAC,QAASjD,EAAW,QAAS,OAAQA,EAAW,MAAM,CAAC,EAE3ER,GAAe,CAAC2B,EAAyBnB,IAA6C,CAC7FA,EAAW,SAAW,OACxBV,GAAkC6B,EAASA,EAAQ,OAAQnB,CAAU,EAErEmB,EAAQ,QAAQ/B,GAA8B+B,EAAQ,OAAQnB,CAAU,CAAC,CAE7E,ICtRA,IAgBMkD,GAMAC,GAiGOC,GAGAC,GA1HbC,GAAAC,GAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,CAE3D,EAEMT,GACF,CAACS,EAA+BC,EAAiCC,IAAqC,CACpG,IAAMC,EAASH,EAAO,CAAC,EAAE,KACnBI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EAEfM,EAAcH,EACdI,EAAOC,EAAU,cAAcP,EAAW,KAAME,EAAO,MAAM,EAC7DM,EAAYD,EAAU,gBAAgBL,EAAQI,CAAI,EAClDG,EAAWF,EAAU,kBAAkBL,EAAQI,CAAI,EAEnDI,EAAYH,EAAU,KAAKJ,EAAM,IAAI,EACrCQ,EAAWP,EAAOG,EAAU,KAAKH,EAAK,IAAI,EAAI,EACpD,GAAIM,IAAcD,GAAaL,GAAQO,IAAaF,EAClD,MAAM,IAAI,MAAM,+BAA+BA,CAAQ;AAAA;AAAA,2BAEpCC,CAAS,qBAAqBC,CAAQ,EAAE,EAG7D,IAAMC,EAAmB,CAAC,EAC1B,QAASC,EAAI,EAAGA,EAAIX,EAAO,OAAQ,EAAEW,EAC/BA,EAAIP,EACNM,EAAiB,KAAKV,EAAOW,CAAC,CAAC,EAE/BD,EAAiB,KAAK,CAAC,EAI3B,IAAME,EAAaC,GAAiBN,CAAQ,EACtCO,EAAWC,GAA4BlB,EAAO,CAAC,EAAE,QAAQ,EACzDmB,EAAY,CAChBC,GAAc,IAAKpB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAU,EACjEK,GAAc,QAAShB,EAAM,SAAUA,EAAM,KAAMW,CAAU,CAC/D,EACIV,GACFc,EAAU,KAAKC,GAAc,OAAQf,EAAK,SAAUA,EAAK,KAAMU,CAAU,CAAC,EAE5EI,EAAU,KAAKE,GAAe,SAAUrB,EAAO,CAAC,EAAE,SAAUM,EAAaS,CAAU,CAAC,EAEpF,IAAMO,EAAoBpB,EAAc,EAClCqB,EAAkBrB,EAAc,EAElCoB,GACFH,EAAU,KAAKE,GAAe,mBAAkCR,CAAgB,CAAC,EAE/EU,GACFJ,EAAU,KAAKE,GAAe,iBAAgCR,CAAgB,CAAC,EAGjF,IAAMW,EAAmBC,GAA+B;AAAA,0BACpCf,CAAQ;AAAA,oCACEA,EAAWK,CAAU;AAAA,yBAChCd,EAAW,OAAO;AAAA;AAAA,IAEvCwB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA,IAC3CM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,uBAE5CiB,GAAW,MAAOX,CAAU,CAAC;AAAA,6BACvBW,GAAW,MAAOX,CAAU,CAAC;AAAA;AAAA;AAAA,oBAGtCY,GAAUV,EAAUF,EAAY,eAAe,CAAC;AAAA;AAAA;AAAA;AAAA,iBAInDa,GAAU,aAAcb,CAAU,CAAC;AAAA,4BACxBa,GAAU,mBAAoBb,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI9CY,GAAUV,EAAUF,EAAY,eAAe,CAAC;AAAA,uBAChDY,GAAUV,EAAUF,EAAY,UAAU,CAAC;AAAA,6BACrCI,EAAU,CAAC,EAAE,KAAK,KAAK;AAAA,UAC1Cd,EAAO,KAAKsB,GAAUV,EAAUF,EAAY,SAAS,CAAC,GAAK,EAAE;AAAA;AAAA;AAAA;AAAA,MAIjEO,EAAoB,oCAAsC,EAAE;AAAA,MAC5DC,EAAkB,4CAA8C,EAAE;AAAA,KAE5DM,EAAU,CAAC,CAAC,KAAMvB,EAAa,SAAUN,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIsB,GACFO,EAAQ,KAAK,CAAC,KAAMhB,EAAkB,UAAwB,CAAC,EAE7DU,GACFM,EAAQ,KAAK,CAAC,KAAMhB,EAAkB,UAAwB,CAAC,EAG1D,CACL,KAAM,qBACN,YAAa,CAAC,KAAM,GAAGZ,EAAW,QAAQ,IAAIC,CAAW,IAAIF,EAAO,MAAM,EAAE,EAC5E,WAAY,KAAO,CAAC,QAAA6B,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKpB,EAAY,EAAuB,CAAC,CAAC,GAC/F,gBAAAe,CACF,CACF,EAEShC,GAA4BS,GACrC6B,GAA4B,CAAC,KAAM7B,EAAW,KAAM,QAASA,EAAW,OAAO,CAAC,EAEvER,GAAY,CAACsC,EAAyB9B,IAA0C,CAC3FX,GAAeyC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQxC,GAA2BwC,EAAQ,OAAQ9B,EAAY8B,EAAQ,WAAW,CAAC,CAC7F,IC7HA,IASMC,GAUOC,GAnBbC,GAAAC,GAAA,kBAIAC,KAGAC,KAEML,GAAkBM,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACxF,MAAM,IAAI,MAAM,kCAAkC,CAEtD,EAEaL,GAAUM,GAAkC,CACvDP,GAAeO,EAAQ,MAAM,EAC7B,IAAMC,EAAcC,GAAc,UAAUF,EAAQ,OAAO,CAAC,EAAE,KAAMA,EAAQ,OAAO,CAAC,EAAE,KAAM,EAAI,EAChG,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,uCAAwC,EAE1DD,EAAQ,QAAQG,GAAwBH,EAAQ,OAAQ,CAAC,WAAY,GAAI,mBAAoB,EAAE,EAAGC,CAAW,CAAC,CAChH,IC1BA,IAYMG,GA2NOC,GAGPC,GAEAC,GAmCAC,GA2BOC,GA1SbC,GAAAC,GAAA,kBAIAC,KACAC,KACAC,KAEAC,KACAC,KACAC,KAEMb,GAAiB,CAACc,EAA+BC,IAAoD,CACzG,IAAMC,EAAQF,EAAO,CAAC,EAChBG,EAAMH,EAAO,CAAC,EACdI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EACfM,EAAiBN,EAAO,CAAC,EACzBO,EAAuBP,EAAO,CAAC,EAC/BQ,EAAUR,EAAO,CAAC,EAClBS,EAAYT,EAAO,CAAC,EAoC1B,GAAIE,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMQ,EAAe,GACfC,EAAYT,EAAM,KAAK,CAAC,EACxBU,EAAiBV,EAAM,KAAK,CAAC,EAC7BW,EAAaX,EAAM,KAAK,SAAW,EAAKQ,EAAeR,EAAM,KAAK,CAAC,EAAI,EAAIA,EAAM,KAAK,CAAC,EAChDD,EAAW,SAAWC,EAAM,KAAK,CAAC,EAC3EY,EAAmBF,EAEnBG,EAAqB,EACrBC,EAAoB,EAClBC,EAAW,KAAK,MAAMJ,EAAaZ,EAAW,QAAQ,EAC5D,GAAIO,GAAWC,EAAW,CACxB,GAAID,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,mDAAmD,EAErE,GAAIC,EAAU,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,qDAAqD,EAEvEM,EAAqBP,EAAQ,KAAK,CAAC,EACnCQ,EAAoBR,EAAQ,KAAK,CAAC,CACpC,SAAWA,GAAWC,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,IAAIS,EACJ,GAAIf,EAAK,CACP,GAAID,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kEAAkE,EAEpF,GAAIC,EAAI,KAAK,OAAS,GAAKA,EAAI,KAAK,OAAS,EAC3C,MAAM,IAAI,MAAM,uDAAuD,EAEzE,GAAID,EAAM,KAAK,CAAC,IAAMC,EAAI,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,4DAA4D,EAG9E,GAAIA,EAAI,KAAK,SAAW,EAAG,CACzB,GAAIA,EAAI,KAAK,CAAC,IAAMD,EAAM,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,6DAA6D,EAE/EgB,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,SAAWA,EAAI,KAAK,SAAW,EAAG,CAChC,GAAIA,EAAI,KAAK,CAAC,IAAMF,EAAW,UAAYE,EAAI,KAAK,CAAC,IAAM,GAAKA,EAAI,KAAK,CAAC,IAAMc,EAC9E,MAAM,IAAI,MAAM,4FAA4F,EAE9G,GAAIb,EACF,MAAM,IAAI,MAAM,yDAAyD,EAE3Ec,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,KAAO,CACL,GAAIA,EAAI,KAAK,CAAC,IAAMF,EAAW,UAAYE,EAAI,KAAK,CAAC,IAAMc,EACzD,MAAM,IAAI,MAAM,wFAAwF,EAG1GC,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,CACF,KAAO,CACL,GAAID,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,uEAAuE,EAEzF,GAAIA,EAAM,KAAK,SAAW,IAAMA,EAAM,KAAK,CAAC,IAAMD,EAAW,UAAYC,EAAM,KAAK,CAAC,IAAM,GACzF,MAAM,IAAI,MAAM,8FAA8F,EAGhHgB,EAAY,CACd,CAEA,GAAIb,EAAM,CACR,GAAIA,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,8CAA8C,EAGhE,GAAID,GACEF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,CAAC,IAAM,EAC/C,MAAM,IAAI,MAAM,oCAAoC,CAG1D,CAEA,IAAIiB,IACJ,GAAIb,EAAgB,CAClBa,EAAW,EACX,IAAMC,EAAWd,EAAe,KAUhC,MATIc,EAAS,SAAW,EAClBA,EAAS,CAAC,IAAMT,EAClBQ,EAAW,EACFC,EAAS,CAAC,IAAM,EAAIT,EAAY,IACzCQ,EAAW,GAEJC,EAAS,SAAW,GAAKA,EAAS,CAAC,IAAMT,GAAaS,EAAS,CAAC,IAAMN,IAC/EK,EAAW,GAETA,IAAa,EACT,IAAI,MAAM,0FAA0F,EAEtG,IAAI,MAAM,oBAAoB,CACtC,CAEA,IAAIE,EAAe,GACfC,EAAcT,EAClB,GAAIT,EAAO,CACT,GAAIA,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,qDAAqD,EAGvE,GAAIF,EAAM,KAAK,CAAC,IAAME,EAAM,KAAK,CAAC,EAChC,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIA,EAAM,KAAK,SAAW,EAAG,CAC3B,GAAIU,IAAqBV,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,wEAAwE,EAE1FkB,EAAclB,EAAM,KAAK,CAAC,CAC5B,KAAO,CACL,GAAIU,IAAqBV,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,kFAAkF,EAEpGkB,EAAclB,EAAM,KAAK,CAAC,EAAIA,EAAM,KAAK,CAAC,EAC1CiB,EAAe,EACjB,CACF,CAEA,IAAME,EAAsBR,EAAqBD,EAC3CU,EAAsB,GAO5B,GAAIlB,EACF,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIC,EACF,MAAM,IAAI,MAAM,6BAA6B,EAE/C,GAAIC,EACF,MAAM,IAAI,MAAM,0BAA0B,EAE5C,GAAIC,EACF,MAAM,IAAI,MAAM,4BAA4B,EAG9C,MAAO,CACL,UAAAE,EACA,eAAAC,EACA,mBAAAG,EACA,iBAAAD,EACA,oBAAAS,EACA,kBAAAP,EACA,gBAAiB,EACjB,WAAAH,EACA,YAAAS,EACA,SAAAL,EACA,UAAW,KAAK,MAAMK,EAAcrB,EAAW,QAAQ,EACvD,SAAUA,EAAW,SACrB,iBAAkB,GAClB,uBAAwB,GACxB,gBAAiBA,EAAW,gBAC5B,SAAAkB,EACA,MAAOlB,EAAW,MAClB,oBAAAuB,EACA,aAAAH,EACA,UAAAH,CACF,CACF,EAGa/B,GAAqCc,GAC9CwB,GAA4B,CAAC,GAAGxB,CAAU,CAAC,EAEzCb,GAAgDqC,GAA4B,CAAC,KAAM,CAAC,EAAG,EAAG,EAAG,CAAC,CAAC,CAAC,EAEhGpC,GACF,CAACqC,EAAyBC,EAAiBtB,EAAkBM,EAAmBC,EAC/EC,EAAoBe,IAAuB,CAC1C,IAAMC,EAAc,CAAClB,EAAWC,EAAgBC,CAAU,EACpDiB,EAAaC,EAAU,KAAKF,CAAW,EAEvCG,EAAWC,GAA4BN,EAAI,QAAQ,EACnDO,EAAmBC,GAA+B;AAAA,uBACvCP,CAAU;AAAA,uBACVf,CAAU;AAAA;AAAA,wDAEuBmB,CAAQ;AAAA,yDACPA,CAAQ;AAAA,wEACOA,CAAQ;AAAA;AAAA,IAE5EG,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,KAM9D,OAAOJ,EAAQ,QACX,CACE,KAAM,4BACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,UAAAf,EAAW,eAAAC,EAAgB,WAAAC,EAAY,WAAAe,CAAU,CAAC,CAAC,EACvF,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAI,SAAU,aAAgC,CAAC,EACvF,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAI,CACF,EACA,CAAC,OAAQ,CAACP,EAAKtB,CAAI,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAC7C,EAEEf,GACF,CAACoC,EAAyBf,EAAmByB,EAAkBxB,EAAwBK,EACtFoB,EAAmBhC,EAAmBuB,IAAwB,CAG7D,IAAIU,EAAgBD,EACpB,GAAKhC,EAOE,CACL,GAAIO,IAAmB,EACrB,MAAM,IAAI,MAAM,mFAAmF,EAEnG,OAAA0B,EACIjD,GAAiBqC,EAASW,EAAOhC,EAAMM,EAAWC,EAAgBwB,EAAWnB,EAAUW,CAAW,EACtGU,EAAgBA,EAAc,QAAQ,CAAC3B,EAAWC,EAAgBwB,EAAUnB,CAAQ,CAAC,EAC9ES,EAAQ,QACXa,GAA2BD,EAAelD,GAAyB,IAAI,EACvE,CAAC,OAAQ,CAACkD,CAAa,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAEnD,KAjBE,QAAID,EAAM,KAAK,SAAW,IACxBC,EAAgBD,EAAM,QAAQ,CAAC1B,EAAWC,EAAgBwB,EAAUnB,CAAQ,CAAC,GAExES,EAAQ,QACXa,GAA2BD,EAAelD,GAAyB,IAAI,EACvE,CAAC,OAAQ,CAACkD,CAAa,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAanD,EAES/C,GAAqB,CAACmC,EAAyBzB,IAAqC,CAC/F,IAAMuC,EAAStD,GAAewC,EAAQ,OAAQzB,CAAU,EAExD,GAAIyB,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpC,MAAM,IAAI,MAAM,+BAA+B,EAGjD,GAAIA,EAAQ,OAAO,CAAC,GAAG,KAAK,SAAW,EACrC,MAAM,IAAI,MAAM,8BAA8B,EAIhD,IAAMe,EAASf,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,GACvFA,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EAEhCgB,EAAIpD,GACNoC,EAASc,EAAO,UAAWA,EAAO,SAAUA,EAAO,eAAgBA,EAAO,SAAUd,EAAQ,OAAO,CAAC,EACpGA,EAAQ,OAAO,CAAC,EAAG,CAAC,EAExB,GAAIe,EACF,OAAOE,GACHjB,EAASgB,EAAGhB,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAG,OAAW,OAAW,OAC3FA,EAAQ,OAAO,CAAC,EAAGc,EAAQvC,CAAU,EAG3C,IAAM2C,EAAItD,GACNoC,EAASc,EAAO,UAAWA,EAAO,SAAUA,EAAO,iBAAkBA,EAAO,SAAUd,EAAQ,OAAO,CAAC,EACtGA,EAAQ,OAAO,CAAC,EAAGc,EAAO,UAAU,EAElCK,EAAIvD,GACNoC,EAASc,EAAO,UAAWA,EAAO,SAAUA,EAAO,iBAAkBA,EAAO,UAAWd,EAAQ,OAAO,CAAC,EACvGA,EAAQ,OAAO,CAAC,EAAG,EAAIc,EAAO,UAAU,EAE5CG,GACIjB,EAASgB,EAAGE,EAAGC,EAAGnB,EAAQ,OAAO,CAAC,EAAG,OAAWA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGc,EACzGvC,CAAU,CAChB,IC9UA,IAkBM6C,GAmBAC,GA8BAC,GA8BAC,GA0BAC,GA0BAC,GAiBAC,GA0BAC,GAaAC,GA0BOC,GAMAC,GA7ObC,GAAAC,GAAA,kBAGAC,KAEAC,KACAC,KAGAC,KASMhB,GAAkBiB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,QAAU,EAAG,CACtB,IAAIC,EAAYD,EAAO,CAAC,EAAE,KAAK,OAAS,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EAI9D,GAHIA,EAAO,SAAW,IACpBC,EAAYD,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAEpD,CAACC,EACH,MAAM,IAAI,MAAM,6EAA6E,CAEjG,CACF,EAEMjB,GACF,CAACkB,EAAuBC,EAA8BC,EAAiCC,EACtFC,EAAkBC,IAAkC,CACnD,IAAMC,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,sBACKP,EAAO,WAAW,UAAWQ,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI5CP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA,4BAGPN,EAAaM,CAAC,CAAC;AAAA,UAIrC,MAAO;AAAA,oBACOJ,CAAQ,IAAIC,CAAa;AAAA;AAAA;AAAA;AAAA,cAI/BE,CAAK;AAAA;AAAA;AAAA,OAIf,EAEExB,GACF,CAACiB,EAAuBC,EAA8BC,EAAiCC,IAA2B,CAChH,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSP,EAAO,WAAW,UAAWQ,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gCAKvC,GAAKP,EAAUO,CAAC,EAAI,EAAE;AAAA;AAAA,4BAE1BP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,gCAIRN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEvB,GACF,CAACgB,EAAuBC,EAA8BC,EAAiCC,IAA2B,CAChH,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSP,EAAO,WAAW,UAAWQ,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,2BAI5CP,EAAUO,CAAC,CAAC;AAAA,wBACfP,EAAUO,CAAC,EAAI,CAAC;AAAA;AAAA,gCAERN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEtB,GACF,CAACe,EAAuBC,EAA8BC,EAAiCC,IAA2B,CAChH,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSP,EAAO,WAAW,UAAWQ,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA,yBAE9CP,EAAUO,CAAC,CAAC;AAAA;AAAA,2BAEVP,EAAUO,CAAC,CAAC;AAAA,yBACdP,EAAUO,CAAC,CAAC;AAAA;AAAA,gCAELN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEErB,GACF,CAACc,EAAuBC,EAA8BC,EAAiCO,EACtFL,IAA6B,CAC5B,OAAQK,EAAW,KAAM,CACvB,IAAK,GACH,OAAO3B,GAAekB,EAAQC,EAAWC,EAAcO,EAAW,KAAML,EAAUK,EAAW,KAAK,EACpG,IAAK,GACH,OAAO1B,GAAciB,EAAQC,EAAWC,EAAcO,EAAW,IAAI,EACvE,IAAK,GACH,OAAOzB,GAAWgB,EAAQC,EAAWC,EAAcO,EAAW,IAAI,EACpE,IAAK,GACH,OAAOxB,GAAWe,EAAQC,EAAWC,EAAcO,EAAW,IAAI,EACpE,QACE,MAAM,IAAI,MAAM,cAAc,CAClC,CACF,EAEEtB,GACF,CAACuB,EAA4BZ,EAA+BW,EAA2BL,IACzE,CACR,IAAMH,EAAYH,EAAO,CAAC,EAAE,KACtBa,EAAaC,EAAU,SAASX,EAAU,MAAM,EAAGQ,EAAW,IAAI,EAClEI,EAAaD,EAAU,KAAKD,CAAU,EACtCT,EAAeU,EAAU,eAAeX,CAAS,EAEjDD,EAASc,GAAe,SAAUhB,EAAO,CAAC,EAAE,SAAUa,CAAU,EAChEI,EAAQC,GAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUG,CAAS,EAExDgB,EAAa/B,GAAcc,EAAQC,EAAWC,EAAcO,EAAYL,CAAQ,EAYtF,MAXgB;AAAA,gBACVM,EAAa,iBAAiBK,EAAOf,CAAM,CAAC;AAAA,gBAC5CU,EAAa,UAAU,CAAC;AAAA,gBACxBA,EAAa,sCAAsCG,CAAU,CAAC;AAAA;AAAA,8BAEhDb,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,4BAEtCI,CAAQ;AAAA,gBACpBa,CAAU;AAAA;AAAA,YAIlB,EAEF7B,GAAuB,CAACU,EAA+BW,IAA2C,CACtG,IAAMS,EAAcN,EAAU,SAASd,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGW,EAAW,IAAI,EAC9E,MAAO,CACL,KAAM,MACN,YAAa,CAAC,KAAMA,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMS,EAAa,SAAUpB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAU,KAAKM,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBR,GAAgBvB,GAAgBuB,EAAcZ,EAAQW,EAAY,KAAK,CAC1F,CACF,EAEMpB,GAAgC,CAACS,EAA+BW,IAA6C,CACjH,GAAIX,EAAO,OAAS,EAAG,CACrB,IAAMqB,EAAerB,EAAO,CAAC,EAAE,iBAAiB,EAC1CsB,EAAStB,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,KAAQA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAI,EAElFQ,EAAYR,EAAO,CAAC,EAAE,KAAK,OAC3BuB,EAAa,IAAI,WAAW,EAAIf,CAAS,EAAE,KAAK,CAAC,EACvD,GAAIR,EAAO,QAAU,EAAG,CACtB,IAAMwB,EAAOxB,EAAO,CAAC,EAAE,iBAAiB,EACxC,QAASU,EAAI,EAAGA,EAAIc,EAAK,OAAQd,IAC/Ba,EAAW,OAAOC,EAAKd,CAAC,CAAC,CAAC,EAAI,OAAOW,EAAaX,CAAC,CAAC,EACpDa,EAAW,OAAOC,EAAKd,CAAC,CAAC,EAAIF,CAAS,EAAI,OAAOa,EAAaX,EAAIc,EAAK,MAAM,CAAC,CAElF,MACEH,EAAa,QAAQ,CAACI,EAAGf,IAAMa,EAAW,OAAOb,CAAC,CAAC,EAAK,OAAOe,CAAC,CAAE,EAGpE,IAAMpB,EAAiB,CAAC,EACxB,OAAAkB,EAAW,QAAQE,GAAKpB,EAAK,KAAKoB,CAAC,CAAC,EAE7BC,GAA4B,CAAC,KAAMf,EAAW,KAAM,MAAAW,EAAO,KAAAjB,CAAI,CAAC,CACzE,KACE,QAAOM,CAEX,EAEanB,GAAM,CAACmC,EAAyBhB,IAAoC,CAC/E5B,GAAe4C,EAAQ,MAAM,EAC7B,IAAMC,EAAoBrC,GAA8BoC,EAAQ,OAAQhB,CAAU,EAClFgB,EAAQ,QAAQrC,GAAqBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxF,EAEanC,GAAsBkB,GAAuD,CACxF,IAAMkB,EAAOlB,EAAW,KAClBW,EAAQX,EAAW,MACnBN,EAAOM,EAAW,KACxB,OAAOe,GAA4B,CAAC,KAAAG,EAAM,MAAAP,EAAO,KAAAjB,CAAI,CAAC,CACxD,IClPA,IAgBMyB,GASAC,GA4BAC,GAwKAC,GAaAC,GA4BOC,GAYAC,GAKPC,GAYOC,GAKAC,GAUPC,GAqBOC,GAKAC,GAgBAC,GAKAC,GAjWbC,GAAAC,GAAA,kBAIAC,KACAC,KAGAC,KAQMnB,GAAkBoB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,4BAA4B,EAE9C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMnB,GAA0C,CAC5CoB,EAAmBC,EAA2BC,IAAyD,CACzG,IAAMC,EAAiBF,EAAW,SAAW,OACvCG,EAA2BJ,EAAM,KAAK,MAAM,EAC9CG,GACFC,EAAyB,OAAO,EAAG,EAAGA,EAAyB,IAAI,CAAE,EAEvE,IAAMC,EAAe,OAAO,eAAe,KAAKJ,EAAY,WAAW,EACjEK,EAAcL,EAAW,YAAY,MAAM,EAC3CM,EAAUN,EAAW,QAAQ,MAAM,EACnCO,EAAsBH,EAAgBJ,EAAiC,UAAU,MAAM,EAAI,CAAC,EAC5FQ,EAAOR,EAAW,KAAK,MAAM,EACnCS,GAAa,qBAAqBR,EAAkBE,EAA0BE,EAAaC,EAASC,EAAWC,CAAI,EAEnH,IAAME,EAA4BD,GAAa,uBAC3CR,EAAkBE,EAA0BG,EAASC,EAAWF,EAAaG,EAAMR,EAAW,OAAO,EAEnGW,EAAgB,OAAO,OAAO,CAAC,EAAGX,CAAU,EAC9CI,EACF,OAAO,OAAOO,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,UAAAD,EAAW,SAAUP,EAAW,QAAQ,CAAC,EAEnG,OAAO,OAAOW,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,SAAUR,EAAW,QAAQ,CAAC,EAE1F,IAAMY,EAA2BF,EAA0B,MAAM,EACjE,OAAAE,EAAyB,KAAKA,EAAyB,OAAO,EAAG,CAAC,EAAE,CAAC,CAAC,EAC/D,CAACD,EAAeT,EAAiBU,EAA2BF,CAAyB,CAC9F,EAEM9B,GAAsB,CACxBiC,EAA4BC,EAAkBC,EAA2BC,EACzEhB,EAA2BiB,EAAaC,EAAaC,IAA0B,CACjF,IAAMjB,EAAiBF,EAAW,SAAW,OACvCoB,EAAYL,EACZM,EAAWP,EAAE,KAAK,MAClBQ,EAAOF,EAAU,OACjBG,EAAaC,EAAU,KAAKR,CAAW,EACvCS,EAASC,GAAe,SAAUZ,EAAE,KAAK,OAAQE,CAAW,EAElE,GAAIhB,EAAW,YAAY,QAAU,EAAG,CACtC,IAAM2B,EAAK3B,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7D4B,EAAK5B,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrD6B,EAAU7B,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxD8B,EAAQ9B,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClD+B,EAAUT,GAAQpB,EAAiB,EAAI,GACzC8B,EAAQ,GACRC,EAAQ,GACRC,EAAW,GAqBf,GApBIL,EAAUC,IAAU,EACtBE,EAAQ;AAAA,4CAC8BL,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQX,EAAUW,CAAO,CAAC;AAAA;AAAA;AAAA;AAAA,kCAI5DjB,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAGjBe,EAAQ;AAAA,4CAC8BL,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,kCAC9Cf,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAIfjB,EAAW,YAAY,SAAW,EAAG,CACvC,IAAMmC,EAAKnC,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7DoC,EAAKpC,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrDqC,GAAUrC,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxDsC,GAAQtC,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClDuC,EAAUjB,GAAQpB,EAAiB,EAAI,GACvCsC,GAAOpB,EAAUmB,CAAO,EAC1BF,GAAUC,KAAU,EACtBL,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,EAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQC,EAAI;AAAA,4BACpDb,CAAE;AAAA;AAAA;AAAA,gBAKtBM,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,EAAO;AAAA,kBAG1EH,EAAW;AAAA;AAAA,aAGb,CAoBA,MAlBoB;AAAA,cACVrB,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,cAExCZ,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2BAExCJ,CAAQ,MAAMA,CAAQ,IAAIF,CAAK;AAAA;AAAA,gBAE1Cc,CAAK;AAAA,gBACLD,CAAK;AAAA,gBACLE,CAAQ;AAAA,gBACRhB,CAAG;AAAA;AAAA;AAAA,cAKjB,KAAO,CACL,GAAIhB,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMuC,EAAajB,EAAU,KAAKxB,EAAW,WAAW,EAClD0C,EAAgBlB,EAAU,eAAexB,EAAW,WAAW,EAC/D2C,EAAcD,EAAc,OAC5BE,EAAW5C,EAAW,KAAK,OAC3B6C,EAAU7C,EAAW,KAAK,OAAO,CAAC8C,EAAKC,IAAQD,EAAMC,CAAG,EAC1DC,EAAU,GACd,OAAIH,EACFG,EAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAQgBlC,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3CG,CAAG;AAAA,iBAGf+B,EAAU;AAAA;AAAA,8BAEclC,EAAE,gBAAgB,UAAU,CAAC;AAAA,gBAC3CG,CAAG;AAAA,cAGK;AAAA,cACVJ,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,sCAEhBmB,CAAQ,KAAK5C,EAAW,KAAK,IAAIiD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,2CACnD3B,CAAI,KAAKF,EAAU,IAAI6B,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+CAC1CN,CAAW,KAAKD,EAAc,IAAIO,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC/DN,CAAW,KAAK3C,EAAW,QAAQ,IAAIiD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAAA,cAEzFpC,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,wCAE3BkB,CAAW;AAAA;AAAA,4BAEvBlB,EAAO,KAAK,KAAK,IAAIN,CAAK;AAAA;AAAA;AAAA;AAAA,0CAIZsB,CAAU;AAAA;AAAA,uCAEbE,EAAc,CAAC;AAAA;AAAA;AAAA;AAAA,0BAI5BA,EAAc,CAAC;AAAA;AAAA;AAAA,+BAGVrB,EAAOqB,CAAW,UAAUrB,CAAI;AAAA,2DACJA,EAAOqB,CAAW;AAAA,oCACzCrB,EAAOqB,CAAW;AAAA,oBAClCK,CAAO;AAAA;AAAA,gBAEX9B,CAAG;AAAA;AAAA;AAAA,cAKjB,CACF,EAcMrC,GAA6BmB,IAA+D,CAChG,OAAQA,EAAW,OACnB,QAAS,CAAC,SAAU,QAAS,aAAc,YAAY,EAAEA,EAAW,QAAkB,EACtF,SAAUA,EAAW,UACrB,YAAaA,EAAW,aACxB,QAASA,EAAW,QACpB,KAAMA,EAAW,IACnB,GAMMlB,GACF,CAACoE,EAAcnD,EAAmBE,EAA2BD,IAAmD,CAC9G,GAAM,CAACmD,EAAoBnC,CAAW,EAClCrC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEwC,EAAajB,EAAU,KAAK2B,EAAmB,WAAW,EAE1DrC,EAAIsC,GAAc,IAAKrD,EAAM,SAAUA,EAAM,IAAI,EACjDsB,EAAWP,EAAE,KAAK,MAElBG,EAAM,kBACRC,EAAM,GACV,OAAIiC,EAAmB,gBACrBjC,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,KAEzCvB,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,WAEpC,CACL,KAAAS,EACA,YAAa,CAAC,KAAMlD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMgB,EAAa,SAAUjB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbjC,GAAoBiC,EAAcC,EAAGf,EAAM,KAAMiB,EAAamC,EAAoBlC,EAAKC,EAAK,KAAK,CACvG,CACF,EAESnC,GAA8BiB,GAA+D,CACxG,IAAMqD,EAAmBrD,EAAW,oBAAiC,EAE/DsD,EAAOzE,GAA0BmB,CAAU,EAEjD,GAAIsD,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,OAAOC,GAA4B,CAAC,gBAAAF,EAAiB,GAAGC,CAAI,CAAC,CAC/D,EAEatE,GAAc,CAACwE,EAAyBxD,IAA4C,CAC/FtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ1E,GAA6B,cAAe0E,EAAQ,OAAO,CAAC,EAAG,GAAOxD,CAAU,CAAC,CACnG,EAEMf,GAAuB,CAC3B,QAAS,GACT,SAAU,EACV,gBAAiB,GACjB,YAAa,CAAC,EACd,QAAS,CAAC,EACV,KAAM,CAAC,EACP,aAAc,EACd,UAAW,CAAC,EACZ,SAAU,EACZ,EAEaC,GAAoCc,GAA+D,CAC9G,IAAMyD,EAASzD,EAAW,OAC1B,MAAO,CAAC,OAAAyD,EAAQ,GAAGxE,GAAsB,SAAUwE,CAAM,CAC3D,EAEatE,GAAoB,CAACqE,EAAyBxD,IAA4C,CACrGtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ1E,GAA6B,oBAAqB0E,EAAQ,OAAO,CAAC,EAAG,GAAMxD,CAAU,CAAC,CACxG,EAOMZ,GACF,CAAC8D,EAAcnD,EAAmBE,EAA2BD,IAA+C,CAC1G,GAAM,CAACmD,EAAoBnC,CAAW,EAClCrC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEgB,EAAM;AAAA;AAAA,MAGNC,EAAM,GACNJ,EAAIsC,GAAc,IAAKrD,EAAM,SAAUA,EAAM,IAAI,EACvD,MAAO,CACL,KAAAmD,EACA,YAAa,CAAC,KAAMlD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMgB,EAAa,SAAUjB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbjC,GAAoBiC,EAAcC,EAAGf,EAAM,KAAMiB,EAAamC,EAAoBlC,EAAKC,EAAK,MAAM,CACxG,CACF,EAES7B,GAAU,CAACmE,EAAyBxD,IAAwC,CACvFtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpE,GAAyB,UAAWoE,EAAQ,OAAO,CAAC,EAAG,GAAOxD,CAAU,CAAC,CAC3F,EAEaV,GAA0BU,GAA2D,CAChG,IAAM0D,EAAe1D,EAAW,cAC1BO,EAAYP,EAAW,UAEvBsD,EAAOzE,GAA0BmB,CAAU,EAEjD,GAAI0D,IAAiB,EACnB,MAAM,IAAI,MAAM,6DAA6D,EAE/E,GAAIJ,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,oEAAoE,EAGtF,OAAOC,GAA4B,CAAC,aAAAG,EAAc,UAAAnD,EAAW,GAAG+C,CAAI,CAAC,CACvE,EAEa/D,GAAgCS,GAA2D,CACtG,IAAMyD,EAASzD,EAAW,OAC1B,MAAO,CAAC,OAAAyD,EAAQ,GAAGxE,GAAsB,SAAUwE,CAAM,CAC3D,EAEajE,GAAgB,CAACgE,EAAyBxD,IAAwC,CAC7FtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpE,GAAyB,gBAAiBoE,EAAQ,OAAO,CAAC,EAAG,GAAMxD,CAAU,CAAC,CAChG,ICpWA,IAUM2D,GAUAC,GAwBOC,GA5CbC,GAAAC,GAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GAAwB,CAACQ,EAAeC,EAAeC,IAAwB,CACnF,IAAMC,EAAiBH,IAAUC,EAC3BG,EAA8BJ,EAAQC,GAASC,EAAQ,EACvDG,EAA8BL,EAAQC,GAASC,EAAQ,EAE7D,GAAIC,GAAkBC,GAA+BC,EACnD,MAAM,IAAI,MAAM,2CAA4C,CAEhE,EAEMZ,GAAyB,CAACO,EAAeC,EAAeC,EAAeI,IAAoC,CAC/G,IAAMC,EAAc,KAAK,IAAI,KAAK,MAAMN,EAAQD,GAASE,CAAK,CAAC,EACzDM,EAAwB,CAACD,CAAW,EACpCE,EAAaF,EAEbG,EAASC,GAAe,SAAUL,EAAUE,CAAW,EACvDI,EAAWF,EAAO,KAAK,QAEvBG,EAAmBC,GAA+B;AAAA,UAChDA,EAAa,iBAAiBJ,CAAM,CAAC;AAAA,UACrCI,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,+BACzCG,CAAQ,IAAIZ,CAAK,OAAOY,CAAQ,kBAAkBA,CAAQ,IAAIV,CAAK;AAAA,SAEhG,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,CAACF,EAAOC,EAAOC,CAAK,EAAE,IAAIa,GAAKA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,CAAC,EAC1E,gBAAAF,EACA,WAAY,KACR,CAAC,QAAS,CAAC,CAAC,KAAML,EAAa,SAAAF,CAAQ,CAAC,EACvC,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CAAC,EAC1E,CACF,EAEaf,GAASsB,GAAkC,CACtD,IAAIhB,EAAQ,EACRC,EAAQ,EACRC,EAAQ,EACRc,EAAQ,OAAO,CAAC,EAAE,WAAa,GACjChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,GAClCA,EAAQ,OAAO,CAAC,EAAE,WAAa,IACxChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,GAE3CC,GAAI,OAAO,sBACbzB,GAAsBQ,EAAOC,EAAOC,CAAK,EAG3Cc,EAAQ,QAAQvB,GAAuBO,EAAOC,EAAOC,EAAOc,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CACvG,IC9DA,IAgCME,GAoBAC,GASAC,GA8CAC,GA2CAC,GAkCAC,GAaAC,GAwBAC,GAyBAC,GAuBAC,GAmCAC,GAYAC,GAkDAC,GAwEAC,GA4FAC,GAOOC,GAUAC,GAniBbC,GAAAC,GAAA,kBAKAC,KACAC,KAGAC,KAuBMrB,GAAiB,CAACsB,EAAkBC,IAAuC,CAK/E,GAJAD,EAAO,MAAOE,GAAUA,EAAQ,IAAM,IAAM,CAClB,MAAM,IAAI,MAAM,oDAAoD,CACtE,EAAE,EAEtBF,EAAO,OAAS,GAClB,GAAIC,EAAW,OAAS,UACtB,GAAI,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,gEAAgE,UAEzEC,EAAW,OAAS,SACzB,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,+DAA+D,EAIvF,EAEMrB,GAAe,CAACqB,EAA2BG,EAAyBC,IAA2B,CACnGD,EAAK,MAAOD,GAAUA,GAAS,GAAKA,EAAQE,IAAS,IAAM,CACnC,MAAM,IAAI,MAAM,qEAAqE,CACvF,EAAE,EACxB,IAAMC,EAAY,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAG,EAC1C,OAAAD,EAAK,QAAQ,CAACD,EAAOI,IAAUD,EAAUH,CAAK,EAAIF,EAAOM,CAAK,CAAC,EACxDD,CACT,EAEMzB,GACF,CAAC2B,EAA+BN,EAA8BO,EAAsBR,EACnFS,EAAiBC,IAAwB,CACxC,GAAM,CAACC,EAAeC,EAAkBC,CAAe,EAClDL,EAAe,GAAM,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,GAAKD,EAAO,OAAS,EAAK,EAAI,GAAI,EAAE,EACrEH,EAAOG,EAAO,CAAC,EAAE,KAAK,OAC5B,GAAII,EAAgB,GAAKJ,EAAO,OAASI,GAAiBJ,EAAOI,CAAa,EAAE,KAAK,OAAS,EAC5FJ,EAAOI,CAAa,EAAE,gBAAgB,EAAE,QAAST,GAAUQ,EAAI,KAAKR,CAAK,CAAC,UAEjED,EAAW,0BAA4B,qBAChD,MAAM,IAAI,MAAM,2FAA2F,EAG7G,GAAIW,EAAmB,GAAKL,EAAO,OAASK,GAAoBL,EAAOK,CAAgB,EAAE,KAAK,OAAS,EAAG,CAExG,GADAL,EAAOK,CAAgB,EAAE,gBAAgB,EAAE,QAASV,GAAUF,EAAO,KAAKE,CAAK,CAAC,EAC5EF,EAAO,SAAW,GACjBA,EAAO,SAAWI,GAASI,GAAgB,IAAMR,EAAO,SAAWC,EAAW,KAAK,OACtF,MAAM,IAAI,MACN,6FAA6F,EAEnGvB,GAAesB,EAAQC,CAAU,EAC7BA,EAAW,KAAK,OAAS,GAC3BtB,GAAaqB,EAAQC,EAAW,KAAMG,CAAI,EAAE,QAAQ,CAACF,EAAOI,IAAUN,EAAOM,CAAK,EAAIJ,CAAK,CAE/F,CACA,GAAIW,EAAkB,GAAKN,EAAO,OAASM,IACzCN,EAAOM,CAAe,EAAE,iBAAiB,EAAE,QAASX,GAAUO,EAAM,KAAK,OAAOP,CAAK,CAAC,CAAC,EACnFO,EAAM,SAAWL,GAASI,GAAgB,IAAMC,EAAM,SAAWR,EAAW,KAAK,QACnF,MAAM,IAAI,MAAM,4FAA4F,EAIhH,GAAIA,EAAW,KAAK,OAAS,EAAG,CAC9B,GAAID,EAAO,SAAWC,EAAW,KAAK,OACpC,MAAM,IAAI,MAAM,0FAA0F,EAE5G,GAAIQ,EAAM,SAAWR,EAAW,KAAK,OACnC,MAAM,IAAI,MACN,8FAA8F,CAEtG,CACA,GAAI,OAAOD,EAAW,KAAe,OAAOS,EAAU,KAAeT,EAAO,OAAS,GAAKS,EAAM,OAASL,EACvG,MAAM,IAAI,MAAM,yDAAyD,CAE7E,EAEEvB,GACF,CAACiC,EAAiDC,IAC9C,2DAA2DA,CAAK,aAAaA,CAAK,oBAAoBA,CAAK;AAAA,uBAC5FA,CAAK,eAAeA,CAAK,aAAaA,CAAK,QAAQA,CAAK,OAC1E,IAAM,CACD,OAAQD,EAAwB,CAC9B,IAAK,aACH,MAAO,4BACT,IAAK,qBACH,MAAO,sKAKT,IAAK,uBACH,MAAO,oCACT,IAAK,gBACH,MAAO,6LAKT,IAAK,qBACH,MAAO,oRAIoCC,CAAK,4CAElD,IAAK,uBACH,MAAO,CACL,8CAA+C,kDAC/C,qCAAsC,4CACtC,oDACF,EAAE,KAAK;AAAA,CAAI,EACb,IAAK,aACH,MAAO,4CACT,QACE,MAAM,IAAI,MAAM,6BAA6BD,CAAsB,mBAAmB,CAC1F,CACF,GAAG,EACP,IAEEhC,GAA8B,CAACkC,EAA0BR,EAAsBO,IACjF,6CAA6CA,CAAK,4BAA4BA,CAAK,MAAQ,IAAM,CAC/F,OAAQC,EAAa,CACnB,IAAK,oBACH,MAAO,yIAKT,IAAK,QACH,MAAO,2BACT,IAAK,OACH,MAAO,0BACT,IAAK,qBACH,MAAO,0KAKT,IAAK,SACL,QACE,GAAIR,EAAe,GACjB,MAAO,mLAOT,MAAM,IAAI,MAAM,gBAAgBQ,CAAW,mBAAmB,CAClE,CACF,GAAG,EACH,IAEEjC,GAAY,CAAC2B,EAAwBP,EAAyBC,IAA2B,CAC7F,IAAMa,EAAS,IAAI,MAAMb,CAAI,EAAE,KAAK,CAAC,EAAE,OAAO,IAAI,MAAMA,CAAI,EAAE,KAAK,CAAC,CAAC,EAC/Dc,EAAWR,EAAI,SAAW,EAAIO,EAASP,EAAI,MAAM,EACvD,OAAIP,EAAK,OAAS,GAChBA,EAAK,QAAQ,CAACgB,EAAGC,IAAM,CACrBH,EAAOE,CAAC,EAAID,EAASE,CAAC,EACtBH,EAAOG,EAAIhB,CAAI,EAAIc,EAASf,EAAK,OAASiB,CAAC,CAC7C,CAAC,EACMH,GAEFC,CACT,EAEMlC,GACF,CAACqC,EAA+BrB,EAA2BS,EAA0BN,IACrE,CACV,IAAImB,EAAwB,CAAC,EAC7B,GAAIb,EAAM,OAAS,EACjB,GAAIN,EAAK,OAAS,EAAG,CAEnB,GADAkB,EAAW,QAASF,GAAMG,EAAY,KAAKH,CAAC,CAAC,EACzC,KAAK,IAAI,GAAGhB,CAAI,EAAIkB,EAAW,OACjC,MAAM,IAAI,MAAM,sBAAsB,EAExClB,EAAK,QAAQ,CAACgB,EAAGC,IAAME,EAAYH,CAAC,EAAIV,EAAMW,CAAC,CAAC,CAClD,MACEX,EAAM,QAASU,GAAMG,EAAY,KAAKH,CAAC,CAAC,MAErC,CACL,GAAInB,EAAO,SAAW,EACpB,MAAM,IAAI,MAAM,yCAAyC,EAEzDsB,EAAcD,EAAW,IAAI,CAACnB,EAAOI,IAAU,KAAK,MAAMJ,EAAQF,EAAOM,CAAK,CAAC,CAAC,CAEpF,CACA,OAAOgB,CACT,EAEFrC,GAAoB,CAACoC,EAA+BrB,EAAkBC,IAA2C,CACrH,IAAMsB,GAAiB,IAAM,CAC3B,OAAQtB,EAAW,sBAAuB,CACxC,IAAK,aACH,OAAOA,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAImB,GAAKpB,EAAOoB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGpB,EAAQ,OAAO,SAAS,EAC1E,IAAK,cACH,OAAOC,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAImB,GAAKpB,EAAOoB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGpB,EAAQ,OAAO,SAAS,EAC1E,QACE,MAAM,IAAI,MAAM,4BAA4BC,EAAW,qBAAqB,mBAAmB,CACnG,CACF,GAAG,EACHD,EAAO,KAAK,EAAK,EAAGA,EAAO,MAAM,EACjC,IAAMwB,EAAsBH,EAAW,MAAM,EAC7C,OAAIpB,EAAW,KAAK,OAAS,GAC3BA,EAAW,KAAK,QAASkB,GAAMnB,EAAOmB,CAAC,EAAII,CAAa,EACxDtB,EAAW,KAAK,QAASkB,GAAMK,EAAoBL,CAAC,EAAI,KAAK,MAAME,EAAWF,CAAC,EAAInB,EAAOmB,CAAC,CAAC,CAAC,IAE7FnB,EAAO,KAAKuB,EAAe,EAAGvB,EAAO,MAAM,EAC3CwB,EAAoB,QAAQ,CAACL,EAAGC,IAAMI,EAAoBJ,CAAC,EAAI,KAAK,MAAMD,EAAInB,EAAOoB,CAAC,CAAC,CAAC,GAEnFI,CACT,EAEMtC,GACF,CAACuC,EAAuBJ,EAA+BC,EAAgCtB,EACtFU,IAAmC;AAAA,kEAC0Be,EAAO,KAAK,OAAO,cAC7EA,EAAO,KAAK,KAAK,KAAKH,EAAY,MAAM;AAAA,sCACVD,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,uCAC3DE,EAAY,MAAM,KAAKA,EAAY,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,6BACxEK,EAAO,KAAK,KAAK,KAAKzB,EAAO,MAAM,KAAKA,EAAO,IAAIoB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,0BAC7EK,EAAO,KAAK,KAAK,KAAKf,EAAI,MAAM,KAAKA,EAAI,IAAIU,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,mCAC3DK,EAAO,KAAK,KAAK,KAAKH,EAAY,MAAM;AAAA,gCAC3CA,EAAY,MAAM;AAAA,4BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA,iCAE1DG,EAAO,KAAK,KAAK;AAAA;AAAA,4EAE0BA,EAAO,KAAK,KAAK;AAAA,kBAC3EA,EAAO,KAAK,KAAK,qBAAqBA,EAAO,KAAK,KAAK,oCACjEJ,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,OAMnBlC,GACF,CAACuC,EAAsBD,EAAuBJ,EAA+BC,EAC5EtB,EAA2BU,EAAwBiB,IAAsC;AAAA,+DAC/BF,EAAO,KAAK,OAAO,QAAQC,EAAM,KAAK,OAAO;AAAA,wCACpEL,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC3DE,EAAY,MAAM,KAAKA,EAAY,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+BACxEM,EAAM,KAAK,KAAK,KAAK1B,EAAO,MAAM,KAAKA,EAAO,IAAIoB,GAAK,GAAGA,CAAC,EAAE,EAAE,KAAK,GAAG,CAAC;AAAA,4BAC3EM,EAAM,KAAK,KAAK,KAAKhB,EAAI,MAAM,KAAKA,EAAI,IAAIU,GAAK,GAAGA,CAAC,EAAE,EAAE,KAAK,GAAG,CAAC;AAAA,4BAClEM,EAAM,KAAK,OAAO;AAAA,kCACZJ,EAAY,MAAM;AAAA,8BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA,4EAKjBI,EAAM,KAAK,KAAK;AAAA,sBACtEA,EAAM,KAAK,KAAK,qBAAqBA,EAAM,KAAK,KAAK,oCACnEL,EAAW,MAAM;AAAA,mBACNM,CAAgB,4CAA4CD,EAAM,KAAK,KAAK;AAAA;AAAA;AAAA,2CAGpDA,EAAM,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAS/CA,EAAM,WAAW,eAAgB,IAAK,YAAY,CAAC;AAAA;AAAA;AAAA,OAKzDtC,GAAoB,CAACsC,EAAsBL,IAA0C;AAAA,yCAClDK,EAAM,KAAK,OAAO;AAAA,sCACrBL,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,gCAClEC,EAAW,MAAM;AAAA,2BACtBA,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAQjFhC,GACF,CAACqC,EAAsBD,EAAuBJ,EAA+BrB,EAC5E2B,EAA2BC,IAAuC,CACjE,GAAM,CAACC,EAAUC,EAAWC,EAAUC,CAAU,EAC5CX,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAE,EAAKrB,EAAO,CAAC,IAAM,EAAM,CAAC,EAAG,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,EAAG,CAAC,EACxFe,EAAQW,EAAM,KAAK,MACzB,MAAO;AAAA,wEAC2DX,CAAK;AAAA,0BACnDW,EAAM,KAAK,OAAO;AAAA,qBACvBI,CAAS,uBAAuBT,EAAWS,CAAS,CAAC;AAAA,qBACrDC,CAAQ,uBAAuBV,EAAWU,CAAQ,CAAC;AAAA,YAC5DV,EAAW,MAAM;AAAA,uBACNW,CAAU;AAAA,uBACVH,CAAQ;AAAA;AAAA,qBAEVH,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA;AAAA,8CAGZD,EAAO,KAAK,OAAO,QAAQV,CAAK;AAAA;AAAA,gBAE9DA,CAAK,sBAAsBe,CAAS;AAAA,gBACpCf,CAAK,sBAAsBgB,CAAQ;AAAA,YACvCJ,CAAgB,0BAA0BN,EAAWS,CAAS,CAAC,6BACjET,EAAWU,CAAQ,CAAC;AAAA,iBACbH,CAAkB;AAAA;AAAA,8BAELP,EAAWS,CAAS,CAAC;AAAA,8BACrBT,EAAWU,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAOtCV,EAAW,OAAS,CAAC;AAAA,wCACOW,CAAU;AAAA,sCACZH,CAAQ;AAAA;AAAA,iBAE7Bd,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK,YAAYA,CAAK;AAAA,iBACtBA,CAAK,MAAMA,CAAK;AAAA,wBACTA,CAAK;AAAA,kBACXA,CAAK;AAAA;AAAA,MAGnB,EAEEzB,GACF,CAACoC,EAAsBD,EAAuBJ,EAA+BC,EAC5EtB,EAA2BU,EAAwBuB,EAAqBN,EACxEC,EAA4BM,IAAoC,CAC/D,GAAM,CAACJ,EAAWC,CAAQ,EAAIV,EAAW,SAAW,EAAI,CAAC,EAAG,CAAC,EAAKrB,EAAO,CAAC,IAAM,EAAO,CAAC,EAAG,CAAC,EAAI,CAAC,EAAG,CAAC,EAC/Fe,EAAQW,EAAM,KAAK,MACnBS,EAAoCC,GAAwB,CAChE,IAAMC,EAAYD,IAAQN,EAAY,MAAQ,MAC9C,MAAO;AAAA,WACJO,CAAS,oCAAoCX,EAAM,KAAK,OAAO,oBAC9DD,EAAO,KAAK,OAAO,QAAQV,CAAK;AAAA,4BAChBO,EAAY,SAAW,EAAI,gBAAkB,iBAAiBc,CAAG,GAAG;AAAA,2BACrErB,CAAK,iDAAiDA,CAAK,kBAAkBf,EAAOoC,CAAG,CAAC;AAAA,UACzGrB,CAAK,IAAIO,EAAYc,CAAG,CAAC,MAAMrB,CAAK,IAAIM,EAAWe,CAAG,CAAC,MAAM1B,EAAI0B,CAAG,CAAC,KAAK1B,EAAI0B,CAAG,CAAC,MAAMf,EAAW,MAAM;AAAA,gCACnFN,CAAK;AAAA;AAAA;AAAA,cAGvBY,CAAgB,0CAA0CN,EAAWe,CAAG,CAAC;AAAA,mBACpER,CAAkB;AAAA;AAAA,0BAEXb,CAAK,gBAAgBA,CAAK;AAAA;AAAA,gBAEpCsB,CAAS,KAAKtB,CAAK,oBAAoBA,CAAK;AAAA,gBAC5CsB,CAAS,WAAWA,CAAS,OAAOhB,EAAWe,CAAG,CAAC;AAAA,kBACjDF,CAAc;AAAA;AAAA;AAAA,yBAGPP,CAAgB;AAAA,uBAClBC,CAAkB;AAAA;AAAA,gBAEzBS,CAAS,iBAAiBA,CAAS,KAAKhB,EAAWe,CAAG,CAAC;AAAA;AAAA;AAAA,kCAGrCV,EAAM,KAAK,OAAO;AAAA,6BACvBU,CAAG,WAAWC,CAAS;AAAA,0BAC1BD,IAAQN,EAAY,SAASJ,EAAM,gBAAgB,kBAAkB,CAAC,KAAO;AAAA,uGACA;AAAA;AAAA;AAAA,QAIjG,EAEA,MAAO;AAAA,MACPS,EAAiCL,CAAS,CAAC;AAAA,MAC3CK,EAAiCJ,CAAQ,CAAC;AAAA,qCACXhB,CAAK,cAAcA,CAAK;AAAA;AAAA,wBAErCA,CAAK,gBAAgBA,CAAK;AAAA,wBAC1BA,CAAK;AAAA,wBACLA,CAAK;AAAA,uBACNA,CAAK;AAAA,oBACRkB,CAAW,wBAAwBA,CAAW,yBACxDA,CAAW,yBAAyBA,CAAW;AAAA,oBACrCA,CAAW,mBAAmBA,CAAW;AAAA,oBACzCA,CAAW,2BAA2BA,CAAW;AAAA,oBACjDA,CAAW,yBAAyBA,CAAW,0BACzDA,CAAW,0BAA0BA,CAAW;AAAA;AAAA;AAAA;AAAA,qCAIrBlB,CAAK,sBAAsBA,CAAK,YAAYA,CAAK;AAAA,oBAClEA,CAAK;AAAA;AAAA;AAAA;AAAA,2CAIkBU,EAAO,KAAK,OAAO,QAAQV,CAAK;AAAA,wBACnDW,EAAM,KAAK,OAAO;AAAA;AAAA;AAAA,KAItC,EAEEnC,GACF,CAAC+C,EAAyBrC,EAA8BO,EAAsB+B,EAC7E9B,EAA0B+B,IAA6C,CACtE,IAAMnB,EAAaiB,EAAY,KACzB5B,EAAM3B,GAAUyD,EAAUvC,EAAW,KAAMoB,EAAW,MAAM,EAE9DC,EAActC,GAAgBqC,EAAYkB,EAAa9B,EAAOR,EAAW,IAAI,EAC7ED,EAASuC,EAAY,MAAM,EAC3BA,EAAY,SAAW,IACzBvC,EAASqB,EAAW,IAAI,CAACnB,EAAOI,IAAUJ,IAAU,EAAI,EAAMoB,EAAYhB,CAAK,EAAIJ,CAAK,EACpFD,EAAW,wBAA0B,YACvCqB,EAAcrC,GAAkBoC,EAAYrB,EAAQC,CAAU,IAGlE,IAAMwB,EAASgB,GAAe,SAAUH,EAAY,SAAUhB,CAAW,EACnEI,EAAQgB,GAAc,QAASJ,EAAY,SAAUjB,CAAU,EAC/DsB,EAAaC,EAAU,KAAKtB,CAAW,EACvCuB,EAAUxB,EAAW,SAAWC,EAAY,QAAUD,EAAW,MAAM,CAACyB,EAAG1B,IAAM0B,IAAMxB,EAAYF,CAAC,CAAC,EACrGO,EAAmB1B,EAAW,0BAA4B,qBAC1D8C,EAAWrB,EAAM,KAAK,MACtBsB,EAAmBC,GAA+B;AAAA,QACtDJ,EAAU,GAAK;AAAA,QACfhE,GAA2CoB,EAAW,wBAAyB8C,CAAQ,CAAC;AAAA,SACvF,IAAM,CACP,OAAQ9C,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA,gBACHb,GAAkBsC,EAAOL,CAAU,CAAC;AAAA,gBACpCvC,GAA4BmB,EAAW,YAAaO,EAAcuC,CAAQ,CAAC;AAAA,gBAE3E5D,GACIuC,EAAOD,EAAQJ,EAAYC,EAAatB,EAAQU,EAAKiB,CAAgB,CAAC;AAAA,gBAEhF,IAAK,SACH,MAAO;AAAA,gBACHzC,GAA0CuC,EAAQJ,EAAYC,EAAatB,EAAQU,CAAG,CAAC;AAAA,gBAEvFrB,GACIqC,EAAOD,EAAQJ,EAAYrB,EAAQ2B,EAAkB1B,EAAW,kBAAkB,CAAC;AAAA,gBAE7F,IAAK,QACH,MAAO;AAAA,cAEHX,GACIoC,EAAOD,EAAQJ,EAAYC,EAAatB,EAAQU,EAAKT,EAAW,YAAa0B,EAC7E1B,EAAW,mBAAoBA,EAAW,cAAc,CAAC;AAAA,cAEnE,QACE,MAAM,MAAM,qBAAqB,CACrC,CACF,GAAG,CAAC;AAAA,OACH;AAAA,QACCgD,EAAa,iBAAiBvB,EAAOD,CAAM,CAAC;AAAA,QAC5CwB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCN,CAAU,CAAC;AAAA,UAC9DE,EAAU,0CAA4C;AAAA,8BAClCpB,EAAO,gBAAgB,YAAY,CAAC;AAAA,4BACtCC,EAAM,KAAK,OAAO;AAAA,WACnC,IAAM,CACT,OAAQzB,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA;AAAA,+CAE4ByB,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA,yCAE3CzB,EAAW,kBAAkB;AAAA,mBAE5D,IAAK,SACH,MAAO,6DACT,IAAK,QACH,MAAO,4DACT,QACE,MAAM,MAAM,4BAA4BA,EAAW,IAAI,EAAE,CAC7D,CACF,GAAG,CAAC;AAAA,SACD;AAAA,SAGH,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM,GAAGA,EAAW,QAAQ,IAAIO,CAAY,IAAIR,EAAO,OAAS,EAAIA,EAAS,EAAE,IAC3ES,EAAM,OAAS,EAAIA,EAAQ,EAAE,IAAIoC,CAAO,EAC9C,EACA,gBAAAG,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM1B,EAAa,SAAUgB,EAAY,QAAQ,CAAC,EAC7D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEEnD,GAAuC0D,GAAoC,CAC/E,IAAMC,EAAmBD,EAAQ,iBAGjC,OAF2B,IAAI,YAAYC,EAAkBA,EAAiB,WAAY,CAAC,EACnD,CAAC,CAE3C,EAEa1D,GAAS,CAACyD,EAAyBjD,IAAuC,CACrF,IAAMD,EAAmB,CAAC,EACpBS,EAAkB,CAAC,EACnBC,EAAgB,CAAC,EACjBF,EAAehB,GAAoC0D,CAAO,EAChEtE,GAAesE,EAAQ,OAAQjD,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAC3EwC,EAAQ,QACJ3D,GAAwB2D,EAAQ,OAAO,CAAC,EAAGjD,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC7G,EAEahB,GAAyBO,GAA0D,CAC9F,IAAMmD,EAAYnD,EAAW,UACvBE,EAAOF,EAAW,KAClBoD,EACFpD,EAAW,wBACTgC,EAAchC,EAAW,YACzBiC,EAAiBjC,EAAW,iBAA6B,EACzD2B,EAAqB3B,EAAW,mBAChCqD,EAA+CrD,EAAW,sBAC1DsD,EAAatD,EAAW,KAExBe,EAA4Bf,EAAW,cAAgB,GAAK,SAAWA,EAAW,YACxF,OAAOuD,GAA4B,CACjC,UAAAJ,EACA,KAAAjD,EACA,wBAAAkD,EACA,YAAApB,EACA,eAAAC,EACA,mBAAAN,EACA,sBAAA0B,EACA,KAAAC,EACA,YAAAvC,CACF,CAAC,CACH,IC1jBA,IAeMyC,GAyDAC,GAyFOC,GAoBAC,GArLbC,GAAAC,GAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,IAAMC,EAAoBD,EAAO,CAAC,EAC5BE,EAAmBF,EAAO,CAAC,EAC3BG,EAAoBH,EAAO,CAAC,EAElC,GAAIC,EAAM,WAAaC,EAAK,UAAYD,EAAM,WAAaE,EAAM,SAC/D,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAIF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAIC,EAAK,KAAK,SAAW,GAAKA,EAAK,KAAK,SAAW,EACjD,MAAM,IAAI,MAAM,uBAAuB,EAGzC,IAAME,EAAaH,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EAC7CI,EAAiBJ,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EACvD,GAAIC,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAME,EACtC,MAAM,IAAI,MAAM,8CAA8C,EAEhE,GAAIF,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMG,EACtC,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIF,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,IAAMC,EACxC,MAAM,IAAI,MAAM,+CAA+C,EAEjE,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBN,EAAO,CAAC,EACjC,GAAIM,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMF,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CAEA,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMO,EAAmBP,EAAO,CAAC,EACjC,GAAIO,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMH,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CACF,EAEMb,GACF,CAACS,EAA+BQ,EAAqCC,EAAqBC,IACvE,CACb,IAAMC,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAcH,EACdI,EAAaH,EACbR,EAAaO,EAAW,MAAM,EAAE,EAAE,CAAC,EACnCK,EAAmBN,EAAaC,EAAW,MAAM,EAAG,EAAE,EAAE,OAAO,CAAC,EAAI,CAAC,EACrEM,EAAejB,EAAO,OAAS,EAC/BkB,EAAelB,EAAO,OAAS,EAC/BmB,EAAgBT,GAAcD,EAAc,EAC5CW,EAAqBV,GAAcD,EAAc,EACjDY,EAA4BZ,EAAc,EAE1Ca,EAAaC,GAAiBnB,CAAU,EACxCoB,EAAY,CAChBC,GAAc,IAAKzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACjEG,GAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACpEG,GAAc,QAASzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CACvE,EACIL,GACFO,EAAU,KAAKC,GAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAElFJ,GACFM,EAAU,KAAKC,GAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAEtFE,EAAU,KAAKE,GAAe,SAAU1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAChFH,GACFK,EAAU,KAAKE,GAAe,eAA8BV,CAAgB,CAAC,EAE3EI,GACFI,EAAU,KAAKE,GAAe,iBAAgCV,CAAgB,CAAC,EAE7EK,GACFG,EAAU,KAAKE,GAAe,mBAAoB1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAEhG,IAAMK,EAAWC,GAA4B5B,EAAO,CAAC,EAAE,QAAQ,EACzD6B,EAAmBC,GAA+B;AAAA,gCAClC1B,CAAU;AAAA,0CACAA,EAAakB,CAAU;AAAA,6BACpCd,EAAW,OAAO;AAAA;AAAA,QAEvCsB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA;AAAA,QAE3CM,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCf,EAAaX,CAAU,CAAC;AAAA;AAAA,oBAEjE2B,GAAW,MAAOT,CAAU,CAAC;AAAA,0BACvBS,GAAW,MAAOT,CAAU,CAAC;AAAA;AAAA;AAAA,4BAG3BJ,EAAe,UAAY,KAAK;AAAA;AAAA;AAAA,YAGhDG,EAA4B,wCAA0C,EAAE;AAAA;AAAA,2BAEzDW,GAAUL,EAAUL,EAAY,OAAO,CAAC;AAAA;AAAA;AAAA;AAAA,qBAI9CW,GAAU,MAAOX,CAAU,CAAC;AAAA,8BACnBW,GAAU,YAAaX,CAAU,CAAC;AAAA,UACtDH,EAAgB,iCAAmC,EAAE;AAAA,UACrDC,EAAqB,6CAA+C,EAAE;AAAA;AAAA,uDAEzBO,CAAQ,aAAaA,CAAQ;AAAA,eACrEV,EAAe,UAAY,KAAK;AAAA;AAAA,SAG/BiB,EAAU,CAAC,CAAC,KAAMpB,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIS,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMvB,EAAY,SAAUX,EAAO,CAAC,EAAE,QAAQ,CAAC,EAGxD,CACL,KAAM,yBACN,YAAa,CAAC,KAAMQ,EAAW,QAAQ,EACvC,gBAAAqB,EACA,WAAY,KAAO,CAAC,QAAAK,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKnB,EAAaX,EAAa,EAAE,CAAC,CAAC,EAC1F,CACF,EAEKZ,GAAgB,CAAC2C,EAAyB3B,IAA8C,CAGnGlB,GAAe6C,EAAQ,MAAM,EAG7B,IAAMD,EAAU,CAAC,CAAC,EACdC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAK,CAAC,EAEhBC,EAAQ,QACJ5C,GAA+B4C,EAAQ,OAAQ3B,EAAY2B,EAAQ,YAAa,EAAU,EAAG,CAAC,QAAAD,CAAO,CAAC,CAC5G,EAEazC,GAAgCe,GAAiE,CAC5G,IAAM4B,EAAU5B,EAAW,QAC3B,OAAO6B,GAA4B,CAAC,QAAAD,CAAO,CAAC,CAC9C,ICxLA,IAiBME,GAkBAC,GAcAC,GAeAC,GAcAC,GAsBAC,GAmFOC,GAYAC,GAnMbC,GAAAC,GAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAQMb,GAAiB,CAACc,EAA+BC,IAAsC,CAC3F,GAAI,CAACD,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIC,EAAW,KAAK,SAAW,GAC7B,GAAIA,EAAW,KAAK,SAAWA,EAAW,OAAO,QAAUA,EAAW,KAAK,SAAWA,EAAW,KAAK,OACpG,MAAM,IAAI,MAAM,iDAAiD,UAE1DA,EAAW,OAAO,SAAWA,EAAW,KAAK,OACtD,MAAM,IAAI,MAAM,2CAA2C,EAE7DD,EAAO,MAAM,CAAC,EAAE,QAAQ,CAACE,EAAGC,IAAQ,CAClC,GAAIH,EAAOG,EAAM,CAAC,EAAE,WAAa,GAAkBH,EAAOG,EAAM,CAAC,EAAE,WAAa,EAC9E,MAAM,IAAI,MAAM,SAASA,CAAG,qCAAqC,CAErE,CAAC,CACH,EAEMhB,GAAY,CAACa,EAA+BG,IAA0B,CAC1E,IAAMC,EAAkB,CAAC,EACzB,GAAIJ,EAAO,OAASG,EAClB,GAAIH,EAAOG,CAAG,EAAE,WAAa,EAC3BH,EAAOG,CAAG,EAAE,iBAAiB,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,UACxDL,EAAOG,CAAG,EAAE,WAAa,EAClCH,EAAOG,CAAG,EAAE,cAAc,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,MAE9D,OAAM,IAAI,MAAM,SAASF,CAAG,qCAAqC,EAGrE,OAAOC,CACT,EAEMhB,GACF,CAACY,EAA+BC,IAAiD,CAC/E,GAAID,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBnB,GAAUa,EAAQ,CAAC,EACtCO,EAAiBpB,GAAUa,EAAQ,CAAC,EACtCQ,EAAiBrB,GAAUa,EAAQ,CAAC,EACxC,OAAIQ,EAAK,SAAW,IAClBA,EAAO,CAAC,GAAG,MAAMR,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,KAAK,CAAC,GAEzCS,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,KACE,QAAOP,CAEX,EAEEZ,GACF,CAACqB,EAAeC,EAAeC,EAA+BJ,EAAyBK,IACzE,CACR,IAAIC,EAAWJ,EAIf,OAHIA,EAAQ,IACVI,GAAYF,EAAWJ,EAAKG,CAAK,CAAC,GAEhCE,EAAMF,CAAK,EAAI,EACV,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,EAAI,CAAC,CAAC,EAE3D,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,CAAC,CAAC,CAElE,EAEFrB,GACF,CAACc,EAAsBW,EAAuBH,EAA+BI,IAC/D,2CAA2CD,EAAO,KAAK,OAAO,QAAQX,EAAM,KAAK,OAAO;AAAA,8BAC5EA,EAAM,KAAK,OAAO;AAAA;AAAA,yBAEvBQ,EAAW,MAAM;AAAA,kCACRK,GAAa,uBAAwB,IAAKL,EAAW,MAAM,CAAC;AAAA,4BAClEK,GAAa,iBAAkB,IAAKL,EAAW,MAAM,CAAC;AAAA,4BACtDK,GAAa,iBAAkB,IAAKL,EAAW,MAAM,CAAC;AAAA,6BACrDK,GAAa,kBAAmB,IAAKL,EAAW,MAAM,CAAC;AAAA,gCACpDI,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAOjFJ,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA,SAKpErB,GAAyB,CAACS,EAA+BC,IAA6C,CAC1G,IAAMW,EAAaZ,EAAO,CAAC,EAAE,KACvBkB,EAAYC,EAAU,KAAKP,CAAU,EACrCJ,EAAQP,EAAW,KAAK,OAAS,EAAKkB,EAAU,cAAclB,EAAW,KAAMW,EAAW,MAAM,EAC1D,CAAC,GAAG,MAAMA,EAAW,MAAM,EAAE,KAAK,CAAC,EAC3EC,EAAQ1B,GAAUa,EAAQ,CAAC,EAC/Ba,EAAM,QAASO,GAASA,IAAS,IAAM,IAAM,CACnB,MAAM,IAAI,MAAM,kBAAkB,CACpC,EAAE,EACtBP,EAAM,SAAW,IACnBA,EAAQ,MAAML,EAAK,MAAM,EAAE,KAAK,CAAC,GAEnC,IAAMF,EAASL,EAAW,OAAO,IAAI,CAACoB,EAAOC,IAAMjC,GAAkBgC,EAAOC,EAAGV,EAAYJ,EAAMK,CAAK,CAAC,EAEjGN,EAAON,EAAW,KAAK,IAAI,CAACsB,EAAKD,IAAMjC,GAAkBkC,EAAKD,EAAGV,EAAYJ,EAAMK,CAAK,CAAC,EAE/F,GAAIL,EAAK,SAAWF,EAAO,QAAUE,EAAK,SAAWD,EAAK,OACxD,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIC,EAAK,SAAWI,EAAW,OAC7B,QAASU,EAAI,EAAGA,EAAIV,EAAW,OAAQ,EAAEU,EAClCd,EAAK,SAASc,CAAC,IAClBhB,EAAO,OAAOgB,EAAG,EAAG,CAAC,EACrBf,EAAK,OAAOe,EAAG,EAAGV,EAAWU,CAAC,CAAC,EAC/BT,EAAM,OAAOS,EAAG,EAAG,CAAC,GAI1B,IAAME,EAAQX,EAAM,IAAIO,GAAQ,KAAK,KAAKA,CAAI,CAAC,EAE/CP,EAAM,QAAQ,CAACO,EAAME,EAAGG,IAAU,CAChC,GAAIL,EAAO,EAAG,CACZ,IAAMM,GAAYnB,EAAKe,CAAC,EAAIhB,EAAOgB,CAAC,GAAKF,EACnCO,EAASrB,EAAOgB,CAAC,EACjBM,EAAWD,EAASD,EAAWb,EAAMS,CAAC,EAC5ChB,EAAOgB,CAAC,EAAIM,EACZrB,EAAKe,CAAC,EAAIK,EACVF,EAAMH,CAAC,EAAI,CAACF,CACd,CACF,CAAC,EAED,IAAMJ,EAAcJ,EAAW,MAAM,CAAC,EACtCJ,EAAK,QAAQ,CAACqB,EAAM3B,IAAM,CACxBc,EAAYa,CAAI,EAAI,KAAK,MAAMtB,EAAKsB,CAAI,EAAIvB,EAAOuB,CAAI,GAAKhB,EAAMgB,CAAI,CAAC,CACzE,CAAC,EACD,IAAMC,EAA+B,CAAC,KAAMd,EAAa,SAAUhB,EAAO,CAAC,EAAE,QAAQ,EAE/Ee,EAASgB,GAAe,SAAU/B,EAAO,CAAC,EAAE,SAAUgB,EAAY,MAAM,EACxEZ,EAAQ4B,GAAc,QAAShC,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACxEiC,EAAad,EAAU,KAAKH,CAAW,EACvCkB,EAA8B,CAClC,CAAC,KAAM,aAAc,KAAM,KAAK,EAAG,CAAC,KAAM,SAAU,KAAM,MAAO,OAAQ5B,EAAO,MAAM,EACtF,CAAC,KAAM,QAAS,KAAM,MAAO,OAAQkB,EAAM,MAAM,EAAG,CAAC,KAAM,QAAS,KAAM,MAAO,OAAQX,EAAM,MAAM,CACvG,EAEMsB,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAMF,CAAU,EAAG,CAAC,KAAM,SAAU,KAAM3B,CAAM,EAAG,CAAC,KAAM,QAAS,KAAMkB,CAAK,EAC/F,CAAC,KAAM,SAAU,KAAMX,CAAK,EAAG,GAAGuB,GAA2BpC,EAAO,CAAC,EAAE,IAAI,EAC3E,GAAGoC,GAA2BpB,CAAW,CAC3C,EAEMqB,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiBJ,CAAQ,EAAE,iBAAiB9B,EAAOW,CAAM,CAAC;AAAA,UACrEzB,GAA0Bc,EAAOW,EAAQH,EAAYI,CAAW,CAAC;AAAA,UACjEsB,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,gCACrDvB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDA,EAAO,YAAY,aAAcX,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,SAE9E,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,GAAGoB,EAAM,MAAM,IAAIlB,EAAO,MAAM,IAAIO,EAAM,MAAM,GAAI,kBAAmB,CAAC,MAAM,CAAC,EACnG,gBAAAwB,EACA,WAAY,KAAO,CACjB,QAAS,CAACP,CAAgB,EAC1B,cAAe,CAAC,EAAG,KAAK,KAAKZ,EAAY,EAAuB,CAAC,EACjE,gBAAAiB,CACF,EACF,CACF,EAEa3C,GAAQ,CAAC+C,EAAyBtC,IAAsC,CACnFf,GAAeqD,EAAQ,OAAQtC,CAAU,EACzC,IAAMuC,EAAoBpD,GAAgCmD,EAAQ,OAAQtC,CAAU,EACpFsC,EAAQ,QAAQhD,GAAuBgD,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAO1F,EAEa/C,GAAwBQ,GAAyD,CAC5F,IAAMK,EAASL,EAAW,OACpBM,EAAON,EAAW,KAClBO,EAAOP,EAAW,KACxB,OAAOQ,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,ICxMA,IAcMiC,GAUAC,GAwHOC,GAKAC,GArJbC,GAAAC,GAAA,kBAQAC,KACAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,8BAA8B,CAElD,EAMMR,GAA2B,CAACS,EAAmBC,IAA+C,CAClG,IAAMC,EAAQF,EAAM,KACdG,EAAaC,EAAU,KAAKF,CAAK,EACjCG,EAAK,GACPC,EAAOL,EAAW,KAItB,GAHIK,EAAO,IACTA,EAAOJ,EAAM,OAASI,GAEpBA,EAAOJ,EAAM,OAAS,EACxB,MAAM,IAAI,MAAM,0CAA0C,EAG5D,IAAMK,EAAOL,EAAMI,CAAI,EACjBE,EAAOL,EAAaI,EACpBE,EAAaC,GAAiBH,CAAI,EAClCI,EAAaJ,EAAOE,EAEpBG,EAAY,CAACC,EAAcJ,IAC3BA,IAAe,EACV,WAAWI,CAAI,OAAOA,CAAI,YAAYA,CAAI,OAAOA,CAAI,OACnDJ,IAAe,EACjB,OAAOI,CAAI,OAAOA,CAAI,MACpBJ,IAAe,EACjB,WAAWI,CAAI,OAAOA,CAAI,QAAQA,CAAI,MAGxCA,EAEHC,EAAIC,GAAc,IAAKf,EAAM,SAAUA,EAAM,KAAMS,CAAU,EAC7DO,EAASC,GAAe,SAAUjB,EAAM,SAAUA,EAAM,KAAMS,CAAU,EACxES,EAAYJ,EAAE,KAAK,MAEnBK,EAAgBC,GAA4BpB,EAAM,QAAQ,IAAM,MAClE,mBAAmBkB,CAAS,oBAC5B,mBAAmBA,CAAS,eAC1BG,EAAmBC,GAA+B;AAAA,sCACpBJ,CAAS;AAAA,sCACTA,CAAS;AAAA,4CACHA,CAAS,KAAKb,CAAE;AAAA;AAAA,4DAEAa,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,gEAKLA,CAAS;AAAA;AAAA;AAAA;AAAA,QAIjEI,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBR,EAAGE,CAAM,CAAC;AAAA,QAC7EM,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA,qBAGXjB,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAMbc,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAmBID,CAAS,IAAIN,EAAU,kBAAmBH,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,0BAKtDS,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAeRA,CAAS,IAAIK,GAAU,kBAAmBd,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAU9E,MAAO,CACL,KAAM,UACN,YAAa,CAAC,KAAM,GAAGA,CAAU,GAAI,kBAAmB,CAAC,MAAM,CAAC,EAChE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMP,EAAO,SAAUF,EAAM,QAAQ,CAAC,EACjD,cAAe,CAAC,EAAGQ,CAAI,EACvB,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAMG,CAAU,CAAC,CACtD,GACA,gBAAAU,CACF,CACF,EAEa7B,GAAU,CAACgC,EAAyBvB,IAAwC,CACvFX,GAAekC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAyBiC,EAAQ,OAAO,CAAC,EAAGvB,CAAU,CAAC,CACzE,EAEaR,GAA0BQ,GACnCwB,GAA4B,CAAC,KAAMxB,EAAW,IAAc,CAAC,ICtJjE,IAgBMyB,GAMAC,GAWAC,GASAC,GAqBAC,GAkDOC,GAOAC,GAxHbC,GAAAC,GAAA,kBAIAC,KACAC,KAGAC,KAQMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,CAEpC,EAEMX,GACF,CAACW,EAA+BC,IAAiD,CAC/E,IAAMC,EAAuB,CAAC,EAC1BC,EAAqBF,EAAW,WACpC,OAAID,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQI,GAAKF,EAAW,KAAK,OAAOE,CAAC,CAAC,CAAC,EACpED,EAAaD,EAAW,QAEnBG,GAA4B,CAAC,WAAAF,EAAY,KAAMF,EAAW,KAAM,WAAAC,CAAU,CAAC,CACpF,EAEEZ,GAA4BgB,GAAoC;AAAA;AAAA,gCAEtCA,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,GAEtBf,GAAuBgB,GAAsC,CACjE,IAAMD,EAAkBC,EAAQ,OAC1BC,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIH,EAAiB,EAAEG,EAAG,CACxC,IAAMC,EAAgBH,EAAQE,CAAC,EAAE,aAAa,UAAW,mBAAmB,EACxEH,IAAoB,EACtBE,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,uBAAuBC,CAAC,QAAQC,CAAa,IAAI,EACvDD,IAAMH,EAAkB,EACjCE,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,4BAA4BC,CAAC,OAAOC,CAAa,IAAI,CAExE,CACA,MAAO;AAAA,uDAC8CH,EAAQ,CAAC,EAAE,KAAK,OAAO;AAAA,UACpEC,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,QAE9B,EAEMhB,GAAyB,CAACQ,EAA+BC,IAA6C,CAC1G,IAAMU,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAWd,EAAO,CAAC,EAAE,SACrBe,EAAOJ,EAAW,OAClBK,EAAOf,EAAW,KAClBgB,EAAgBD,EAAO,EAAKL,EAAW,OAASK,EAAOA,EACvDT,EAAU,IAAI,MAAqBN,EAAW,UAAU,EACxDiB,EAAQC,GAAc,QAASL,EAAUH,CAAU,EACnDS,EAAmB,IAAI,MAAcnB,EAAW,UAAU,EAC1DoB,EAAkC,CAAC,EACnCC,EAA2B,CAAC,EAC9BC,EAAc,EAClB,QAASd,EAAI,EAAGA,EAAIR,EAAW,WAAYQ,IAAK,CAC9Cc,GAAetB,EAAW,WAAWQ,CAAC,EACtCW,EAAiBX,CAAC,EAAIc,EACtB,IAAMC,EAAcb,EAAW,MAAM,EACrCa,EAAYvB,EAAW,IAAI,EAAIA,EAAW,WAAWQ,CAAC,EACtDa,EAAa,KAAKE,CAAW,EAC7BjB,EAAQE,CAAC,EAAIgB,GAAe,SAAShB,CAAC,GAAIK,EAAUQ,EAAab,CAAC,CAAC,EACnEY,EAAkB,KAAK,CAAC,KAAMC,EAAab,CAAC,EAAG,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,CAC9E,CACA,IAAM0B,EAAcX,EAAO,EAAI,UAAY,WAAWE,CAAY,IAC5DU,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,iBAAiBV,EAAO,GAAGX,CAAO,CAAC;AAAA,wCACZa,EAAiB,MAAM,KAAKA,EAAiB,IAAIX,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,IAC5GnB,GAAyB8B,EAAiB,MAAM,CAAC;AAAA,IACjD7B,GAAoBgB,CAAO,CAAC;AAAA;AAAA,IAE5BqB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,oBAE/CM,EAAM,gBAAgB,YAAY,CAAC;AAAA,8CACTQ,CAAW;AAAA;AAAA,UAE/CA,CAAW;AAAA;AAAA;AAAA,KAInB,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAMzB,EAAW,QAAQ,EACvC,gBAAA0B,EACA,WAAY,KAAO,CACjB,QAASN,EACT,cAAe,CAAC,EAAG,KAAK,KAAKT,EAAY,EAAuB,CAAC,CACnE,EACF,CACF,EAEanB,GAAQ,CAACoC,EAAyB5B,IAAsC,CACnFb,GAAeyC,EAAQ,MAAM,EAC7B,IAAMC,EACFD,EAAQ,OAAO,SAAW,EAAI5B,EAAaZ,GAAgCwC,EAAQ,OAAQ5B,CAAU,EACzG4B,EAAQ,QAAQrC,GAAuBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC1F,EAEapC,GAAwBO,GAAyD,CAC5F,IAAMe,EAAOf,EAAW,KAClBC,EAAuBD,EAAW,WAClCE,EAAaF,EAAW,WAAuB,EAAIC,EAAW,OAASD,EAAW,WACxF,GAAIE,IAAeD,EAAW,OAC5B,MAAM,IAAI,MAAM,+CAA+C,EAEjE,OAAOG,GAA4B,CAAC,KAAAW,EAAM,WAAAb,EAAY,WAAAD,CAAU,CAAC,CACnE,IChIA,IAUM6B,GAIAC,GAyBAC,GAUOC,GAoCAC,GArFbC,GAAAC,GAAA,kBAGAC,KAEAC,KAGAC,KAEMT,GAAcU,GAChB,MAAM,KAAKA,EAAkB,iBAAiB,EAAG,MAAM,EAGrDT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,GAChEA,EAAO,CAAC,EAAE,WAAa,GACzB,MAAM,IAAI,MAAM,uDAAuD,EAGzE,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,oCAAoC,EAKtD,GAFmCX,GAAWW,EAAO,CAAC,CAAC,EAE3C,SAAWA,EAAO,CAAC,EAAE,KAAK,OACpC,MAAM,IAAI,MAAM,uFAAuF,CAE3G,EAEMT,GAAiB,CAACU,EAA+BC,IAAkD,CACvG,IAAMC,EAAwB,CAAC,EAE/B,QAASC,EAAI,EAAGA,EAAIH,EAAW,OAAQ,EAAEG,EACvCD,EAAY,KAAKF,EAAWG,CAAC,EAAIF,EAAQE,CAAC,CAAC,EAG7C,OAAOD,CACT,EAEaX,GAAyBQ,GAA+C,CACnF,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAA6Bb,GAAWW,EAAO,CAAC,CAAC,EACjDG,EAAcZ,GAAeU,EAAYC,CAAO,EAChDG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAAWP,EAAO,CAAC,EAAE,SACrBQ,EAAQC,GAAc,QAASF,EAAUN,CAAU,EACnDS,EAASC,GAAe,SAAUJ,EAAUJ,CAAW,EAEvDS,EAAmBC,GAA+B;AAAA,2BAC/BL,EAAM,QAAQ,GAAGP,CAAU,CAAC;AAAA,QAC/CY,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,QAC5CG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,4BAC1CK,EAAO,gBAAgB,YAAY,CAAC;AAAA,0BACtCF,EAAM,KAAK,OAAO;AAAA,4BAChBP,EAAW,MAAM;AAAA,8BACfS,EAAO,WAAW,gBAAiB,GAAG,CAAC,OAAOF,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA;AAAA,UAErGA,EAAM,WAAW,eAAgB,IAAK,eAAe,CAAC;AAAA;AAAA,QAExDE,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,OAG1E,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAM,GAAGN,CAAO,EAAE,EAChC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAO,CACF,CACF,EAEanB,GAAQqB,GAAkC,CACrDxB,GAAewB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQtB,GAAsBsB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACtE,ICxFA,IAUMC,GA8DAC,GA+BOC,GAvGbC,GAAAC,GAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GACF,CAACQ,EAA4BC,EAA+BC,EAA+BC,EAC1FC,IAAuB,CACtB,IAAMC,EAAaC,EAAU,KAAKJ,CAAU,EACtCK,EAAU,KAAK,KAAKF,EAAa,CAAC,EAElCG,EAASC,GAAe,aAAcL,EAAYF,EAAY,CAAC,EAC/DQ,EAAIC,GAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEW,EAAID,GAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEY,EAAIF,GAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAElEa,EACEC,EAAa,CAACL,EAAWE,EAAWC,IAAc,UAAUD,CAAC,KAAKF,CAAC,KAAKG,CAAC,IAC/E,GAAI,CAACV,EACHW,EAAaN,EAAO,YAChB,aACAO,EAAWL,EAAE,YAAY,YAAY,EAAGE,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAChG,CACL,IAAMG,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IAE9CI,EAAc,oBAAoBJ,CAAC,OAAO,cAAiB,EAAIA,GAAK,CAAE,KAC5E,MAAO;AAAA,+BACcA,CAAC,MAAMV,EAAO,gBAAgB,qBAAqBU,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMR,EAAE,2BAA2B,gBAAgBQ,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAMN,EAAE,2BAA2B,gBAAgBM,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAML,EAAE,2BAA2B,gBAAgBK,CAAC,GAAIV,CAAM,CAAC;AAAA,wBACjEU,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIJ,EAAWK,EAAaC,EAAaC,CAAW,CAAC;AAAA,WAErF,EACIlB,IAAe,EACjBU,EAAa;AAAA;AAAA,cAETE,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCF,EAAa;AAAA,cACTE,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACHhB,EAAa,iBAAiBa,EAAGH,EAAGE,EAAGJ,CAAM,CAAC;AAAA,UAC9CR,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCO,CAAO,CAAC;AAAA,UAC3DO,CAAU;AAAA,QAEhB,EAEErB,GAA4BQ,GAA+C,CAC/E,IAAMsB,EAAQtB,EAAO,CAAC,EAAE,KAClBuB,EAAQvB,EAAO,CAAC,EAAE,KAClBwB,EAAQxB,EAAO,CAAC,EAAE,KAClByB,EAAiBzB,EAAO,CAAC,EAAE,SAE3BE,EAAc,EAAEG,EAAU,SAASiB,EAAOC,CAAK,GAAKlB,EAAU,SAASkB,EAAOC,CAAK,GACrFE,EAAcJ,EACdlB,EAAaC,EAAU,KAAKiB,CAAK,EAGrC,GAAIpB,EAAa,CACf,IAAMyB,EAAkBC,GAAc,UAAUA,GAAc,UAAUN,EAAOC,EAAO,EAAK,EAAIC,EAAO,EAAK,EAC3G,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,6CAA8C,EAEhED,EAAcC,EACdvB,EAAaC,EAAU,KAAKqB,CAAW,CACzC,CAEA,MAAO,CACL,KAAM,QACN,gBAAkB3B,GACdR,GAA2BQ,EAAcC,EAAQ0B,EAAaxB,EAAauB,CAAc,EAC7F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUD,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKrB,EAAa,GAA0B,CAAgB,CAAC,CACvF,EACF,CACF,EAEaX,GAASoC,GAAkC,CACtDA,EAAQ,QAAQrC,GAAyBqC,EAAQ,MAAM,CAAC,CAC1D,ICzGA,IAwCaC,GAxCbC,GAAAC,GAAA,kBAGAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KAOajC,GAA+D,IAAI,IAAI,CAClF,CAAC,MAAO,CAAUkC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAwB,CAAC,EAC7C,CAAC,SAAU,CAACC,GAAQD,EAAwB,CAAC,EAC7C,CAAC,OAAQ,CAAUE,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACC,GAAWC,EAAwB,CAAC,EAEnD,CAAC,cAAe,CAAMC,GAAkBC,EAA0B,CAAC,EACnE,CAAC,qBAAsB,CAACC,EAAS,CAAC,EAClC,CAAC,UAAW,CAACC,EAAO,CAAC,EACrB,CAAC,gBAAiB,CAACC,EAAa,CAAC,EACjC,CAAC,OAAQ,CAAUC,GAAeC,EAAmB,CAAC,EACtD,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,gBAAiB,CAACC,GAAeC,EAA4B,CAAC,EAC/D,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,MAAO,CAAUC,GAAcC,EAAoB,CAAC,EACrD,CAAC,QAAS,CAAWC,EAAK,CAAC,EAC3B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EACnB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACf,GAAMC,EAAmB,CAAC,EACzC,CAAC,SAAU,CAACe,GAAQC,EAAqB,CAAC,EAC1C,CAAC,iBAAkB,CAACC,GAAgBC,EAA6B,CAAC,EAClE,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,oBAAqB,CAAMC,GAAwBC,EAAgC,CAAC,EACrF,CAAC,gBAAiB,CAAMC,GAAoBC,EAA4B,CAAC,EACzE,CAAC,UAAW,CAAWC,EAAO,CAAC,EAC/B,CAAC,iBAAkB,CAAWC,EAAc,CAAC,EAC7C,CAAC,wBAAyB,CAACC,GAAcC,EAA2B,CAAC,EACrE,CAAC,qBAAsB,CAACC,GAAWC,EAAwB,CAAC,EAC5D,CAAC,YAAa,CAAUC,GAAoBvB,EAAoB,CAAC,EACjE,CAAC,OAAQ,CAAWwB,EAAI,CAAC,EACzB,CAAC,cAAe,CAAWC,EAAW,CAAC,EACvC,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EAEnB,CAAC,UAAW,CAAMC,GAAcC,EAAsB,CAAC,EACvD,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,qBAAsB,CAACC,GAAoBC,EAAiC,CAAC,EAC9E,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAACC,GAAKC,EAAkB,CAAC,EACjC,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,QAAS,CAACC,EAAK,CAAC,EACjB,CAAC,aAAc,CAAUC,EAAU,CAAC,EACpC,CAAC,YAAa,CAACC,GAAWC,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACC,GAAYD,EAAqB,CAAC,EAClD,CAAC,YAAa,CAACE,GAAWF,EAAqB,CAAC,EAChD,CAAC,YAAa,CAACG,GAAWH,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACI,GAAYJ,EAAqB,CAAC,EAClD,CAAC,WAAY,CAACK,GAAUL,EAAqB,CAAC,EAC9C,CAAC,WAAY,CAACM,GAAUN,EAAqB,CAAC,EAC9C,CAAC,eAAgB,CAACO,GAAcP,EAAqB,CAAC,EACtD,CAAC,kBAAmB,CAACQ,GAAiBR,EAAqB,CAAC,EAC5D,CAAC,kBAAmB,CAACS,GAAiBT,EAAqB,CAAC,EAC5D,CAAC,OAAQ,CAAUU,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,yBAA0B,CAACC,GAAeC,EAA4B,CAAC,EACxE,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAACC,GAASC,EAAsB,CAAC,EAC7C,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,kBAAmB,CAAUC,GAA0BrE,EAAoB,CAAC,EAC7E,CAAC,OAAQ,CAACsE,EAAI,CAAC,EACf,CAAC,YAAa,CAACC,GAAWC,EAAwB,CAAC,EACnD,CAAC,QAAS,CAACC,EAAK,CAAC,CACnB,CAAC,IC9HD,IAoBaC,GApBbC,GAAAC,GAAA,kBAGAC,KAEAC,KAGAC,KAYaL,GAAN,KAAqB,CAI1B,YAAoBM,EAAwB,CAAxB,aAAAA,EAClB,KAAK,KAAO,IAAI,IAChB,KAAK,gBAAkB,EACzB,CACA,YAAYC,EAAkC,CAC5C,OAAO,KAAK,KAAK,IAAIA,CAAG,CAC1B,CACA,YAAYA,EAAcC,EAA0B,CAClD,KAAK,KAAK,IAAID,EAAKC,CAAQ,CAC7B,CACA,IAAIC,EAAyBC,EAAyCC,EAClEC,EAAmBC,EAAoBC,EACvCC,EAA0D,CAC5D,IAAMC,EAAS,KAAK,QAAQ,OAEtBC,EAAqB,KAAK,QAAQ,sBAAsB,EAC9DA,EAAmB,YAAYR,EAAc,eAAe,EAC5D,IAAMS,EAAU,CAAC,EACjB,QAAWC,KAASP,EAClBM,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQC,EAAM,MAAM,CAAC,CAAC,EAE1E,QAAWC,KAAUP,EACnBK,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQE,EAAO,MAAM,CAAC,CAAC,EAEvEL,GACFG,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAUH,CAAoB,CAAC,EAExE,IAAMM,EAAYL,EAAO,gBACrB,CAAC,OAAQP,EAAc,gBAAgB,mBAAmB,CAAC,EAAG,QAAAS,EAAS,MAAOT,EAAc,YAAY,IAAI,CAAC,EAOjH,GANAQ,EAAmB,aAAa,EAAGI,CAAS,EAE5CJ,EAAmB,mBAAmB,GAAGH,CAAa,EAEtD,KAAK,QAAQ,wBAET,KAAK,QAAQ,eAAe,EAAG,CAC7B,OAAO,KAAK,QAAQ,UAAc,MACpC,KAAK,QAAQ,UAAY,KAAK,QAAQ,eAAe,OAEjD,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,aAAa,GAE5F,IAAMQ,EAAW,KAAK,QAAQ,eAAe,OAEzC,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,QAAQ,EAErF,KAAK,QAAQ,eAAe,EAC5B,KAAK,QAAQ,kBAAkB,EAAE,gBAAgB,KAAK,QAAQ,SAAW,EAAG,EAAG,KAAK,QAAQ,UAAU,OAAQ,CAAC,EAC/G,KAAK,QAAQ,kBAAkB,EAAE,mBAC7B,KAAK,QAAQ,UAAU,OAAQ,EAAGA,EAAS,OAAQ,EAAG,KAAK,QAAQ,cAAgB,CAAC,EACxF,KAAK,QAAQ,MAAM,EAEnB,IAAMC,EAAW,KAAK,QAAQ,gBACxBC,EAAa,KAAK,QAAQ,QAAQ,IAAID,CAAQ,EAC9CE,EAAa,IAAID,EAAW,CAAC,CAAC,KAAKA,EAAW,CAAC,CAAC,GAEjDF,EAAS,OAAO,SAAS,WAAW,IAAI,EAAE,KAAK,IAAM,CACxD,IAAMI,EAAa,IAAI,eAAeJ,EAAS,OAAO,eAAe,CAAC,EAChEK,EAAeD,EAAW,CAAC,EAC3BE,EAAaF,EAAW,CAAC,EAE/BJ,EAAS,OAAO,MAAM,EAElB,OAAO,KAAK,QAAQ,cAAkB,MACxC,KAAK,QAAQ,cAAgBK,GAG/B,IAAME,EAAY,OAAOF,EAAe,KAAK,QAAQ,aAAa,EAC5DG,EAAU,OAAOF,EAAa,KAAK,QAAQ,aAAa,EAE9D,GAAI,CAAC,OAAO,cAAcC,CAAS,GAAK,CAAC,OAAO,cAAcC,CAAO,EACnE,MAAM,IAAI,WAAW,2BAA2B,EAGlD,KAAK,QAAQ,eAAe,QAAQR,EAAS,EAAE,EAC/C,IAAIS,EAAc,GAClBrB,EAAiB,QAAQ,CAACsB,EAAOC,IAAM,CACrCF,GAAe,SAASE,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC7F,CAAC,EACD,IAAIG,EAAe,GACnBxB,EAAkB,QAAQ,CAACqB,EAAOC,IAAM,CACtCE,GAAgB,UAAUF,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC/F,CAAC,EAED,QAAQ,IAAI,uBAAuBT,CAAQ,IAAIE,CAAU,IAAIhB,EAAc,YAAY,IAAI,KAAKsB,CAAW,GACvGI,CAAY,mBAAmBL,EAAUD,CAAS,KAAK,CAC7D,CAAC,CACH,CAEI,KAAK,QAAQ,uBAAyB,IACxC,KAAK,QAAQ,MAAM,CAEvB,CACA,SAAgB,CAEhB,CACA,MAAMO,EAA0BC,EAAiE,CAC/F,IAAMrB,EAAS,KAAK,QAAQ,OACtBsB,EAAuB,CAAC,EAC1BtB,EAAO,SAAS,IAAI,YAAY,GAClCsB,EAAW,KAAK,aAAa,EAE/B,IAAMC,EAAeC,GAAmBH,CAA2B,EAC7DI,EAAWL,EAAY,gBAAgBG,CAAY,EACnDG,EAAO,GAAGJ,EAAW,KAAK;AAAA,CAAI,CAAC;AAAA,EAAKC,EAAa,yBAAyB;AAAA,EAAKE,CAAQ,GACvFE,EAAe3B,EAAO,mBAAmB,CAAC,KAAA0B,EAAM,MAAON,EAAY,IAAI,CAAC,EAC9EQ,GAAU,UAAW,IAAM,YAAYR,EAAY,IAAI,iBAAiBM,CAAI,EAAE,EAE9E,IAAMG,EAAkB7B,EAAO,sBAC3B,CAAC,QAAS,CAAC,OAAQ2B,EAAc,WAAY,MAAM,EAAG,OAAQ,OAAQ,MAAOP,EAAY,IAAI,CAAC,EAElG,MAAO,CAAC,YAAAA,EAAa,gBAAAS,CAAe,CACtC,CAEA,2BAA2B/B,EACE,CAC3B,IAAMgC,EAAI,OAAOhC,GAAkB,SAAWA,EAAgBA,EAAc,EACtEiC,EAAI,OAAOjC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEkC,EAAI,OAAOlC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEmC,EAAoB,KAAK,QAAQ,OAAO,OAAO,iCACrD,GAAIH,GAAKG,GAAqBF,GAAKE,GAAqBD,GAAKC,EAC3D,MAAO,CAACH,EAAGC,EAAGC,CAAC,EAEjB,IAAME,EAAOJ,EAAIC,EAAIC,EACjBG,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EAC/C,GAAIC,EAAkBF,EAAmB,CAEvC,GADAE,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EACvCC,EAAkBF,EACpB,MAAM,IAAI,MAAM,6CAA6C,EAE/D,MAAO,CAACE,EAAiBA,EAAiBA,CAAe,CAC3D,KACE,OAAO,CAACA,EAAiBA,EAAiB,CAAC,CAE/C,CACF,IC9JA,IAYMC,GA4CAC,GAqBOC,GA7EbC,GAAAC,GAAA,kBAKAC,KACAC,KACAC,KACAC,KACAC,KAGMT,GACF,CAACU,EAAqCC,IAA2E,CAC/G,GAAIA,EAAkB,SAAWD,EAAa,OAC5C,MAAM,IAAI,MAAM,4BAA4BC,EAAkB,MAAM,wCAChED,EAAa,MAAM,GAAG,EAG5B,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIH,EAAa,OAAQ,EAAEG,EAAG,CAC5C,IAAMC,EAAOJ,EAAaG,CAAC,EAAE,SAC7B,OAAQF,EAAkBE,CAAC,EAAG,CAC5B,IAAK,OAAQ,CACXD,EAAW,KAAK,EAAE,EAClB,KACF,CACA,IAAK,OAAQ,CACXA,EAAW,KAAK,GAAGE,CAAI,EAAE,EACzB,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAOL,EAAaG,CAAC,EAAE,KAAK,OAClCD,EAAW,KAAK,GAAGE,CAAI,IAAIC,CAAI,EAAE,EACjC,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAON,EAAaG,CAAC,EAAE,KAAK,KAAK,GAAG,EAC1CD,EAAW,KAAK,GAAGE,CAAI,IAAIE,CAAI,EAAE,EACjC,KACF,CACA,QACE,MAAM,IAAI,MAAM,iCAAiCL,EAAkBE,CAAC,CAAC,EAAE,CAC3E,CACF,CAEA,OAAOD,EAAW,KAAK,GAAG,CAC5B,EASEX,GACF,CAACgB,EAA0BP,EAAqCQ,IAA0C,CAGxG,IAAIC,EAAMF,EAAY,KACtB,OAAIA,EAAY,aAAa,OAC3BE,GAAO,IAAMF,EAAY,YAAY,KAAO,KAE9CE,GAAO,IAAMD,EACT,IACOlB,GACIU,EACAO,EAAY,aAAa,mBACrB,IAAI,MAAwCP,EAAa,MAAM,EAAE,KAAK,MAAM,CAAC,CAAC,GAC1FS,CACT,EAMSjB,GAAN,KAAoB,CAApB,cAiBL,qBAA+B,KAoC/B,KAAQ,eAAyC,KACjD,KAAQ,mBAAiD,KACzD,2BAAwB,EAIxB,mBAAgB,EAQhB,gCAA4E,IAAI,IAlChF,IAAI,yBAAoD,CACtD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,yEAAyE,EAG3F,IAAIkB,EAAO,KAAK,iBAAiB,IAAI,KAAK,eAAe,EACzD,OAAKA,IACHA,EAAO,CAAC,EACR,KAAK,iBAAiB,IAAI,KAAK,gBAAiBA,CAAI,GAG/CA,CACT,CAwBA,MAAM,WAAWC,EAAyB,CACxC,GAAI,CAAC,UAAU,IAEb,MAAM,IAAI,MAAM,yCAAyC,EAG3D,IAAMC,EAAU,MAAM,UAAU,IAAI,eAAe,EACnD,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,KAAK,IAAMD,EACX,IAAME,EAAqC,CAAC,EACtCC,EAAwC,CAC5C,eAAgB,CACd,+BAAgCF,EAAQ,OAAO,+BAC/C,iCAAkCA,EAAQ,OAAO,iCACjD,4BAA6BA,EAAQ,OAAO,4BAC5C,cAAeA,EAAQ,OAAO,cAC9B,kCAAmCA,EAAQ,OAAO,kCAClD,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,wBAC3C,EACA,iBAAAC,CACF,EAEID,EAAQ,SAAS,IAAI,iBAAiB,GACxCC,EAAiB,KAAK,iBAAiB,EAErCD,EAAQ,SAAS,IAAI,YAAY,GACnCC,EAAiB,KAAK,YAAY,EAGpC,KAAK,OAAS,MAAMD,EAAQ,cAAcE,CAAgB,EAC1D,KAAK,eAAiBC,GAAqB,IAAI,EAC/C,KAAK,eAAiB,IAAIC,GAAe,IAAI,EAC7C,KAAK,QAAU,IAAI,IACnB,KAAK,qBAAuB,IAAI,IAChC,KAAK,iBAAmB,IAAI,IAG5BC,GAAgBN,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,EAI1C,KAAK,OAAO,kBAAoBO,GAAM,CAChCA,EAAG,iBAAiB,oBAEtB,QAAQ,MAAM,mDAAmDA,EAAG,MAAM,OAAO,EAAE,CAEvF,EAEA,OAAO,eAAe,KAAK,IAAI,OAAQ,SAAU,CAAC,MAAO,KAAK,MAAM,CAAC,CACvE,CAEA,SAAgB,CACV,OAAO,KAAK,SAAa,KAC3B,KAAK,SAAS,QAAQ,EAExB,KAAK,eAAe,QAAQ,CAC9B,CAEA,mBAAuC,CACrC,OAAK,KAAK,iBACR,KAAK,eAAiB,KAAK,OAAO,qBAAqB,GAElD,KAAK,cACd,CAEA,uBAA+C,CAC7C,GAAI,CAAC,KAAK,mBAAoB,CAC5B,IAAMC,EAAkD,CAAC,EACrD,KAAK,eAAe,IAClB,OAAO,KAAK,SAAa,MAC3B,KAAK,SAAW,KAAK,OAAO,eAAe,CACzC,KAAM,YACN,MAAO,KAAK,aACd,CAAC,GAEHA,EAAsB,gBAAkB,CACtC,SAAU,KAAK,SACf,0BAA2B,EAC3B,oBAAqB,CACvB,GAGF,KAAK,mBAAqB,KAAK,kBAAkB,EAAE,iBAAiBA,CAAqB,CAC3F,CACA,OAAO,KAAK,kBACd,CAEA,gBAAuB,CACjB,KAAK,qBACP,KAAK,mBAAmB,IAAI,EAC5B,KAAK,mBAAqB,KAE9B,CAEA,OAAc,CACR,KAAK,iBACP,KAAK,eAAe,EACpB,KAAK,OAAO,MAAM,OAAO,CAAC,KAAK,kBAAkB,EAAE,OAAO,CAAC,CAAC,EAC5D,KAAK,eAAe,sBAAsB,EAC1C,KAAK,eAAiB,KACtB,KAAK,sBAAwB,EAEjC,CAEA,gBAA0B,CACxB,MAAI,QAAK,OAAO,SAAS,IAAI,iBAAiB,GAAK,KAAK,IAAI,OAAO,gBAAkB,UAKvF,CAaA,IAAIC,EAAsBC,EAAyCC,EAC/DC,EACAC,EAAmG,CAErG,IAAMC,EAAwB,CAAC,EAC/B,QAAStB,EAAI,EAAGA,EAAIkB,EAAiB,OAAQ,EAAElB,EAAG,CAChD,IAAMuB,EAAU,KAAK,eAAe,IAAIL,EAAiBlB,CAAC,EAAE,IAAI,EAChE,GAAI,CAACuB,EACH,MAAM,IAAI,MAAM,0BAA0BL,EAAiBlB,CAAC,EAAE,IAAI,EAAE,EAEtEsB,EAAWtB,CAAC,EAAIuB,CAClB,CAEA,GAAM,CAAC,QAAAC,EAAS,cAAAC,EAAe,gBAAAC,CAAe,EAAIT,EAAQ,WAAWC,CAAgB,EAG/ES,EAAyBR,EAAc,SAAW,EAAIK,EAAQ,IAAI,CAACI,EAAG5B,IAAMA,CAAC,EAAImB,EACvF,GAAIQ,EAAuB,SAAWH,EAAQ,OAC5C,MAAM,IAAI,MAAM,eAAeG,EAAuB,MAAM,qBAAqBH,EAAQ,MAAM,GAAG,EAIpG,IAAMK,EAAkC,CAAC,EACnCC,EAAyB,CAAC,EAChC,QAAS9B,EAAI,EAAGA,EAAIwB,EAAQ,OAAQ,EAAExB,EAAG,CAIvC,GAAI,CAAC,OAAO,UAAU2B,EAAuB3B,CAAC,CAAC,GAAK2B,EAAuB3B,CAAC,EAAI,IAC5E2B,EAAuB3B,CAAC,GAAKwB,EAAQ,OACvC,MAAM,IAAI,MAAM,yBAAyBG,EAAuB3B,CAAC,CAAC,EAAE,EAEtE,GAAI2B,EAAuB3B,CAAC,IAAM,GAChC,SAEF,IAAM+B,EAAcJ,EAAuB3B,CAAC,IAAM,GAC5CgC,EAAeL,EAAuB3B,CAAC,IAAM,GAC7CiC,EAAcF,GAAeC,EAC/BX,EAAyBG,EAAQxB,CAAC,EAAE,SAAUwB,EAAQxB,CAAC,EAAE,IAAI,EAC7DoB,EAAmBO,EAAuB3B,CAAC,EAAGwB,EAAQxB,CAAC,EAAE,SAAUwB,EAAQxB,CAAC,EAAE,IAAI,EAChFuB,EAAU,KAAK,eAAe,IAAIU,EAAW,IAAI,EACvD,GAAI,CAACV,EACH,MAAM,IAAI,MAAM,2BAA2BU,EAAW,IAAI,EAAE,EAK9D,GAHIF,GACF,KAAK,cAAc,KAAKR,CAAO,EAE7BS,EAAc,CAChB,IAAIE,EAAiB,KAAK,qBAAqB,IAAI,KAAK,eAAgB,EACnEA,IACHA,EAAiB,CAAC,EAClB,KAAK,qBAAqB,IAAI,KAAK,gBAAkBA,CAAc,GAErEA,EAAe,KAAKX,CAAO,CAC7B,CACAM,EAAkB,KAAKI,CAAU,EACjCH,EAAY,KAAKP,CAAO,CAC1B,CAMA,IAAIY,EACJ,GAAIT,EAAiB,CACnB,IAAIU,EAAgB,EACdC,EAAoB,CAAC,EAE3BX,EAAgB,QAAQY,GAAK,CAC3B,IAAM/B,EAAO,OAAO+B,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACvD,GAAI/B,EAAK,SAAW,EAClB,OAGF,IAAMgC,GAAgBhC,EAAK,QAAU,EAAIA,EAAK,OAAS,EAAI,GAC3D6B,EAAgB,KAAK,KAAKA,EAAgBG,EAAa,EAAIA,GAC3DF,EAAQ,KAAKD,CAAa,EAI1BA,GAAiB7B,EAAK,OAAS,EAAI,KAAK,KAAKA,EAAK,OAAS,CAAC,EAAI,GAAKA,EAAK,OAAS,CACrF,CAAC,EAID,IAAMiC,EAAsB,GAC5BJ,EAAgB,KAAK,KAAKA,EAAgBI,CAAmB,EAAIA,EACjE,IAAMC,EAAc,IAAI,YAAYL,CAAa,EACjDV,EAAgB,QAAQ,CAACY,EAAGtC,IAAM,CAChC,IAAM0C,GAASL,EAAQrC,CAAC,EAClBO,GAAO,OAAO+B,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACnDA,EAAE,OAAS,QACb,IAAI,WAAWG,EAAaC,GAAQnC,GAAK,MAAM,EAAE,IAAIA,EAAI,EAChD+B,EAAE,OAAS,SACpB,IAAI,YAAYG,EAAaC,GAAQnC,GAAK,MAAM,EAAE,IAAIA,EAAI,EAE1D,IAAI,aAAakC,EAAaC,GAAQnC,GAAK,MAAM,EAAE,IAAIA,EAAI,CAE/D,CAAC,EAED,IAAMoC,EAEF,KAAK,eAAe,OAAOP,EAAe,eAAe,SAAW,eAAe,OAAO,EAC9F,KAAK,OAAO,MAAM,YAAYO,EAAkB,OAAQ,EAAGF,EAAa,EAAGL,CAAa,EACxF,KAAK,eAAe,QAAQO,EAAkB,EAAE,EAChDR,EAAuB,CAAC,OAAQ,EAAG,KAAMC,EAAe,OAAQO,EAAkB,MAAM,CAC1F,CAEA,IAAMC,EAA0B,KAAK,eAAe,2BAA2BnB,CAAa,EACtFpB,EAAuBuC,EAAwB,CAAC,IAAM,GAAKA,EAAwB,CAAC,IAAM,EAE1FtC,EAAMlB,GAAwB6B,EAASC,EAAkBb,CAAoB,EAC/EwC,EAAW,KAAK,eAAe,YAAYvC,CAAG,EAClD,OAAKuC,IACHA,EAAW,KAAK,eAAe,MAAM5B,EAAS2B,CAAuB,EACrE,KAAK,eAAe,YAAYtC,EAAKuC,CAAQ,EAC7CC,GAAU,OAAQ,IAAM,mBAAmBxC,CAAG,kBAAkBW,EAAQ,IAAI,EAAE,GAGhF6B,GACI,OACA,IAAM,yBAAyB7B,EAAQ,IAAI,UAAUX,CAAG,UAAUsC,EAAwB,CAAC,CAAC,IACxFA,EAAwB,CAAC,CAAC,IAAIA,EAAwB,CAAC,CAAC,EAAE,EAClE,KAAK,eAAe,IAChBC,EAAU3B,EAAkBW,EAAmBP,EAAYQ,EAAac,EACxET,CAAoB,EAEjBN,CACT,CAEA,OAAOkB,EAAmBxC,EAAwB,CAChD,KAAK,eAAe,OAAOwC,EAAWxC,CAAI,CAC5C,CAEA,OAAOyC,EAAaC,EAAmB,CACrC,KAAK,eAAe,OAAOD,EAAKC,CAAG,CACrC,CAEA,MAAM,SAASF,EAAmBG,EAAkD,CAGlF,MAAM,KAAK,eAAe,SAASH,EAAWG,CAAe,CAC/D,CAEA,MAAMC,EAAsB,CAC1B,OAAO,KAAK,eAAe,OAAOA,CAAI,EAAE,EAC1C,CAEA,KAAKC,EAAqB,CACxB,OAAO,KAAK,eAAe,QAAQA,CAAG,CACxC,CAEA,aAAaC,EAAgBC,EAAkBC,EAAoBC,EAAwB,CACzF,IAAMC,EAAKC,GAAwB,IAAIL,CAAM,EAC7C,GAAI,CAACI,EACH,MAAM,IAAI,MAAM,2BAA2BJ,CAAM,EAAE,EAGrD,KAAK,QAAQ,IAAIC,EAAU,CAACD,EAAQG,EAAUC,EAAG,CAAC,EAAG,CAACA,EAAG,CAAC,EAAGF,CAAS,CAAC,CAAC,CAC1E,CAEA,cAAcD,EAAwB,CACpC,IAAMpB,EAAiB,KAAK,qBAAqB,IAAIoB,CAAQ,EAC7D,GAAIpB,EAAgB,CAClB,QAAW3B,KAAQ2B,EACjB,KAAK,eAAe,QAAQ3B,EAAK,EAAE,EAErC,KAAK,qBAAqB,OAAO+C,CAAQ,CAC3C,CAEA,KAAK,iBAAiB,OAAOA,CAAQ,EACrC,KAAK,QAAQ,OAAOA,CAAQ,CAC9B,CAEA,cAAcA,EAAkBK,EAAyBC,EAA6C,CACpG,IAAMC,EAAS,KAAK,QAAQ,IAAIP,CAAQ,EACxC,GAAI,CAACO,EACH,MAAM,IAAI,MAAM,uBAAuBP,CAAQ,EAAE,EAEnD,GAAM,CAACD,EAAQG,EAAUM,EAAaC,CAAU,EAAIF,EACpD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,YAAYR,CAAM,KAAKG,CAAQ,2CAA2C,EAE5F,KAAK,gBAAkBF,EAGnBS,EAAW,CAAC,IACdA,EAAW,CAAC,EAAIA,EAAW,CAAC,EAAEA,EAAW,CAAC,CAAC,EAC3CA,EAAW,CAAC,EAAI,QAGlBjB,GAAU,OAAQ,IAAM,kCAAkCO,CAAM,KAAKG,CAAQ,MAAM,EAEnF,IAAMQ,EAAgB,KAAK,IAAI,MAE/B,KAAK,cAAgB,CAAC,EACtB,GAAI,CACF,OAAIA,GACF,KAAK,OAAO,eAAe,YAAY,EAGzCF,EAAYH,EAASI,EAAW,CAAC,CAAC,EAC3B,CACT,OAASE,EAAG,CACV,OAAAL,EAAO,KAAK,QAAQ,QAAQ,qBAAqBP,CAAM,KAAKG,CAAQ,aAAaS,CAAC,EAAE,CAAC,EAC9E,CACT,QAAE,CACID,GACFJ,EAAO,KAAK,KAAK,OAAO,cAAc,EAAE,KACpCM,GAAOA,EAAM,qCAAqCb,CAAM,KAAKG,CAAQ,MAAMU,EAAI,OAAO,GAAK,IAAI,CAAC,EAGtG,QAAW3D,KAAQ,KAAK,cACtB,KAAK,eAAe,QAAQA,EAAK,EAAE,EAErC,KAAK,cAAgB,CAAC,EACtB,KAAK,gBAAkB,IACzB,CACF,CAGA,eAAe4D,EAAmBC,EAAeC,EAAmBlB,EAAsB,CACxF,IAAImB,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EACxEG,IACHA,EAA4B,IAAI,IAChC,KAAK,2BAA2B,IAAIH,EAAWG,CAAyB,GAG1E,IAAMC,EAAiBD,EAA0B,IAAIF,CAAK,EACpDI,EAAK,KAAK,eAAe,uBAAuBH,EAAQlB,EAAMoB,IAAiB,CAAC,CAAC,EACvF,OAAAD,EAA0B,IAAIF,EAAO,CAACI,EAAIH,CAAM,CAAC,EAC1CG,CACT,CACA,kBAAkBL,EAAyB,CACzC,IAAMG,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EAC3EG,IACFA,EAA0B,QAAQG,GAAc,KAAK,eAAe,yBAAyBA,EAAW,CAAC,CAAC,CAAC,EAC3G,KAAK,2BAA2B,OAAON,CAAS,EAEpD,CACA,UAAUpB,EAA8B,CACtC,IAAMxB,EAAU,KAAK,eAAe,IAAIwB,CAAS,EACjD,GAAI,CAACxB,EACH,MAAM,IAAI,MAAM,2BAA2BwB,CAAS,EAAE,EAExD,OAAOxB,EAAQ,MACjB,CACA,iBAAiBmD,EAAsBvB,EAAclD,EAClB,CACjC,MAAO,UAAY,CACjB,IAAMM,EAAO,MAAMoE,GAAgB,KAAMD,EAAWvB,CAAI,EACxD,OAAOyB,GAAWrE,EAAK,OAAQN,CAAI,CACrC,CACF,CAEF,ICjhBA,IAAA4E,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAgBMC,GAuCAC,GA6EOF,GApIbG,GAAAC,GAAA,kBAMAC,KAEAC,KACAC,KAEAC,KAKMP,GAAN,MAAMQ,CAAqC,CACzC,YACYC,EAAuCC,EAAkCC,EACjEC,EAAyB,CADjC,YAAAH,EAAuC,cAAAC,EAAkC,UAAAC,EACjE,UAAAC,CAA0B,CAE9C,iBAAgC,CAC9B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMC,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,aACJ,IAAI,aAAa,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CAChG,CAEA,kBAAkC,CAChC,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,cACJ,IAAI,cAAc,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjG,CAEA,eAA4B,CAC1B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,WAAe,IAAI,WAAW,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjH,CAEA,QAAQE,EAAwC,CAC9C,GAAID,EAAU,KAAKC,CAAO,IAAMD,EAAU,KAAK,KAAK,IAAI,EACtD,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,IAAIN,EAAe,KAAK,OAAQ,KAAK,SAAU,KAAK,KAAMO,CAAO,CAC1E,CACF,EAEMd,GAAN,KAAmD,CAYjD,YAAoBQ,EAA+BO,EAAwBC,EAA2B,CAAlF,YAAAR,EAA+B,aAAAO,EAFnD,KAAQ,iBAAmB,EAC3B,KAAQ,eAAiB,EAEvB,IAAME,EAAUT,EAAO,QAGnBU,EAAaF,GAAqB,EACtC,KAAK,gBAAkBC,EAAQC,GAAW,EAC1C,IAAMC,EAAaF,EAAQC,GAAW,EACtC,KAAK,YAAcD,EAAQC,GAAW,EACtC,KAAK,iBAAmBD,EAAQC,GAAW,EAC3C,KAAK,eAAiBD,EAAQC,GAAW,EAEzC,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIF,EAAYE,IAAK,CACnC,IAAMZ,EAAWQ,EAAQC,GAAW,EAC9BR,EAAOO,EAAQC,GAAW,EAC1BI,EAAML,EAAQC,GAAW,EACzBP,EAAiB,CAAC,EACxB,QAASY,EAAI,EAAGA,EAAID,EAAKC,IACvBZ,EAAK,KAAKM,EAAQC,GAAW,CAAC,EAEhCE,EAAO,KAAK,IAAIrB,GAAeS,EAAQC,EAAUC,EAAMC,CAAI,CAAC,CAC9D,CACA,KAAK,OAASS,CAChB,CA/BA,IAAI,kBAA6C,CAC/C,OAAO,KAAK,QAAQ,uBACtB,CACA,IAAI,kBAA+B,CACjC,OAAO,KAAK,OAAO,OAAO,SAAS,KAAK,iBAAkB,KAAK,iBAAmB,KAAK,cAAc,CACvG,CA4BA,QAAQI,EAAsBC,EAAyE,CAErG,IAAMC,EACFD,GAAsB,QAAQ,IAAIJ,GAAK,OAAOA,GAAM,SAAW,KAAK,OAAOA,CAAC,EAAIA,CAAC,GAAK,KAAK,OAEzFM,EAAgBF,GAAsB,SAAW,CAAC,EAClDG,EAAqB,CAACC,EAAepB,EAAkBE,IACzD,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,OAAOoB,EAAOlB,CAAI,EAAGA,CAAI,EACtEmB,EAAwB,CAACrB,EAAkBE,IAAwC,CACvF,IAAMoB,EAAcC,GAAqBvB,CAAQ,EACjD,GAAI,CAACsB,EACH,MAAM,IAAI,MAAM,0BAA0BtB,CAAQ,EAAE,EAEtD,IAAMwB,EAAaF,EAAclB,EAAU,KAAKF,CAAI,EACpD,OAAO,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,QAAQ,eAAe,OAAOwB,CAAU,EAAE,GAAItB,CAAI,CAC1G,EACA,OAAO,KAAK,QAAQ,IAAIa,EAASE,EAAcC,EAAeC,EAAoBE,CAAqB,CACzG,CAEA,OAAOD,EAAelB,EAAiC,CACrD,IAAMuB,EAAQ,KAAK,OAAO,UAAU,EACpC,GAAI,CACF,IAAMxB,EAAO,KAAK,OAAO,YAAY,EAAIC,EAAK,QAAU,CAAsB,EAC1EwB,EAASzB,GAAQ,EACrB,KAAK,OAAO,QAAQyB,GAAQ,EAAIxB,EAAK,OACrC,QAASU,EAAI,EAAGA,EAAIV,EAAK,OAAQU,IAC/B,KAAK,OAAO,QAAQc,GAAQ,EAAIxB,EAAKU,CAAC,EAExC,OAAO,KAAK,OAAO,YAAY,KAAK,gBAAiBQ,EAAOnB,CAAI,CAClE,OAAS0B,EAAG,CACV,MAAM,IAAI,MACN,sCAAsCP,CAAK,gBAAgBlB,CAAI,8GAErDyB,CAAC,EAAE,CACnB,QAAE,CACA,KAAK,OAAO,aAAaF,CAAK,CAChC,CACF,CACF,EAEapC,GAAO,MAAMU,EAAuB6B,IAA4B,CAC3E,IAAMvC,EAAOU,EAAO,SACpB,GAAIV,GAAQ,UAAU,IAAK,CACzB,GAAI,CAACuC,EAAI,KAAK,KACZ,MAAM,IAAI,MACN,mGAAmG,EAEzG,IAAMtB,EAAU,IAAIuB,GACpB,MAAMvB,EAAQ,WAAWsB,CAAG,EAE5BvC,EAEIiB,EAGCwB,GAAiBxB,EAAQ,MAAMwB,CAAI,EAGnCC,GAAgBzB,EAAQ,KAAKyB,CAAG,EAGjC,CAACC,EAAaC,EAAaH,EAAcI,EAAc,KAAU,CAC/D,GAAIA,EACFC,GAAU,UAAW,IAAM,kCAAkCH,CAAG,SAASC,CAAG,UAAUH,CAAI,EAAE,EAC5FxB,EAAQ,OAAO0B,EAAKC,CAAG,MAClB,CACLE,GAAU,UAAW,IAAM,yCAAyCH,CAAG,eAAeC,CAAG,UAAUH,CAAI,EAAE,EACzG,IAAM7B,EAAOF,EAAO,OAAO,SAASiC,EAAKA,EAAMF,CAAI,EACnDxB,EAAQ,OAAO2B,EAAKhC,CAAI,CAC1B,CACF,EAGA,MAAMmC,EAAmBC,EAAoBP,IACxB,CACfK,GACI,UACA,IAAM,wCAAwCC,CAAS,gBAAgBC,CAAU,UAAUP,CAAI,EAAE,EAErG,MAAMxB,EAAQ,SAAS8B,EAAW,IAAMrC,EAAO,OAAO,SAASsC,EAAYA,EAAaP,CAAI,CAAC,CAC/F,EAGJ,CAACQ,EAAcC,EAAgBC,IAAuBlC,EAAQ,aAC1DgC,EAAMC,EAAQC,EACdZ,EAAI,OAASA,EAAI,OAAO,gBAAkB,UAAY7B,EAAO,aAAaA,EAAO,iBAAiBwC,CAAM,CAAC,EACnD,GAAGA,CAAM,EAAE,EAGpEA,GAAmBjC,EAAQ,cAAciC,CAAM,EAGhD,CAACA,EAAgBhC,EAA2BkC,EAAuBC,IAAwC,CACzGP,GACI,UACA,IAAM,mCAAmCM,CAAa,YAAYF,CAAM,uBACpEhC,CAAiB,EAAE,EAC3B,IAAMoC,EAAU,IAAIpD,GAAmBQ,EAAQO,EAASC,CAAiB,EACzE,OAAOD,EAAQ,cAAciC,EAAQI,EAASD,CAAM,CACtD,CAAC,CACP,CACF,ICjMA,IAYIE,GAOEC,GAoBAC,GAWOC,GA+CPC,GAEOC,GAMAC,GAgBAC,GA+FAC,GAMAC,GAoBAC,GAqEAC,GA6NAC,GAgBAC,GApiBbC,GAAAC,GAAA,kBAMAC,KACAC,KACAC,KACAC,KACAC,KAEIpB,GAAoB,GAOlBC,GAA8BoB,GAA4C,CAC9E,IAAMC,EAAOC,GAAY,EACnBC,EAAQF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMG,EAAaH,EAAK,WAAW,CAAC,EAEpC,OADkBA,EAAK,wBAAwBD,EAAeI,EAAYA,EAAa,CAAC,IACtE,GAChBC,GAAe,uCAAwC,EAElD,CAACJ,EAAK,OAAOG,EAAa,CAAC,EAAGH,EAAK,OAAOG,EAAa,EAAI,CAAC,CAAC,CACtE,QAAE,CACAH,EAAK,aAAaE,CAAK,CACzB,CACF,EAOMtB,GAAU,CAACyB,EAAoBC,IAA+B,CAChDL,GAAY,EAAE,SAASI,EAAYC,CAAY,IAC/C,GAChBF,GAAe,+BAAgC,CAEnD,EAMavB,GAAc,MAAM0B,GAA4B,CAE3D3B,GAAQ2B,EAAI,KAAK,WAAaC,GAAqBD,EAAI,QAAQ,CAAC,EAEhC,CAI9B,IAAME,EAAW,cAAuB,KACxC,MAAMA,EAASR,GAAY,EAAGM,CAAG,CACnC,CAEA7B,GAAoB,EACtB,EAkCMI,GAAiB,IAAI,IAEdC,GAAsB,IAAeL,GAMrCM,GAAyB0B,GAAwC,CAC5E,IAAMV,EAAOC,GAAY,EACnBU,EAAkBX,EAAK,QAAQU,EAAM,UAAU,EACrD,GAAIC,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+DD,EAAM,UAAU,GAAG,EAEpG,OAAAV,EAAK,OAAO,IAAIU,EAAOC,CAAe,EAC/B,CAACA,EAAiBD,EAAM,UAAU,CAC3C,EAQazB,GACT,CAAC2B,EAAkCC,IAA2E,CAC5G,IAAMb,EAAOC,GAAY,EAErBF,EAAgB,EAChBe,EAAuB,EACvBC,EAAkB,EAClBC,EAAmB,CAAC,EAClBC,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CACF,CAACJ,EAAsBE,CAAM,EAAIG,GAAkBN,CAAO,EAE1Dd,EAAgBC,EAAK,kBAAkBY,EAAU,CAAC,EAAGA,EAAU,CAAC,EAAGE,CAAoB,EACnFf,IAAkB,GACpBK,GAAe,yBAA0B,EAG3C,GAAM,CAACgB,EAAYC,CAAW,EAAI1C,GAA2BoB,CAAa,EAEpEuB,EAAa,CAAC,EACdC,EAAc,CAAC,EACfC,EAAwE,CAAC,EAC/E,QAASC,EAAI,EAAGA,EAAIL,EAAYK,IAAK,CACnC,IAAMC,EAAO1B,EAAK,iBAAiBD,EAAe0B,CAAC,EAC/CC,IAAS,GACXtB,GAAe,0BAA2B,EAE5Ca,EAAsB,KAAKS,CAAI,EAC/BJ,EAAW,KAAKtB,EAAK,aAAa0B,CAAI,CAAC,CACzC,CACA,QAASD,EAAI,EAAGA,EAAIJ,EAAaI,IAAK,CACpC,IAAMC,EAAO1B,EAAK,kBAAkBD,EAAe0B,CAAC,EAChDC,IAAS,GACXtB,GAAe,2BAA4B,EAE7Cc,EAAuB,KAAKQ,CAAI,EAChC,IAAMC,EAAa3B,EAAK,aAAa0B,CAAI,EACzCH,EAAY,KAAKI,CAAU,EAEK,CAC9B,IAAMC,EAAW,OAAOf,GAAS,yBAA4B,SACzDA,EAAQ,wBACRA,GAAS,0BAA0Bc,CAAU,GAAK,MACtD,GAAIC,IAAa,OAASA,IAAa,cAAgBA,IAAa,aAClE,MAAM,IAAI,MAAM,4CAA4CA,CAAQ,GAAG,EAEzEJ,EAAyB,KAAKI,CAAQ,CACxC,CACF,CAGA,IAAIC,EAAoC,KACxC,OAAkCL,EAAyB,KAAKM,GAAKA,IAAM,YAAY,IACrFf,EAAkBf,EAAK,kBAAkBD,CAAa,EAClDgB,IAAoB,GACtBX,GAAe,0BAA2B,EAG5CyB,EAAe,CACb,OAAQd,EACR,yBAAAS,EACA,gCAAiCA,EAAyB,IAAIM,GAAKC,GAAyBD,CAAC,CAAC,CAChG,GAGFhD,GAAe,IAAIiB,EAAe,CAACA,EAAekB,EAAuBC,EAAwBW,CAAY,CAAC,EACvG,CAAC9B,EAAeuB,EAAYC,CAAW,CAChD,OAASS,EAAG,CACV,MAAAf,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EAEpDlB,IAAoB,GACtBf,EAAK,mBAAmBe,CAAe,EAGrChB,IAAkB,GACpBC,EAAK,mBAAmBD,CAAa,EAEjCiC,CACR,QAAE,CACAhC,EAAK,MAAMY,EAAU,CAAC,CAAC,EACnBE,IAAyB,GAC3Bd,EAAK,0BAA0Bc,CAAoB,EAErDE,EAAO,QAAQkB,GAASlC,EAAK,MAAMkC,CAAK,CAAC,CAC3C,CACF,EAOShD,GACT,CAACwB,EAAmBG,IAA2E,CAC7F,IAAMD,EAAmC5B,GAAsB0B,CAAK,EACpE,OAAOzB,GAAsB2B,EAAWC,CAAO,CACjD,EAES1B,GAAkBgD,GAA4B,CACzD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,+CAA+CD,CAAS,EAAE,EAE5E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEnFC,GACFrC,EAAK,mBAAmBqC,EAAe,MAAM,EAG/CrC,EAAK,wBAAwBmC,CAAS,EAEtClB,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACxDjC,EAAK,mBAAmBD,CAAa,EACrCjB,GAAe,OAAOqD,CAAS,CACjC,EAEa/C,GACT,CAACkD,EAA6BC,EAAyBvB,EAAkBmB,EAAmBK,IAChF,CACN,GAAI,CAACF,EAAQ,CACXC,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAMvC,EAAOC,GAAY,EAEnBwC,EAAWH,EAAO,CAAC,EACnBI,EAAOJ,EAAO,CAAC,EACfV,EAAWU,EAAO,CAAC,EAErBK,EACAC,EAEJ,GAAIH,IAAa,UAAYb,IAAa,aACxC,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,IAAa,aAAc,CAC7B,IAAMiB,EAAYP,EAAO,CAAC,EAAE,UACtBQ,EAAqBC,GAAqBC,GAA2BP,CAAQ,CAAC,EACpFG,EAAiBF,EAAK,OAAO,CAACO,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAIJ,EACnDH,EAAU3C,EAAK,mBAAmBmC,EAAWK,EAAOK,EAAWD,CAAc,CAC/E,KAAO,CACL,IAAMO,EAAOb,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQa,CAAI,EAAG,CAEvBP,EAAiB,EAAIO,EAAK,OAC1BR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB,IAAIS,EAAYT,EAAU,EAC1B,QAASlB,EAAI,EAAGA,EAAI0B,EAAK,OAAQ1B,IAAK,CACpC,GAAI,OAAO0B,EAAK1B,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjEzB,EAAK,QAAQoD,GAAW,EAAIC,GAAgBF,EAAK1B,CAAC,EAAGT,CAAM,CAC7D,CACF,MACE4B,EAAiBO,EAAK,WACtBR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB3C,EAAK,OAAO,IAAI,IAAI,WAAWmD,EAAK,OAAQA,EAAK,WAAYP,CAAc,EAAGD,CAAO,CAEzF,CAEA,IAAMzC,EAAQF,EAAK,UAAU,EACvBsD,EAAatD,EAAK,WAAW,EAAI0C,EAAK,MAAM,EAClD,GAAI,CACF,IAAIa,EAAWD,EAAa,EAC5BZ,EAAK,QAAQc,GAAKxD,EAAK,OAAOuD,GAAU,EAAIC,CAAC,EAC7C,IAAMlB,EAAStC,EAAK,iBAChBgD,GAA2BP,CAAQ,EAAGE,EAASC,EAAgBU,EAAYZ,EAAK,OAChFX,GAAyBH,CAAQ,CAAC,EAClCU,IAAW,GACblC,GAAe,iDAAiD+B,CAAS,WAAWK,CAAK,GAAG,EAE9FD,EAAc,KAAKD,CAAM,CAC3B,QAAE,CACAtC,EAAK,aAAaE,CAAK,CACzB,CACF,EAKKb,GAAM,MACf8C,EAAmBsB,EAAwBC,EAAgCC,EAC3EC,EAA2C/C,IAAoE,CACjH,IAAMb,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,6CAA6CD,CAAS,EAAE,EAE1E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEjFhB,EAAaqC,EAAa,OAC1BpC,EAAcsC,EAAc,OAE9BE,EAAmB,EACnBC,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAE/BC,EAAiBlE,EAAK,UAAU,EAChCmE,EAAoBnE,EAAK,WAAWoB,EAAa,CAAC,EAClDgD,EAAmBpE,EAAK,WAAWoB,EAAa,CAAC,EACjDiD,EAAqBrE,EAAK,WAAWqB,EAAc,CAAC,EACpDiD,EAAoBtE,EAAK,WAAWqB,EAAc,CAAC,EAEzD,GAAI,CACF,CAACwC,EAAkBC,CAAgB,EAAIS,GAAc1D,CAAO,EAG5D,QAASY,GAAI,EAAGA,GAAIL,EAAYK,KAC9BrC,GAAyBsE,EAAajC,EAAC,EAAGsC,EAAoBE,EAAmB9B,EAAWsB,EAAahC,EAAC,CAAC,EAI7G,QAASA,GAAI,EAAGA,GAAIJ,EAAaI,KAC/BrC,GACIwE,EAAcnC,EAAC,EAAGuC,EAAqBC,EAAmB9B,EAAWf,EAAauC,EAAclC,EAAC,CAAC,EAGxG,IAAI+C,EAAmBL,EAAoB,EACvCM,GAAkBL,EAAmB,EACrCM,GAAoBL,EAAqB,EACzCM,EAAmBL,EAAoB,EAC3C,QAAS7C,GAAI,EAAGA,GAAIL,EAAYK,KAC9BzB,EAAK,QAAQwE,GAAkB,EAAIT,EAAmBtC,EAAC,EACvDzB,EAAK,QAAQyE,IAAiB,EAAIxD,EAAsBwC,EAAahC,EAAC,CAAC,EAEzE,QAASA,GAAI,EAAGA,GAAIJ,EAAaI,KAC/BzB,EAAK,QAAQ0E,IAAmB,EAAIV,EAAoBvC,EAAC,EACzDzB,EAAK,QAAQ2E,GAAkB,EAAIzD,EAAuByC,EAAclC,EAAC,CAAC,EAG5E,GAAkCY,EAAgB,CAChD,GAAM,CAAC,OAAAuC,GAAQ,yBAAApD,GAA0B,gCAAAqD,EAA+B,EAAIxC,EAE5E,GAAIpB,EAAsB,SAAWG,EACnC,MAAM,IAAI,MAAM,2BACZA,CAAU,4DAA4DH,EAAsB,MAAM,IAAI,EAI5G,QAASQ,GAAI,EAAGA,GAAIL,EAAYK,KAAK,CACnC,IAAMe,GAAQiB,EAAahC,EAAC,EACV,MAAMzB,EAAK,cAAc4E,GAAQ3D,EAAsBuB,EAAK,EAAGuB,EAAmBtC,EAAC,CAAC,IACpF,GAChBrB,GAAe,oBAAoBqB,EAAC,iBAAiBU,CAAS,GAAG,CAErE,CAGA,QAASV,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMe,GAAQmB,EAAclC,EAAC,EACZmC,EAAcnC,EAAC,IAAI,CAAC,EAIjBzB,EAAK,eAAe4E,GAAQ1D,EAAuBsB,EAAK,EAAGwB,EAAoBvC,EAAC,EAAG,CAAC,IACpF,GAChBrB,GAAe,mCAAmCqB,EAAC,iBAAiBU,CAAS,GAAG,EAK9EnC,EAAK,eAAe4E,GAAQ1D,EAAuBsB,EAAK,EAAG,EAAGqC,GAAgCrC,EAAK,CAAC,IACtF,GAChBpC,GAAe,qBAAqBqB,EAAC,QAAQD,GAAyBC,EAAC,CAAC,gBAAgBU,CAAS,GAAG,CAG1G,CACF,CAEA,IAAI2C,GAE8BzC,EAChCyC,GAAY,MAAM9E,EAAK,mBACnBD,EAAesC,EAAe,OAAQhB,EAAagD,EAAoBR,CAAgB,EAE3FiB,GAAY,MAAM9E,EAAK,QACnBD,EAAeqE,EAAkBD,EAAmB/C,EAAYkD,EAAmBjD,EACnFgD,EAAoBR,CAAgB,EAGtCiB,KAAc,GAChB1E,GAAe,0BAA0B,EAG3C,IAAM2E,GAA2B,CAAC,EAElC,QAAStD,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMa,GAAStC,EAAK,QAAQqE,EAAqB,EAAI5C,EAAC,EACtD,GAAIa,KAAW0B,EAAoBvC,EAAC,EAAG,CAErCsD,GAAO,KAAKnB,EAAcnC,EAAC,CAAE,EAC7B,QACF,CAEA,IAAMuD,GAA2BhF,EAAK,UAAU,EAE1CiF,GAAmBjF,EAAK,WAAW,EAAI,CAAC,EAE1CkF,GAAmB,GACnBC,GAA6BhF,GAAa,EAC9C,GAAI,CACgBH,EAAK,kBACnBsC,GAAQ2C,GAAkBA,GAAmB,EAAGA,GAAmB,EAAGA,GAAmB,EAAE,IAC7E,GAChB7E,GAAe,4CAA4CqB,EAAC,GAAG,EAEjE,IAAI2D,GAAkBH,GAAmB,EACnCxC,GAAWzC,EAAK,QAAQoF,IAAiB,EAC/CjF,GAAaH,EAAK,QAAQoF,IAAiB,EAC3C,IAAM9B,GAAatD,EAAK,QAAQoF,IAAiB,EAC3CC,GAAarF,EAAK,QAAQoF,IAAiB,EAC3C1C,GAAO,CAAC,EACd,QAASjB,GAAI,EAAGA,GAAI4D,GAAY5D,KAC9BiB,GAAK,KAAK1C,EAAK,QAAQsD,GAAa,EAAI7B,EAAC,CAAC,EAE5CzB,EAAK,SAASsD,EAAU,EAExB,IAAMgC,GAAO5C,GAAK,OAAO,CAACO,GAAGC,KAAMD,GAAIC,GAAG,CAAC,EAC3CiC,GAAOI,GAA2B9C,EAAQ,EAE1C,IAAM+C,GAAoBnD,GAAgB,yBAAyBsB,EAAclC,EAAC,CAAC,EAEnF,GAAI0D,KAAS,SAAU,CACrB,GAAIK,KAAsB,aACxB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,GAAuB,CAAC,EAC1BrC,GAAYjD,GAAa,EAC7B,QAASsB,GAAI,EAAGA,GAAI6D,GAAM7D,KAAK,CAC7B,IAAMiE,GAAS1F,EAAK,QAAQoD,IAAW,EACjCuC,GAAiBlE,KAAM6D,GAAO,EAAI,OAAYtF,EAAK,QAAQoD,EAAS,EAAIsC,GAC9ED,GAAW,KAAKzF,EAAK,aAAa0F,GAAQC,EAAc,CAAC,CAC3D,CACAZ,GAAO,KAAK,CAACI,GAAMzC,GAAM+C,GAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgBF,GAAO,EAAG,CAClD,IAAMzC,GAAY7C,EAAK,cAAcG,EAAU,EACzCyF,GAAc7C,GAAqBN,EAAQ,EACjD,GAAImD,KAAgB,QAAa,CAACC,GAAyBV,EAAI,EAC7D,MAAM,IAAI,MAAM,0BAA0BA,EAAI,EAAE,EAIlDD,GAAmB,GAEnBH,GAAO,KAAK,CACVI,GAAMzC,GAAM,CACV,UAAAG,GACA,SAAU7C,EAAK,qBAAqB6C,GAAWyC,GAAOM,GAAaT,EAAI,EACvE,QAAS,IAAM,CACbnF,EAAK,kBAAkBsC,EAAM,CAC/B,CACF,EACA,YACF,CAAC,CACH,KAAO,CACL,IAAMwD,GAAwBC,GAAkCZ,EAAI,EAC9DhC,GAAO,IAAI2C,GAAsBR,EAAI,EAC3C,IAAI,WAAWnC,GAAK,OAAQA,GAAK,WAAYA,GAAK,UAAU,EACvD,IAAInD,EAAK,OAAO,SAASG,GAAYA,GAAagD,GAAK,UAAU,CAAC,EACvE4B,GAAO,KAAK,CAACI,GAAMzC,GAAMS,GAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACAnD,EAAK,aAAagF,EAAwB,EACtCG,KAAS,UAAYhF,IACvBH,EAAK,MAAMG,EAAU,EAElB+E,IACHlF,EAAK,kBAAkBsC,EAAM,CAEjC,CACF,CAEA,OAAID,GACFrC,EAAK,sBAAsBqC,EAAe,MAAM,EAG3C0C,EACT,QAAE,CACA/E,EAAK,aAAakE,CAAc,EAEhCH,EAAmB,QAAQiC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EACzDhC,EAAoB,QAAQgC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EAC1D/B,EAAkB,QAAQgC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,EAExCpC,IAAqB,GACvB7D,EAAK,sBAAsB6D,CAAgB,EAE7CC,EAAiB,QAAQmC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,CAC7C,CACF,EAKa3G,GAAgB6C,GAA4B,CACvD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAMrC,EAAgBqC,EAAQ,CAAC,EAGzB8D,EAAkBlG,EAAK,iBAAiBD,CAAa,EACvDmG,IAAoB,GACtB9F,GAAe,iCAAkC,EAEnDJ,EAAK,SAASkG,CAAe,CAC/B,EAEa3G,GAA8B4G,GAAsE,CAC/G,IAAMC,EAA6B,CAAC,EACpC,QAAW9D,KAAU6D,EAAS,CAC5B,IAAMhD,EAAOb,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQa,CAAI,GAAK,WAAYA,GACtCiD,EAAQ,KAAKjD,EAAK,MAAM,CAE5B,CACA,OAAOiD,CACT,IC7iBA,IAAAC,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,2zzTCAA,IASMC,GACFC,GACAC,GACAC,GACAC,GAKAC,GACAC,GACEC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GAEAC,GAMAC,GAwEAC,GAEOC,GA6CAC,GAaAC,GAaAC,GAcAC,GAkBAC,GAaAC,GAyBAC,GAaAC,GAtQbC,GAAAC,GAAA,kBAGAC,KAGAC,KACAC,KAEM9B,GAAU,IAAe,CAAC,CAAC+B,GAAI,KAAK,OAAS,OAAO,SAAa,IAEnE7B,GAAe,GACfC,GAAc,GACdC,GAAU,GAORG,GAAiF,CAAC,EAClFC,GAAuF,CAAC,EACxFC,GAA+E,CAAC,EAChFC,GAAyD,CAAC,EAC1DC,GAAsE,CAAC,EACvEC,GAAuD,CAAC,EACxDC,GAAiE,CAAC,EAElEC,GAAe,IAAY,CAC/B,GAAIZ,IAAgB,CAACC,IAAeC,IAAW,CAACH,GAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMc,GAAwBiB,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACH9B,GAAe,GACX8B,EAAG,KAAK,KACV5B,GAAU,GACVC,GAAkB,CAAC,EAAE2B,EAAG,KAAK,GAAG,IAEhC7B,GAAc,GACdE,GAAkB,CAAC,EAAE,GAEvB,MACF,IAAK,WACC2B,EAAG,KAAK,IACV1B,GAAiB,CAAC,EAAE0B,EAAG,KAAK,GAAG,EAE/B1B,GAAiB,CAAC,EAAE,EAEtB,MACF,IAAK,kBACC0B,EAAG,KAAK,IACVzB,GAA+B,MAAM,EAAG,CAAC,EAAEyB,EAAG,KAAK,GAAG,EAEtDzB,GAA+B,MAAM,EAAG,CAAC,EAAEyB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,kBACCA,EAAG,KAAK,IACVxB,GAA+B,MAAM,EAAG,CAAC,EAAEwB,EAAG,KAAK,GAAG,EAEtDxB,GAA+B,MAAM,EAAG,CAAC,EAAEwB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,SACCA,EAAG,KAAK,IACVvB,GAAuB,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAG,EAE9CvB,GAAuB,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAI,EAEjD,MACF,IAAK,UACCA,EAAG,KAAK,IACVtB,GAAwB,MAAM,EAAG,CAAC,EAAEsB,EAAG,KAAK,GAAG,EAE/CtB,GAAwB,MAAM,EAAG,CAAC,EAAE,EAEtC,MACF,IAAK,MACCsB,EAAG,KAAK,IACVrB,GAAa,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAG,EAEpCrB,GAAa,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAI,EAEvC,MACF,IAAK,gBACCA,EAAG,KAAK,IACVpB,GAAsB,MAAM,EAAG,CAAC,EAAEoB,EAAG,KAAK,GAAG,EAE7CpB,GAAsB,MAAM,EAAG,CAAC,EAAE,EAEpC,MACF,IAAK,yBACCoB,EAAG,KAAK,IACVnB,GAA6B,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAG,EAEpDnB,GAA6B,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAI,EAEvD,MACF,QACF,CACF,EAEMhB,GAAY,OAAO,SAAa,IAAe,UAAU,eAAqC,IAAM,OAE7FC,GAAgC,SAA0B,CACrE,GAAsCjB,GAAQ,EAAG,CAC/C,GAAIG,GACF,OAEF,GAAID,GACF,MAAM,IAAI,MAAM,0CAA4C,EAE9D,GAAIE,GACF,MAAM,IAAI,MAAM,uCAAyC,EAG3D,OAAAF,GAAe,GAGX6B,GAAI,KAAK,YAAc,QACrBf,IAAaA,GAAU,QAAQ,OAAO,IAAM,IAC9Ce,GAAI,KAAK,UAAYf,GAAU,OAAO,EAAG,CAAEA,GAAW,YAAY,GAAG,EAAI,CAAC,GAIvE,IAAI,QAAc,CAACiB,EAASC,IAAW,CAC5CjC,IAAa,UAAU,EAEvB,IAAMkC,EAAY,IAAI,gBAAgB,IAAI,KACtC,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAC9BlC,GAAc,IAAI,OAAOkC,EAAW,CAAC,KAAM,uBAAuB,CAAC,EACnElC,GAAY,QAAW+B,GAAmBE,EAAOF,CAAE,EACnD/B,GAAY,UAAYc,GACxB,IAAI,gBAAgBoB,CAAS,EAC7B9B,GAAoB,CAAC4B,EAASC,CAAM,EACpC,IAAME,EAA0B,CAAC,KAAM,YAAa,GAAKL,GAAI,IAAI,EACjE9B,GAAY,YAAYmC,CAAO,CACjC,CAAC,CAEH,KACE,QAAOC,GAAsBN,GAAI,IAAI,CAEzC,EAEab,GAAoB,MAAMa,GAA4B,CACjE,GAAsC/B,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5C5B,GAAmB,CAAC2B,EAASC,CAAM,EACnC,IAAME,EAA0B,CAAC,KAAM,WAAY,GAAKL,CAAG,EAC3D9B,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAED,MAAWE,GAAYP,CAAG,CAE9B,EAEaZ,GAAwB,MAAMoB,GACHvC,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAA+B,CAACmB,EAASC,IAAW,CAC7D3B,GAA+B,KAAK,CAAC0B,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,MAAAG,CAAK,CAAC,EACtEtC,GAAa,YAAYmC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,GAEWpB,GAAsBoB,CAAK,EAI9BnB,GAAwB,MAAMoB,EAAkCC,IAEjCzC,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAAqC,CAACmB,EAASC,IAAW,CACnE1B,GAA+B,KAAK,CAACyB,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,UAAAI,EAAW,QAAAC,CAAO,CAAC,EACnFxC,GAAa,YAAYmC,CAAO,CAClC,CAAC,GAEWhB,GAAsBoB,EAAWC,CAAO,EAI/CpB,GACT,MAAMkB,EAAmBE,IAAoF,CAC/G,GAAsCzC,GAAQ,EAAG,CAE/C,GAAIyC,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAA3B,GAAa,EACN,IAAI,QAAqC,CAACmB,EAASC,IAAW,CACnEzB,GAAuB,KAAK,CAACwB,EAASC,CAAM,CAAC,EAC7C,IAAME,EAA0B,CAAC,KAAM,SAAU,GAAK,CAAC,MAAAG,EAAO,QAAAE,CAAO,CAAC,EACtExC,GAAa,YAAYmC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,CACH,KACE,QAAYlB,GAAckB,EAAOE,CAAO,CAE5C,EAEanB,GAAiB,MAAMoB,GAAqC,CACvE,GAAsC1C,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5CxB,GAAwB,KAAK,CAACuB,EAASC,CAAM,CAAC,EAC9C,IAAME,EAA0B,CAAC,KAAM,UAAW,GAAKM,CAAS,EAChEzC,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAEId,GAAeoB,CAAS,CAEjC,EAEanB,GAAM,MACfmB,EAAmBC,EAAwBC,EAA0BC,EACrEC,EAAqCL,IAAoE,CAC3G,GAAsCzC,GAAQ,EAAG,CAE/C,GAAI4C,EAAO,KAAKG,GAAKA,EAAE,CAAC,IAAM,KAAK,EACjC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAID,EAAQ,KAAKC,GAAKA,CAAC,EACrB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAAjC,GAAa,EACN,IAAI,QAAsC,CAACmB,EAASC,IAAW,CACpEvB,GAAa,KAAK,CAACsB,EAASC,CAAM,CAAC,EACnC,IAAMc,EAAqBJ,EACrBR,EACF,CAAC,KAAM,MAAO,GAAK,CAAC,UAAAM,EAAW,aAAAC,EAAc,OAAQK,EAAoB,cAAAH,EAAe,QAAAJ,CAAO,CAAC,EACpGxC,GAAa,YAAYmC,EAAca,GAA2BD,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAYzB,GAAImB,EAAWC,EAAcC,EAAQC,EAAeC,EAASL,CAAO,CAEpF,EAEajB,GAAe,MAAMkB,GAAqC,CACrE,GAAsC1C,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5CtB,GAAsB,KAAK,CAACqB,EAASC,CAAM,CAAC,EAC5C,IAAME,EAA0B,CAAC,KAAM,gBAAiB,GAAKM,CAAS,EACtEzC,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAEIZ,GAAakB,CAAS,CAE/B,EAEajB,GAAsB,SACKzB,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAAiB,CAACmB,EAASC,IAAW,CAC/CrB,GAA6B,KAAK,CAACoB,EAASC,CAAM,CAAC,EACnD,IAAME,EAA0B,CAAC,KAAM,wBAAwB,EAC/DnC,GAAa,YAAYmC,CAAO,CAClC,CAAC,GAEWX,GAAoB,IC/QpC,IAUIyB,GAESC,GAWAC,GAiBAC,GAxCbC,GAAAC,GAAA,kBAIAC,KAGAC,KACAC,KAIaP,GAAuB,CAACQ,EAAgBC,IAA0C,CAC7F,OAAQD,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAC,UAAWA,EAAO,SAAS,EAAG,YAAY,EAC/E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQC,EAAQ,CAAC,EAAE,CAChF,CACF,EAEaR,GAAwBO,GAAmC,CACtE,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIE,GAAOF,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMG,EAAWH,EAAO,CAAC,EACzB,GAAI,CAACI,GAAyBD,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAC,UAAAE,EAAW,SAAAC,EAAU,QAAAC,CAAO,EAAIP,EAAO,CAAC,EAC/C,OAAOE,GAAO,cAAcG,EAAW,CAAC,SAAAF,EAAU,KAAMH,EAAO,CAAC,EAAG,SAAAM,EAAU,QAAAC,CAAO,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BP,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEaN,GAAN,KAA8E,CAMnF,MAAM,sBAAsBc,EAA8C,CAGxE,IAAMC,EAAW,MAAM,MAAMD,CAAI,EACjC,GAAIC,EAAS,SAAW,IACtB,MAAM,IAAI,MAAM,yBAAyBD,CAAI,EAAE,EAEjD,IAAME,EAAc,MAAMD,EAAS,YAAY,EAC/C,OAAOE,GAAsB,IAAI,WAAWD,CAAW,CAAC,CAC1D,CAEA,MAAM,UAAUE,EAAiCC,EAA0D,CASzG,GARM,MAAMC,GAAoB,IACzBvB,KACHA,GAA+BwB,GAAkBC,EAAG,GAEtD,MAAMzB,GACNA,GAA+B,QAG7B,OAAOqB,GAAiB,SAC1B,GAAI,OAAO,QAAY,KAAe,QAAQ,UAAY,QAAQ,SAAS,KAAM,CAE/E,IAAMK,EAAQ,KAAM,SAASL,CAAY,EACzC,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMM,GAAcD,EAAOJ,CAAO,CAC1F,KAAO,CAGL,IAAMM,EAAmC,MAAM,KAAK,sBAAsBP,CAAY,EAEtF,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMQ,GAAsBD,EAAWN,CAAO,CACtG,KAEA,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMK,GAAcN,EAAcC,CAAO,CAEnG,CAEA,MAAM,SAAyB,CAC7B,OAAOQ,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IAAIC,EAAiCC,EAAqCV,EACzC,CACrC,IAAMW,EAAuB,CAAC,EACxBC,EAAyB,CAAC,EAChC,OAAO,QAAQH,CAAK,EAAE,QAAQI,GAAO,CACnC,IAAMC,EAAOD,EAAI,CAAC,EACZ1B,EAAS0B,EAAI,CAAC,EACdE,EAAQ,KAAK,WAAW,QAAQD,CAAI,EAC1C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkBD,CAAI,GAAG,EAE3CH,EAAW,KAAKxB,CAAM,EACtByB,EAAa,KAAKG,CAAK,CACzB,CAAC,EAED,IAAMC,EAAkC,CAAC,EACnCC,EAA0B,CAAC,EACjC,OAAO,QAAQP,CAAO,EAAE,QAAQG,GAAO,CACrC,IAAMC,EAAOD,EAAI,CAAC,EACZ1B,EAAS0B,EAAI,CAAC,EACdE,EAAQ,KAAK,YAAY,QAAQD,CAAI,EAC3C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmBD,CAAI,GAAG,EAE5CE,EAAY,KAAK7B,CAAM,EACvB8B,EAAc,KAAKF,CAAK,CAC1B,CAAC,EAED,IAAMG,EACFP,EAAW,IAAI,CAACQ,EAAGC,IAAMzC,GAAqBwC,EAAG,IAAM,UAAU,KAAK,WAAWP,EAAaQ,CAAC,CAAC,CAAC,GAAG,CAAC,EACnGC,EAAUL,EAAY,IACxB,CAACG,EAAGC,IAAMD,EAAIxC,GAAqBwC,EAAG,IAAM,WAAW,KAAK,YAAYF,EAAcG,CAAC,CAAC,CAAC,GAAG,EAAI,IAAI,EAElGE,EAAU,MAAMC,GAAI,KAAK,UAAWX,EAAcM,EAAQD,EAAeI,EAASrB,CAAO,EAEzFwB,EAAuC,CAAC,EAC9C,QAASJ,EAAI,EAAGA,EAAIE,EAAQ,OAAQF,IAClCI,EAAU,KAAK,YAAYP,EAAcG,CAAC,CAAC,CAAC,EAAIJ,EAAYI,CAAC,GAAKxC,GAAqB0C,EAAQF,CAAC,CAAC,EAEnG,OAAOI,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdC,GAAa,KAAK,SAAS,CAClC,CACF,ICxIA,IAeaC,GAmBAC,GAlCbC,GAAAC,GAAA,kBAIAC,KAEAC,KACAC,KAQaN,GAAkB,IAAY,CAazC,IAZI,OAAOO,GAAI,KAAK,aAAgB,UAAYA,GAAI,KAAK,YAAc,KACrEA,GAAI,KAAK,YAAc,GAGrB,OAAOA,GAAI,KAAK,MAAS,YAC3BA,GAAI,KAAK,KAAO,IAGd,OAAOA,GAAI,KAAK,OAAU,YAC5BA,GAAI,KAAK,MAAQ,IAGf,OAAOA,GAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,GAAI,KAAK,UAAU,GAAKA,GAAI,KAAK,YAAc,EAAG,CACjH,IAAMC,EAAqB,OAAO,UAAc,IAAc,SAAK,EAAE,OAAS,UAAU,oBACxFD,GAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAMC,GAAsB,GAAK,CAAC,CAAC,CAC5E,CACF,EAEaP,GAAN,KAAuD,CAC5D,MAAM,MAAsB,CAE1BD,GAAgB,EAGhB,MAAMS,GAA8B,CACtC,CAKA,MAAM,8BAA8BC,EAAiCC,EAChC,CACnC,IAAMC,EAAU,IAAIC,GACpB,aAAMD,EAAQ,UAAUF,EAAcC,CAAO,EACtC,QAAQ,QAAQC,CAAO,CAChC,CACF,ICpDA,IAAAE,GAAA,GAAAC,GAAAD,GAAA,iBAAAE,KAAA,IAIaA,GAJbC,GAAAC,GAAA,kBAGAC,KACaH,GAAc,IAAII,KCI/BC,KACAA,KAGAA,KCNO,IAAMC,GAAU,SDIvB,IAAOC,GAAQC,GAUe,CAC5B,IAAMC,EAA4C,cAAoC,YAEpD,OAAO,UAAc,KAAe,UAAU,KAC9EC,GAAgB,SAAUD,EAAa,CAAC,EAE1CC,GAAgB,MAAOD,EAAa,EAAE,EACtCC,GAAgB,OAAQD,EAAa,EAAE,EAErCC,GAAgB,UAAWD,EAAa,CAAC,EACzCC,GAAgB,QAASD,EAAa,CAAC,CAE3C,CAEA,OAAO,eAAeE,GAAI,SAAU,MAAO,CAAC,MAAOC,GAAS,WAAY,EAAI,CAAC",
  "names": ["backends", "backendsSortedByPriority", "registerBackend", "resolveBackend", "init_backend_impl", "__esmMin", "name", "backend", "priority", "currentBackend", "i", "backendHints", "backendNames", "errors", "backendName", "backendInfo", "isInitializing", "e", "init_backend", "__esmMin", "init_backend_impl", "version", "init_version", "__esmMin", "logLevelValue", "env", "init_env_impl", "__esmMin", "init_version", "version", "value", "env", "init_env", "__esmMin", "init_env_impl", "tensorToDataURL", "tensorToImageData", "init_tensor_conversion_impl", "__esmMin", "tensor", "options", "canvas", "pixels2DContext", "width", "height", "inputformat", "norm", "normMean", "normBias", "stride", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "j", "R", "G", "B", "A", "image", "channels", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "bufferToTensor", "tensorFromImage", "tensorFromTexture", "tensorFromGpuBuffer", "tensorFromPinnedBuffer", "init_tensor_factory_impl", "__esmMin", "init_tensor_impl", "buffer", "options", "height", "width", "norm", "normMean", "normBias", "inputformat", "outputformat", "stride", "float32Data", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "Tensor", "image", "isHTMLImageEle", "isImageDataEle", "isImageBitmap", "isString", "data", "bufferToTensorOptions", "canvas", "pixels2DContext", "tempCanvas", "resolve", "reject", "context", "newImage", "img", "texture", "download", "dispose", "dims", "gpuBuffer", "dataType", "type", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "isBigIntChecked", "checkBigInt", "init_tensor_impl_type_mapping", "__esmMin", "isBigInt64ArrayAvailable", "isBigUint64ArrayAvailable", "calculateSize", "tensorReshape", "init_tensor_utils_impl", "__esmMin", "init_tensor_impl", "dims", "size", "i", "dim", "tensor", "Tensor", "Tensor", "init_tensor_impl", "__esmMin", "init_tensor_conversion_impl", "init_tensor_factory_impl", "init_tensor_impl_type_mapping", "init_tensor_utils_impl", "arg0", "arg1", "arg2", "checkBigInt", "type", "dims", "expectedTypedArrayConstructor", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "data", "maybeDims", "typedArrayConstructor", "firstElementType", "mappedType", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "size", "calculateSize", "image", "options", "tensorFromImage", "texture", "tensorFromTexture", "gpuBuffer", "tensorFromGpuBuffer", "buffer", "tensorFromPinnedBuffer", "tensorToDataURL", "tensorToImageData", "releaseData", "tensorReshape", "Tensor", "init_tensor", "__esmMin", "init_tensor_impl", "InferenceSession", "init_inference_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_InferenceSession", "handler", "feeds", "arg1", "arg2", "fetches", "options", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "arg0", "arg3", "filePathOrUint8Array", "buffer", "byteOffset", "byteLength", "backendHints", "i", "resolveBackend", "InferenceSession", "init_inference_session", "__esmMin", "init_inference_session_impl", "init_onnx_value", "__esmMin", "noBackendErrMsg", "TrainingSession", "init_training_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_TrainingSession", "handler", "trainingOptions", "sessionOptions", "evalModel", "optimizerModel", "options", "backendHints", "i", "backend", "resolveBackend", "feeds", "arg1", "arg2", "fetches", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "trainableOnly", "array", "paramsSize", "TrainingSession", "init_training_session", "__esmMin", "init_training_session_impl", "esm_exports", "__export", "InferenceSession", "Tensor", "TrainingSession", "env", "registerBackend", "init_esm", "__esmMin", "init_backend", "init_env", "init_inference_session", "init_tensor", "init_onnx_value", "init_training_session", "fs_exports", "__export", "readFile", "init_fs", "__esmMin", "path_exports", "__export", "join", "init_path", "__esmMin", "require_ort_wasm_simd_jsep", "__commonJSMin", "exports", "module", "ortWasm", "_scriptDir", "moduleArg", "g", "aa", "ba", "a", "b", "c", "d", "e", "f", "h", "k", "l", "m", "n", "q", "r", "u", "p", "t", "ca", "da", "ea", "fa", "ha", "ia", "ja", "w", "ka", "la", "ma", "fs", "na", "oa", "pa", "qa", "noExitRuntime", "x", "ra", "y", "A", "sa", "K", "M", "N", "Q", "ta", "ua", "va", "wa", "xa", "ya", "za", "R", "Aa", "Ba", "Ca", "Da", "Ea", "Fa", "Ga", "Ha", "Ia", "Ja", "Ka", "S", "v", "La", "Ma", "Na", "Oa", "T", "Pa", "Qa", "Ta", "Ra", "Sa", "Ua", "Va", "Wa", "Xa", "Ya", "Za", "$a", "bb", "ab", "cb", "db", "eb", "gb", "fb", "hb", "ib", "jb", "kb", "lb", "B", "z", "mb", "nb", "ob", "U", "pb", "qb", "rb", "sb", "tb", "ub", "vb", "wb", "xb", "yb", "zb", "Ab", "Bb", "Cb", "Ke", "Db", "Eb", "Fb", "Gb", "Hb", "Ib", "Jb", "Kb", "Lb", "Mb", "Nb", "Ob", "Pb", "Qb", "Rb", "Sb", "Tb", "Ub", "Vb", "Wb", "Xb", "Yb", "Zb", "$b", "ac", "bc", "cc", "dc", "ec", "fc", "gc", "hc", "ic", "jc", "kc", "lc", "mc", "nc", "oc", "pc", "qc", "rc", "sc", "tc", "uc", "vc", "wc", "xc", "yc", "zc", "Ac", "Bc", "Cc", "Dc", "Ec", "Fc", "Gc", "Hc", "Ic", "Jc", "Kc", "Lc", "Mc", "Nc", "Oc", "Pc", "Qc", "Rc", "Sc", "Tc", "Uc", "Vc", "Wc", "Xc", "Yc", "Zc", "$c", "ad", "bd", "cd", "dd", "ed", "fd", "gd", "hd", "jd", "kd", "ld", "md", "nd", "od", "pd", "qd", "rd", "sd", "td", "ud", "vd", "wd", "xd", "yd", "zd", "Ad", "Bd", "Cd", "Dd", "Ed", "Fd", "Gd", "Hd", "Id", "Jd", "Kd", "Ld", "Md", "Nd", "Od", "Pd", "Qd", "Rd", "Sd", "Td", "Ud", "Vd", "Wd", "Xd", "Yd", "Zd", "$d", "ae", "be", "ce", "de", "ee", "fe", "ge", "he", "ie", "je", "ke", "le", "me", "ne", "oe", "pe", "qe", "re", "se", "te", "ue", "ve", "we", "xe", "ye", "ze", "Ae", "Be", "Ce", "De", "Ee", "Fe", "Ge", "He", "Ie", "Je", "Le", "W", "X", "Me", "dynCall_vi", "dynCall_vii", "Ne", "dynCall_iii", "Oe", "Pe", "dynCall_v", "Qe", "Re", "Se", "Te", "Ue", "Ve", "We", "Xe", "Ye", "Ze", "$e", "af", "bf", "cf", "df", "ef", "ff", "gf", "hf", "jf", "kf", "lf", "mf", "nf", "of", "pf", "qf", "rf", "sf", "tf", "uf", "vf", "wf", "xf", "yf", "zf", "Af", "Bf", "Cf", "Df", "Ef", "Ff", "Gf", "Hf", "If", "Jf", "Kf", "C", "D", "E", "F", "G", "H", "I", "J", "L", "O", "P", "Lf", "Mf", "Nf", "Of", "Pf", "Qf", "Rf", "Sf", "Tf", "Uf", "Vf", "Wf", "Xf", "Yf", "Zf", "$f", "ag", "bg", "cg", "dg", "eg", "fg", "gg", "hg", "ig", "jg", "kg", "lg", "mg", "ng", "og", "pg", "qg", "rg", "sg", "tg", "ug", "vg", "wg", "xg", "yg", "zg", "Ag", "Bg", "Cg", "Dg", "Eg", "Fg", "Gg", "Hg", "Ig", "Jg", "Kg", "Lg", "Mg", "Ng", "Og", "Pg", "Qg", "Rg", "Sg", "Tg", "Ug", "Vg", "Wg", "Xg", "Yg", "Zg", "$g", "ah", "bh", "ch", "dh", "eh", "fh", "gh", "hh", "ih", "jh", "kh", "lh", "mh", "nh", "oh", "ph", "qh", "rh", "sh", "th", "uh", "vh", "wh", "xh", "yh", "zh", "Ah", "Bh", "Ch", "Dh", "Eh", "Fh", "Gh", "Hh", "Ih", "Jh", "Kh", "Lh", "Mh", "Nh", "Y", "Z", "Oh", "Ph", "Qh", "require_worker_threads", "__commonJSMin", "require_perf_hooks", "__commonJSMin", "os_exports", "__export", "cpus", "init_os", "__esmMin", "require_ort_wasm_simd_threaded_jsep", "__commonJSMin", "exports", "module", "ortWasmThreaded", "_scriptDir", "moduleArg", "d", "l", "p", "u", "v", "aa", "z", "ba", "A", "ca", "da", "ea", "fa", "ha", "B", "ia", "a", "b", "c", "e", "f", "h", "k", "q", "m", "n", "r", "w", "y", "D", "g", "t", "ja", "ka", "la", "E", "ma", "F", "G", "H", "I", "na", "oa", "J", "pa", "fs", "qa", "ra", "sa", "ta", "K", "L", "noExitRuntime", "M", "N", "ua", "P", "Q", "va", "wa", "xa", "ya", "za", "Aa", "R", "Ba", "S", "Ca", "Da", "Ea", "T", "Fa", "Ga", "Ha", "Ia", "U", "Ja", "V", "x", "Ka", "La", "Ma", "W", "Na", "Oa", "Pa", "Qa", "X", "Sa", "Ra", "Ta", "Ua", "Va", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "jb", "kb", "lb", "mb", "nb", "ob", "pb", "qb", "rb", "sb", "tb", "ub", "vb", "wb", "xb", "Y", "yb", "zb", "Ab", "Bb", "Db", "Cb", "Eb", "Fb", "Hb", "Gb", "Ib", "Jb", "Kb", "Lb", "Nb", "Mb", "Ob", "Pb", "Qb", "Rb", "Sb", "Tb", "Vb", "Wb", "Xb", "Yb", "Zb", "$b", "Ub", "O", "ac", "bc", "cc", "Z", "dc", "ec", "fc", "gc", "hc", "ic", "jc", "kc", "lc", "mc", "nc", "oc", "pc", "qc", "rc", "sc", "vc", "tc", "uc", "wc", "xc", "yc", "zc", "require_ort_wasm_threaded_worker", "__commonJSMin", "exports", "module", "ortWasmFactory", "ortWasmFactoryThreaded", "wasm", "initialized", "initializing", "aborted", "isMultiThreadSupported", "isSimdSupported", "getWasmFileName", "initializeWebAssembly", "getInstance", "init_wasm_factory", "__esmMin", "useSimd", "useThreads", "flags", "timeout", "numThreads", "simd", "wasmPaths", "wasmPrefixOverride", "wasmFileName", "wasmPathOverride", "isTimeout", "tasks", "resolve", "reject", "factory", "config", "fileName", "scriptDirectory", "prefix", "scriptSourceCode", "module", "what", "allocWasmString", "iterateExtraOptions", "checkLastError", "init_wasm_utils", "__esmMin", "init_wasm_factory", "data", "allocs", "wasm", "getInstance", "dataLength", "dataOffset", "options", "prefix", "seen", "handler", "key", "value", "name", "message", "stack", "paramsOffset", "errorCode", "errorMessagePointer", "errorMessage", "setRunOptions", "init_run_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "options", "wasm", "getInstance", "runOptionsHandle", "allocs", "runOptions", "tagDataOffset", "allocWasmString", "checkLastError", "iterateExtraOptions", "key", "value", "keyDataOffset", "valueDataOffset", "e", "alloc", "getGraphOptimzationLevel", "getExecutionMode", "appendDefaultOptions", "setExecutionProviders", "setSessionOptions", "init_session_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "graphOptimizationLevel", "executionMode", "options", "session", "ep", "sessionOptionsHandle", "executionProviders", "allocs", "epName", "webnnOptions", "keyDataOffset", "allocWasmString", "valueDataOffset", "getInstance", "checkLastError", "numThreads", "webgpuOptions", "epNameDataOffset", "wasm", "sessionOptions", "logIdDataOffset", "logSeverityLevel", "logVerbosityLevel", "optimizedModelFilePathOffset", "name", "value", "nameOffset", "iterateExtraOptions", "key", "e", "alloc", "tensorDataTypeStringToEnum", "tensorDataTypeEnumToString", "getTensorElementSize", "tensorTypeToTypedArrayConstructor", "logLevelStringToEnum", "isGpuBufferSupportedType", "dataLocationStringToEnum", "init_wasm_common", "__esmMin", "type", "typeProto", "dateType", "logLevel", "location", "logLevelPrefix", "doLog", "configLogLevel", "debug", "configureLogger", "LOG", "LOG_DEBUG", "init_log", "__esmMin", "init_wasm_common", "level", "message", "$configLogLevel", "$debug", "logLevel", "msg", "messageLevel", "logLevelStringToEnum", "configLevel", "args", "createView", "init_tensor_view", "__esmMin", "init_wasm_common", "dataBuffer", "type", "tensorTypeToTypedArrayConstructor", "init_types", "__esmMin", "calcNormalizedBufferSize", "guid", "createNewGpuDataId", "downloadGpuData", "GpuDataManagerImpl", "createGpuDataManager", "init_gpu_data_manager", "__esmMin", "init_log", "init_types", "size", "backend", "gpuBuffer", "originalSize", "getTargetBuffer", "bufferSize", "gpuReadBuffer", "commandEncoder", "arrayBuffer", "targetBuffer", "id", "data", "srcArrayBuffer", "srcOffset", "srcLength", "gpuDataCache", "gpuBufferForUploading", "LOG_DEBUG", "sourceId", "destinationId", "sourceGpuDataCache", "destinationGpuDataCache", "buffer", "previousBuffer", "usage", "isStorage", "isUniform", "freeBuffers", "buffers", "gpuData", "cachedData", "storage", "args", "AttributeWithCacheKeyImpl", "createAttributeWithCacheKey", "init_attribute_with_cache_key", "__esmMin", "attribute", "name", "MatMulUtil", "BroadcastUtil", "ShapeUtil", "PoolConvUtil", "GemmUtil", "MIN_CLIP", "MAX_CLIP", "init_util", "__esmMin", "a", "b", "adims", "bdims", "isMatMul", "arank", "brank", "crank", "cdims", "cShapeMatMul", "i", "aLen", "bLen", "shape", "finalShape", "inputRank", "finalRank", "_ShapeUtil", "dims", "axis", "start", "end", "size", "rank", "strides", "tensorRank", "axes", "x", "perm", "v", "pad", "shape1", "shape2", "_PoolConvUtil", "isGlobalOperator", "inputDims", "kernelShape", "dilations", "pads", "dim", "isChannelLast", "autoPad", "outputDims", "filterDims", "inSize", "stride", "dilation", "kernel", "padHeadIndex", "padTailIndex", "dkernel", "padNeeded", "leftShape", "transLeft", "rightShape", "transRight", "biasShape", "M", "K", "N", "kDim", "WORKGROUP_SIZE", "getWgslMappedType", "tensorTypeToWsglStorageType", "createTensorShapeVariables", "getMaxComponents", "fillVector", "castToF32", "sumVector", "getElementAt", "createIndicesHelper", "inputVariable", "outputVariable", "internalVariable", "ShaderHelperImpl", "createShaderHelper", "getBroadcastDims", "enableShapesUniforms", "init_common", "__esmMin", "init_wasm_common", "init_util", "type", "components", "mappedType", "dims", "ShapeUtil", "size", "dataType", "value", "name", "index", "length", "tensorType", "shapeOrRank", "usage", "useUniform", "rank", "rankIdentity", "indicesType", "valueType", "storageType", "normalizeDim", "dim", "implementationUsed", "uniformPrefix", "shape", "strides", "o2iSnippet", "i", "offsetToIndicesImplementation", "offsetToIndices", "varOffset", "offsets", "indicesToOffsetImplementation", "indicesToOffset", "varIndices", "indices", "init", "indicesGet", "idx", "indicesSet", "broadcastedIndicesToOffsetImplementation", "broadcastedIndicesToOffset", "output", "implKey", "setByOffset", "offset", "getByOffset", "getByIndicesImplementation", "getImplementation", "functionParams", "dimsParams", "get", "normalizedIndices", "getByIndices", "setByIndicesImplementation", "setImplementation", "impls", "impl", "indicesAndValue", "normalizedDispatchGroup", "workgroupSize", "workgroupSizeX", "workgroupSizeY", "workgroupSizeZ", "is1DimensionDispatch", "paramList", "globalIdxDefinition", "variable", "bindingIndex", "access", "variables", "v", "additionalUniforms", "uniformSnippets", "typeTemp", "dispatchGroup", "inShape", "outShape", "inRank", "a", "_rank", "validateInputs", "getAdjustedPerm", "getOutputShape", "permFunctionBody", "createTransposeProgramInfo", "transpose", "parseTransposeAttributes", "init_transpose", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputRank", "perm", "inputShape", "ShapeUtil", "rank", "input", "output", "reverseFunc", "i", "inputTensor", "permAttr", "inputDataType", "useShapesUniforms", "enableShapesUniforms", "outputShape", "outShapeOrRank", "inShapeOrRank", "outputVariable", "inputVariable", "getShaderSource", "shaderHelper", "outputSize", "createTensorShapeVariables", "context", "attributes", "createAttributeWithCacheKey", "reduceOps", "reduceSharedOps", "reduceInitValues", "reduceOutputValues", "getInnerMostAxes", "computeOutAndReduceShapes", "expandShapeToKeepDim", "areAxesInnerMostDims", "getAxesPermutation", "createReduceSharedProgramInfo", "reduceCommon", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "init_reduce_shared", "__esmMin", "init_util", "init_common", "init_reduce", "init_transpose", "numInnerAxes", "rank", "res", "i", "shape", "axes", "outputShape", "dim", "reduceShape", "expandShape", "shapeIdx", "axis", "name", "shaderCache", "inputs", "reduceType", "outputDataType", "inputShape", "outputSize", "ShapeUtil", "reduceSize", "input", "inputVariable", "output", "outputVariable", "workgroupSize", "sharedMemorySnippet", "shaderHelper", "context", "attributes", "updatedAttributes", "createReduceAttributesFromInputs", "updatedAxes", "_dim", "normalizeAxes", "permutedAxes", "createTransposeProgramInfo", "finalOutputShape", "validateInputs", "noOp", "createReduceProgramInfo", "createReduceAttributesFromInputs", "runReduceProgram", "reduceLogSumNaive", "reduceL1Naive", "reduceL2Naive", "reduceLogSumExpNaive", "reduceMaxNaive", "reduceMeanNaive", "reduceMinNaive", "reduceProdNaive", "reduceSumNaive", "reduceSumSquareNaive", "useNaiveReduceMethod", "reduceMean", "reduceL1", "reduceL2", "reduceLogSumExp", "reduceMax", "reduceMin", "reduceProd", "reduceSum", "reduceSumSquare", "reduceLogSum", "parseReduceAttributes", "init_reduce", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "init_reduce_shared", "inputs", "input", "name", "shaderCache", "reduceOp", "axesInput", "outputDataType", "keepDims", "noopWithEmptyAxes", "outputShape", "inputShape", "axes", "ShapeUtil", "reduceOnAllAxes", "d", "i", "idxCopy", "inputVariable", "output", "outputVariable", "ops", "inputOffsetAssignment", "initinputOffsetLet", "initinputOffsetVar", "initinputOffset", "reduceOps", "k", "l", "outputSize", "shaderHelper", "attributes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "_output", "idxZero", "size", "shape", "reduceSize", "dim", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "validateInputs", "argMin", "argMax", "parseArgMinMaxAttributes", "init_argminmax", "__esmMin", "init_wasm_common", "init_attribute_with_cache_key", "init_reduce", "inputs", "context", "attributes", "argMinMaxOp", "input", "output", "axes", "idxZero", "k", "createReduceProgramInfo", "createAttributeWithCacheKey", "validateAttentionInputs", "parseAttentionAttributes", "computeInPlaceSoftmax", "computeAttentionProbs", "computeVxAttentionScore", "applyAttention", "prepare", "attention", "init_attention", "__esmMin", "init_attribute_with_cache_key", "init_types", "init_common", "inputs", "attributes", "input", "weights", "bias", "maskIndex", "past", "relativePositionBias", "batchSize", "sequenceLength", "inputHiddenSize", "qHiddenSize", "kHiddenSize", "vHiddenSize", "sz", "kvSequenceLength", "pastSequenceLength", "totalSequenceLength", "maxSequenceLength", "maskType", "createAttributeWithCacheKey", "context", "n", "d", "components", "getMaxComponents", "inputHelper", "outputVariable", "threadMaxValue", "dataType", "tensorTypeToWsglStorageType", "WG", "dComp", "elementsPerWG", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "q", "key", "_bias", "parameters", "probsShape", "alpha", "qInput", "inputVariable", "kInput", "output", "vectorizedHeadSize", "M", "N", "K", "TILE_SIZE", "dispatch", "probs", "v", "params", "outputShape", "probsHelper", "vHelper", "k", "_maskIndex", "_past", "_pastKey", "_pastValue", "validateInputs", "createBatchNormInferenceProgramInfo", "parseBatchNormAttributes", "batchNorm", "init_batch_norm", "__esmMin", "init_esm", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "checkShapeEqual", "actual", "expected", "message", "r", "v", "i", "shape", "epsilon", "spatial", "format", "yShape", "components", "getMaxComponents", "cComponents", "outputSize", "ShapeUtil", "useShapesUniforms", "enableShapesUniforms", "shapeOrRank", "x", "inputVariable", "scale", "bias", "inputMean", "inputVar", "y", "outputVariable", "calcCOffset", "cOffset", "getInferenceModeShaderSource", "helper", "createTensorShapeVariables", "createAttributeWithCacheKey", "context", "outputCount", "updatedAttributes", "env", "validateInputs", "createBiasAddProgramInfo", "biasAdd", "init_bias_add", "__esmMin", "init_util", "init_common", "inputs", "outputShape", "channels", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "bias", "residual", "output", "outputVariable", "shaderHelper", "context", "createElementwiseProgramShader", "createElementwiseProgramInfo", "abs", "acos", "acosh", "asin", "asinh", "atan", "atanh", "parseCastAttributes", "cast", "generateClipAttributesFromInputs", "clip", "ceil", "cos", "cosh", "parseAlphaAttributes", "elu", "erfImpl", "erf", "exp", "floor", "gelu", "leakyRelu", "not", "neg", "reciprocal", "relu", "sigmoid", "sin", "sinh", "sqrt", "tan", "tanh", "thresholdedRelu", "log", "init_unary_op", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "shaderHelper", "datasize", "inputDataType", "outputDataType", "funcCall", "additionalImplementation", "vecSize", "expression", "input", "inputVariable", "output", "outputVariable", "name", "cacheKey", "ShapeUtil", "inputTensors", "context", "attributes", "createAttributeWithCacheKey", "func", "inputs", "min", "MIN_CLIP", "max", "MAX_CLIP", "clipAttributes", "dataType", "tensorTypeToWsglStorageType", "a", "varType", "validateInputs", "createBiasSplitGeluProgramInfo", "biasSplitGelu", "init_bias_split_gelu", "__esmMin", "init_util", "init_common", "init_unary_op", "inputs", "outputShape", "input", "inputVariable", "bias", "output", "outputVariable", "outputSize", "ShapeUtil", "dataType", "tensorTypeToWsglStorageType", "shaderHelper", "erfImpl", "context", "createBinaryOpProgramShader", "createBinaryOpProgramInfo", "runBinaryOp", "add", "div", "equal", "mul", "pow", "sub", "greater", "less", "greaterOrEqual", "lessOrEqual", "init_binary_op", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "dimsA", "dimsB", "dimsOutput", "vectorize", "doBroadcast", "sharedDimensionDivisibleBy4", "funcCall", "typeA", "typeB", "typeOutput", "useShapesUniforms", "additionalImplementation", "expressionScalar", "expressionVector", "a", "b", "inputAShapeOrRank", "inputBShapeOrRank", "outputShapeOrRank", "output", "outputVariable", "inputVariable", "assignment", "isAOneElement", "ShapeUtil", "isBOneElement", "aLastDimDivisibleBy4", "bLastDimDivisibleBy4", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "name", "cacheKey", "outputDataType", "isBroadcast", "outputShape", "outputSize", "cacheKeyAux", "calculatedShape", "BroadcastUtil", "sharedDimension", "i", "dimA", "dimB", "enableShapesUniforms", "createTensorShapeVariables", "context", "type", "validateInputs", "calculateInputIndexImpl", "assignOutputData", "createConcatProgramInfo", "concat", "parseConcatAttributes", "init_concat", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputType", "inputDimensionality", "input", "numberOfTensors", "sizeInConcatAxisStr", "output", "codeLines", "i", "returnSnippet", "axis", "inputShape", "adjustedAxis", "outputShape", "dataNShape", "axisIndex", "outputSize", "ShapeUtil", "sizeInConcatAxis", "inputVars", "dataType", "previousSum", "inputDependencies", "inputShapeOrRanks", "enableInputShapesUniforms", "programUniforms", "enableShapesUniforms", "inputVariable", "createTensorShapeVariables", "enableOutputShapesUniforms", "outputShapeOrRank", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "getActivationSnippet", "parseInternalActivationAttributes", "init_fuse_utils", "__esmMin", "init_util", "attributes", "valueType", "activation", "clipMin", "clipMax", "MIN_CLIP", "MAX_CLIP", "typeSnippet", "biasSnippet", "init_activation_util", "__esmMin", "component", "dataType", "hasBias", "utilFunctions", "init_conv_util", "__esmMin", "strideStr", "writeDataToSubAVec4Snippet", "calculateResultSnippet", "makeMatMulPackedVec4Source", "writeDataToSubASnippet", "readDataFromSubASnippet", "makeMatMulPackedSource", "matMulReadWriteFnSource", "createMatmulProgramInfo", "init_matmul_packed_webgpu", "__esmMin", "init_util", "init_common", "init_fuse_utils", "init_activation_util", "transpose", "batchDims", "transposeA", "innerElementSize", "workPerThread", "workgroupSize", "type", "tileInner", "splitK", "splitedDimInner", "tileAOuter", "tileBOuter", "tileAWidth", "tileAHight", "rowPerThreadB", "sequentialAccessByThreads", "rowPerThreadA", "colPerThreadA", "matmulSnippet", "component", "hasBias", "applyActivation", "variables", "batchShapes", "isChannelsLast", "batchAShape", "batchBShape", "batchShape", "batchVariable", "aVariable", "bVariable", "outputVariable", "broadCastADims", "getBroadcastDims", "broadCastBDims", "dataType", "tensorTypeToWsglStorageType", "getAIndices", "aRank", "batchRank", "resStr", "i", "j", "getBIndices", "bRank", "typeSnippet", "inputs", "activationAttributes", "outputShape", "reshapedOutputShape", "aShape", "bShape", "outerDimsA", "outerDimsB", "outerDims", "enableBatchUniforms", "enableShapesUniforms", "batchShapeOrRank", "internalVariable", "batchSize", "ShapeUtil", "dimAOuter", "dimInner", "dimBOuter", "isVec4", "elementsPerThread", "dispatch", "components", "aShapeTemp", "enableAShapesUniforms", "aShapeOrRank", "bShapeTemp", "enableBShapesUniforms", "bShapeOrRank", "outputShapeTemp", "A", "inputVariable", "B", "output", "inputVariables", "programUniforms", "createTensorShapeVariables", "inputDependencies", "activationFunction", "getActivationSnippet", "declareFunctions", "biasComponents", "getShaderSource", "shaderHelper", "conv2dCommonSnippet", "createConv2DMatMulProgramInfo", "init_conv2d_mm_webgpu", "__esmMin", "init_log", "init_common", "init_fuse_utils", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "fitAOuter", "fitBOuter", "fitInner", "addBias", "attributes", "innerElementSizeX", "innerElementSizeW", "innerElementSize", "dataType", "getXSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readXSnippet", "typeSnippet", "sampleX", "sampleW", "resType", "aType", "bType", "activationFunction", "applyActivation", "getActivationSnippet", "biasSnippet", "inputs", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileAOuter", "tileBOuter", "tileInner", "elementsSize", "t", "tensorTypeToWsglStorageType", "components", "programUniforms", "x", "inputVariable", "w", "inputVariables", "createTensorShapeVariables", "declareFunctions", "bias", "output", "outputVariable", "shaderHelper", "utilFunctions", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createGroupedConvProgramInfo", "init_conv_grouped", "__esmMin", "init_util", "init_common", "init_conv", "init_fuse_utils", "inputs", "attributes", "squeezeOutputShapeFunction", "hasBias", "processBias", "xShape", "wShape", "outputChannelsPerGroup", "isChannelLast", "outputShape", "calculateOutputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "activationFunction", "applyActivation", "getActivationSnippet", "x", "inputVariable", "w", "inputVars", "getShaderSource", "shaderHelper", "calculateOutputShape", "weightTransposeAttribute", "validateInputs", "getAdjustedConvAttributes", "parseConvAttributes", "conv2d", "conv1d", "conv", "init_conv", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_conv2d_mm_webgpu", "init_matmul_packed_webgpu", "init_conv_grouped", "init_fuse_utils", "init_transpose", "inputShape", "kernelShape", "dilations", "adjustPads", "strides", "isChannelLast", "batchSize", "inputSpatialShape", "spatialRank", "outChannels", "dilatedKernelShape", "v", "i", "outputShape", "inputs", "attributes", "dataChannel", "filterInChannel", "pads", "PoolConvUtil", "newAttributes", "activationAttributes", "parseInternalActivationAttributes", "format", "autoPad", "group", "wIsConst", "createAttributeWithCacheKey", "context", "adjustedAttributes", "createGroupedConvProgramInfo", "isChannelsLast", "hasBias", "inputHeight", "inputWidth", "inputChannels", "weightHeight", "weightWidth", "outHeight", "outWidth", "sameSize", "batch", "xReshaped", "wReshaped", "matmulOutputShape", "matmulInputs", "transposedWeight", "createTransposeProgramInfo", "sharedDim", "createMatmulProgramInfo", "sequentialAccessByThreads", "convInputs", "dimAOuter", "dimBOuter", "dimInner", "createConv2DMatMulProgramInfo", "conv2dTransposeCommonSnippet", "createConv2DTransposeMatMulProgramInfo", "init_conv_backprop_mm_webgpu", "__esmMin", "init_log", "init_common", "init_fuse_utils", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "addBias", "attributes", "innerElementSize", "type", "typeSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readASnippet", "sampleA", "sampleW", "activationFunction", "applyActivation", "getActivationSnippet", "biasSnippet", "inputs", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileInner", "components", "programUniforms", "x", "inputVariable", "w", "output", "outputVariable", "inputVariables", "createTensorShapeVariables", "declareFunctions", "bias", "shaderHelper", "utilFunctions", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createConvTranspose2DOpProgramShaderSource", "createConvTranspose2DProgramInfo", "init_conv_backprop_webgpu", "__esmMin", "init_log", "init_util", "init_common", "shaderHelper", "inputs", "attributes", "outputShape", "hasBias", "is1DimensionDispatch", "isVec4", "dataType", "isChannelsLast", "rowDim", "colDim", "channelDim", "outputSize", "ShapeUtil", "workPerThread", "group", "wShape", "inputChannelsPerGroup", "outputChannelsPerGroup", "declareFunctions", "components", "w", "inputVariable", "dy", "inputVariables", "output", "outputVariable", "codeSnippet4", "codeSnippet", "squeezeOutputShapeFunction", "dispatch", "LOG_DEBUG", "tensorTypeToWsglStorageType", "computeTotalPad", "distributePadding", "calculateOutputShapeAndPads", "getAdjustedConvTransposeAttributes", "parseConvTransposeAttributes", "validateInputs", "weightTransposePerm", "convTranspose2d", "convTranspose1d", "convTranspose", "init_conv_transpose", "__esmMin", "init_attribute_with_cache_key", "init_conv_backprop_mm_webgpu", "init_conv_backprop_webgpu", "init_fuse_utils", "init_transpose", "inDim", "stride", "adj", "kernel", "dilation", "outSize", "totalPad", "autoPad", "pads", "head", "tail", "smallPad", "inputShape", "kernelShape", "dilations", "group", "strides", "isChannelLast", "outputPadding", "outputShape", "spatialRank", "updateOutputShape", "i", "batchSize", "outChannels", "j", "inSize", "attributes", "inputs", "a", "b", "isChannelsLast", "newAttributes", "cacheKey", "activationAttributes", "parseInternalActivationAttributes", "format", "wIsConst", "createAttributeWithCacheKey", "dataChannel", "filterInChannel", "featureMaps", "context", "adjustedAttributes", "hasBias", "createConvTranspose2DProgramInfo", "outHeight", "outWidth", "weightHeight", "weightWidth", "inputChannels", "dimAOuter", "dimBOuter", "dimInner", "sequentialAccessByThreads", "transposedWeight", "createTransposeProgramInfo", "convTransposeInputs", "createConv2DTransposeMatMulProgramInfo", "symbolPattern", "termPattern", "termPatternOnly", "lhsPattern", "lhsPatternOnly", "EinsumTerm", "EinsumEquation", "appendMax", "createEinsumProgramInfo", "einsum", "parseEinsumAttributes", "init_einsum", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputIndex", "symbol", "index", "value", "inputs", "equation", "lhs", "rhs", "inputTerm", "dims", "einsumTerm", "sym", "info", "dimValue", "term", "isInput", "rank", "ellipsis", "ellipsisDims", "nextDim", "indexSymbols", "i", "ellipsisDimLength", "j", "name", "enableInputShapesUniforms", "inputShapes", "dataType", "einsumEquation", "outputShape", "inputVars", "shapeOrRank", "inputVariable", "outputSize", "ShapeUtil", "enableOutputShapesUniforms", "enableShapesUniforms", "outputShapeOrRank", "output", "outputVariable", "uniformsSymbols", "getShaderSource", "shaderHelper", "idxCopy", "initProd", "initSum", "updateSum", "reduceOpsSetIndices", "reduceOpsLoopHeaders", "reduceOpsLoopFooters", "reduceOpCompute", "isReduceOpsWithoutLoop", "outputIndex", "indices", "reduceOps", "inputVar", "_var", "enableShapeUniform", "programUniformsInit", "programUniforms", "_", "createTensorShapeVariables", "acc", "inputProgramUniforms", "context", "attributes", "input", "createAttributeWithCacheKey", "validateInputs", "getAdjustedShape", "calculateOutputShape", "createExpandProgramInfo", "expand", "init_expand", "__esmMin", "init_wasm_common", "init_util", "init_common", "inputs", "inputShape", "shape", "shapeIndex", "inputShapeIndex", "shape1", "shape2", "diff", "i", "outputShape", "dataType", "components", "outputSize", "ShapeUtil", "enableInputShapeUniform", "enableShapesUniforms", "enableOutputShapeUniform", "getShaderSource", "shaderHelper", "inputShapeOrRank", "outputShapeOrRank", "input", "inputVariable", "output", "outputVariable", "assignment", "singleAssignment", "resStr", "x", "typeCast", "programUniforms", "createTensorShapeVariables", "context", "validateInputs", "createGatherProgramInfo", "parseGatherAttributes", "gather", "init_gather", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "indicesShape", "inputRank", "axis", "ShapeUtil", "outputShape", "axisDimLimit", "components", "outputSize", "enableInputShapesUniforms", "enableShapesUniforms", "inputShapeOrRank", "enableIndicesShapesUniforms", "indicesShapeOrRank", "enableOutputShapesUniforms", "outputShapeOrRank", "programUniforms", "createTensorShapeVariables", "inputDependencies", "getShaderSource", "shaderHelper", "data", "inputVariable", "indices", "output", "outputVariable", "calcDataIndices", "x", "indicesRank", "calcStr", "i", "j", "assignment", "singleAssignment", "resStr", "typeCast", "createAttributeWithCacheKey", "context", "validateInputs", "createGatherElementsProgramInfo", "parseGatherElementsAttributes", "gatherElements", "init_gather_elements", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "inputOutputDataType", "inputRank", "inputStrides", "ShapeUtil", "inputSize", "indicesShape", "indicesDataType", "indicesSize", "axis", "axisDimLimit", "outputShape", "outputSize", "input", "inputVariable", "indices", "output", "outputVariable", "getShaderSource", "shaderHelper", "i", "createAttributeWithCacheKey", "context", "validateInputs", "offsetC", "createGemmProgramInfo", "gemm", "parseGemmAttributes", "init_gemm", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "m", "n", "dims", "broadcastM", "broadcastN", "offset", "attributes", "aShape", "bShape", "M", "N", "K", "GemmUtil", "outputShape", "outputSize", "ShapeUtil", "line", "dataType", "tensorTypeToWsglStorageType", "calculateAlpha", "calculateC", "inputStorageBuffersDeclarations", "getShaderSource", "shaderHelper", "context", "createAttributeWithCacheKey", "metadata", "createInstanceNormProgramInfo", "computeMean", "createInstanceNormNHWCProgramInfo", "parseInstanceNormAttributes", "instanceNorm", "init_instance_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "xShape", "outputShape", "axis", "normCount", "ShapeUtil", "normSize", "C", "x", "inputVariable", "scale", "bias", "output", "outputVariable", "variables", "dataType", "workgroupSize", "getShaderSource", "shaderHelper", "context", "input", "n", "h", "c", "epsilon", "components", "getMaxComponents", "inputHelper", "scaleHelper", "biasHelper", "WG", "outputType", "sumCastType", "setOutputValue", "var1", "var2", "unitsOfWork", "wgSize", "getMeanShaderSource", "fillVector", "meanValues", "N", "H", "outputSize", "outputHelper", "tensorTypeToWsglStorageType", "scaleType", "scaleCastType", "channelScaleShift", "createAttributeWithCacheKey", "validateInputs", "createLayerNormProgramInfo", "parseLayerNormAttributes", "layerNorm", "init_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "outputCount", "xShape", "scale", "bias", "outputShape", "axis", "ShapeUtil", "normCount", "normSize", "scaleSize", "biasSize", "meanInvStdDevDim", "i", "components", "getMaxComponents", "dataType", "tensorTypeToWsglStorageType", "variables", "inputVariable", "outputVariable", "hasMeanDataOutput", "hasInvStdOutput", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "createAttributeWithCacheKey", "context", "validateInputs", "matMul", "init_matmul", "__esmMin", "init_util", "init_matmul_packed_webgpu", "inputs", "context", "outputShape", "BroadcastUtil", "createMatmulProgramInfo", "validateInputs", "parseMultiHeadAttentionAttributes", "weightTransposeAttribute", "addBiasTranspose", "maybeTransposeToBNSHAndAddBias", "multiHeadAttention", "init_multi_head_attentiion", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_types", "init_attention", "init_common", "init_transpose", "inputs", "attributes", "query", "key", "value", "bias", "keyPaddingMask", "relativePositionBias", "pastKey", "pastValue", "dmmhaPacking", "batchSize", "sequenceLength", "hiddenSize", "kvSequenceLength", "pastSequenceLength", "maxSequenceLength", "headSize", "qkvFormat", "maskType", "maskDims", "passPastInKv", "vHiddenSize", "totalSequenceLength", "broadcastResPosBias", "createAttributeWithCacheKey", "context", "qkv", "biasOffset", "outputShape", "outputSize", "ShapeUtil", "dataType", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "numHeads", "input", "reshapedInput", "createTransposeProgramInfo", "params", "kvBNSH", "Q", "applyAttention", "K", "V", "validateInputs", "getPadConstant", "getPadReflect", "getPadEdge", "getPadWrap", "getPadSnippet", "generatePadCode", "createPadProgramInfo", "createPadAttributesFromInputs", "pad", "parsePadAttributes", "init_pad", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "validPads", "output", "inputDims", "inputStrides", "pads", "dataType", "constantValue", "inputRank", "block", "i", "attributes", "shaderHelper", "outputDims", "ShapeUtil", "outputSize", "outputVariable", "input", "inputVariable", "padSnippet", "outputShape", "bigInt64Pads", "value", "updatePads", "axes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "mode", "validateInputs", "getAdjustedPoolAttributesAndOutputShape", "generatePoolingCode", "parsePoolCommonAttributes", "createAveragePoolProgramInfo", "parseAveragePoolAttributes", "averagePool", "globalPoolAttributes", "parseGlobalAveragePoolAttributes", "globalAveragePool", "createMaxPoolProgramInfo", "maxPool", "parseMaxPoolAttributes", "parseGlobalMaxPoolAttributes", "globalMaxPool", "init_pool", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "isGlobalOperator", "isChannelsLast", "inputShapeAsChannelFirst", "hasDilations", "kernelShape", "strides", "dilations", "pads", "PoolConvUtil", "outputShapeAsChannelFirst", "newAttributes", "outputShapeAsChannelLast", "shaderHelper", "x", "xShape", "outputShape", "op1", "op2", "start", "inputDims", "dataType", "rank", "outputSize", "ShapeUtil", "output", "outputVariable", "kw", "sw", "pwStart", "pwEnd", "dimIdxW", "codeW", "codeH", "codeHEnd", "kh", "sh", "phStart", "phEnd", "dimIdxH", "dimH", "kernelSize", "kernelStrides", "stridesRank", "padsRank", "hasPads", "sum", "cur", "padCode", "i", "name", "adjustedAttributes", "inputVariable", "countIncludePad", "attr", "createAttributeWithCacheKey", "context", "format", "storageOrder", "validateInputsContent", "createRangeProgramInfo", "range", "init_range", "__esmMin", "init_esm", "init_wasm_common", "init_common", "start", "limit", "delta", "sameStartLimit", "increasingRangeNegativeStep", "decreasingRangePositiveStep", "dataType", "numElements", "outputShape", "outputSize", "output", "outputVariable", "wgslType", "getShaderSource", "shaderHelper", "x", "context", "env", "validateScales", "updateScales", "validateInputs", "getOriginalCoordinateFromResizedCoordinate", "getNearestPixelFromOriginal", "updateRoI", "initOutputShape", "adjustOutputShape", "calculateOriginalIndicesFromOutputIndices", "calculateInputIndicesFromOutputIndices", "checkInputIndices", "bilinearInterpolation", "bicubicInterpolation", "createResizeProgramInfo", "getOpsetVersionFromCustomDataBuffer", "resize", "parseResizeAttributes", "init_resize", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "scales", "attributes", "value", "axes", "rank", "newScales", "index", "inputs", "opsetVersion", "sizes", "roi", "roiInputIndex", "scalesInputIndex", "sizesInputIndex", "coordinateTransferMode", "dType", "nearestMode", "roiTmp", "roiLocal", "v", "i", "inputShape", "outputShape", "scaleInPolicy", "adjustedOutputShape", "output", "input", "useExtrapolation", "extrapolationValue", "batchIdx", "heightIdx", "widthIdx", "channelIdx", "cubicCoeffA", "excludeOutside", "createCubicInterpolationFunction", "idx", "direction", "inputTensor", "scalesInput", "roiInput", "outputVariable", "inputVariable", "outputSize", "ShapeUtil", "noScale", "d", "dataType", "getShaderSource", "shaderHelper", "context", "customDataBuffer", "antialias", "coordinateTransformMode", "keepAspectRatioPolicy", "mode", "createAttributeWithCacheKey", "validateInputs", "createSkipLayerNormProgramInfo", "skipLayerNorm", "parseSkipLayerNormAttributes", "init_skip_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "skip", "gamma", "hiddenSize", "sequenceLength", "beta", "bias", "attributes", "outputCount", "isTraining", "inputShape", "inputSize", "ShapeUtil", "outputShape", "outputSize", "meanInvStdDevDim", "hasBetaInput", "hasBiasInput", "hasMeanOutput", "hasInvStdDevOutput", "hasInputSkipBiasSumOutput", "components", "getMaxComponents", "variables", "inputVariable", "outputVariable", "dataType", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "context", "epsilon", "createAttributeWithCacheKey", "validateInputs", "readInput", "createSliceAttributesFromInputs", "fixStartEndValues", "calculateInputIndicesImpl", "createSliceProgramInfo", "slice", "parseSliceAttributes", "init_slice", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "_", "idx", "input", "v", "starts", "ends", "axes", "createAttributeWithCacheKey", "value", "index", "inputShape", "steps", "newValue", "output", "outputShape", "getElementAt", "inputSize", "ShapeUtil", "step", "start", "i", "end", "signs", "array", "numSteps", "newEnd", "newStart", "axis", "outputTensorInfo", "outputVariable", "inputVariable", "outputSize", "uniforms", "programUniforms", "createTensorShapeVariables", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "validateInputs", "createSoftmaxProgramInfo", "softmax", "parseSoftmaxAttributes", "init_softmax", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "shape", "outputSize", "ShapeUtil", "WG", "axis", "cols", "rows", "components", "getMaxComponents", "packedCols", "maxVector", "name", "x", "inputVariable", "output", "outputVariable", "valueType", "threadMaxDecl", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "sumVector", "context", "createAttributeWithCacheKey", "validateInputs", "createSplitAttributesFromInputs", "calculateOutputIndexImpl", "writeBufferDataImpl", "createSplitProgramInfo", "split", "parseSplitAttributes", "init_split", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "splitSizes", "numOutputs", "v", "createAttributeWithCacheKey", "numberOfTensors", "outputs", "codeLines", "i", "returnSnippet", "inputShape", "inputSize", "ShapeUtil", "dataType", "rank", "axis", "adjustedAxis", "input", "inputVariable", "sizeInConcatAxis", "outputsTensorInfo", "outputShapes", "previousSum", "outputShape", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "getRepeats", "validateInputs", "getOutputShape", "createTileProgramInfo", "tile", "init_tile", "__esmMin", "init_wasm_common", "init_util", "init_common", "repeatsTensorView", "inputs", "inputShape", "repeats", "outputShape", "i", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "createWhereOpProgramShader", "createWhereOpProgramInfo", "where", "init_where", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "inputs", "dimsOutput", "isBroadcast", "typeOutput", "outputSize", "ShapeUtil", "vecSize", "output", "outputVariable", "a", "inputVariable", "b", "c", "assignment", "expression", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "expressionC", "dimsA", "dimsB", "dimsC", "outputDataType", "outputShape", "calculatedShape", "BroadcastUtil", "context", "WEBGPU_OP_RESOLVE_RULES", "init_op_resolve_rules", "__esmMin", "init_argminmax", "init_attention", "init_batch_norm", "init_bias_add", "init_bias_split_gelu", "init_binary_op", "init_concat", "init_conv", "init_conv_transpose", "init_einsum", "init_expand", "init_gather", "init_gather_elements", "init_gemm", "init_instance_norm", "init_layer_norm", "init_matmul", "init_multi_head_attentiion", "init_pad", "init_pool", "init_range", "init_reduce", "init_resize", "init_skip_layer_norm", "init_slice", "init_softmax", "init_split", "init_tile", "init_transpose", "init_unary_op", "init_where", "abs", "acos", "acosh", "add", "argMax", "parseArgMinMaxAttributes", "argMin", "asin", "asinh", "atan", "atanh", "attention", "parseAttentionAttributes", "averagePool", "parseAveragePoolAttributes", "batchNorm", "biasAdd", "biasSplitGelu", "cast", "parseCastAttributes", "ceil", "clip", "concat", "parseConcatAttributes", "conv", "parseConvAttributes", "convTranspose", "parseConvTransposeAttributes", "cos", "cosh", "div", "einsum", "parseEinsumAttributes", "elu", "parseAlphaAttributes", "equal", "erf", "exp", "expand", "floor", "gather", "parseGatherAttributes", "gatherElements", "parseGatherElementsAttributes", "gelu", "gemm", "parseGemmAttributes", "globalAveragePool", "parseGlobalAveragePoolAttributes", "globalMaxPool", "parseGlobalMaxPoolAttributes", "greater", "greaterOrEqual", "instanceNorm", "parseInstanceNormAttributes", "layerNorm", "parseLayerNormAttributes", "leakyRelu", "less", "lessOrEqual", "log", "matMul", "maxPool", "parseMaxPoolAttributes", "mul", "multiHeadAttention", "parseMultiHeadAttentionAttributes", "neg", "not", "pad", "parsePadAttributes", "pow", "range", "reciprocal", "reduceMin", "parseReduceAttributes", "reduceMean", "reduceMax", "reduceSum", "reduceProd", "reduceL1", "reduceL2", "reduceLogSum", "reduceLogSumExp", "reduceSumSquare", "relu", "resize", "parseResizeAttributes", "sigmoid", "sin", "sinh", "slice", "parseSliceAttributes", "skipLayerNorm", "parseSkipLayerNormAttributes", "split", "parseSplitAttributes", "sqrt", "softmax", "parseSoftmaxAttributes", "sub", "tan", "tanh", "thresholdedRelu", "tile", "transpose", "parseTransposeAttributes", "where", "ProgramManager", "init_program_manager", "__esmMin", "init_wasm_common", "init_log", "init_common", "backend", "key", "artifact", "buildArtifact", "inputTensorViews", "outputTensorViews", "inputs", "outputs", "dispatchGroup", "uniformBufferBinding", "device", "computePassEncoder", "entries", "input", "output", "bindGroup", "syncData", "kernelId", "kernelInfo", "kernelName", "mappedData", "startTimeU64", "endTimeU64", "startTime", "endTime", "inputShapes", "value", "i", "tensorDataTypeEnumToString", "outputShapes", "programInfo", "normalizedDispatchGroupSize", "extensions", "shaderHelper", "createShaderHelper", "userCode", "code", "shaderModule", "LOG_DEBUG", "computePipeline", "x", "y", "z", "limitPerDimension", "size", "dispatchAverage", "getProgramInputTensorInfoDependencyKey", "getProgramInfoUniqueKey", "WebGpuBackend", "init_backend_webgpu", "__esmMin", "init_log", "init_tensor_view", "init_gpu_data_manager", "init_op_resolve_rules", "init_program_manager", "inputTensors", "inputDependencies", "inputInfos", "i", "type", "rank", "dims", "programInfo", "is1DimensionDispatch", "key", "data", "env", "adapter", "requiredFeatures", "deviceDescriptor", "createGpuDataManager", "ProgramManager", "configureLogger", "ev", "computePassDescriptor", "program", "inputTensorViews", "outputIndices", "createKernelOutput", "createIntermediateOutput", "inputDatas", "gpuData", "outputs", "dispatchGroup", "programUniforms", "validatedOutputIndices", "_", "outputTensorViews", "outputDatas", "isTemporary", "isPersistent", "tensorView", "persistentData", "uniformBufferBinding", "currentOffset", "offsets", "v", "baseAlignment", "maxAlignmentOfField", "arrayBuffer", "offset", "uniformBufferData", "normalizedDispatchGroup", "artifact", "LOG_DEBUG", "gpuDataId", "src", "dst", "getTargetBuffer", "size", "ptr", "opType", "kernelId", "attribute", "nodeName", "op", "WEBGPU_OP_RESOLVE_RULES", "context", "errors", "kernel", "kernelEntry", "attributes", "useErrorScope", "e", "err", "sessionId", "index", "buffer", "sessionInputOutputMapping", "previousBuffer", "id", "bufferInfo", "gpuBuffer", "downloadGpuData", "createView", "init_exports", "__export", "init", "TensorViewImpl", "ComputeContextImpl", "init_init", "__esmMin", "init_wasm_common", "init_backend_webgpu", "init_log", "init_util", "_TensorViewImpl", "module", "dataType", "data", "dims", "elementCount", "ShapeUtil", "newDims", "backend", "contextDataOffset", "heapU32", "dataIndex", "inputCount", "inputs", "i", "dim", "d", "program", "inputsOutputsMapping", "mappedInputs", "outputIndices", "createKernelOutput", "index", "createTemporaryOutput", "elementSize", "getTensorElementSize", "bufferSize", "stack", "offset", "e", "env", "WebGpuBackend", "size", "ptr", "src", "dst", "isSourceGpu", "LOG_DEBUG", "gpuDataId", "dataOffset", "name", "kernel", "attribute", "sessionHandle", "errors", "context", "ortEnvInitialized", "getSessionInputOutputCount", "initOrt", "initRuntime", "activeSessions", "isOrtEnvInitialized", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "prepareInputOutputTensor", "run", "endProfiling", "extractTransferableBuffers", "init_wasm_core_impl", "__esmMin", "init_run_options", "init_session_options", "init_wasm_common", "init_wasm_factory", "init_wasm_utils", "sessionHandle", "wasm", "getInstance", "stack", "dataOffset", "checkLastError", "numThreads", "loggingLevel", "env", "logLevelStringToEnum", "initJsep", "model", "modelDataOffset", "modelData", "options", "sessionOptionsHandle", "ioBindingHandle", "allocs", "inputNamesUTF8Encoded", "outputNamesUTF8Encoded", "setSessionOptions", "inputCount", "outputCount", "inputNames", "outputNames", "outputPreferredLocations", "i", "name", "nameString", "location", "bindingState", "l", "dataLocationStringToEnum", "e", "buf", "alloc", "sessionId", "session", "ioBindingState", "tensor", "tensorHandles", "index", "dataType", "dims", "rawData", "dataByteLength", "gpuBuffer", "elementSizeInBytes", "getTensorElementSize", "tensorDataTypeStringToEnum", "a", "b", "data", "dataIndex", "allocWasmString", "dimsOffset", "dimIndex", "d", "inputIndices", "inputTensors", "outputIndices", "outputTensors", "runOptionsHandle", "runOptionsAllocs", "inputTensorHandles", "outputTensorHandles", "inputOutputAllocs", "beforeRunStack", "inputValuesOffset", "inputNamesOffset", "outputValuesOffset", "outputNamesOffset", "setRunOptions", "inputValuesIndex", "inputNamesIndex", "outputValuesIndex", "outputNamesIndex", "handle", "outputPreferredLocationsEncoded", "errorCode", "output", "beforeGetTensorDataStack", "tensorDataOffset", "keepOutputTensor", "type", "tensorDataIndex", "dimsLength", "size", "tensorDataTypeEnumToString", "preferredLocation", "stringData", "offset", "maxBytesToRead", "elementSize", "isGpuBufferSupportedType", "typedArrayConstructor", "tensorTypeToTypedArrayConstructor", "v", "p", "profileFileName", "tensors", "buffers", "require_main", "__commonJSMin", "exports", "module", "isProxy", "proxyWorker", "initializing", "initialized", "aborted", "initWasmCallbacks", "initOrtCallbacks", "createSessionAllocateCallbacks", "createSessionFinalizeCallbacks", "createSessionCallbacks", "releaseSessionCallbacks", "runCallbacks", "endProfilingCallbacks", "isOrtEnvInitializedCallbacks", "ensureWorker", "onProxyWorkerMessage", "scriptSrc", "initializeWebAssemblyInstance", "initializeRuntime", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "run", "endProfiling", "isOrtEnvInitialized", "init_proxy_wrapper", "__esmMin", "init_esm", "init_wasm_core_impl", "init_wasm_factory", "env", "ev", "resolve", "reject", "workerUrl", "message", "initializeWebAssembly", "initRuntime", "model", "modeldata", "options", "sessionId", "inputIndices", "inputs", "outputIndices", "outputs", "t", "serializableInputs", "extractTransferableBuffers", "runtimeInitializationPromise", "encodeTensorMetadata", "decodeTensorMetadata", "OnnxruntimeWebAssemblySessionHandler", "init_session_handler_inference", "__esmMin", "init_esm", "init_proxy_wrapper", "init_wasm_common", "tensor", "getName", "Tensor", "dataType", "isGpuBufferSupportedType", "gpuBuffer", "download", "dispose", "path", "response", "arrayBuffer", "createSessionAllocate", "pathOrBuffer", "options", "isOrtEnvInitialized", "initializeRuntime", "env", "model", "createSession", "modelData", "createSessionFinalize", "releaseSession", "feeds", "fetches", "inputArray", "inputIndices", "kvp", "name", "index", "outputArray", "outputIndices", "inputs", "t", "i", "outputs", "results", "run", "resultMap", "endProfiling", "initializeFlags", "OnnxruntimeWebAssemblyBackend", "init_backend_wasm", "__esmMin", "init_esm", "init_proxy_wrapper", "init_session_handler_inference", "env", "numCpuLogicalCores", "initializeWebAssemblyInstance", "pathOrBuffer", "options", "handler", "OnnxruntimeWebAssemblySessionHandler", "backend_wasm_inference_exports", "__export", "wasmBackend", "init_backend_wasm_inference", "__esmMin", "init_backend_wasm", "OnnxruntimeWebAssemblyBackend", "init_esm", "version", "lib_default", "esm_exports", "wasmBackend", "registerBackend", "env", "version"]
}
